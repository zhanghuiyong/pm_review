@article{2012.08113v1,
 abstract = {Precision medicine has the potential to revolutionize healthcare, but much of
the data for patients is locked away in unstructured free-text, limiting
research and delivery of effective personalized treatments. Generating large
annotated datasets for information extraction from clinical notes is often
challenging and expensive due to the high level of expertise needed for high
quality annotations. To enable natural language processing for small dataset
sizes, we develop a novel enriched hierarchical annotation scheme and
algorithm, Supervised Line Attention (SLA), and apply this algorithm to
predicting categorical tumor attributes from kidney and colon cancer pathology
reports from the University of California San Francisco (UCSF). Whereas
previous work only annotated document level labels, we in addition ask the
annotators to enrich the traditional label by asking them to also highlight the
relevant line or potentially lines for the final label, which leads to a 20%
increase of annotation time required per document. With the enriched
annotations, we develop a simple and interpretable machine learning algorithm
that first predicts the relevant lines in the document and then predicts the
tumor attribute. Our results show across the small dataset sizes of 32, 64,
128, and 186 labeled documents per cancer, SLA only requires half the number of
labeled documents as state-of-the-art methods to achieve similar or better
micro-f1 and macro-f1 scores for the vast majority of comparisons that we made.
Accounting for the increased annotation time, this leads to a 40% reduction in
total annotation time over the state of the art.},
 author = {Nick Altieri and Briton Park and Mara Olson and John DeNero and Anobel Odisho and Bin Yu},
 comment = {},
 doi = {},
 eprint = {2012.08113v1},
 journal = {arXiv preprint},
 title = {Enriched Annotations for Tumor Attribute Classification from Pathology Reports with Limited Labeled Data},
 url = {http://arxiv.org/abs/2012.08113v1},
 year = {2020}
}

@article{2110.03063v1,
 abstract = {High-throughput technologies such as next generation sequencing allow
biologists to observe cell function with unprecedented resolution, but the
resulting datasets are too large and complicated for humans to understand
without the aid of advanced statistical methods. Machine learning (ML)
algorithms, which are designed to automatically find patterns in data, are well
suited to this task. Yet these models are often so complex as to be opaque,
leaving researchers with few clues about underlying mechanisms. Interpretable
machine learning (iML) is a burgeoning subdiscipline of computational
statistics devoted to making the predictions of ML models more intelligible to
end users. This article is a gentle and critical introduction to iML, with an
emphasis on genomic applications. I define relevant concepts, motivate leading
methodologies, and provide a simple typology of existing approaches. I survey
recent examples of iML in genomics, demonstrating how such techniques are
increasingly integrated into research workflows. I argue that iML solutions are
required to realize the promise of precision medicine. However, several open
challenges remain. I examine the limitations of current state of the art tools
and propose a number of directions for future research. While the horizon for
iML in genomics is wide and bright, continued progress requires close
collaboration across disciplines.},
 author = {David S. Watson},
 comment = {},
 doi = {},
 eprint = {2110.03063v1},
 journal = {arXiv preprint},
 title = {Interpretable Machine Learning for Genomics},
 url = {http://arxiv.org/abs/2110.03063v1},
 year = {2021}
}

@article{2110.07069v1,
 abstract = {Single-cell RNA sequencing (scRNA-seq) has the potential to provide powerful,
high-resolution signatures to inform disease prognosis and precision medicine.
This paper takes an important first step towards this goal by developing an
interpretable machine learning algorithm, CloudPred, to predict individuals'
disease phenotypes from their scRNA-seq data. Predicting phenotype from
scRNA-seq is challenging for standard machine learning methods -- the number of
cells measured can vary by orders of magnitude across individuals and the cell
populations are also highly heterogeneous. Typical analysis creates pseudo-bulk
samples which are biased toward prior annotations and also lose the single cell
resolution. CloudPred addresses these challenges via a novel end-to-end
differentiable learning algorithm which is coupled with a biologically informed
mixture of cell types model. CloudPred automatically infers the cell
subpopulation that are salient for the phenotype without prior annotations. We
developed a systematic simulation platform to evaluate the performance of
CloudPred and several alternative methods we propose, and find that CloudPred
outperforms the alternative methods across several settings. We further
validated CloudPred on a real scRNA-seq dataset of 142 lupus patients and
controls. CloudPred achieves AUROC of 0.98 while identifying a specific
subpopulation of CD4 T cells whose presence is highly indicative of lupus.
CloudPred is a powerful new framework to predict clinical phenotypes from
scRNA-seq data and to identify relevant cells.},
 author = {Bryan He and Matthew Thomson and Meena Subramaniam and Richard Perez and Chun Jimmie Ye and James Zou},
 comment = {Preprint of an article published in Pacific Symposium on Biocomputing
  \copyright\ 2021 World Scientific Publishing Co., Singapore,
  http://psb.stanford.edu/},
 doi = {},
 eprint = {2110.07069v1},
 journal = {arXiv preprint},
 title = {CloudPred: Predicting Patient Phenotypes From Single-cell RNA-seq},
 url = {http://arxiv.org/abs/2110.07069v1},
 year = {2021}
}

@article{2212.13261v3,
 abstract = {Artificial intelligence (AI) systems utilizing deep neural networks (DNNs)
and machine learning (ML) algorithms are widely used for solving important
problems in bioinformatics, biomedical informatics, and precision medicine.
However, complex DNNs or ML models, which are often perceived as opaque and
black-box, can make it difficult to understand the reasoning behind their
decisions. This lack of transparency can be a challenge for both end-users and
decision-makers, as well as AI developers. Additionally, in sensitive areas
like healthcare, explainability and accountability are not only desirable but
also legally required for AI systems that can have a significant impact on
human lives. Fairness is another growing concern, as algorithmic decisions
should not show bias or discrimination towards certain groups or individuals
based on sensitive attributes. Explainable artificial intelligence (XAI) aims
to overcome the opaqueness of black-box models and provide transparency in how
AI systems make decisions. Interpretable ML models can explain how they make
predictions and the factors that influence their outcomes. However, most
state-of-the-art interpretable ML methods are domain-agnostic and evolved from
fields like computer vision, automated reasoning, or statistics, making direct
application to bioinformatics problems challenging without customization and
domain-specific adaptation. In this paper, we discuss the importance of
explainability in the context of bioinformatics, provide an overview of
model-specific and model-agnostic interpretable ML methods and tools, and
outline their potential caveats and drawbacks. Besides, we discuss how to
customize existing interpretable ML methods for bioinformatics problems.
Nevertheless, we demonstrate how XAI methods can improve transparency through
case studies in bioimaging, cancer genomics, and text mining.},
 author = {Md. Rezaul Karim and Tanhim Islam and Oya Beyan and Christoph Lange and Michael Cochez and Dietrich Rebholz-Schuhmann and Stefan Decker},
 comment = {},
 doi = {},
 eprint = {2212.13261v3},
 journal = {arXiv preprint},
 title = {Explainable AI for Bioinformatics: Methods, Tools, and Applications},
 url = {http://arxiv.org/abs/2212.13261v3},
 year = {2022}
}

@article{2301.00188v1,
 abstract = {Reinforcement learning (RL) is one of the most important branches of AI. Due
to its capacity for self-adaption and decision-making in dynamic environments,
reinforcement learning has been widely applied in multiple areas, such as
healthcare, data markets, autonomous driving, and robotics. However, some of
these applications and systems have been shown to be vulnerable to security or
privacy attacks, resulting in unreliable or unstable services. A large number
of studies have focused on these security and privacy problems in reinforcement
learning. However, few surveys have provided a systematic review and comparison
of existing problems and state-of-the-art solutions to keep up with the pace of
emerging threats. Accordingly, we herein present such a comprehensive review to
explain and summarize the challenges associated with security and privacy in
reinforcement learning from a new perspective, namely that of the Markov
Decision Process (MDP). In this survey, we first introduce the key concepts
related to this area. Next, we cover the security and privacy issues linked to
the state, action, environment, and reward function of the MDP process,
respectively. We further highlight the special characteristics of security and
privacy methodologies related to reinforcement learning. Finally, we discuss
the possible future research directions within this area.},
 author = {Yunjiao Lei and Dayong Ye and Sheng Shen and Yulei Sui and Tianqing Zhu and Wanlei Zhou},
 comment = {},
 doi = {},
 eprint = {2301.00188v1},
 journal = {arXiv preprint},
 title = {New Challenges in Reinforcement Learning: A Survey of Security and Privacy},
 url = {http://arxiv.org/abs/2301.00188v1},
 year = {2022}
}

@article{2301.10009v1,
 abstract = {The adoption of artificial intelligence (AI) in healthcare is growing
rapidly. Remote patient monitoring (RPM) is one of the common healthcare
applications that assist doctors to monitor patients with chronic or acute
illness at remote locations, elderly people in-home care, and even hospitalized
patients. The reliability of manual patient monitoring systems depends on staff
time management which is dependent on their workload. Conventional patient
monitoring involves invasive approaches which require skin contact to monitor
health status. This study aims to do a comprehensive review of RPM systems
including adopted advanced technologies, AI impact on RPM, challenges and
trends in AI-enabled RPM. This review explores the benefits and challenges of
patient-centric RPM architectures enabled with Internet of Things wearable
devices and sensors using the cloud, fog, edge, and blockchain technologies.
The role of AI in RPM ranges from physical activity classification to chronic
disease monitoring and vital signs monitoring in emergency settings. This
review results show that AI-enabled RPM architectures have transformed
healthcare monitoring applications because of their ability to detect early
deterioration in patients' health, personalize individual patient health
parameter monitoring using federated learning, and learn human behavior
patterns using techniques such as reinforcement learning. This review discusses
the challenges and trends to adopt AI to RPM systems and implementation issues.
The future directions of AI in RPM applications are analyzed based on the
challenges and trends},
 author = {Thanveer Shaik and Xiaohui Tao and Niall Higgins and Lin Li and Raj Gururajan and Xujuan Zhou and U. Rajendra Acharya},
 comment = {},
 doi = {10.1002/widm.1485},
 eprint = {2301.10009v1},
 journal = {arXiv preprint},
 title = {Remote patient monitoring using artificial intelligence: Current state, applications, and challenges},
 url = {http://arxiv.org/abs/2301.10009v1},
 year = {2023}
}

@article{2301.12729v1,
 abstract = {Virtual Mental Health Assistants (VMHAs) have become a prevalent method for
receiving mental health counseling in the digital healthcare space. An
assistive counseling conversation commences with natural open-ended topics to
familiarize the client with the environment and later converges into more
fine-grained domain-specific topics. Unlike other conversational systems, which
are categorized as open-domain or task-oriented systems, VMHAs possess a hybrid
conversational flow. These counseling bots need to comprehend various aspects
of the conversation, such as dialogue-acts, intents, etc., to engage the client
in an effective conversation. Although the surge in digital health research
highlights applications of many general-purpose response generation systems,
they are barely suitable in the mental health domain -- the prime reason is the
lack of understanding in mental health counseling. Moreover, in general,
dialogue-act guided response generators are either limited to a template-based
paradigm or lack appropriate semantics. To this end, we propose READER -- a
REsponse-Act guided reinforced Dialogue genERation model for the mental health
counseling conversations. READER is built on transformer to jointly predict a
potential dialogue-act d(t+1) for the next utterance (aka response-act) and to
generate an appropriate response u(t+1). Through the
transformer-reinforcement-learning (TRL) with Proximal Policy Optimization
(PPO), we guide the response generator to abide by d(t+1) and ensure the
semantic richness of the responses via BERTScore in our reward computation. We
evaluate READER on HOPE, a benchmark counseling conversation dataset and
observe that it outperforms several baselines across several evaluation metrics
-- METEOR, ROUGE, and BERTScore. We also furnish extensive qualitative and
quantitative analyses on results, including error analysis, human evaluation,
etc.},
 author = {Aseem Srivastava and Ishan Pandey and Md. Shad Akhtar and Tanmoy Chakraborty},
 comment = {This paper has been accepted by The Web Conference (WWW) 2023},
 doi = {},
 eprint = {2301.12729v1},
 journal = {arXiv preprint},
 title = {Response-act Guided Reinforced Dialogue Generation for Mental Health Counseling},
 url = {http://arxiv.org/abs/2301.12729v1},
 year = {2023}
}

@article{2302.00662v2,
 abstract = {Offline reinforcement learning is important in domains such as medicine,
economics, and e-commerce where online experimentation is costly, dangerous or
unethical, and where the true model is unknown. However, most methods assume
all covariates used in the behavior policy's action decisions are observed.
Though this assumption, sequential ignorability/unconfoundedness, likely does
not hold in observational data, most of the data that accounts for selection
into treatment may be observed, motivating sensitivity analysis. We study
robust policy evaluation and policy optimization in the presence of
sequentially-exogenous unobserved confounders under a sensitivity model. We
propose and analyze orthogonalized robust fitted-Q-iteration that uses
closed-form solutions of the robust Bellman operator to derive a loss
minimization problem for the robust Q function, and adds a bias-correction to
quantile estimation. Our algorithm enjoys the computational ease of
fitted-Q-iteration and statistical improvements (reduced dependence on quantile
estimation error) from orthogonalization. We provide sample complexity bounds,
insights, and show effectiveness both in simulations and on real-world
longitudinal healthcare data of treating sepsis. In particular, our model of
sequential unobserved confounders yields an online Markov decision process,
rather than partially observed Markov decision process: we illustrate how this
can enable warm-starting optimistic reinforcement learning algorithms with
valid robust bounds from observational data.},
 author = {David Bruns-Smith and Angela Zhou},
 comment = {updated with new warmstarting, complex healthcare data case study},
 doi = {},
 eprint = {2302.00662v2},
 journal = {arXiv preprint},
 title = {Robust Fitted-Q-Evaluation and Iteration under Sequentially Exogenous Unobserved Confounders},
 url = {http://arxiv.org/abs/2302.00662v2},
 year = {2023}
}

@article{2302.02898v1,
 abstract = {In recent years, mobile robot navigation approaches have become increasingly
important due to various application areas ranging from healthcare to warehouse
logistics. In particular, Deep Reinforcement Learning approaches have gained
popularity for robot navigation but are not easily accessible to non-experts
and complex to develop. In recent years, efforts have been made to make these
sophisticated approaches accessible to a wider audience. In this paper, we
present Arena-Web, a web-based development and evaluation suite for developing,
training, and testing DRL-based navigation planners for various robotic
platforms and scenarios. The interface is designed to be intuitive and engaging
to appeal to non-experts and make the technology accessible to a wider
audience. With Arena-Web and its interface, training and developing Deep
Reinforcement Learning agents is simplified and made easy without a single line
of code. The web-app is free to use and openly available under the link stated
in the supplementary materials.},
 author = {Linh Kästner and Reyk Carstens and Christopher Liebig and Volodymyr Shcherbyna and Lena Nahrworld and Subhin Lee and Jens Lambrecht},
 comment = {10 pages, 9 figures},
 doi = {},
 eprint = {2302.02898v1},
 journal = {arXiv preprint},
 title = {Arena-Web -- A Web-based Development and Benchmarking Platform for Autonomous Navigation Approaches},
 url = {http://arxiv.org/abs/2302.02898v1},
 year = {2023}
}

@article{2302.04052v1,
 abstract = {Irregularly-sampled time series (ITS) are native to high-impact domains like
healthcare, where measurements are collected over time at uneven intervals.
However, for many classification problems, only small portions of long time
series are often relevant to the class label. In this case, existing ITS models
often fail to classify long series since they rely on careful imputation, which
easily over- or under-samples the relevant regions. Using this insight, we then
propose CAT, a model that classifies multivariate ITS by explicitly seeking
highly-relevant portions of an input series' timeline. CAT achieves this by
integrating three components: (1) A Moment Network learns to seek relevant
moments in an ITS's continuous timeline using reinforcement learning. (2) A
Receptor Network models the temporal dynamics of both observations and their
timing localized around predicted moments. (3) A recurrent Transition Model
models the sequence of transitions between these moments, cultivating a
representation with which the series is classified. Using synthetic and real
data, we find that CAT outperforms ten state-of-the-art methods by finding
short signals in long irregular time series.},
 author = {Thomas Hartvigsen and Jidapa Thadajarassiri and Xiangnan Kong and Elke Rundensteiner},
 comment = {},
 doi = {},
 eprint = {2302.04052v1},
 journal = {arXiv preprint},
 title = {Finding Short Signals in Long Irregular Time Series with Continuous-Time Attention Policy Networks},
 url = {http://arxiv.org/abs/2302.04052v1},
 year = {2023}
}

@article{2302.09212v1,
 abstract = {Reinforcement learning (RL) has been extensively researched for enhancing
human-environment interactions in various human-centric tasks, including
e-learning and healthcare. Since deploying and evaluating policies online are
high-stakes in such tasks, off-policy evaluation (OPE) is crucial for inducing
effective policies. In human-centric environments, however, OPE is challenging
because the underlying state is often unobservable, while only aggregate
rewards can be observed (students' test scores or whether a patient is released
from the hospital eventually). In this work, we propose a human-centric OPE
(HOPE) to handle partial observability and aggregated rewards in such
environments. Specifically, we reconstruct immediate rewards from the
aggregated rewards considering partial observability to estimate expected total
returns. We provide a theoretical bound for the proposed method, and we have
conducted extensive experiments in real-world human-centric tasks, including
sepsis treatments and an intelligent tutoring system. Our approach reliably
predicts the returns of different policies and outperforms state-of-the-art
benchmarks using both standard validation methods and human-centric
significance tests.},
 author = {Ge Gao and Song Ju and Markel Sanz Ausin and Min Chi},
 comment = {Accepted to AAMAS23},
 doi = {},
 eprint = {2302.09212v1},
 journal = {arXiv preprint},
 title = {HOPE: Human-Centric Off-Policy Evaluation for E-Learning and Healthcare},
 url = {http://arxiv.org/abs/2302.09212v1},
 year = {2023}
}

@article{2303.04129v1,
 abstract = {Foundation models pretrained on diverse data at scale have demonstrated
extraordinary capabilities in a wide range of vision and language tasks. When
such models are deployed in real world environments, they inevitably interface
with other entities and agents. For example, language models are often used to
interact with human beings through dialogue, and visual perception models are
used to autonomously navigate neighborhood streets. In response to these
developments, new paradigms are emerging for training foundation models to
interact with other agents and perform long-term reasoning. These paradigms
leverage the existence of ever-larger datasets curated for multimodal,
multitask, and generalist interaction. Research at the intersection of
foundation models and decision making holds tremendous promise for creating
powerful new systems that can interact effectively across a diverse range of
applications such as dialogue, autonomous driving, healthcare, education, and
robotics. In this manuscript, we examine the scope of foundation models for
decision making, and provide conceptual tools and technical background for
understanding the problem space and exploring new research directions. We
review recent approaches that ground foundation models in practical decision
making applications through a variety of methods such as prompting, conditional
generative modeling, planning, optimal control, and reinforcement learning, and
discuss common challenges and open problems in the field.},
 author = {Sherry Yang and Ofir Nachum and Yilun Du and Jason Wei and Pieter Abbeel and Dale Schuurmans},
 comment = {},
 doi = {},
 eprint = {2303.04129v1},
 journal = {arXiv preprint},
 title = {Foundation Models for Decision Making: Problems, Methods, and Opportunities},
 url = {http://arxiv.org/abs/2303.04129v1},
 year = {2023}
}

@article{2303.08731v1,
 abstract = {From out-competing grandmasters in chess to informing high-stakes healthcare
decisions, emerging methods from artificial intelligence are increasingly
capable of making complex and strategic decisions in diverse, high-dimensional,
and uncertain situations. But can these methods help us devise robust
strategies for managing environmental systems under great uncertainty? Here we
explore how reinforcement learning, a subfield of artificial intelligence,
approaches decision problems through a lens similar to adaptive environmental
management: learning through experience to gradually improve decisions with
updated knowledge. We review where reinforcement learning (RL) holds promise
for improving evidence-informed adaptive management decisions even when
classical optimization methods are intractable. For example, model-free deep RL
might help identify quantitative decision strategies even when models are
nonidentifiable. Finally, we discuss technical and social issues that arise
when applying reinforcement learning to adaptive management problems in the
environmental domain. Our synthesis suggests that environmental management and
computer science can learn from one another about the practices, promises, and
perils of experience-based decision-making.},
 author = {Melissa Chapman and Lily Xu and Marcus Lapeyrolerie and Carl Boettiger},
 comment = {In press at Philosophical Transactions of the Royal Society B},
 doi = {10.1098/rstb.2022.0195},
 eprint = {2303.08731v1},
 journal = {arXiv preprint},
 title = {Bridging adaptive management and reinforcement learning for more robust decisions},
 url = {http://arxiv.org/abs/2303.08731v1},
 year = {2023}
}

@article{2303.11191v1,
 abstract = {With the fast improvement of machine learning, reinforcement learning (RL)
has been used to automate human tasks in different areas. However, training
such agents is difficult and restricted to expert users. Moreover, it is mostly
limited to simulation environments due to the high cost and safety concerns of
interactions in the real world. Demonstration Learning is a paradigm in which
an agent learns to perform a task by imitating the behavior of an expert shown
in demonstrations. It is a relatively recent area in machine learning, but it
is gaining significant traction due to having tremendous potential for learning
complex behaviors from demonstrations. Learning from demonstration accelerates
the learning process by improving sample efficiency, while also reducing the
effort of the programmer. Due to learning without interacting with the
environment, demonstration learning would allow the automation of a wide range
of real world applications such as robotics and healthcare. This paper provides
a survey of demonstration learning, where we formally introduce the
demonstration problem along with its main challenges and provide a
comprehensive overview of the process of learning from demonstrations from the
creation of the demonstration data set, to learning methods from
demonstrations, and optimization by combining demonstration learning with
different machine learning methods. We also review the existing benchmarks and
identify their strengths and limitations. Additionally, we discuss the
advantages and disadvantages of the paradigm as well as its main applications.
Lastly, we discuss our perspective on open problems and research directions for
this rapidly growing field.},
 author = {André Correia and Luís A. Alexandre},
 comment = {35 pages, 9 figures},
 doi = {},
 eprint = {2303.11191v1},
 journal = {arXiv preprint},
 title = {A Survey of Demonstration Learning},
 url = {http://arxiv.org/abs/2303.11191v1},
 year = {2023}
}

@article{2303.16914v1,
 abstract = {In the field of functional genomics, the analysis of gene expression profiles
through Machine and Deep Learning is increasingly providing meaningful insight
into a number of diseases. The paper proposes a novel algorithm to perform
Feature Selection on genomic-scale data, which exploits the reconstruction
capabilities of autoencoders and an ad-hoc defined Explainable Artificial
Intelligence-based score in order to select the most informative genes for
diagnosis, prognosis, and precision medicine. Results of the application on a
Chronic Lymphocytic Leukemia dataset evidence the effectiveness of the
algorithm, by identifying and suggesting a set of meaningful genes for further
medical investigation.},
 author = {Carlo Adornetto and Gianluigi Greco},
 comment = {8 pages, 5 figures, Best Doctoral Consortium Paper AIxIA2022 (Udine,
  Italy)},
 doi = {},
 eprint = {2303.16914v1},
 journal = {arXiv preprint},
 title = {A New Deep Learning and XAI-Based Algorithm for Features Selection in Genomics},
 url = {http://arxiv.org/abs/2303.16914v1},
 year = {2023}
}

@article{2304.00006v1,
 abstract = {The challenges of using inadequate online recruitment systems can be
addressed with machine learning and software engineering techniques.
Bi-directional personalization reinforcement learning-based architecture with
active learning can get recruiters to recommend qualified applicants and also
enable applicants to receive personalized job recommendations. This paper
focuses on how machine learning techniques can enhance the recruitment process
in the travel nursing industry by helping speed up data acquisition using a
multi-model data service and then providing personalized recommendations using
bi-directional reinforcement learning with active learning. This need was
especially evident when trying to respond to the overwhelming needs of
healthcare facilities during the COVID-19 pandemic. The need for traveling
nurses and other healthcare professionals was more evident during the lockdown
period. A data service was architected for job feed processing using an
orchestration of natural language processing (NLP) models that synthesize
job-related data into a database efficiently and accurately. The multi-model
data service provided the data necessary to develop a bi-directional
personalization system using reinforcement learning with active learning that
could recommend travel nurses and healthcare professionals to recruiters and
provide job recommendations to applicants using an internally developed smart
match score as a basis. The bi-directional personalization reinforcement
learning-based architecture with active learning combines two personalization
systems - one that runs forward to recommend qualified candidates for jobs and
another that runs backward and recommends jobs for applicants.},
 author = {Ezana N. Beyenne},
 comment = {Masters thesis},
 doi = {},
 eprint = {2304.00006v1},
 journal = {arXiv preprint},
 title = {Bi-directional personalization reinforcement learning-based architecture with active learning using a multi-model data service for the travel nursing industry},
 url = {http://arxiv.org/abs/2304.00006v1},
 year = {2023}
}

@article{2304.00026v1,
 abstract = {This paper presents a review of the field of reinforcement learning (RL),
with a focus on providing a comprehensive overview of the key concepts,
techniques, and algorithms for beginners. RL has a unique setting, jargon, and
mathematics that can be intimidating for those new to the field or artificial
intelligence more broadly. While many papers review RL in the context of
specific applications, such as games, healthcare, finance, or robotics, these
papers can be difficult for beginners to follow due to the inclusion of
non-RL-related work and the use of algorithms customized to those specific
applications. To address these challenges, this paper provides a clear and
concise overview of the fundamental principles of RL and covers the different
types of RL algorithms. For each algorithm/method, we outline the main
motivation behind its development, its inner workings, and its limitations. The
presentation of the paper is aligned with the historical progress of the field,
from the early 1980s Q-learning algorithm to the current state-of-the-art
algorithms such as TD3, PPO, and offline RL. Overall, this paper aims to serve
as a valuable resource for beginners looking to construct a solid understanding
of the fundamentals of RL and be aware of the historical progress of the field.
It is intended to be a go-to reference for those interested in learning about
RL without being distracted by the details of specific applications.},
 author = {Mohamed-Amine Chadi and Hajar Mousannif},
 comment = {},
 doi = {},
 eprint = {2304.00026v1},
 journal = {arXiv preprint},
 title = {Understanding Reinforcement Learning Algorithms: The Progress from Basic Q-learning to Proximal Policy Optimization},
 url = {http://arxiv.org/abs/2304.00026v1},
 year = {2023}
}

@article{2304.03365v3,
 abstract = {Model-based reinforcement learning (MBRL) provides a way to learn a
transition model of the environment, which can then be used to plan
personalized policies for different patient cohorts and to understand the
dynamics involved in the decision-making process. However, standard MBRL
algorithms are either sensitive to changes in the reward function or achieve
suboptimal performance on the task when the transition model is restricted.
Motivated by the need to use simple and interpretable models in critical
domains such as healthcare, we propose a novel robust decision-focused (RDF)
algorithm that learns a transition model that achieves high returns while being
robust to changes in the reward function. We demonstrate our RDF algorithm can
be used with several model classes and planning algorithms. We also provide
theoretical and empirical evidence, on a variety of simulators and real patient
data, that RDF can learn simple yet effective models that can be used to plan
personalized policies.},
 author = {Abhishek Sharma and Sonali Parbhoo and Omer Gottesman and Finale Doshi-Velez},
 comment = {Machine Learning for Healthcare (MLHC) 2024},
 doi = {},
 eprint = {2304.03365v3},
 journal = {arXiv preprint},
 title = {Decision-Focused Model-based Reinforcement Learning for Reward Transfer},
 url = {http://arxiv.org/abs/2304.03365v3},
 year = {2023}
}

@article{2305.01738v1,
 abstract = {Many reinforcement learning (RL) applications have combinatorial action
spaces, where each action is a composition of sub-actions. A standard RL
approach ignores this inherent factorization structure, resulting in a
potential failure to make meaningful inferences about rarely observed
sub-action combinations; this is particularly problematic for offline settings,
where data may be limited. In this work, we propose a form of linear Q-function
decomposition induced by factored action spaces. We study the theoretical
properties of our approach, identifying scenarios where it is guaranteed to
lead to zero bias when used to approximate the Q-function. Outside the regimes
with theoretical guarantees, we show that our approach can still be useful
because it leads to better sample efficiency without necessarily sacrificing
policy optimality, allowing us to achieve a better bias-variance trade-off.
Across several offline RL problems using simulators and real-world datasets
motivated by healthcare, we demonstrate that incorporating factored action
spaces into value-based RL can result in better-performing policies. Our
approach can help an agent make more accurate inferences within underexplored
regions of the state-action space when applying RL to observational datasets.},
 author = {Shengpu Tang and Maggie Makar and Michael W. Sjoding and Finale Doshi-Velez and Jenna Wiens},
 comment = {30 pages, 18 figures, 2 tables. NeurIPS 2022. Code available at
  https://github.com/MLD3/OfflineRL_FactoredActions},
 doi = {},
 eprint = {2305.01738v1},
 journal = {arXiv preprint},
 title = {Leveraging Factored Action Spaces for Efficient Offline Reinforcement Learning in Healthcare},
 url = {http://arxiv.org/abs/2305.01738v1},
 year = {2023}
}

@article{2305.03870v2,
 abstract = {Standard approaches to sequential decision-making exploit an agent's ability
to continually interact with its environment and improve its control policy.
However, due to safety, ethical, and practicality constraints, this type of
trial-and-error experimentation is often infeasible in many real-world domains
such as healthcare and robotics. Instead, control policies in these domains are
typically trained offline from previously logged data or in a growing-batch
manner. In this setting a fixed policy is deployed to the environment and used
to gather an entire batch of new data before being aggregated with past batches
and used to update the policy. This improvement cycle can then be repeated
multiple times. While a limited number of such cycles is feasible in real-world
domains, the quality and diversity of the resulting data are much lower than in
the standard continually-interacting approach. However, data collection in
these domains is often performed in conjunction with human experts, who are
able to label or annotate the collected data. In this paper, we first explore
the trade-offs present in this growing-batch setting, and then investigate how
information provided by a teacher (i.e., demonstrations, expert actions, and
gradient information) can be leveraged at training time to mitigate the sample
complexity and coverage requirements for actor-critic methods. We validate our
contributions on tasks from the DeepMind Control Suite.},
 author = {Patrick Emedom-Nnamdi and Abram L. Friesen and Bobak Shahriari and Nando de Freitas and Matt W. Hoffman},
 comment = {Reincarnating Reinforcement Learning Workshop at ICLR 2023},
 doi = {},
 eprint = {2305.03870v2},
 journal = {arXiv preprint},
 title = {Knowledge Transfer from Teachers to Learners in Growing-Batch Reinforcement Learning},
 url = {http://arxiv.org/abs/2305.03870v2},
 year = {2023}
}

@article{2305.14243v5,
 abstract = {Training multimodal foundation models is challenging due to the limited
availability of multimodal datasets. While many public datasets pair images
with text, few combine images with audio or text with audio. Even rarer are
datasets that align all three modalities at once. Critical domains such as
healthcare, infrastructure, or transportation are particularly affected by
missing modalities. This makes it difficult to integrate all modalities into a
large pre-trained neural network that can be used out-of-the-box or fine-tuned
for different downstream tasks. We introduce LoReTTa (Linking mOdalities with a
tRansitive and commutativE pre-Training sTrAtegy) to address this understudied
problem. Our self-supervised framework unifies causal modeling and masked
modeling with the rules of commutativity and transitivity. This allows us to
transition within and between modalities. As a result, our pre-trained models
are better at exploring the true underlying joint probability distribution.
Given a dataset containing only the disjoint combinations (A, B) and (B, C),
LoReTTa can model the relation A <-> C with A <-> B <-> C. In particular, we
show that a transformer pre-trained with LoReTTa can handle any mixture of
modalities at inference time, including the never-seen pair (A, C) and the
triplet (A, B, C). We extensively evaluate our approach on a synthetic,
medical, and reinforcement learning dataset. Across different domains, our
universal multimodal transformer consistently outperforms strong baselines such
as GPT, BERT, and CLIP on tasks involving the missing modality tuple.},
 author = {Manuel Tran and Yashin Dicente Cid and Amal Lahiani and Fabian J. Theis and Tingying Peng and Eldad Klaiman},
 comment = {Accepted at NeurIPS 2023 (poster). Camera-ready version},
 doi = {},
 eprint = {2305.14243v5},
 journal = {arXiv preprint},
 title = {Training Transitive and Commutative Multimodal Transformers with LoReTTa},
 url = {http://arxiv.org/abs/2305.14243v5},
 year = {2023}
}

@article{2305.17473v4,
 abstract = {Deep learning (DL) has emerged as a powerful subset of machine learning (ML)
and artificial intelligence (AI), outperforming traditional ML methods,
especially in handling unstructured and large datasets. Its impact spans across
various domains, including speech recognition, healthcare, autonomous vehicles,
cybersecurity, predictive analytics, and more. However, the complexity and
dynamic nature of real-world problems present challenges in designing effective
deep learning models. Consequently, several deep learning models have been
developed to address different problems and applications. In this article, we
conduct a comprehensive survey of various deep learning models, including
Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Temporal
Convolutional Networks (TCN), Transformer, Kolmogorov-Arnold networks (KAN),
Generative Models, Deep Reinforcement Learning (DRL), and Deep Transfer
Learning. We examine the structure, applications, benefits, and limitations of
each model. Furthermore, we perform an analysis using three publicly available
datasets: IMDB, ARAS, and Fruit-360. We compared the performance of six
renowned deep learning models: CNN, RNN, Long Short-Term Memory (LSTM),
Bidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional GRU alongside
two newer models, TCN and Transformer, using the IMDB and ARAS datasets.
Additionally, we evaluated the performance of eight CNN-based models, including
VGG (Visual Geometry Group), Inception, ResNet (Residual Network),
InceptionResNet, Xception (Extreme Inception), MobileNet, DenseNet (Dense
Convolutional Network), and NASNet (Neural Architecture Search Network), for
image classification tasks using the Fruit-360 dataset.},
 author = {Farhad Mortezapour Shiri and Thinagaran Perumal and Norwati Mustapha and Raihani Mohamed},
 comment = {62 pages, 37 figures},
 doi = {10.32604/jai.2024.054314},
 eprint = {2305.17473v4},
 journal = {arXiv preprint},
 title = {A Comprehensive Overview and Comparative Analysis on Deep Learning Models: CNN, RNN, LSTM, GRU},
 url = {http://arxiv.org/abs/2305.17473v4},
 year = {2023}
}

@article{2305.20062v2,
 abstract = {Chats emerge as an effective user-friendly approach for information
retrieval, and are successfully employed in many domains, such as customer
service, healthcare, and finance. However, existing image retrieval approaches
typically address the case of a single query-to-image round, and the use of
chats for image retrieval has been mostly overlooked. In this work, we
introduce ChatIR: a chat-based image retrieval system that engages in a
conversation with the user to elicit information, in addition to an initial
query, in order to clarify the user's search intent. Motivated by the
capabilities of today's foundation models, we leverage Large Language Models to
generate follow-up questions to an initial image description. These questions
form a dialog with the user in order to retrieve the desired image from a large
corpus. In this study, we explore the capabilities of such a system tested on a
large dataset and reveal that engaging in a dialog yields significant gains in
image retrieval. We start by building an evaluation pipeline from an existing
manually generated dataset and explore different modules and training
strategies for ChatIR. Our comparison includes strong baselines derived from
related applications trained with Reinforcement Learning. Our system is capable
of retrieving the target image from a pool of 50K images with over 78% success
rate after 5 dialogue rounds, compared to 75% when questions are asked by
humans, and 64% for a single shot text-to-image retrieval. Extensive
evaluations reveal the strong capabilities and examine the limitations of
CharIR under different settings. Project repository is available at
https://github.com/levymsn/ChatIR.},
 author = {Matan Levy and Rami Ben-Ari and Nir Darshan and Dani Lischinski},
 comment = {Camera Ready version for NeurIPS 2023},
 doi = {},
 eprint = {2305.20062v2},
 journal = {arXiv preprint},
 title = {Chatting Makes Perfect: Chat-based Image Retrieval},
 url = {http://arxiv.org/abs/2305.20062v2},
 year = {2023}
}

@article{2306.03158v1,
 abstract = {As an emerging concept, the Metaverse has the potential to revolutionize the
social interaction in the post-pandemic era by establishing a digital world for
online education, remote healthcare, immersive business, intelligent
transportation, and advanced manufacturing. The goal is ambitious, yet the
methodologies and technologies to achieve the full vision of the Metaverse
remain unclear. In this paper, we first introduce the three infrastructure
pillars that lay the foundation of the Metaverse, i.e., human-computer
interfaces, sensing and communication systems, and network architectures. Then,
we depict the roadmap towards the Metaverse that consists of four stages with
different applications. To support diverse applications in the Metaverse, we
put forward a novel design methodology: task-oriented design, and further
review the challenges and the potential solutions. In the case study, we
develop a prototype to illustrate how to synchronize a real-world device and
its digital model in the Metaverse by task-oriented design, where a deep
reinforcement learning algorithm is adopted to minimize the required
communication throughput by optimizing the sampling and prediction systems
subject to a synchronization error constraint.},
 author = {Zhen Meng and Changyang She and Guodong Zhao and Muhammad A. Imran and Mischa Dohler and Yonghui Li and Branka Vucetic},
 comment = {This paper is accepted by the IEEE Wireless Communications},
 doi = {},
 eprint = {2306.03158v1},
 journal = {arXiv preprint},
 title = {Task-Oriented Metaverse Design in the 6G Era},
 url = {http://arxiv.org/abs/2306.03158v1},
 year = {2023}
}

@article{2306.03362v1,
 abstract = {Training practical agents usually involve offline and online reinforcement
learning (RL) to balance the policy's performance and interaction costs. In
particular, online fine-tuning has become a commonly used method to correct the
erroneous estimates of out-of-distribution data learned in the offline training
phase. However, even limited online interactions can be inaccessible or
catastrophic for high-stake scenarios like healthcare and autonomous driving.
In this work, we introduce an interaction-free training scheme dubbed
Offline-with-Action-Preferences (OAP). The main insight is that, compared to
online fine-tuning, querying the preferences between pre-collected and learned
actions can be equally or even more helpful to the erroneous estimate problem.
By adaptively encouraging or suppressing policy constraint according to action
preferences, OAP could distinguish overestimation from beneficial policy
improvement and thus attains a more accurate evaluation of unseen data.
Theoretically, we prove a lower bound of the behavior policy's performance
improvement brought by OAP. Moreover, comprehensive experiments on the D4RL
benchmark and state-of-the-art algorithms demonstrate that OAP yields higher
(29% on average) scores, especially on challenging AntMaze tasks (98% higher).},
 author = {Qisen Yang and Shenzhi Wang and Matthieu Gaetan Lin and Shiji Song and Gao Huang},
 comment = {International Conference on Machine Learning 2023},
 doi = {},
 eprint = {2306.03362v1},
 journal = {arXiv preprint},
 title = {Boosting Offline Reinforcement Learning with Action Preference Query},
 url = {http://arxiv.org/abs/2306.03362v1},
 year = {2023}
}

@article{2306.13630v1,
 abstract = {Reinforcement Learning has received wide interest due to its success in
competitive games. Yet, its adoption in everyday applications is limited (e.g.
industrial, home, healthcare, etc.). In this paper, we address this limitation
by presenting a framework for planning over offline skills and solving complex
tasks in real-world environments. Our framework is comprised of three modules
that together enable the agent to learn from previously collected data and
generalize over it to solve long-horizon tasks. We demonstrate our approach by
testing it on a robotic arm that is required to solve complex tasks.},
 author = {Ben-ya Halevy and Yehudit Aperstein and Dotan Di Castro},
 comment = {},
 doi = {},
 eprint = {2306.13630v1},
 journal = {arXiv preprint},
 title = {Offline Skill Graph (OSG): A Framework for Learning and Planning using Offline Reinforcement Learning Skills},
 url = {http://arxiv.org/abs/2306.13630v1},
 year = {2023}
}

@article{2307.01519v1,
 abstract = {Tailoring treatment for individual patients is crucial yet challenging in
order to achieve optimal healthcare outcomes. Recent advances in reinforcement
learning offer promising personalized treatment recommendations; however, they
rely solely on current patient observations (vital signs, demographics) as the
patient's state, which may not accurately represent the true health status of
the patient. This limitation hampers policy learning and evaluation, ultimately
limiting treatment effectiveness. In this study, we propose the Deep Attention
Q-Network for personalized treatment recommendations, utilizing the Transformer
architecture within a deep reinforcement learning framework to efficiently
incorporate all past patient observations. We evaluated the model on real-world
sepsis and acute hypotension cohorts, demonstrating its superiority to
state-of-the-art models. The source code for our model is available at
https://github.com/stevenmsm/RL-ICU-DAQN.},
 author = {Simin Ma and Junghwan Lee and Nicoleta Serban and Shihao Yang},
 comment = {},
 doi = {},
 eprint = {2307.01519v1},
 journal = {arXiv preprint},
 title = {Deep Attention Q-Network for Personalized Treatment Recommendation},
 url = {http://arxiv.org/abs/2307.01519v1},
 year = {2023}
}

@article{2308.02594v4,
 abstract = {Deep Reinforcement Learning (DRL) has made significant advancements in
various fields, such as autonomous driving, healthcare, and robotics, by
enabling agents to learn optimal policies through interactions with their
environments. However, the application of DRL in safety-critical domains
presents challenges, particularly concerning the safety of the learned
policies. DRL agents, which are focused on maximizing rewards, may select
unsafe actions, leading to safety violations. Runtime safety monitoring is thus
essential to ensure the safe operation of these agents, especially in
unpredictable and dynamic environments. This paper introduces SMARLA, a
black-box safety monitoring approach specifically designed for DRL agents.
SMARLA utilizes machine learning to predict safety violations by observing the
agent's behavior during execution. The approach is based on Q-values, which
reflect the expected reward for taking actions in specific states. SMARLA
employs state abstraction to reduce the complexity of the state space,
enhancing the predictive capabilities of the monitoring model. Such abstraction
enables the early detection of unsafe states, allowing for the implementation
of corrective and preventive measures before incidents occur. We quantitatively
and qualitatively validated SMARLA on three well-known case studies widely used
in DRL research. Empirical results reveal that SMARLA is accurate at predicting
safety violations, with a low false positive rate, and can predict violations
at an early stage, approximately halfway through the execution of the agent,
before violations occur. We also discuss different decision criteria, based on
confidence intervals of the predicted violation probabilities, to trigger
safety mechanisms aiming at a trade-off between early detection and low false
positive rates.},
 author = {Amirhossein Zolfagharian and Manel Abdellatif and Lionel C. Briand and Ramesh S},
 comment = {},
 doi = {},
 eprint = {2308.02594v4},
 journal = {arXiv preprint},
 title = {SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents},
 url = {http://arxiv.org/abs/2308.02594v4},
 year = {2023}
}

@article{2308.05075v1,
 abstract = {Offline Reinforcement learning is commonly used for sequential
decision-making in domains such as healthcare and education, where the rewards
are known and the transition dynamics $T$ must be estimated on the basis of
batch data. A key challenge for all tasks is how to learn a reliable estimate
of the transition dynamics $T$ that produce near-optimal policies that are safe
enough so that they never take actions that are far away from the best action
with respect to their value functions and informative enough so that they
communicate the uncertainties they have. Using data from an expert, we propose
a new constraint-based approach that captures our desiderata for reliably
learning a posterior distribution of the transition dynamics $T$ that is free
from gradients. Our results demonstrate that by using our constraints, we learn
a high-performing policy, while considerably reducing the policy's variance
over different datasets. We also explain how combining uncertainty estimation
with these constraints can help us infer a partial ranking of actions that
produce higher returns, and helps us infer safer and more informative policies
for planning.},
 author = {Leo Benac and Sonali Parbhoo and Finale Doshi-Velez},
 comment = {8 pages, 1 plots, 2 tables},
 doi = {},
 eprint = {2308.05075v1},
 journal = {arXiv preprint},
 title = {Bayesian Inverse Transition Learning for Offline Settings},
 url = {http://arxiv.org/abs/2308.05075v1},
 year = {2023}
}

@article{2308.06094v1,
 abstract = {We propose a framework that can incrementally expand the explanatory temporal
logic rule set to explain the occurrence of temporal events. Leveraging the
temporal point process modeling and learning framework, the rule content and
weights will be gradually optimized until the likelihood of the observational
event sequences is optimal. The proposed algorithm alternates between a master
problem, where the current rule set weights are updated, and a subproblem,
where a new rule is searched and included to best increase the likelihood. The
formulated master problem is convex and relatively easy to solve using
continuous optimization, whereas the subproblem requires searching the huge
combinatorial rule predicate and relationship space. To tackle this challenge,
we propose a neural search policy to learn to generate the new rule content as
a sequence of actions. The policy parameters will be trained end-to-end using
the reinforcement learning framework, where the reward signals can be
efficiently queried by evaluating the subproblem objective. The trained policy
can be used to generate new rules in a controllable way. We evaluate our
methods on both synthetic and real healthcare datasets, obtaining promising
results.},
 author = {Chao Yang and Lu Wang and Kun Gao and Shuang Li},
 comment = {27 pages},
 doi = {},
 eprint = {2308.06094v1},
 journal = {arXiv preprint},
 title = {Reinforcement Logic Rule Learning for Temporal Point Processes},
 url = {http://arxiv.org/abs/2308.06094v1},
 year = {2023}
}

@article{2308.12367v3,
 abstract = {With the growing use of machine learning (ML) models in critical domains such
as finance and healthcare, the need to offer recourse for those adversely
affected by the decisions of ML models has become more important; individuals
ought to be provided with recommendations on actions to take for improving
their situation and thus receiving a favorable decision. Prior work on
sequential algorithmic recourse -- which recommends a series of changes --
focuses on action feasibility and uses the proximity of feature changes to
determine action costs. However, the uncertainties of feature changes and the
risk of higher than average costs in recourse have not been considered. It is
undesirable if a recourse could (with some probability) result in a worse
situation from which recovery requires an extremely high cost. It is essential
to incorporate risks when computing and evaluating recourse. We call the
recourse computed with such risk considerations as Safe Algorithmic Recourse
(SafeAR). The objective is to empower people to choose a recourse based on
their risk tolerance. In this work, we discuss and show how existing recourse
desiderata can fail to capture the risk of higher costs. We present a method to
compute recourse policies that consider variability in cost and connect
algorithmic recourse literature with risk-sensitive reinforcement learning. We
also adopt measures "Value at Risk" and "Conditional Value at Risk" from the
financial literature to summarize risk concisely. We apply our method to two
real-world datasets and compare policies with different risk-aversion levels
using risk measures and recourse desiderata (sparsity and proximity).},
 author = {Haochen Wu and Shubham Sharma and Sunandita Patra and Sriram Gopalakrishnan},
 comment = {Accepted to AAAI 2024 main track with oral presentation; Supplemental
  material appended to main paper},
 doi = {10.1609/aaai.v38i14.29522},
 eprint = {2308.12367v3},
 journal = {arXiv preprint},
 title = {SafeAR: Safe Algorithmic Recourse by Risk-Aware Policies},
 url = {http://arxiv.org/abs/2308.12367v3},
 year = {2023}
}

@article{2308.13135v2,
 abstract = {We propose a nonparametric additive model for estimating interpretable value
functions in reinforcement learning, with an application in optimizing
postoperative recovery through personalized, adaptive recommendations. While
reinforcement learning has achieved significant success in various domains,
recent methods often rely on black-box approaches such as neural networks,
which hinder the examination of individual feature contributions to a
decision-making policy. Our novel method offers a flexible technique for
estimating action-value functions without explicit parametric assumptions,
overcoming the limitations of the linearity assumption of classical algorithms.
By incorporating local kernel regression and basis expansion, we obtain a
sparse, additive representation of the action-value function, enabling local
approximation and retrieval of nonlinear, independent contributions of select
state features and the interactions between joint feature pairs. We validate
our approach through a simulation study and apply it to spine disease recovery,
uncovering recommendations aligned with clinical knowledge. This method bridges
the gap between flexible machine learning techniques and the interpretability
required in healthcare applications, paving the way for more personalized
interventions.},
 author = {Patrick Emedom-Nnamdi and Timothy R. Smith and Jukka-Pekka Onnela and Junwei Lu},
 comment = {28 pages, 13 figures},
 doi = {10.1214/24-AOAS1987},
 eprint = {2308.13135v2},
 journal = {arXiv preprint},
 title = {Nonparametric Additive Value Functions: Interpretable Reinforcement Learning with an Application to Surgical Recovery},
 url = {http://arxiv.org/abs/2308.13135v2},
 year = {2023}
}

@article{2308.16585v1,
 abstract = {Background Weight loss trajectories after bariatric surgery vary widely
between individuals, and predicting weight loss before the operation remains
challenging. We aimed to develop a model using machine learning to provide
individual preoperative prediction of 5-year weight loss trajectories after
surgery. Methods In this multinational retrospective observational study we
enrolled adult participants (aged $\ge$18 years) from ten prospective cohorts
(including ABOS [NCT01129297], BAREVAL [NCT02310178], the Swedish Obese
Subjects study, and a large cohort from the Dutch Obesity Clinic [Nederlandse
Obesitas Kliniek]) and two randomised trials (SleevePass [NCT00793143] and
SM-BOSS [NCT00356213]) in Europe, the Americas, and Asia, with a 5 year
followup after Roux-en-Y gastric bypass, sleeve gastrectomy, or gastric band.
Patients with a previous history of bariatric surgery or large delays between
scheduled and actual visits were excluded. The training cohort comprised
patients from two centres in France (ABOS and BAREVAL). The primary outcome was
BMI at 5 years. A model was developed using least absolute shrinkage and
selection operator to select variables and the classification and regression
trees algorithm to build interpretable regression trees. The performances of
the model were assessed through the median absolute deviation (MAD) and root
mean squared error (RMSE) of BMI. Findings10 231 patients from 12 centres in
ten countries were included in the analysis, corresponding to 30 602
patient-years. Among participants in all 12 cohorts, 7701 (75$\bullet$3%) were
female, 2530 (24$\bullet$7%) were male. Among 434 baseline attributes available
in the training cohort, seven variables were selected: height, weight,
intervention type, age, diabetes status, diabetes duration, and smoking status.
At 5 years, across external testing cohorts the overall mean MAD BMI was
2$\bullet$8 kg/m${}^2$ (95% CI 2$\bullet$6-3$\bullet$0) and mean RMSE BMI was
4$\bullet$7 kg/m${}^2$ (4$\bullet$4-5$\bullet$0), and the mean difference
between predicted and observed BMI was-0$\bullet$3 kg/m${}^2$ (SD 4$\bullet$7).
This model is incorporated in an easy to use and interpretable web-based
prediction tool to help inform clinical decision before surgery.
InterpretationWe developed a machine learning-based model, which is
internationally validated, for predicting individual 5-year weight loss
trajectories after three common bariatric interventions.},
 author = {Patrick Saux and Pierre Bauvin and Violeta Raverdy and Julien Teigny and Hélène Verkindt and Tomy Soumphonphakdy and Maxence Debert and Anne Jacobs and Daan Jacobs and Valerie Monpellier and Phong Ching Lee and Chin Hong Lim and Johanna C Andersson-Assarsson and Lena Carlsson and Per-Arne Svensson and Florence Galtier and Guelareh Dezfoulian and Mihaela Moldovanu and Severine Andrieux and Julien Couster and Marie Lepage and Erminia Lembo and Ornella Verrastro and Maud Robert and Paulina Salminen and Geltrude Mingrone and Ralph Peterli and Ricardo V Cohen and Carlos Zerrweck and David Nocca and Carel W Le Roux and Robert Caiazzo and Philippe Preux and François Pattou},
 comment = {The Lancet Digital Health, 2023},
 doi = {10.1016/S2589-7500(23)00135-8},
 eprint = {2308.16585v1},
 journal = {arXiv preprint},
 title = {Development and validation of an interpretable machine learning-based calculator for predicting 5-year weight trajectories after bariatric surgery: a multinational retrospective cohort SOPHIA study},
 url = {http://arxiv.org/abs/2308.16585v1},
 year = {2023}
}

@article{2309.00841v1,
 abstract = {Question-answering (QA) is a significant application of Large Language Models
(LLMs), shaping chatbot capabilities across healthcare, education, and customer
service. However, widespread LLM integration presents a challenge for small
businesses due to the high expenses of LLM API usage. Costs rise rapidly when
domain-specific data (context) is used alongside queries for accurate
domain-specific LLM responses. One option is to summarize the context by using
LLMs and reduce the context. However, this can also filter out useful
information that is necessary to answer some domain-specific queries. In this
paper, we shift from human-oriented summarizers to AI model-friendly summaries.
Our approach, LeanContext, efficiently extracts $k$ key sentences from the
context that are closely aligned with the query. The choice of $k$ is neither
static nor random; we introduce a reinforcement learning technique that
dynamically determines $k$ based on the query and context. The rest of the less
important sentences are reduced using a free open source text reduction method.
We evaluate LeanContext against several recent query-aware and query-unaware
context reduction approaches on prominent datasets (arxiv papers and BBC news
articles). Despite cost reductions of $37.29\%$ to $67.81\%$, LeanContext's
ROUGE-1 score decreases only by $1.41\%$ to $2.65\%$ compared to a baseline
that retains the entire context (no summarization). Additionally, if free
pretrained LLM-based summarizers are used to reduce context (into human
consumable summaries), LeanContext can further modify the reduced context to
enhance the accuracy (ROUGE-1 score) by $13.22\%$ to $24.61\%$.},
 author = {Md Adnan Arefeen and Biplob Debnath and Srimat Chakradhar},
 comment = {The paper is under review},
 doi = {},
 eprint = {2309.00841v1},
 journal = {arXiv preprint},
 title = {LeanContext: Cost-Efficient Domain-Specific Question Answering Using LLMs},
 url = {http://arxiv.org/abs/2309.00841v1},
 year = {2023}
}

@article{2309.10186v2,
 abstract = {Reinforcement learning is well known for its ability to model sequential
tasks and learn latent data patterns adaptively. Deep learning models have been
widely explored and adopted in regression and classification tasks. However,
deep learning has its limitations such as the assumption of equally spaced and
ordered data, and the lack of ability to incorporate graph structure in terms
of time-series prediction. Graphical neural network (GNN) has the ability to
overcome these challenges and capture the temporal dependencies in time-series
data. In this study, we propose a novel approach for predicting time-series
data using GNN and monitoring with Reinforcement Learning (RL). GNNs are able
to explicitly incorporate the graph structure of the data into the model,
allowing them to capture temporal dependencies in a more natural way. This
approach allows for more accurate predictions in complex temporal structures,
such as those found in healthcare, traffic and weather forecasting. We also
fine-tune our GraphRL model using a Bayesian optimisation technique to further
improve performance. The proposed framework outperforms the baseline models in
time-series forecasting and monitoring. The contributions of this study include
the introduction of a novel GraphRL framework for time-series prediction and
the demonstration of the effectiveness of GNNs in comparison to traditional
deep learning models such as RNNs and LSTMs. Overall, this study demonstrates
the potential of GraphRL in providing accurate and efficient predictions in
dynamic RL environments.},
 author = {Thanveer Shaik and Xiaohui Tao and Haoran Xie and Lin Li and Jianming Yong and Yuefeng Li},
 comment = {This work has been submitted to the IEEE for possible publication},
 doi = {10.1109/TETCI.2024.3398024},
 eprint = {2309.10186v2},
 journal = {arXiv preprint},
 title = {Graph-enabled Reinforcement Learning for Time Series Forecasting with Adaptive Intelligence},
 url = {http://arxiv.org/abs/2309.10186v2},
 year = {2023}
}

@article{2309.10980v4,
 abstract = {Effective patient monitoring is vital for timely interventions and improved
healthcare outcomes. Traditional monitoring systems often struggle to handle
complex, dynamic environments with fluctuating vital signs, leading to delays
in identifying critical conditions. To address this challenge, we propose a
novel AI-driven patient monitoring framework using multi-agent deep
reinforcement learning (DRL). Our approach deploys multiple learning agents,
each dedicated to monitoring a specific physiological feature, such as heart
rate, respiration, and temperature. These agents interact with a generic
healthcare monitoring environment, learn the patients' behavior patterns, and
make informed decisions to alert the corresponding Medical Emergency Teams
(METs) based on the level of emergency estimated. In this study, we evaluate
the performance of the proposed multi-agent DRL framework using real-world
physiological and motion data from two datasets: PPG-DaLiA and WESAD. We
compare the results with several baseline models, including Q-Learning, PPO,
Actor-Critic, Double DQN, and DDPG, as well as monitoring frameworks like
WISEML and CA-MAQL. Our experiments demonstrate that the proposed DRL approach
outperforms all other baseline models, achieving more accurate monitoring of
patient's vital signs. Furthermore, we conduct hyperparameter optimization to
fine-tune the learning process of each agent. By optimizing hyperparameters, we
enhance the learning rate and discount factor, thereby improving the agents'
overall performance in monitoring patient health status.},
 author = {Thanveer Shaik and Xiaohui Tao and Lin Li and Haoran Xie and Hong-Ning Dai and Feng Zhao and Jianming Yong},
 comment = {This work has been submitted to the IEEE for possible publication.
  arXiv admin note: text overlap with arXiv:2309.10576},
 doi = {},
 eprint = {2309.10980v4},
 journal = {arXiv preprint},
 title = {Adaptive Multi-Agent Deep Reinforcement Learning for Timely Healthcare Interventions},
 url = {http://arxiv.org/abs/2309.10980v4},
 year = {2023}
}

@article{2309.11914v1,
 abstract = {With an increasing focus on precision medicine in medical research, numerous
studies have been conducted in recent years to clarify the relationship between
treatment effects and patient characteristics. The treatment effects for
patients with different characteristics are always heterogeneous, and various
heterogeneous treatment effect machine learning estimation methods have been
proposed owing to their flexibility and high prediction accuracy. However, most
machine learning methods rely on black-box models, preventing direct
interpretation of the relationship between patient characteristics and
treatment effects. Moreover, most of these studies have focused on continuous
or binary outcomes, although survival outcomes are also important in medical
research. To address these challenges, we propose a heterogeneous treatment
effect estimation method for survival data based on RuleFit, an interpretable
machine learning method. Numerical simulation results confirmed that the
prediction performance of the proposed method was comparable to that of
existing methods. We also applied a dataset from an HIV study, the AIDS
Clinical Trials Group Protocol 175 dataset, to illustrate the interpretability
of the proposed method using real data. Consequently, the proposed method
established an interpretable model with sufficient prediction accuracy.},
 author = {Ke Wan and Kensuke Tanioka and Toshio Shimokawa},
 comment = {},
 doi = {},
 eprint = {2309.11914v1},
 journal = {arXiv preprint},
 title = {Survival causal rule ensemble method considering the main effect for estimating heterogeneous treatment effects},
 url = {http://arxiv.org/abs/2309.11914v1},
 year = {2023}
}

@article{2309.14084v1,
 abstract = {In the domain of Natural Language Processing (NLP), Named Entity Recognition
(NER) stands out as a pivotal mechanism for extracting structured insights from
unstructured text. This manuscript offers an exhaustive exploration into the
evolving landscape of NER methodologies, blending foundational principles with
contemporary AI advancements. Beginning with the rudimentary concepts of NER,
the study spans a spectrum of techniques from traditional rule-based strategies
to the contemporary marvels of transformer architectures, particularly
highlighting integrations such as BERT with LSTM and CNN. The narrative
accentuates domain-specific NER models, tailored for intricate areas like
finance, legal, and healthcare, emphasizing their specialized adaptability.
Additionally, the research delves into cutting-edge paradigms including
reinforcement learning, innovative constructs like E-NER, and the interplay of
Optical Character Recognition (OCR) in augmenting NER capabilities. Grounding
its insights in practical realms, the paper sheds light on the indispensable
role of NER in sectors like finance and biomedicine, addressing the unique
challenges they present. The conclusion outlines open challenges and avenues,
marking this work as a comprehensive guide for those delving into NER research
and applications.},
 author = {Kalyani Pakhale},
 comment = {},
 doi = {},
 eprint = {2309.14084v1},
 journal = {arXiv preprint},
 title = {Comprehensive Overview of Named Entity Recognition: Models, Domain-Specific Applications and Challenges},
 url = {http://arxiv.org/abs/2309.14084v1},
 year = {2023}
}

@article{2310.03161v1,
 abstract = {Inspired by recent developments in attention models for image classification
and natural language processing, we present various Attention based
architectures in reinforcement learning (RL) domain, capable of performing well
on OpenAI Gym Atari-2600 game suite. In spite of the recent success of Deep
Reinforcement learning techniques in various fields like robotics, gaming and
healthcare, they suffer from a major drawback that neural networks are
difficult to interpret. We try to get around this problem with the help of
Attention based models. In Attention based models, extracting and overlaying of
attention map onto images allows for direct observation of information used by
agent to select actions and easier interpretation of logic behind the chosen
actions. Our models in addition to playing well on gym-Atari environments, also
provide insights on how agent perceives its environment. In addition, motivated
by recent developments in attention based video-classification models using
Vision Transformer, we come up with an architecture based on Vision
Transformer, for image-based RL domain too. Compared to previous works in
Vision Transformer, our model is faster to train and requires fewer
computational resources. 3},
 author = {Victor Vadakechirayath George},
 comment = {Master's thesis at Albert-Ludwigs-University, Freiburg Faculty of
  Engineering, Department of Computer Science Chair for Machine Learning.
  Advisor: Raghu Rajan, Examiners: Prof. Dr. Frank Hutter, Prof. Dr. Thomas
  Brox},
 doi = {},
 eprint = {2310.03161v1},
 journal = {arXiv preprint},
 title = {Neural architecture impact on identifying temporally extended Reinforcement Learning tasks},
 url = {http://arxiv.org/abs/2310.03161v1},
 year = {2023}
}

@article{2310.07123v2,
 abstract = {Off-policy evaluation (OPE) is important for closing the gap between offline
training and evaluation of reinforcement learning (RL), by estimating
performance and/or rank of target (evaluation) policies using offline
trajectories only. It can improve the safety and efficiency of data collection
and policy testing procedures in situations where online deployments are
expensive, such as healthcare. However, existing OPE methods fall short in
estimating human feedback (HF) signals, as HF may be conditioned over multiple
underlying factors and is only sparsely available; as opposed to the
agent-defined environmental rewards (used in policy optimization), which are
usually determined over parametric functions or distributions. Consequently,
the nature of HF signals makes extrapolating accurate OPE estimations to be
challenging. To resolve this, we introduce an OPE for HF (OPEHF) framework that
revives existing OPE methods in order to accurately evaluate the HF signals.
Specifically, we develop an immediate human reward (IHR) reconstruction
approach, regularized by environmental knowledge distilled in a latent space
that captures the underlying dynamics of state transitions as well as issuing
HF signals. Our approach has been tested over two real-world experiments,
adaptive in-vivo neurostimulation and intelligent tutoring, as well as in a
simulation environment (visual Q&A). Results show that our approach
significantly improves the performance toward estimating HF signals accurately,
compared to directly applying (variants of) existing OPE methods.},
 author = {Qitong Gao and Ge Gao and Juncheng Dong and Vahid Tarokh and Min Chi and Miroslav Pajic},
 comment = {Accepted to NeurIPS 2023},
 doi = {},
 eprint = {2310.07123v2},
 journal = {arXiv preprint},
 title = {Off-Policy Evaluation for Human Feedback},
 url = {http://arxiv.org/abs/2310.07123v2},
 year = {2023}
}

@article{2310.07747v2,
 abstract = {Learning controllers with offline data in decision-making systems is an
essential area of research due to its potential to reduce the risk of
applications in real-world systems. However, in responsibility-sensitive
settings such as healthcare, decision accountability is of paramount
importance, yet has not been adequately addressed by the literature. This paper
introduces the Accountable Offline Controller (AOC) that employs the offline
dataset as the Decision Corpus and performs accountable control based on a
tailored selection of examples, referred to as the Corpus Subset. AOC operates
effectively in low-data scenarios, can be extended to the strictly offline
imitation setting, and displays qualities of both conservation and
adaptability. We assess AOC's performance in both simulated and real-world
healthcare scenarios, emphasizing its capability to manage offline control
tasks with high levels of performance while maintaining accountability.},
 author = {Hao Sun and Alihan Hüyük and Daniel Jarrett and Mihaela van der Schaar},
 comment = {},
 doi = {},
 eprint = {2310.07747v2},
 journal = {arXiv preprint},
 title = {Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples},
 url = {http://arxiv.org/abs/2310.07747v2},
 year = {2023}
}

@article{2310.10549v1,
 abstract = {The emergence of new services and applications in emerging wireless networks
(e.g., beyond 5G and 6G) has shown a growing demand for the usage of artificial
intelligence (AI) in the Internet of Things (IoT). However, the proliferation
of massive IoT connections and the availability of computing resources
distributed across future IoT systems have strongly demanded the development of
distributed AI for better IoT services and applications. Therefore, existing
AI-enabled IoT systems can be enhanced by implementing distributed machine
learning (aka distributed learning) approaches. This work aims to provide a
comprehensive survey on distributed learning for IoT services and applications
in emerging networks. In particular, we first provide a background of machine
learning and present a preliminary to typical distributed learning approaches,
such as federated learning, multi-agent reinforcement learning, and distributed
inference. Then, we provide an extensive review of distributed learning for
critical IoT services (e.g., data sharing and computation offloading,
localization, mobile crowdsensing, and security and privacy) and IoT
applications (e.g., smart healthcare, smart grid, autonomous vehicle, aerial
IoT networks, and smart industry). From the reviewed literature, we also
present critical challenges of distributed learning for IoT and propose several
promising solutions and research directions in this emerging area.},
 author = {Mai Le and Thien Huynh-The and Tan Do-Duy and Thai-Hoc Vu and Won-Joo Hwang and Quoc-Viet Pham},
 comment = {},
 doi = {},
 eprint = {2310.10549v1},
 journal = {arXiv preprint},
 title = {Applications of Distributed Machine Learning for the Internet-of-Things: A Comprehensive Survey},
 url = {http://arxiv.org/abs/2310.10549v1},
 year = {2023}
}

@article{2310.14526v3,
 abstract = {Restless multi-arm bandits (RMABs), a class of resource allocation problems
with broad application in areas such as healthcare, online advertising, and
anti-poaching, have recently been studied from a multi-agent reinforcement
learning perspective. Prior RMAB research suffers from several limitations,
e.g., it fails to adequately address continuous states, and requires retraining
from scratch when arms opt-in and opt-out over time, a common challenge in many
real world applications. We address these limitations by developing a neural
network-based pre-trained model (PreFeRMAB) that has general zero-shot ability
on a wide range of previously unseen RMABs, and which can be fine-tuned on
specific instances in a more sample-efficient way than retraining from scratch.
Our model also accommodates general multi-action settings and discrete or
continuous state spaces. To enable fast generalization, we learn a novel single
policy network model that utilizes feature information and employs a training
procedure in which arms opt-in and out over time. We derive a new update rule
for a crucial $\lambda$-network with theoretical convergence guarantees and
empirically demonstrate the advantages of our approach on several challenging,
real-world inspired problems.},
 author = {Yunfan Zhao and Nikhil Behari and Edward Hughes and Edwin Zhang and Dheeraj Nagaraj and Karl Tuyls and Aparna Taneja and Milind Tambe},
 comment = {},
 doi = {},
 eprint = {2310.14526v3},
 journal = {arXiv preprint},
 title = {Towards a Pretrained Model for Restless Bandits via Multi-arm Generalization},
 url = {http://arxiv.org/abs/2310.14526v3},
 year = {2023}
}

@article{2310.17146v1,
 abstract = {In applying reinforcement learning (RL) to high-stakes domains, quantitative
and qualitative evaluation using observational data can help practitioners
understand the generalization performance of new policies. However, this type
of off-policy evaluation (OPE) is inherently limited since offline data may not
reflect the distribution shifts resulting from the application of new policies.
On the other hand, online evaluation by collecting rollouts according to the
new policy is often infeasible, as deploying new policies in these domains can
be unsafe. In this work, we propose a semi-offline evaluation framework as an
intermediate step between offline and online evaluation, where human users
provide annotations of unobserved counterfactual trajectories. While tempting
to simply augment existing data with such annotations, we show that this naive
approach can lead to biased results. Instead, we design a new family of OPE
estimators based on importance sampling (IS) and a novel weighting scheme that
incorporate counterfactual annotations without introducing additional bias. We
analyze the theoretical properties of our approach, showing its potential to
reduce both bias and variance compared to standard IS estimators. Our analyses
reveal important practical considerations for handling biased, noisy, or
missing annotations. In a series of proof-of-concept experiments involving
bandits and a healthcare-inspired simulator, we demonstrate that our approach
outperforms purely offline IS estimators and is robust to imperfect
annotations. Our framework, combined with principled human-centered design of
annotation solicitation, can enable the application of RL in high-stakes
domains.},
 author = {Shengpu Tang and Jenna Wiens},
 comment = {36 pages, 12 figures, 5 tables. NeurIPS 2023. Code available at
  https://github.com/MLD3/CounterfactualAnnot-SemiOPE},
 doi = {},
 eprint = {2310.17146v1},
 journal = {arXiv preprint},
 title = {Counterfactual-Augmented Importance Sampling for Semi-Offline Policy Evaluation},
 url = {http://arxiv.org/abs/2310.17146v1},
 year = {2023}
}

@article{2310.18354v1,
 abstract = {Reinforcement learning (RL) has emerged as a powerful approach for tackling
complex medical decision-making problems such as treatment planning,
personalized medicine, and optimizing the scheduling of surgeries and
appointments. It has gained significant attention in the field of Natural
Language Processing (NLP) due to its ability to learn optimal strategies for
tasks such as dialogue systems, machine translation, and question-answering.
This paper presents a review of the RL techniques in NLP, highlighting key
advancements, challenges, and applications in healthcare. The review begins by
visualizing a roadmap of machine learning and its applications in healthcare.
And then it explores the integration of RL with NLP tasks. We examined dialogue
systems where RL enables the learning of conversational strategies, RL-based
machine translation models, question-answering systems, text summarization, and
information extraction. Additionally, ethical considerations and biases in
RL-NLP systems are addressed.},
 author = {Ying Liu and Haozhu Wang and Huixue Zhou and Mingchen Li and Yu Hou and Sicheng Zhou and Fang Wang and Rama Hoetzlein and Rui Zhang},
 comment = {},
 doi = {},
 eprint = {2310.18354v1},
 journal = {arXiv preprint},
 title = {A Review of Reinforcement Learning for Natural Language Processing, and Applications in Healthcare},
 url = {http://arxiv.org/abs/2310.18354v1},
 year = {2023}
}

@article{2311.12188v5,
 abstract = {Reinforcement learning-based large language models, such as ChatGPT, are
believed to have potential to aid human experts in many domains, including
healthcare. There is, however, little work on ChatGPT's ability to perform a
key task in healthcare: formal, probabilistic medical diagnostic reasoning.
This type of reasoning is used, for example, to update a pre-test probability
to a post-test probability. In this work, we probe ChatGPT's ability to perform
this task. In particular, we ask ChatGPT to give examples of how to use Bayes
rule for medical diagnosis. Our prompts range from queries that use terminology
from pure probability (e.g., requests for a posterior of A given B and C) to
queries that use terminology from medical diagnosis (e.g., requests for a
posterior probability of Covid given a test result and cough). We show how the
introduction of medical variable names leads to an increase in the number of
errors that ChatGPT makes. Given our results, we also show how one can use
prompt engineering to facilitate ChatGPT's partial avoidance of these errors.
We discuss our results in light of recent commentaries on sensitivity and
specificity. We also discuss how our results might inform new research
directions for large language models.},
 author = {Samuel J. Weisenthal},
 comment = {138 pages, 4 tables},
 doi = {},
 eprint = {2311.12188v5},
 journal = {arXiv preprint},
 title = {ChatGPT and post-test probability},
 url = {http://arxiv.org/abs/2311.12188v5},
 year = {2023}
}

@article{2311.13861v1,
 abstract = {The emerging mission-critical Internet of Things (IoT) play a vital role in
remote healthcare, haptic interaction, and industrial automation, where timely
delivery of status updates is crucial. The Age of Information (AoI) is an
effective metric to capture and evaluate information freshness at the
destination. A system design based solely on the optimization of the average
AoI might not be adequate to capture the requirements of mission-critical
applications, since averaging eliminates the effects of extreme events. In this
paper, we introduce a Deep Reinforcement Learning (DRL)-based algorithm to
improve AoI in mission-critical IoT applications. The objective is to minimize
an AoI-based metric consisting of the weighted sum of the average AoI and the
probability of exceeding an AoI threshold. We utilize the actor-critic method
to train the algorithm to achieve optimized scheduling policy to solve the
formulated problem. The performance of our proposed method is evaluated in a
simulated setup and the results show a significant improvement in terms of the
average AoI and the AoI violation probability compared to the related-work.},
 author = {Hossam Farag and Mikael Gidlund and Cedomir Stefanovic},
 comment = {},
 doi = {},
 eprint = {2311.13861v1},
 journal = {arXiv preprint},
 title = {A Deep Reinforcement Learning Approach for Improving Age of Information in Mission-Critical IoT},
 url = {http://arxiv.org/abs/2311.13861v1},
 year = {2023}
}

@article{2311.14110v2,
 abstract = {Evaluating the value of a hypothetical target policy with only a logged
dataset is important but challenging. On the one hand, it brings opportunities
for safe policy improvement under high-stakes scenarios like clinical
guidelines. On the other hand, such opportunities raise a need for precise
off-policy evaluation (OPE). While previous work on OPE focused on improving
the algorithm in value estimation, in this work, we emphasize the importance of
the offline dataset, hence putting forward a data-centric framework for
evaluating OPE problems. We propose DataCOPE, a data-centric framework for
evaluating OPE, that answers the questions of whether and to what extent we can
evaluate a target policy given a dataset. DataCOPE (1) forecasts the overall
performance of OPE algorithms without access to the environment, which is
especially useful before real-world deployment where evaluating OPE is
impossible; (2) identifies the sub-group in the dataset where OPE can be
inaccurate; (3) permits evaluations of datasets or data-collection strategies
for OPE problems. Our empirical analysis of DataCOPE in the logged contextual
bandit settings using healthcare datasets confirms its ability to evaluate both
machine-learning and human expert policies like clinical guidelines. Finally,
we apply DataCOPE to the task of reward modeling in Large Language Model
alignment to demonstrate its scalability in real-world applications.},
 author = {Hao Sun and Alex J. Chan and Nabeel Seedat and Alihan Hüyük and Mihaela van der Schaar},
 comment = {Reward Modeling, Large Language Models, RLHF, Off-Policy Evaluation,
  Data-Centric AI, Data-Centric Reinforcement Learning, Reinforcement Learning},
 doi = {},
 eprint = {2311.14110v2},
 journal = {arXiv preprint},
 title = {When is Off-Policy Evaluation (Reward Modeling) Useful in Contextual Bandits? A Data-Centric Perspective},
 url = {http://arxiv.org/abs/2311.14110v2},
 year = {2023}
}

@article{2312.01530v4,
 abstract = {Machine learning methods often assume that input features are available at no
cost. However, in domains like healthcare, where acquiring features could be
expensive or harmful, it is necessary to balance a feature's acquisition cost
against its predictive value. The task of training an AI agent to decide which
features to acquire is called active feature acquisition (AFA). By deploying an
AFA agent, we effectively alter the acquisition strategy and trigger a
distribution shift. To safely deploy AFA agents under this distribution shift,
we present the problem of active feature acquisition performance evaluation
(AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating
that acquisitions do not affect the underlying feature values; and ii) a no
unobserved confounding (NUC) assumption, stating that retrospective feature
acquisition decisions were only based on observed features. We show that one
can apply missing data methods under the NDE assumption and offline
reinforcement learning under the NUC assumption. When NUC and NDE hold, we
propose a novel semi-offline reinforcement learning framework. This framework
requires a weaker positivity assumption and introduces three new estimators: A
direct method (DM), an inverse probability weighting (IPW), and a double
reinforcement learning (DRL) estimator.},
 author = {Henrik von Kleist and Alireza Zamanian and Ilya Shpitser and Narges Ahmidi},
 comment = {61 pages, 4 tables, 11 Figures},
 doi = {},
 eprint = {2312.01530v4},
 journal = {arXiv preprint},
 title = {Evaluation of Active Feature Acquisition Methods for Time-varying Feature Settings},
 url = {http://arxiv.org/abs/2312.01530v4},
 year = {2023}
}

@article{2312.03619v2,
 abstract = {Active feature acquisition (AFA) agents, crucial in domains like healthcare
where acquiring features is often costly or harmful, determine the optimal set
of features for a subsequent classification task. As deploying an AFA agent
introduces a shift in missingness distribution, it's vital to assess its
expected performance at deployment using retrospective data. In a companion
paper, we introduce a semi-offline reinforcement learning (RL) framework for
active feature acquisition performance evaluation (AFAPE) where features are
assumed to be time-dependent. Here, we study and extend the AFAPE problem to
cover static feature settings, where features are time-invariant, and hence
provide more flexibility to the AFA agents in deciding the order of the
acquisitions. In this static feature setting, we derive and adapt new inverse
probability weighting (IPW), direct method (DM), and double reinforcement
learning (DRL) estimators within the semi-offline RL framework. These
estimators can be applied when the missingness in the retrospective dataset
follows a missing-at-random (MAR) pattern. They also can be applied to
missing-not-at-random (MNAR) patterns in conjunction with appropriate existing
missing data techniques. We illustrate the improved data efficiency offered by
the semi-offline RL estimators in synthetic and real-world data experiments
under synthetic MAR and MNAR missingness.},
 author = {Henrik von Kleist and Alireza Zamanian and Ilya Shpitser and Narges Ahmidi},
 comment = {38 pages, 7 figures, 5 tables},
 doi = {},
 eprint = {2312.03619v2},
 journal = {arXiv preprint},
 title = {Evaluation of Active Feature Acquisition Methods for Static Feature Settings},
 url = {http://arxiv.org/abs/2312.03619v2},
 year = {2023}
}

@article{2312.10230v1,
 abstract = {Despite remarkable achievements in artificial intelligence, the deployability
of learning-enabled systems in high-stakes real-world environments still faces
persistent challenges. For example, in safety-critical domains like autonomous
driving, robotic manipulation, and healthcare, it is crucial not only to
achieve high performance but also to comply with given constraints.
Furthermore, adaptability becomes paramount in non-stationary domains, where
environmental parameters are subject to change. While safety and adaptability
are recognized as key qualities for the new generation of AI, current
approaches have not demonstrated effective adaptable performance in constrained
settings. Hence, this paper breaks new ground by studying the unique challenges
of ensuring safety in non-stationary environments by solving constrained
problems through the lens of the meta-learning approach (learning-to-learn).
While unconstrained meta-learning al-ready encounters complexities in
end-to-end differentiation of the loss due to the bi-level nature, its
constrained counterpart introduces an additional layer of difficulty, since the
constraints imposed on task-level updates complicate the differentiation
process. To address the issue, we first employ successive convex-constrained
policy updates across multiple tasks with differentiable convexprogramming,
which allows meta-learning in constrained scenarios by enabling end-to-end
differentiation. This approach empowers the agent to rapidly adapt to new tasks
under non-stationarity while ensuring compliance with safety constraints.},
 author = {Minjae Cho and Chuangchuang Sun},
 comment = {},
 doi = {},
 eprint = {2312.10230v1},
 journal = {arXiv preprint},
 title = {Constrained Meta-Reinforcement Learning for Adaptable Safety Guarantee with Differentiable Convex Programming},
 url = {http://arxiv.org/abs/2312.10230v1},
 year = {2023}
}

@article{2401.06514v1,
 abstract = {Personalization in machine learning (ML) tailors models' decisions to the
individual characteristics of users. While this approach has seen success in
areas like recommender systems, its expansion into high-stakes fields such as
healthcare and autonomous driving is hindered by the extensive regulatory
approval processes involved. To address this challenge, we propose a novel
framework termed represented Markov Decision Processes (r-MDPs) that is
designed to balance the need for personalization with the regulatory
constraints. In an r-MDP, we cater to a diverse user population, each with
unique preferences, through interaction with a small set of representative
policies. Our objective is twofold: efficiently match each user to an
appropriate representative policy and simultaneously optimize these policies to
maximize overall social welfare. We develop two deep reinforcement learning
algorithms that efficiently solve r-MDPs. These algorithms draw inspiration
from the principles of classic K-means clustering and are underpinned by robust
theoretical foundations. Our empirical investigations, conducted across a
variety of simulated environments, showcase the algorithms' ability to
facilitate meaningful personalization even under constrained policy budgets.
Furthermore, they demonstrate scalability, efficiently adapting to larger
policy budgets.},
 author = {Dmitry Ivanov and Omer Ben-Porat},
 comment = {Accepted to AAAI 2024. Code:
  https://github.com/dimonenka/RL_policy_budget},
 doi = {},
 eprint = {2401.06514v1},
 journal = {arXiv preprint},
 title = {Personalized Reinforcement Learning with a Budget of Policies},
 url = {http://arxiv.org/abs/2401.06514v1},
 year = {2024}
}

@article{2401.10794v1,
 abstract = {In smart healthcare, health monitoring utilizes diverse tools and
technologies to analyze patients' real-time biosignal data, enabling immediate
actions and interventions. Existing monitoring approaches were designed on the
premise that medical devices track several health metrics concurrently,
tailored to their designated functional scope. This means that they report all
relevant health values within that scope, which can result in excess resource
use and the gathering of extraneous data due to monitoring irrelevant health
metrics. In this context, we propose Dynamic Activity-Aware Health Monitoring
strategy (DActAHM) for striking a balance between optimal monitoring
performance and cost efficiency, a novel framework based on Deep Reinforcement
Learning (DRL) and SlowFast Model to ensure precise monitoring based on users'
activities. Specifically, with the SlowFast Model, DActAHM efficiently
identifies individual activities and captures these results for enhanced
processing. Subsequently, DActAHM refines health metric monitoring in response
to the identified activity by incorporating a DRL framework. Extensive
experiments comparing DActAHM against three state-of-the-art approaches
demonstrate it achieves 27.3% higher gain than the best-performing baseline
that fixes monitoring actions over timeline.},
 author = {Ziqiaing Ye and Yulan Gao and Yue Xiao and Zehui Xiong and Dusit Niyato},
 comment = {},
 doi = {},
 eprint = {2401.10794v1},
 journal = {arXiv preprint},
 title = {Deep Reinforcement Learning Empowered Activity-Aware Dynamic Health Monitoring Systems},
 url = {http://arxiv.org/abs/2401.10794v1},
 year = {2024}
}

@article{2402.03661v1,
 abstract = {In this study, we present a transductive inference approach on that reward
information propagation graph, which enables the effective estimation of
rewards for unlabelled data in offline reinforcement learning. Reward inference
is the key to learning effective policies in practical scenarios, while direct
environmental interactions are either too costly or unethical and the reward
functions are rarely accessible, such as in healthcare and robotics. Our
research focuses on developing a reward inference method based on the
contextual properties of information propagation on graphs that capitalizes on
a constrained number of human reward annotations to infer rewards for
unlabelled data. We leverage both the available data and limited reward
annotations to construct a reward propagation graph, wherein the edge weights
incorporate various influential factors pertaining to the rewards.
Subsequently, we employ the constructed graph for transductive reward
inference, thereby estimating rewards for unlabelled data. Furthermore, we
establish the existence of a fixed point during several iterations of the
transductive inference process and demonstrate its at least convergence to a
local optimum. Empirical evaluations on locomotion and robotic manipulation
tasks validate the effectiveness of our approach. The application of our
inferred rewards improves the performance in offline reinforcement learning
tasks.},
 author = {Bohao Qu and Xiaofeng Cao and Qing Guo and Yi Chang and Ivor W. Tsang and Chengqi Zhang},
 comment = {},
 doi = {},
 eprint = {2402.03661v1},
 journal = {arXiv preprint},
 title = {Transductive Reward Inference on Graph},
 url = {http://arxiv.org/abs/2402.03661v1},
 year = {2024}
}

@article{2402.11123v1,
 abstract = {Warfarin, an anticoagulant medication, is formulated to prevent and address
conditions associated with abnormal blood clotting, making it one of the most
prescribed drugs globally. However, determining the suitable dosage remains
challenging due to individual response variations, and prescribing an incorrect
dosage may lead to severe consequences. Contextual bandit and reinforcement
learning have shown promise in addressing this issue. Given the wide
availability of observational data and safety concerns of decision-making in
healthcare, we focused on using exclusively observational data from historical
policies as demonstrations to derive new policies; we utilized offline policy
learning and evaluation in a contextual bandit setting to establish the optimal
personalized dosage strategy. Our learned policies surpassed these baseline
approaches without genotype inputs, even when given a suboptimal demonstration,
showcasing promising application potential.},
 author = {Yong Huang and Charles A. Downs and Amir M. Rahmani},
 comment = {},
 doi = {},
 eprint = {2402.11123v1},
 journal = {arXiv preprint},
 title = {Optimizing Warfarin Dosing Using Contextual Bandit: An Offline Policy Learning and Evaluation Method},
 url = {http://arxiv.org/abs/2402.11123v1},
 year = {2024}
}

@article{2402.15826v1,
 abstract = {Equipping agents with the capacity to justify made decisions using supporting
evidence represents a cornerstone of accountable decision-making. Furthermore,
ensuring that justifications are in line with human expectations and societal
norms is vital, especially in high-stakes situations such as healthcare. In
this work, we propose the use of a debate-based reward model for reinforcement
learning agents, where the outcome of a zero-sum debate game quantifies the
justifiability of a decision in a particular state. This reward model is then
used to train a justifiable policy, whose decisions can be more easily
corroborated with supporting evidence. In the debate game, two argumentative
agents take turns providing supporting evidence for two competing decisions.
Given the proposed evidence, a proxy of a human judge evaluates which decision
is better justified. We demonstrate the potential of our approach in learning
policies for prescribing and justifying treatment decisions of septic patients.
We show that augmenting the reward with the feedback signal generated by the
debate-based reward model yields policies highly favored by the judge when
compared to the policy obtained solely from the environment rewards, while
hardly sacrificing any performance. Moreover, in terms of the overall
performance and justifiability of trained policies, the debate-based feedback
is comparable to the feedback obtained from an ideal judge proxy that evaluates
decisions using the full information encoded in the state. This suggests that
the debate game outputs key information contained in states that is most
relevant for evaluating decisions, which in turn substantiates the practicality
of combining our approach with human-in-the-loop evaluations. Lastly, we
showcase that agents trained via multi-agent debate learn to propose evidence
that is resilient to refutations and closely aligns with human preferences.},
 author = {Aleksa Sukovic and Goran Radanovic},
 comment = {},
 doi = {},
 eprint = {2402.15826v1},
 journal = {arXiv preprint},
 title = {Reward Design for Justifiable Sequential Decision-Making},
 url = {http://arxiv.org/abs/2402.15826v1},
 year = {2024}
}

@article{2402.17003v2,
 abstract = {Online reinforcement learning (RL) algorithms offer great potential for
personalizing treatment for participants in clinical trials. However, deploying
an online, autonomous algorithm in the high-stakes healthcare setting makes
quality control and data quality especially difficult to achieve. This paper
proposes algorithm fidelity as a critical requirement for deploying online RL
algorithms in clinical trials. It emphasizes the responsibility of the
algorithm to (1) safeguard participants and (2) preserve the scientific utility
of the data for post-trial analyses. We also present a framework for
pre-deployment planning and real-time monitoring to help algorithm developers
and clinical researchers ensure algorithm fidelity. To illustrate our
framework's practical application, we present real-world examples from the
Oralytics clinical trial. Since Spring 2023, this trial successfully deployed
an autonomous, online RL algorithm to personalize behavioral interventions for
participants at risk for dental disease.},
 author = {Anna L. Trella and Kelly W. Zhang and Inbal Nahum-Shani and Vivek Shetty and Iris Yan and Finale Doshi-Velez and Susan A. Murphy},
 comment = {},
 doi = {},
 eprint = {2402.17003v2},
 journal = {arXiv preprint},
 title = {Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials},
 url = {http://arxiv.org/abs/2402.17003v2},
 year = {2024}
}

@article{2402.17501v2,
 abstract = {Reinforcement Learning in Healthcare is typically concerned with narrow
self-contained tasks such as sepsis prediction or anesthesia control. However,
previous research has demonstrated the potential of generalist models (the
prime example being Large Language Models) to outperform task-specific
approaches due to their capability for implicit transfer learning. To enable
training of foundation models for Healthcare as well as leverage the
capabilities of state of the art Transformer architectures, we propose the
paradigm of Healthcare as Sequence Modeling, in which interaction between the
patient and the healthcare provider is represented as an event stream and tasks
like diagnosis and treatment selection are modeled as prediction of future
events in the stream. To explore this paradigm experimentally we develop
MIMIC-SEQ, a sequence modeling benchmark derived by translating heterogenous
clinical records from MIMIC-IV dataset into a uniform event stream format,
train a baseline model and explore its capabilities.},
 author = {Vadim Liventsev and Tobias Fritz},
 comment = {},
 doi = {},
 eprint = {2402.17501v2},
 journal = {arXiv preprint},
 title = {Intensive Care as One Big Sequence Modeling Problem},
 url = {http://arxiv.org/abs/2402.17501v2},
 year = {2024}
}

@article{2402.19226v3,
 abstract = {Chronic pain significantly diminishes the quality of life for millions
worldwide. While psychoeducation and therapy can improve pain outcomes, many
individuals experiencing pain lack access to evidence-based treatments or fail
to complete the necessary number of sessions to achieve benefit. Reinforcement
learning (RL) shows potential in tailoring personalized pain management
interventions according to patients' individual needs while ensuring the
efficient use of scarce clinical resources. However, clinicians, patients, and
healthcare decision-makers are concerned that RL solutions could exacerbate
disparities associated with patient characteristics like race or gender. In
this article, we study gender fairness in personalized pain care
recommendations using a real-world application of reinforcement learning
(Piette et al., 2022a). Here, adhering to gender fairness translates to minimal
or no disparity in the utility received by subpopulations as defined by gender.
We investigate whether the selection of relevant patient information (referred
to as features) used to assist decision-making affects gender fairness. Our
experiments, conducted using real-world data Piette, 2022), indicate that
included features can impact gender fairness. Moreover, we propose an RL
solution, NestedRecommendation, that demonstrates the ability: i) to adaptively
learn to select the features that optimize for utility and fairness, and ii) to
accelerate feature selection and in turn, improve pain care recommendations
from early on, by leveraging clinicians' domain expertise.},
 author = {Pratik Gajane and Sean Newman and Mykola Pechenizkiy and John D. Piette},
 comment = {},
 doi = {},
 eprint = {2402.19226v3},
 journal = {arXiv preprint},
 title = {Investigating Gender Fairness in Machine Learning-driven Personalized Care for Chronic Pain},
 url = {http://arxiv.org/abs/2402.19226v3},
 year = {2024}
}

@article{2403.00254v1,
 abstract = {In contemporary rural healthcare settings, the principal challenge in
diagnosing brain images is the scarcity of available data, given that most of
the existing deep learning models demand extensive training data to optimize
their performance, necessitating centralized processing methods that
potentially compromise data privacy. This paper proposes a novel framework
tailored for brain tissue segmentation in rural healthcare facilities. The
framework employs a deep reinforcement learning (DRL) environment in tandem
with a refinement model (RM) deployed locally at rural healthcare sites. The
proposed DRL model has a reduced parameter count and practicality for
implementation across distributed rural sites. To uphold data privacy and
enhance model generalization without transgressing privacy constraints, we
employ federated learning (FL) for cooperative model training. We demonstrate
the efficacy of our approach by training the network with a limited data set
and observing a substantial performance enhancement, mitigating inaccuracies
and irregularities in segmentation across diverse sites. Remarkably, the DRL
model attains an accuracy of up to 80%, surpassing the capabilities of
conventional convolutional neural networks when confronted with data
insufficiency. Incorporating our RM results in an additional accuracy
improvement of at least 10%, while FL contributes to a further accuracy
enhancement of up to 5%. Collectively, the framework achieves an average 92%
accuracy rate within rural healthcare settings characterized by data
constraints.},
 author = {Rukesh Prajapati and Amr S. El-Wakeel},
 comment = {},
 doi = {10.1109/ICC51166.2024.10622470},
 eprint = {2403.00254v1},
 journal = {arXiv preprint},
 title = {Cloud-based Federated Learning Framework for MRI Segmentation},
 url = {http://arxiv.org/abs/2403.00254v1},
 year = {2024}
}

@article{2403.00344v2,
 abstract = {Autonomous assistance of people with motor impairments is one of the most
promising applications of autonomous robotic systems. Recent studies have
reported encouraging results using deep reinforcement learning (RL) in the
healthcare domain. Previous studies showed that assistive tasks can be
formulated as multi-agent RL, wherein there are two agents: a caregiver and a
care-receiver. However, policies trained in multi-agent RL are often sensitive
to the policies of other agents. In such a case, a trained caregiver's policy
may not work for different care-receivers. To alleviate this issue, we propose
a framework that learns a robust caregiver's policy by training it for diverse
care-receiver responses. In our framework, diverse care-receiver responses are
autonomously learned through trials and errors. In addition, to robustify the
care-giver's policy, we propose a strategy for sampling a care-receiver's
response in an adversarial manner during the training. We evaluated the
proposed method using tasks in an Assistive Gym. We demonstrate that policies
trained with a popular deep RL method are vulnerable to changes in policies of
other agents and that the proposed framework improves the robustness against
such changes.},
 author = {Takayuki Osa and Tatsuya Harada},
 comment = {7 pages, accepted for ICRA 2024},
 doi = {},
 eprint = {2403.00344v2},
 journal = {arXiv preprint},
 title = {Robustifying a Policy in Multi-Agent RL with Diverse Cooperative Behaviors and Adversarial Style Sampling for Assistive Tasks},
 url = {http://arxiv.org/abs/2403.00344v2},
 year = {2024}
}

@article{2403.00830v1,
 abstract = {Large language models (LLMs) are revolutionizing various domains with their
remarkable natural language processing (NLP) abilities. However, deploying LLMs
in resource-constrained edge computing and embedded systems presents
significant challenges. Another challenge lies in delivering medical assistance
in remote areas with limited healthcare facilities and infrastructure. To
address this, we introduce MedAide, an on-premise healthcare chatbot. It
leverages tiny-LLMs integrated with LangChain, providing efficient edge-based
preliminary medical diagnostics and support. MedAide employs model
optimizations for minimal memory footprint and latency on embedded edge devices
without server infrastructure. The training process is optimized using low-rank
adaptation (LoRA). Additionally, the model is trained on diverse medical
datasets, employing reinforcement learning from human feedback (RLHF) to
enhance its domain-specific capabilities. The system is implemented on various
consumer GPUs and Nvidia Jetson development board. MedAide achieves 77\%
accuracy in medical consultations and scores 56 in USMLE benchmark, enabling an
energy-efficient healthcare assistance platform that alleviates privacy
concerns due to edge-based deployment, thereby empowering the community.},
 author = {Abdul Basit and Khizar Hussain and Muhammad Abdullah Hanif and Muhammad Shafique},
 comment = {7 pages, 11 figures, ACM conference paper, 33 references},
 doi = {},
 eprint = {2403.00830v1},
 journal = {arXiv preprint},
 title = {MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices},
 url = {http://arxiv.org/abs/2403.00830v1},
 year = {2024}
}

@article{2403.04416v1,
 abstract = {Routing Protocol for Low Power and Lossy Networks (RPL) is the de-facto
routing standard in IoT networks. It enables nodes to collaborate and
autonomously build ad-hoc networks modeled by tree-like destination-oriented
direct acyclic graphs (DODAG). Despite its widespread usage in industry and
healthcare domains, RPL is susceptible to insider attacks. Although the
state-of-the-art RPL ensures that only authenticated nodes participate in
DODAG, such hard security measures are still inadequate to prevent insider
threats. This entails a need to integrate soft security mechanisms to support
decision-making. This paper proposes iTRPL, an intelligent and behavior-based
framework that incorporates trust to segregate honest and malicious nodes
within a DODAG. It also leverages multi-agent reinforcement learning (MARL) to
make autonomous decisions concerning the DODAG. The framework enables a parent
node to compute the trust for its child and decide if the latter can join the
DODAG. It tracks the behavior of the child node, updates the trust, computes
the rewards (or penalties), and shares with the root. The root aggregates the
rewards/penalties of all nodes, computes the overall return, and decides via
its $\epsilon$-Greedy MARL module if the DODAG will be retained or modified for
the future. A simulation-based performance evaluation demonstrates that iTRPL
learns to make optimal decisions with time.},
 author = {Debasmita Dey and Nirnay Ghosh},
 comment = {},
 doi = {},
 eprint = {2403.04416v1},
 journal = {arXiv preprint},
 title = {iTRPL: An Intelligent and Trusted RPL Protocol based on Multi-Agent Reinforcement Learning},
 url = {http://arxiv.org/abs/2403.04416v1},
 year = {2024}
}

@article{2403.05106v2,
 abstract = {Advances in Tiny Machine Learning (TinyML) have bolstered the creation of
smart industry solutions, including smart agriculture, healthcare and smart
cities. Whilst related research contributes to enabling TinyML solutions on
constrained hardware, there is a need to amplify real-world applications by
optimising energy consumption in battery-powered systems. The work presented
extends and contributes to TinyML research by optimising battery-powered
image-based anomaly detection Internet of Things (IoT) systems. Whilst previous
work in this area has yielded the capabilities of on-device inferencing and
training, there has yet to be an investigation into optimising the management
of such capabilities using machine learning approaches, such as Reinforcement
Learning (RL), to improve the deployment battery life of such systems. Using
modelled simulations, the battery life effects of an RL algorithm are
benchmarked against static and dynamic optimisation approaches, with the
foundation laid for a hardware benchmark to follow. It is shown that using RL
within a TinyML-enabled IoT system to optimise the system operations, including
cloud anomaly processing and on-device training, yields an improved battery
life of 22.86% and 10.86% compared to static and dynamic optimisation
approaches respectively. The proposed solution can be deployed to
resource-constrained hardware, given its low memory footprint of 800 B, which
could be further reduced. This further facilitates the real-world deployment of
such systems, including key sectors such as smart agriculture.},
 author = {Jared M. Ping and Ken J. Nixon},
 comment = {Accepted as a full paper by the tinyML Research Symposium 2024},
 doi = {},
 eprint = {2403.05106v2},
 journal = {arXiv preprint},
 title = {Simulating Battery-Powered TinyML Systems Optimised using Reinforcement Learning in Image-Based Anomaly Detection},
 url = {http://arxiv.org/abs/2403.05106v2},
 year = {2024}
}

@article{2403.07309v1,
 abstract = {Sepsis, a life-threatening condition triggered by the body's exaggerated
response to infection, demands urgent intervention to prevent severe
complications. Existing machine learning methods for managing sepsis struggle
in offline scenarios, exhibiting suboptimal performance with survival rates
below 50%. This paper introduces the POSNEGDM -- ``Reinforcement Learning with
Positive and Negative Demonstrations for Sequential Decision-Making" framework
utilizing an innovative transformer-based model and a feedback reinforcer to
replicate expert actions while considering individual patient characteristics.
A mortality classifier with 96.7\% accuracy guides treatment decisions towards
positive outcomes. The POSNEGDM framework significantly improves patient
survival, saving 97.39% of patients, outperforming established machine learning
algorithms (Decision Transformer and Behavioral Cloning) with survival rates of
33.4% and 43.5%, respectively. Additionally, ablation studies underscore the
critical role of the transformer-based decision maker and the integration of a
mortality classifier in enhancing overall survival rates. In summary, our
proposed approach presents a promising avenue for enhancing sepsis treatment
outcomes, contributing to improved patient care and reduced healthcare costs.},
 author = {Dipesh Tamboli and Jiayu Chen and Kiran Pranesh Jotheeswaran and Denny Yu and Vaneet Aggarwal},
 comment = {Accepted to IEEE Journal of Biomedical and Health Informatics, Mar
  2024},
 doi = {},
 eprint = {2403.07309v1},
 journal = {arXiv preprint},
 title = {Reinforced Sequential Decision-Making for Sepsis Treatment: The POSNEGDM Framework with Mortality Classifier and Transformer},
 url = {http://arxiv.org/abs/2403.07309v1},
 year = {2024}
}

@article{2403.08377v1,
 abstract = {Adverse drug-drug interactions~(DDIs) can compromise the effectiveness of
concurrent drug administration, posing a significant challenge in healthcare.
As the development of new drugs continues, the potential for unknown adverse
effects resulting from DDIs becomes a growing concern. Traditional
computational methods for DDI prediction may fail to capture interactions for
new drugs due to the lack of knowledge. In this paper, we introduce a new
problem setup as zero-shot DDI prediction that deals with the case of new
drugs. Leveraging textual information from online databases like DrugBank and
PubChem, we propose an innovative approach TextDDI with a language model-based
DDI predictor and a reinforcement learning~(RL)-based information selector,
enabling the selection of concise and pertinent text for accurate DDI
prediction on new drugs. Empirical results show the benefits of the proposed
approach on several settings including zero-shot and few-shot DDI prediction,
and the selected texts are semantically relevant. Our code and data are
available at \url{https://github.com/zhufq00/DDIs-Prediction}.},
 author = {Fangqi Zhu and Yongqi Zhang and Lei Chen and Bing Qin and Ruifeng Xu},
 comment = {},
 doi = {10.18653/v1/2023.emnlp-main.918},
 eprint = {2403.08377v1},
 journal = {arXiv preprint},
 title = {Learning to Describe for Predicting Zero-shot Drug-Drug Interactions},
 url = {http://arxiv.org/abs/2403.08377v1},
 year = {2024}
}

@article{2403.10946v2,
 abstract = {Online Reinforcement Learning (RL) is typically framed as the process of
minimizing cumulative regret (CR) through interactions with an unknown
environment. However, real-world RL applications usually involve a sequence of
tasks, and the data collected in the first task is used to warm-start the
second task. The performance of the warm-start policy is measured by simple
regret (SR). While minimizing both CR and SR is generally a conflicting
objective, previous research has shown that in stationary environments, both
can be optimized in terms of the duration of the task, $T$.
  In practice, however, in real-world applications, human-in-the-loop decisions
between tasks often results in non-stationarity. For instance, in clinical
trials, scientists may adjust target health outcomes between implementations.
Our results show that task non-stationarity leads to a more restrictive
trade-off between CR and SR. To balance these competing goals, the algorithm
must explore excessively, leading to a CR bound worse than the typical optimal
rate of $T^{1/2}$. These findings are practically significant, indicating that
increased exploration is necessary in non-stationary environments to
accommodate task changes, impacting the design of RL algorithms in fields such
as healthcare and beyond.},
 author = {Ziping Xu and Kelly W. Zhang and Susan A. Murphy},
 comment = {},
 doi = {},
 eprint = {2403.10946v2},
 journal = {arXiv preprint},
 title = {The Fallacy of Minimizing Cumulative Regret in the Sequential Task Setting},
 url = {http://arxiv.org/abs/2403.10946v2},
 year = {2024}
}

@article{2403.11219v1,
 abstract = {Causality has become a fundamental approach for explaining the relationships
between events, phenomena, and outcomes in various fields of study. It has
invaded various fields and applications, such as medicine, healthcare,
economics, finance, fraud detection, cybersecurity, education, public policy,
recommender systems, anomaly detection, robotics, control, sociology,
marketing, and advertising. In this paper, we survey its development over the
past five decades, shedding light on the differences between causality and
other approaches, as well as the preconditions for using it. Furthermore, the
paper illustrates how causality interacts with new approaches such as
Artificial Intelligence (AI), Generative AI (GAI), Machine and Deep Learning,
Reinforcement Learning (RL), and Fuzzy Logic. We study the impact of causality
on various fields, its contribution, and its interaction with state-of-the-art
approaches. Additionally, the paper exemplifies the trustworthiness and
explainability of causality models. We offer several ways to evaluate causality
models and discuss future directions.},
 author = {Abraham Itzhak Weinberg and Cristiano Premebida and Diego Resende Faria},
 comment = {},
 doi = {},
 eprint = {2403.11219v1},
 journal = {arXiv preprint},
 title = {Causality from Bottom to Top: A Survey},
 url = {http://arxiv.org/abs/2403.11219v1},
 year = {2024}
}

@article{2404.03105v2,
 abstract = {Mechanical ventilation is a critical life support intervention that delivers
controlled air and oxygen to a patient's lungs, assisting or replacing
spontaneous breathing. While several data-driven approaches have been proposed
to optimize ventilator control strategies, they often lack interpretability and
alignment with domain knowledge, hindering clinical adoption. This paper
presents a methodology for interpretable reinforcement learning (RL) aimed at
improving mechanical ventilation control as part of connected health systems.
Using a causal, nonparametric model-based off-policy evaluation, we assess RL
policies for their ability to enhance patient-specific outcomes-specifically,
increasing blood oxygen levels (SpO2), while avoiding aggressive ventilator
settings that may cause ventilator-induced lung injuries and other
complications. Through numerical experiments on real-world ICU data from the
MIMIC-III database, we demonstrate that our interpretable decision tree policy
achieves performance comparable to state-of-the-art deep RL methods while
outperforming standard behavior cloning approaches. The results highlight the
potential of interpretable, data-driven decision support systems to improve
safety and efficiency in personalized ventilation strategies, paving the way
for seamless integration into connected healthcare environments.},
 author = {Joo Seung Lee and Malini Mahendra and Anil Aswani},
 comment = {},
 doi = {},
 eprint = {2404.03105v2},
 journal = {arXiv preprint},
 title = {Methodology for Interpretable Reinforcement Learning for Optimizing Mechanical Ventilation},
 url = {http://arxiv.org/abs/2404.03105v2},
 year = {2024}
}

@article{2404.07266v3,
 abstract = {We study the problem of online sequential decision-making given auxiliary
demonstrations from experts who made their decisions based on unobserved
contextual information. These demonstrations can be viewed as solving related
but slightly different problems than what the learner faces. This setting
arises in many application domains, such as self-driving cars, healthcare, and
finance, where expert demonstrations are made using contextual information,
which is not recorded in the data available to the learning agent. We model the
problem as zero-shot meta-reinforcement learning with an unknown distribution
over the unobserved contextual variables and a Bayesian regret minimization
objective, where the unobserved variables are encoded as parameters with an
unknown prior. We propose the Experts-as-Priors algorithm (ExPerior), an
empirical Bayes approach that utilizes expert data to establish an informative
prior distribution over the learner's decision-making problem. This prior
distribution enables the application of any Bayesian approach for online
decision-making, such as posterior sampling. We demonstrate that our strategy
surpasses existing behaviour cloning, online, and online-offline baselines for
multi-armed bandits, Markov decision processes (MDPs), and partially observable
MDPs, showcasing the broad reach and utility of ExPerior in using expert
demonstrations across different decision-making setups.},
 author = {Vahid Balazadeh and Keertana Chidambaram and Viet Nguyen and Rahul G. Krishnan and Vasilis Syrgkanis},
 comment = {},
 doi = {},
 eprint = {2404.07266v3},
 journal = {arXiv preprint},
 title = {Sequential Decision Making with Expert Demonstrations under Unobserved Heterogeneity},
 url = {http://arxiv.org/abs/2404.07266v3},
 year = {2024}
}

@article{2404.07465v2,
 abstract = {Offline reinforcement learning (RL) is vital in areas where active data
collection is expensive or infeasible, such as robotics or healthcare. In the
real world, offline datasets often involve multiple domains that share the same
state and action spaces but have distinct dynamics, and only a small fraction
of samples are clearly labeled as belonging to the target domain we are
interested in. For example, in robotics, precise system identification may only
have been performed for part of the deployments. To address this challenge, we
consider Positive-Unlabeled Offline RL (PUORL), a novel offline RL setting in
which we have a small amount of labeled target-domain data and a large amount
of domain-unlabeled data from multiple domains, including the target domain.
For PUORL, we propose a plug-and-play approach that leverages
positive-unlabeled (PU) learning to train a domain classifier. The classifier
then extracts target-domain samples from the domain-unlabeled data, augmenting
the scarce target-domain data. Empirical results on a modified version of the
D4RL benchmark demonstrate the effectiveness of our method: even when only 1 to
3 percent of the dataset is domain-labeled, our approach accurately identifies
target-domain samples and achieves high performance, even under substantial
dynamics shift. Our plug-and-play algorithm seamlessly integrates PU learning
with existing offline RL pipelines, enabling effective multi-domain data
utilization in scenarios where comprehensive domain labeling is prohibitive.},
 author = {Soichiro Nishimori and Xin-Qiang Cai and Johannes Ackermann and Masashi Sugiyama},
 comment = {},
 doi = {},
 eprint = {2404.07465v2},
 journal = {arXiv preprint},
 title = {Offline Reinforcement Learning with Domain-Unlabeled Data},
 url = {http://arxiv.org/abs/2404.07465v2},
 year = {2024}
}

@article{2404.12530v2,
 abstract = {Reinforcement learning (RL) trains an agent from experiences interacting with
the environment. In scenarios where online interactions are impractical,
offline RL, which trains the agent using pre-collected datasets, has become
popular. While this new paradigm presents remarkable effectiveness across
various real-world domains, like healthcare and energy management, there is a
growing demand to enable agents to rapidly and completely eliminate the
influence of specific trajectories from both the training dataset and the
trained agents. To meet this problem, this paper advocates Trajdeleter, the
first practical approach to trajectory unlearning for offline RL agents. The
key idea of Trajdeleter is to guide the agent to demonstrate deteriorating
performance when it encounters states associated with unlearning trajectories.
Simultaneously, it ensures the agent maintains its original performance level
when facing other remaining trajectories. Additionally, we introduce
Trajauditor, a simple yet efficient method to evaluate whether Trajdeleter
successfully eliminates the specific trajectories of influence from the offline
RL agent. Extensive experiments conducted on six offline RL algorithms and
three tasks demonstrate that Trajdeleter requires only about 1.5% of the time
needed for retraining from scratch. It effectively unlearns an average of 94.8%
of the targeted trajectories yet still performs well in actual environment
interactions after unlearning. The replication package and agent parameters are
available online.},
 author = {Chen Gong and Kecen Li and Jin Yao and Tianhao Wang},
 comment = {Accepted at NDSS 2025. The presented document here is the full
  version of our paper},
 doi = {},
 eprint = {2404.12530v2},
 journal = {arXiv preprint},
 title = {TrajDeleter: Enabling Trajectory Forgetting in Offline Reinforcement Learning Agents},
 url = {http://arxiv.org/abs/2404.12530v2},
 year = {2024}
}

@article{2404.16621v1,
 abstract = {The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.},
 author = {Emre Can Acikgoz and Osman Batur İnce and Rayene Bench and Arda Anıl Boz and İlker Kesen and Aykut Erdem and Erkut Erdem},
 comment = {},
 doi = {},
 eprint = {2404.16621v1},
 journal = {arXiv preprint},
 title = {Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare},
 url = {http://arxiv.org/abs/2404.16621v1},
 year = {2024}
}

@article{2405.00715v6,
 abstract = {Proprietary Large Language Models (LLMs) such as GPT-4 and Gemini have
demonstrated promising capabilities in clinical text summarization tasks.
However, due to patient data privacy concerns and computational costs, many
healthcare providers prefer using small, locally-hosted models over external
generic LLMs. This study presents a comprehensive domain- and task-specific
adaptation process for the open-source LLaMA-2 13 billion parameter model,
enabling it to generate high-quality clinical notes from outpatient
patient-doctor dialogues. Our process incorporates continued pretraining,
supervised fine-tuning, and reinforcement learning from both AI and human
feedback. We introduced a new approach, DistillDirect, for performing on-policy
reinforcement learning with Gemini 1.0 Pro as the teacher model. Our resulting
model, LLaMA-Clinic, can generate clinical notes comparable in quality to those
authored by physicians. In a blinded physician reader study, the majority
(92.8%) of individual evaluations rated the notes generated by LLaMA-Clinic as
"acceptable" or higher across three criteria: real-world readiness,
completeness, and accuracy. In the more challenging "Assessment and Plan"
section, LLaMA-Clinic matched physician-authored notes in real-world readiness
score. We highlight key considerations for future clinical note-generation
tasks, emphasizing the importance of pre-defining a "best practice" note
format, rather than relying on LLMs to determine this for clinical practice.},
 author = {Hanyin Wang and Chufan Gao and Bolun Liu and Qiping Xu and Guleid Hussein and Mohamad El Labban and Kingsley Iheasirim and Hariprasad Korsapati and Chuck Outcalt and Jimeng Sun},
 comment = {},
 doi = {},
 eprint = {2405.00715v6},
 journal = {arXiv preprint},
 title = {Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation},
 url = {http://arxiv.org/abs/2405.00715v6},
 year = {2024}
}

@article{2405.01994v1,
 abstract = {This thesis aims to study some of the mathematical challenges that arise in
the analysis of statistical sequential decision-making algorithms for
postoperative patients follow-up. Stochastic bandits (multiarmed, contextual)
model the learning of a sequence of actions (policy) by an agent in an
uncertain environment in order to maximise observed rewards. To learn optimal
policies, bandit algorithms have to balance the exploitation of current
knowledge and the exploration of uncertain actions. Such algorithms have
largely been studied and deployed in industrial applications with large
datasets, low-risk decisions and clear modelling assumptions, such as
clickthrough rate maximisation in online advertising. By contrast, digital
health recommendations call for a whole new paradigm of small samples,
risk-averse agents and complex, nonparametric modelling. To this end, we
developed new safe, anytime-valid concentration bounds, (Bregman, empirical
Chernoff), introduced a new framework for risk-aware contextual bandits (with
elicitable risk measures) and analysed a novel class of nonparametric bandit
algorithms under weak assumptions (Dirichlet sampling). In addition to the
theoretical guarantees, these results are supported by in-depth empirical
evidence. Finally, as a first step towards personalised postoperative follow-up
recommendations, we developed with medical doctors and surgeons an
interpretable machine learning model to predict the long-term weight
trajectories of patients after bariatric surgery.},
 author = {Patrick Saux},
 comment = {Doctoral thesis. Some pdf readers (e.g. Firefox) have trouble
  rendering the theorems/definitions environment. When reading online, please
  prefer e.g. Chrome},
 doi = {},
 eprint = {2405.01994v1},
 journal = {arXiv preprint},
 title = {Mathematics of statistical sequential decision-making: concentration, risk-awareness and modelling in stochastic bandits, with applications to bariatric surgery},
 url = {http://arxiv.org/abs/2405.01994v1},
 year = {2024}
}

@article{2405.02770v2,
 abstract = {The use of machine learning in Healthcare has the potential to improve
patient outcomes as well as broaden the reach and affordability of Healthcare.
The history of other application areas indicates that strong benchmarks are
essential for the development of intelligent systems. We present Personal
Health Interfaces Leveraging HUman-MAchine Natural interactions (PhilHumans), a
holistic suite of benchmarks for machine learning across different Healthcare
settings - talk therapy, diet coaching, emergency care, intensive care,
obstetric sonography - as well as different learning settings, such as action
anticipation, timeseries modeling, insight mining, language modeling, computer
vision, reinforcement learning and program synthesis},
 author = {Vadim Liventsev and Vivek Kumar and Allmin Pradhap Singh Susaiyah and Zixiu Wu and Ivan Rodin and Asfand Yaar and Simone Balloccu and Marharyta Beraziuk and Sebastiano Battiato and Giovanni Maria Farinella and Aki Härmä and Rim Helaoui and Milan Petkovic and Diego Reforgiato Recupero and Ehud Reiter and Daniele Riboni and Raymond Sterling},
 comment = {},
 doi = {},
 eprint = {2405.02770v2},
 journal = {arXiv preprint},
 title = {PhilHumans: Benchmarking Machine Learning for Personal Health},
 url = {http://arxiv.org/abs/2405.02770v2},
 year = {2024}
}

@article{2405.03236v1,
 abstract = {We study a Federated Reinforcement Learning (FedRL) problem with constraint
heterogeneity. In our setting, we aim to solve a reinforcement learning problem
with multiple constraints while $N$ training agents are located in $N$
different environments with limited access to the constraint signals and they
are expected to collaboratively learn a policy satisfying all constraint
signals. Such learning problems are prevalent in scenarios of Large Language
Model (LLM) fine-tuning and healthcare applications. To solve the problem, we
propose federated primal-dual policy optimization methods based on traditional
policy gradient methods. Specifically, we introduce $N$ local Lagrange
functions for agents to perform local policy updates, and these agents are then
scheduled to periodically communicate on their local policies. Taking natural
policy gradient (NPG) and proximal policy optimization (PPO) as policy
optimization methods, we mainly focus on two instances of our algorithms, ie,
{FedNPG} and {FedPPO}. We show that FedNPG achieves global convergence with an
$\tilde{O}(1/\sqrt{T})$ rate, and FedPPO efficiently solves complicated
learning tasks with the use of deep neural networks.},
 author = {Hao Jin and Liangyu Zhang and Zhihua Zhang},
 comment = {},
 doi = {},
 eprint = {2405.03236v1},
 journal = {arXiv preprint},
 title = {Federated Reinforcement Learning with Constraint Heterogeneity},
 url = {http://arxiv.org/abs/2405.03236v1},
 year = {2024}
}

@article{2405.06784v1,
 abstract = {This survey explores the transformative impact of foundation models (FMs) in
artificial intelligence, focusing on their integration with federated learning
(FL) for advancing biomedical research. Foundation models such as ChatGPT,
LLaMa, and CLIP, which are trained on vast datasets through methods including
unsupervised pretraining, self-supervised learning, instructed fine-tuning, and
reinforcement learning from human feedback, represent significant advancements
in machine learning. These models, with their ability to generate coherent text
and realistic images, are crucial for biomedical applications that require
processing diverse data forms such as clinical reports, diagnostic images, and
multimodal patient interactions.
  The incorporation of FL with these sophisticated models presents a promising
strategy to harness their analytical power while safeguarding the privacy of
sensitive medical data. This approach not only enhances the capabilities of FMs
in medical diagnostics and personalized treatment but also addresses critical
concerns about data privacy and security in healthcare. This survey reviews the
current applications of FMs in federated settings, underscores the challenges,
and identifies future research directions including scaling FMs, managing data
diversity, and enhancing communication efficiency within FL frameworks. The
objective is to encourage further research into the combined potential of FMs
and FL, laying the groundwork for groundbreaking healthcare innovations.},
 author = {Xingyu Li and Lu Peng and Yuping Wang and Weihua Zhang},
 comment = {42 pages},
 doi = {},
 eprint = {2405.06784v1},
 journal = {arXiv preprint},
 title = {Open Challenges and Opportunities in Federated Foundation Models Towards Biomedical Healthcare},
 url = {http://arxiv.org/abs/2405.06784v1},
 year = {2024}
}

@article{2405.18556v2,
 abstract = {In the rapidly changing healthcare landscape, the implementation of offline
reinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix
of unprecedented opportunities and challenges. This position paper offers a
critical examination of the current status of offline RL in the context of
DTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such
as inconsistent and potentially inconclusive evaluation metrics, the absence of
naive and supervised learning baselines, and the diverse choice of RL
formulation in existing research. Through a case study with more than 17,000
evaluation experiments using a publicly available Sepsis dataset, we
demonstrate that the performance of RL algorithms can significantly vary with
changes in evaluation metrics and Markov Decision Process (MDP) formulations.
Surprisingly, it is observed that in some instances, RL algorithms can be
surpassed by random baselines subjected to policy evaluation methods and reward
design. This calls for more careful policy evaluation and algorithm development
in future DTR works. Additionally, we discussed potential enhancements toward
more reliable development of RL-based dynamic treatment regimes and invited
further discussion within the community. Code is available at
https://github.com/GilesLuo/ReassessDTR.},
 author = {Zhiyao Luo and Yangchen Pan and Peter Watkinson and Tingting Zhu},
 comment = {Accepted at ICML 2024. 9 pages for main content, 34 pages in total},
 doi = {},
 eprint = {2405.18556v2},
 journal = {arXiv preprint},
 title = {Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination},
 url = {http://arxiv.org/abs/2405.18556v2},
 year = {2024}
}

@article{2405.18610v1,
 abstract = {Reinforcement learning (RL) has garnered increasing recognition for its
potential to optimise dynamic treatment regimes (DTRs) in personalised
medicine, particularly for drug dosage prescriptions and medication
recommendations. However, a significant challenge persists: the absence of a
unified framework for simulating diverse healthcare scenarios and a
comprehensive analysis to benchmark the effectiveness of RL algorithms within
these contexts. To address this gap, we introduce \textit{DTR-Bench}, a
benchmarking platform comprising four distinct simulation environments tailored
to common DTR applications, including cancer chemotherapy, radiotherapy,
glucose management in diabetes, and sepsis treatment. We evaluate various
state-of-the-art RL algorithms across these settings, particularly highlighting
their performance amidst real-world challenges such as
pharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.
Our experiments reveal varying degrees of performance degradation among RL
algorithms in the presence of noise and patient variability, with some
algorithms failing to converge. Additionally, we observe that using temporal
observation representations does not consistently lead to improved performance
in DTR settings. Our findings underscore the necessity of developing robust,
adaptive RL algorithms capable of effectively managing these complexities to
enhance patient-specific healthcare. We have open-sourced our benchmark and
code at https://github.com/GilesLuo/DTR-Bench.},
 author = {Zhiyao Luo and Mingcheng Zhu and Fenglin Liu and Jiali Li and Yangchen Pan and Jiandong Zhou and Tingting Zhu},
 comment = {13 pages for main content},
 doi = {},
 eprint = {2405.18610v1},
 journal = {arXiv preprint},
 title = {DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime},
 url = {http://arxiv.org/abs/2405.18610v1},
 year = {2024}
}

@article{2405.20038v1,
 abstract = {The rise of new complex attacks scenarios in Internet of things (IoT)
environments necessitate more advanced and intelligent cyber defense techniques
such as various Intrusion Detection Systems (IDSs) which are responsible for
detecting and mitigating malicious activities in IoT networks without human
intervention. To address this issue, deep reinforcement learning (DRL) has been
proposed in recent years, to automatically tackle intrusions/attacks. In this
paper, a comprehensive survey of DRL-based IDS on IoT is presented.
Furthermore, in this survey, the state-of-the-art DRL-based IDS methods have
been classified into five categories including wireless sensor network (WSN),
deep Q-network (DQN), healthcare, hybrid, and other techniques. In addition,
the most crucial performance metrics, namely accuracy, recall, precision, false
negative rate (FNR), false positive rate (FPR), and F-measure, are detailed, in
order to evaluate the performance of each proposed method. The paper provides a
summary of datasets utilized in the studies as well.},
 author = {Afrah Gueriani and Hamza Kheddar and Ahmed Cherif Mazari},
 comment = {},
 doi = {10.1109/IC2EM59347.2023.10419560},
 eprint = {2405.20038v1},
 journal = {arXiv preprint},
 title = {Deep Reinforcement Learning for Intrusion Detection in IoT: A Survey},
 url = {http://arxiv.org/abs/2405.20038v1},
 year = {2024}
}

@article{2406.04505v2,
 abstract = {Clustering and dependence are common in trials. For example, in some cluster
randomized trials (CRTs), pre-existing clusters are enrolled, randomized, and
serve as the basis of intervention delivery. Such CRTs are "fully clustered":
participants are dependent within clusters. In contrast, "partially clustered"
trials contain a mix of participants that are dependent within clusters and
participants that are completely independent. One example of this design is a
trial where participants are artificially grouped together for the purposes of
randomization only; then, for intervention participants, the groups are the
basis for intervention delivery, while control participants are un-grouped.
Another example is an individually randomized group treatment trial (IRGTT)
where participants are individually randomized and, post-randomization,
intervention participants are grouped for intervention delivery, while the
control participants remain un-grouped. For the three trial designs, we use
causal models to non-parametrically describe the data generating process and
formalize the observed data dependence structure. We show that despite the
different randomization approach, both designs can be represented with the same
dependence structure, enabling the use of the same statistical methods for
estimation and inference of causal effects. We propose a novel implementation
of targeted minimum loss-based estimation (TMLE) for these trials. TMLE is
model-robust, leverages covariate adjustment and machine learning, and
estimates many causal effects. In simulations, TMLE achieved comparable higher
statistical power than alternatives for partially clustered designs. Finally,
application to real data from the SEARCH-IPT trial resulted in 20-57%
efficiency gains, demonstrating the consequences of our proposed approach.},
 author = {Joshua Nugent and Elijah Kakande and Gabriel Chamie and Jane Kabami and Asiphas Owaraganise and Diane V. Havlir and Moses Kamya and Laura Balzer},
 comment = {},
 doi = {},
 eprint = {2406.04505v2},
 journal = {arXiv preprint},
 title = {Causal Inference in Randomized Trials with Partial Clustering},
 url = {http://arxiv.org/abs/2406.04505v2},
 year = {2024}
}

@article{2406.04963v1,
 abstract = {Real-world data generation often involves certain geometries (e.g., graphs)
that induce instance-level interdependence. This characteristic makes the
generalization of learning models more difficult due to the intricate
interdependent patterns that impact data-generative distributions and can vary
from training to testing. In this work, we propose a geometric diffusion model
with learnable divergence fields for the challenging generalization problem
with interdependent data. We generalize the diffusion equation with stochastic
diffusivity at each time step, which aims to capture the multi-faceted
information flows among interdependent data. Furthermore, we derive a new
learning objective through causal inference, which can guide the model to learn
generalizable patterns of interdependence that are insensitive across domains.
Regarding practical implementation, we introduce three model instantiations
that can be considered as the generalized versions of GCN, GAT, and
Transformers, respectively, which possess advanced robustness against
distribution shifts. We demonstrate their promising efficacy for
out-of-distribution generalization on diverse real-world datasets.},
 author = {Qitian Wu and Fan Nie and Chenxiao Yang and Junchi Yan},
 comment = {Accepted to ICML 2024. Source codes at
  https://github.com/fannie1208/GLIND},
 doi = {},
 eprint = {2406.04963v1},
 journal = {arXiv preprint},
 title = {Learning Divergence Fields for Shift-Robust Graph Representations},
 url = {http://arxiv.org/abs/2406.04963v1},
 year = {2024}
}

@article{2406.05504v4,
 abstract = {In the context of medical decision making, counterfactual prediction enables
clinicians to predict treatment outcomes of interest under alternative courses
of therapeutic actions given observed patient history. In this work, we present
G-Transformer for counterfactual outcome prediction under dynamic and
time-varying treatment strategies. Our approach leverages a Transformer
architecture to capture complex, long-range dependencies in time-varying
covariates while enabling g-computation, a causal inference method for
estimating the effects of dynamic treatment regimes. Specifically, we use a
Transformer-based encoder architecture to estimate the conditional distribution
of relevant covariates given covariate and treatment history at each time
point, then produces Monte Carlo estimates of counterfactual outcomes by
simulating forward patient trajectories under treatment strategies of interest.
We evaluate G-Transformer extensively using two simulated longitudinal datasets
from mechanistic models, and a real-world sepsis ICU dataset from MIMIC-IV.
G-Transformer outperforms both classical and state-of-the-art counterfactual
prediction models in these settings. To the best of our knowledge, this is the
first Transformer-based architecture that supports g-computation for
counterfactual outcome prediction under dynamic and time-varying treatment
strategies.},
 author = {Hong Xiong and Feng Wu and Leon Deng and Megan Su and Li-wei H Lehman},
 comment = {},
 doi = {},
 eprint = {2406.05504v4},
 journal = {arXiv preprint},
 title = {G-Transformer: Counterfactual Outcome Prediction under Dynamic and Time-varying Treatment Regimes},
 url = {http://arxiv.org/abs/2406.05504v4},
 year = {2024}
}

@article{2406.05633v1,
 abstract = {We address a core problem in causal inference: estimating heterogeneous
treatment effects using panel data with general treatment patterns. Many
existing methods either do not utilize the potential underlying structure in
panel data or have limitations in the allowable treatment patterns. In this
work, we propose and evaluate a new method that first partitions observations
into disjoint clusters with similar treatment effects using a regression tree,
and then leverages the (assumed) low-rank structure of the panel data to
estimate the average treatment effect for each cluster. Our theoretical results
establish the convergence of the resulting estimates to the true treatment
effects. Computation experiments with semi-synthetic data show that our method
achieves superior accuracy compared to alternative approaches, using a
regression tree with no more than 40 leaves. Hence, our method provides more
accurate and interpretable estimates than alternative methods.},
 author = {Retsef Levi and Elisabeth Paulson and Georgia Perakis and Emily Zhang},
 comment = {},
 doi = {},
 eprint = {2406.05633v1},
 journal = {arXiv preprint},
 title = {Heterogeneous Treatment Effects in Panel Data},
 url = {http://arxiv.org/abs/2406.05633v1},
 year = {2024}
}

@article{2406.05893v1,
 abstract = {We explored the challenge of predicting and explaining the occurrence of
events within sequences of data points. Our focus was particularly on scenarios
in which unknown triggers causing the occurrence of events may consist of
non-consecutive, masked, noisy data points. This scenario is akin to an agent
tasked with learning to predict and explain the occurrence of events without
understanding the underlying processes or having access to crucial information.
Such scenarios are encountered across various fields, such as genomics,
hardware and software verification, and financial time series prediction. We
combined analytical, simulation, and machine learning (ML) approaches to
investigate, quantify, and provide solutions to this challenge. We deduced and
validated equations generally applicable to any variation of the underlying
challenge. Using these equations, we (1) described how the level of complexity
changes with various parameters (e.g., number of apparent and hidden states,
trigger length, confidence, etc.) and (2) quantified the data needed to
successfully train an ML model. We then (3) proved our ML solution learns and
subsequently identifies unknown triggers and predicts the occurrence of events.
If the complexity of the challenge is too high, our ML solution can identify
trigger candidates to be used to interactively probe the system under
investigation to determine the true trigger in a way considerably more
efficient than brute force methods. By sharing our findings, we aim to assist
others grappling with similar challenges, enabling estimates on the complexity
of their problem, the data required and a solution to solve it.},
 author = {Harrison Lam and Yuanjie Chen and Noboru Kanazawa and Mohammad Chowdhury and Anna Battista and Stephan Waldert},
 comment = {16 pages, 8 figures, 1 table},
 doi = {},
 eprint = {2406.05893v1},
 journal = {arXiv preprint},
 title = {Event prediction and causality inference despite incomplete information},
 url = {http://arxiv.org/abs/2406.05893v1},
 year = {2024}
}

@article{2406.07005v2,
 abstract = {Causal inference on time series data is a challenging problem, especially in
the presence of unobserved confounders. This work focuses on estimating the
causal effect between two time series that are confounded by a third,
unobserved time series. Assuming spectral sparsity of the confounder, we show
how in the frequency domain this problem can be framed as an adversarial
outlier problem. We introduce Deconfounding by Robust regression (DecoR), a
novel approach that estimates the causal effect using robust linear regression
in the frequency domain. Considering two different robust regression
techniques, we first improve existing bounds on the estimation error for such
techniques. Crucially, our results do not require distributional assumptions on
the covariates. We can therefore use them in time series settings. Applying
these results to DecoR, we prove, under suitable assumptions, upper bounds for
the estimation error of DecoR that imply consistency. We demonstrate DecoR's
effectiveness through experiments on both synthetic and real-world data from
Earth system science. The simulation experiments furthermore suggest that DecoR
is robust with respect to model misspecification.},
 author = {Felix Schur and Jonas Peters},
 comment = {27 pages, 7 figures},
 doi = {},
 eprint = {2406.07005v2},
 journal = {arXiv preprint},
 title = {DecoR: Deconfounding Time Series with Robust Regression},
 url = {http://arxiv.org/abs/2406.07005v2},
 year = {2024}
}

@article{2406.07777v1,
 abstract = {Reinforcement learning (RL) has recently shown promise in predicting
Alzheimer's disease (AD) progression due to its unique ability to model domain
knowledge. However, it is not clear which RL algorithms are well-suited for
this task. Furthermore, these methods are not inherently explainable, limiting
their applicability in real-world clinical scenarios. Our work addresses these
two important questions. Using a causal, interpretable model of AD, we first
compare the performance of four contemporary RL algorithms in predicting brain
cognition over 10 years using only baseline (year 0) data. We then apply SHAP
(SHapley Additive exPlanations) to explain the decisions made by each algorithm
in the model. Our approach combines interpretability with explainability to
provide insights into the key factors influencing AD progression, offering both
global and individual, patient-level analysis. Our findings show that only one
of the RL methods is able to satisfactorily model disease progression, but the
post-hoc explanations indicate that all methods fail to properly capture the
importance of amyloid accumulation, one of the pathological hallmarks of
Alzheimer's disease. Our work aims to merge predictive accuracy with
transparency, assisting clinicians and researchers in enhancing disease
progression modeling for informed healthcare decisions. Code is available at
https://github.com/rfali/xrlad.},
 author = {Raja Farrukh Ali and Stephanie Milani and John Woods and Emmanuel Adenij and Ayesha Farooq and Clayton Mansel and Jeffrey Burns and William Hsu},
 comment = {Previous versions accepted to NeurIPS 2023's XAIA and AAAI 2024's
  XAI4DRL workshops},
 doi = {},
 eprint = {2406.07777v1},
 journal = {arXiv preprint},
 title = {Unifying Interpretability and Explainability for Alzheimer's Disease Progression Prediction},
 url = {http://arxiv.org/abs/2406.07777v1},
 year = {2024}
}

@article{2406.08106v1,
 abstract = {Identifying the underlying reason for a failing dynamic process or otherwise
anomalous observation is a fundamental challenge, yet has numerous industrial
applications. Identifying the failure-causing sub-system using causal
inference, one can ask the question: "Would the observed failure also occur, if
we had replaced the behaviour of a sub-system at a certain point in time with
its normal behaviour?" To this end, a formal description of behaviour of the
full system is needed in which such counterfactual questions can be answered.
However, existing causal methods for root cause identification are typically
limited to static settings and focusing on additive external influences causing
failures rather than structural influences. In this paper, we address these
problems by modelling the dynamic causal system using a Residual Neural Network
and deriving corresponding counterfactual distributions over trajectories. We
show quantitatively that more root causes are identified when an intervention
is performed on the structural equation and the external influence, compared to
an intervention on the external influence only. By employing an efficient
approximation to a corresponding Shapley value, we also obtain a ranking
between the different subsystems at different points in time being responsible
for an observed failure, which is applicable in settings with large number of
variables. We illustrate the effectiveness of the proposed method on a
benchmark dynamic system as well as on a real world river dataset.},
 author = {Juliane Weilbach and Sebastian Gerwinn and Karim Barsim and Martin Fränzle},
 comment = {},
 doi = {},
 eprint = {2406.08106v1},
 journal = {arXiv preprint},
 title = {Counterfactual-based Root Cause Analysis for Dynamical Systems},
 url = {http://arxiv.org/abs/2406.08106v1},
 year = {2024}
}

@article{2406.08311v2,
 abstract = {Tabular synthesis models remain ineffective at capturing complex
dependencies, and the quality of synthetic data is still insufficient for
comprehensive downstream tasks, such as prediction under distribution shifts,
automated decision-making, and cross-table understanding. A major challenge is
the lack of prior knowledge about underlying structures and high-order
relationships in tabular data. We argue that a systematic evaluation on
high-order structural information for tabular data synthesis is the first step
towards solving the problem. In this paper, we introduce high-order structural
causal information as natural prior knowledge and provide a benchmark framework
for the evaluation of tabular synthesis models. The framework allows us to
generate benchmark datasets with a flexible range of data generation processes
and to train tabular synthesis models using these datasets for further
evaluation. We propose multiple benchmark tasks, high-order metrics, and causal
inference tasks as downstream tasks for evaluating the quality of synthetic
data generated by the trained models. Our experiments demonstrate to leverage
the benchmark framework for evaluating the model capability of capturing
high-order structural causal information. Furthermore, our benchmarking results
provide an initial assessment of state-of-the-art tabular synthesis models.
They have clearly revealed significant gaps between ideal and actual
performance and how baseline methods differ. Our benchmark framework is
available at URL https://github.com/TURuibo/CauTabBench.},
 author = {Ruibo Tu and Zineb Senane and Lele Cao and Cheng Zhang and Hedvig Kjellström and Gustav Eje Henter},
 comment = {},
 doi = {},
 eprint = {2406.08311v2},
 journal = {arXiv preprint},
 title = {Causality for Tabular Data Synthesis: A High-Order Structure Causal Benchmark Framework},
 url = {http://arxiv.org/abs/2406.08311v2},
 year = {2024}
}

@article{2406.08697v3,
 abstract = {Offline reinforcement learning is important in many settings with available
observational data but the inability to deploy new policies online due to
safety, cost, and other concerns. Many recent advances in causal inference and
machine learning target estimation of causal contrast functions such as CATE,
which is sufficient for optimizing decisions and can adapt to potentially
smoother structure. We develop a dynamic generalization of the R-learner (Nie
and Wager 2021, Lewis and Syrgkanis 2021) for estimating and optimizing the
difference of $Q^\pi$-functions, $Q^\pi(s,1)-Q^\pi(s,0)$ (which can be used to
optimize multiple-valued actions). We leverage orthogonal estimation to improve
convergence rates in the presence of slower nuisance estimation rates and prove
consistency of policy optimization under a margin condition. The method can
leverage black-box nuisance estimators of the $Q$-function and behavior policy
to target estimation of a more structured $Q$-function contrast.},
 author = {Defu Cao and Angela Zhou},
 comment = {},
 doi = {},
 eprint = {2406.08697v3},
 journal = {arXiv preprint},
 title = {Structured Difference-of-Q via Orthogonal Learning},
 url = {http://arxiv.org/abs/2406.08697v3},
 year = {2024}
}

@article{2406.09207v2,
 abstract = {Sepsis is a life-threatening and serious global health issue. This study
combines knowledge with available hospital data to investigate the potential
causes of Sepsis that can be affected by policy decisions. We investigate the
underlying causal structure of this problem by combining clinical expertise
with score-based, constraint-based, and hybrid structure learning algorithms. A
novel approach to model averaging and knowledge-based constraints was
implemented to arrive at a consensus structure for causal inference. The
structure learning process highlighted the importance of exploring data-driven
approaches alongside clinical expertise. This includes discovering unexpected,
although reasonable, relationships from a clinical perspective. Hypothetical
interventions on Chronic Obstructive Pulmonary Disease, Alcohol dependence, and
Diabetes suggest that the presence of any of these risk factors in patients
increases the likelihood of Sepsis. This finding, alongside measuring the
effect of these risk factors on Sepsis, has potential policy implications.
Recognising the importance of prediction in improving health outcomes related
to Sepsis, the model is also assessed in its ability to predict Sepsis by
evaluating accuracy, sensitivity, and specificity. These three indicators all
had results around 70%, and the AUC was 80%, which means the causal structure
of the model is reasonably accurate given that the models were trained on data
available for commissioning purposes only.},
 author = {Bruno Petrungaro and Neville K. Kitson and Anthony C. Constantinou},
 comment = {},
 doi = {},
 eprint = {2406.09207v2},
 journal = {arXiv preprint},
 title = {Investigating potential causes of Sepsis with Bayesian network structure learning},
 url = {http://arxiv.org/abs/2406.09207v2},
 year = {2024}
}

@article{2406.09567v2,
 abstract = {Decision makers across various domains rely on predictive models to guide
individual-level intervention decisions. However, these models are typically
trained to predict outcomes rather than causal effects, leading to
misalignments when they are used for causal decision making. Experimental data
to train effective causal effect models often is limited. To address this
issue, we propose causal post-processing (CPP), a family of techniques for
refining predictive scores to better align with causal effects using limited
experimental data. Rather than training separate causal models for each
intervention, causal post-processing can adapt existing predictive scores to
support different decision-making requirements, such as estimating effect
sizes, ranking individuals by expected effects, or classifying individuals
based on an intervention threshold. We introduce three main CPP approaches --
monotonic post-processing, correction post-processing, and model-based
post-processing -- each balancing statistical efficiency and flexibility
differently. Through simulations and an empirical application in advertising,
we demonstrate that causal post-processing improves intervention decisions,
particularly in settings where experimental data is expensive or difficult to
obtain at scale. Our findings highlight the advantages of integrating
non-causal predictive models with experimental data, rather than treating them
as competing alternatives, which provides a scalable and data-efficient
approach to causal inference for decision making.},
 author = {Carlos Fernández-Loría and Yanfang Hou and Foster Provost and Jennifer Hill},
 comment = {},
 doi = {},
 eprint = {2406.09567v2},
 journal = {arXiv preprint},
 title = {Causal Post-Processing of Predictive Models},
 url = {http://arxiv.org/abs/2406.09567v2},
 year = {2024}
}

@article{2406.11399v1,
 abstract = {Synthetic control (SC) models are widely used to estimate causal effects in
settings with observational time-series data. To identify the causal effect on
a target unit, SC requires the existence of correlated units that are not
impacted by the intervention. Given one of these potential donor units, how can
we decide whether it is in fact a valid donor - that is, one not subject to
spillover effects from the intervention? Such a decision typically requires
appealing to strong a priori domain knowledge specifying the units, which
becomes infeasible in situations with large pools of potential donors. In this
paper, we introduce a practical, theoretically-grounded donor selection
procedure, aiming to weaken this domain knowledge requirement. Our main result
is a Theorem that yields the assumptions required to identify donor values at
post-intervention time points using only pre-intervention data. We show how
this Theorem - and the assumptions underpinning it - can be turned into a
practical method for detecting potential spillover effects and excluding
invalid donors when constructing SCs. Importantly, we employ sensitivity
analysis to formally bound the bias in our SC causal estimate in situations
where an excluded donor was indeed valid, or where a selected donor was
invalid. Using ideas from the proximal causal inference and instrumental
variables literature, we show that the excluded donors can nevertheless be
leveraged to further debias causal effect estimates. Finally, we illustrate our
donor selection procedure on both simulated and real-world datasets.},
 author = {Michael O'Riordan and Ciarán M. Gilligan-Lee},
 comment = {14 pages, 8 figures},
 doi = {},
 eprint = {2406.11399v1},
 journal = {arXiv preprint},
 title = {Spillover Detection for Donor Selection in Synthetic Control Models},
 url = {http://arxiv.org/abs/2406.11399v1},
 year = {2024}
}

@article{2406.11601v3,
 abstract = {Synthetic datasets generated by structural causal models (SCMs) are commonly
used for benchmarking causal structure learning algorithms. However, the
variances and pairwise correlations in SCM data tend to increase along the
causal ordering. Several popular algorithms exploit these artifacts, possibly
leading to conclusions that do not generalize to real-world settings. Existing
metrics like $\operatorname{Var}$-sortability and
$\operatorname{R^2}$-sortability quantify these patterns, but they do not
provide tools to remedy them. To address this, we propose
internally-standardized structural causal models (iSCMs), a modification of
SCMs that introduces a standardization operation at each variable during the
generative process. By construction, iSCMs are not
$\operatorname{Var}$-sortable. We also find empirical evidence that they are
mostly not $\operatorname{R^2}$-sortable for commonly-used graph families.
Moreover, contrary to the post-hoc standardization of data generated by
standard SCMs, we prove that linear iSCMs are less identifiable from prior
knowledge on the weights and do not collapse to deterministic relationships in
large systems, which may make iSCMs a useful model in causal inference beyond
the benchmarking problem studied here. Our code is publicly available at:
https://github.com/werkaaa/iscm.},
 author = {Weronika Ormaniec and Scott Sussex and Lars Lorch and Bernhard Schölkopf and Andreas Krause},
 comment = {Added additional benchmarks, including PC algorithm, GES, GOLEM.
  Evaluated Var-sortability and R2-sortability of the heuristics for mitigating
  variance accumulation},
 doi = {},
 eprint = {2406.11601v3},
 journal = {arXiv preprint},
 title = {Standardizing Structural Causal Models},
 url = {http://arxiv.org/abs/2406.11601v3},
 year = {2024}
}

@article{2406.12807v1,
 abstract = {Personalized medicine based on medical images, including predicting future
individualized clinical disease progression and treatment response, would have
an enormous impact on healthcare and drug development, particularly for
diseases (e.g. multiple sclerosis (MS)) with long term, complex, heterogeneous
evolutions and no cure. In this work, we present the first stochastic causal
temporal framework to model the continuous temporal evolution of disease
progression via Neural Stochastic Differential Equations (NSDE). The proposed
causal inference model takes as input the patient's high dimensional images
(MRI) and tabular data, and predicts both factual and counterfactual
progression trajectories on different treatments in latent space. The NSDE
permits the estimation of high-confidence personalized trajectories and
treatment effects. Extensive experiments were performed on a large,
multi-centre, proprietary dataset of patient 3D MRI and clinical data acquired
during several randomized clinical trials for MS treatments. Our results
present the first successful uncertainty-based causal Deep Learning (DL) model
to: (a) accurately predict future patient MS disability evolution (e.g. EDSS)
and treatment effects leveraging baseline MRI, and (b) permit the discovery of
subgroups of patients for which the model has high confidence in their response
to treatment even in clinical trials which did not reach their clinical
endpoints.},
 author = {Joshua Durso-Finley and Berardino Barile and Jean-Pierre Falet and Douglas L. Arnold and Nick Pawlowski and Tal Arbel},
 comment = {},
 doi = {},
 eprint = {2406.12807v1},
 journal = {arXiv preprint},
 title = {Probabilistic Temporal Prediction of Continuous Disease Trajectories and Treatment Effects Using Neural SDEs},
 url = {http://arxiv.org/abs/2406.12807v1},
 year = {2024}
}

@article{2406.13111v1,
 abstract = {Autism Spectrum Disorder (ASD) is a neurodevelopmental condition associated
with difficulties with social interactions, communication, and restricted or
repetitive behaviors. To characterize ASD, investigators often use functional
connectivity derived from resting-state functional magnetic resonance imaging
of the brain. However, participants' head motion during the scanning session
can induce motion artifacts. Many studies remove scans with excessive motion,
which can lead to drastic reductions in sample size and introduce selection
bias. To avoid such exclusions, we propose an estimand inspired by causal
inference methods that quantifies the difference in average functional
connectivity in autistic and non-ASD children while standardizing motion
relative to the low motion distribution in scans that pass motion quality
control. We introduce a nonparametric estimator for motion control, called
MoCo, that uses all participants and flexibly models the impacts of motion and
other relevant features using an ensemble of machine learning methods. We
establish large-sample efficiency and multiple robustness of our proposed
estimator. The framework is applied to estimate the difference in functional
connectivity between 132 autistic and 245 non-ASD children, of which 34 and 126
pass motion quality control. MoCo appears to dramatically reduce motion
artifacts relative to no participant removal, while more efficiently utilizing
participant data and accounting for possible selection biases relative to the
na\"ive approach with participant removal.},
 author = {Jialu Ran and Sarah Shultz and Benjamin B. Risk and David Benkeser},
 comment = {},
 doi = {},
 eprint = {2406.13111v1},
 journal = {arXiv preprint},
 title = {Nonparametric Motion Control in Functional Connectivity Studies in Children with Autism Spectrum Disorder},
 url = {http://arxiv.org/abs/2406.13111v1},
 year = {2024}
}

@article{2406.13731v1,
 abstract = {In this paper, we generalize the Pearl and Neyman-Rubin methodologies in
causal inference by introducing a generalized approach that incorporates fuzzy
logic. Indeed, we introduce a fuzzy causal inference approach that consider
both the vagueness and imprecision inherent in data, as well as the subjective
human perspective characterized by fuzzy terms such as 'high', 'medium', and
'low'. To do so, we introduce two fuzzy causal effect formulas: the Fuzzy
Average Treatment Effect (FATE) and the Generalized Fuzzy Average Treatment
Effect (GFATE), together with their normalized versions: NFATE and NGFATE. When
dealing with a binary treatment variable, our fuzzy causal effect formulas
coincide with classical Average Treatment Effect (ATE) formula, that is a
well-established and popular metric in causal inference. In FATE, all values of
the treatment variable are considered equally important. In contrast, GFATE
takes into account the rarity and frequency of these values. We show that for
linear Structural Equation Models (SEMs), the normalized versions of our
formulas, NFATE and NGFATE, are equivalent to ATE. Further, we provide
identifiability criteria for these formulas and show their stability with
respect to minor variations in the fuzzy subsets and the probability
distributions involved. This ensures the robustness of our approach in handling
small perturbations in the data. Finally, we provide several experimental
examples to empirically validate and demonstrate the practical application of
our proposed fuzzy causal inference methods.},
 author = {Amir Saki and Usef Faghihi},
 comment = {25 pages, 6 figures, 4 tables},
 doi = {},
 eprint = {2406.13731v1},
 journal = {arXiv preprint},
 title = {Integrating Fuzzy Logic with Causal Inference: Enhancing the Pearl and Neyman-Rubin Methodologies},
 url = {http://arxiv.org/abs/2406.13731v1},
 year = {2024}
}

@article{2406.13966v1,
 abstract = {Causality lays the foundation for the trajectory of our world. Causal
inference (CI), which aims to infer intrinsic causal relations among variables
of interest, has emerged as a crucial research topic. Nevertheless, the lack of
observation of important variables (e.g., confounders, mediators, exogenous
variables, etc.) severely compromises the reliability of CI methods. The issue
may arise from the inherent difficulty in measuring the variables.
Additionally, in observational studies where variables are passively recorded,
certain covariates might be inadvertently omitted by the experimenter.
Depending on the type of unobserved variables and the specific CI task, various
consequences can be incurred if these latent variables are carelessly handled,
such as biased estimation of causal effects, incomplete understanding of causal
mechanisms, lack of individual-level causal consideration, etc. In this survey,
we provide a comprehensive review of recent developments in CI with latent
variables. We start by discussing traditional CI techniques when variables of
interest are assumed to be fully observed. Afterward, under the taxonomy of
circumvention and inference-based methods, we provide an in-depth discussion of
various CI strategies to handle latent variables, covering the tasks of causal
effect estimation, mediation analysis, counterfactual reasoning, and causal
discovery. Furthermore, we generalize the discussion to graph data where
interference among units may exist. Finally, we offer fresh aspects for further
advancement of CI with latent variables, especially new opportunities in the
era of large language models (LLMs).},
 author = {Yaochen Zhu and Yinhan He and Jing Ma and Mengxuan Hu and Sheng Li and Jundong Li},
 comment = {Accepted by KDD'24 Survey Track},
 doi = {10.1145/3637528.3671450},
 eprint = {2406.13966v1},
 journal = {arXiv preprint},
 title = {Causal Inference with Latent Variables: Recent Advances and Future Prospectives},
 url = {http://arxiv.org/abs/2406.13966v1},
 year = {2024}
}

@article{2406.18936v1,
 abstract = {Why do companies choose particular capital structures? A compelling answer to
this question remains elusive despite extensive research. In this article, we
use double machine learning to examine the heterogeneous causal effect of
credit ratings on leverage. Taking advantage of the flexibility of random
forests within the double machine learning framework, we model the relationship
between variables associated with leverage and credit ratings without imposing
strong assumptions about their functional form. This approach also allows for
data-driven variable selection from a large set of individual company
characteristics, supporting valid causal inference. We report three findings:
First, credit ratings causally affect the leverage ratio. Having a rating, as
opposed to having none, increases leverage by approximately 7 to 9 percentage
points, or 30\% to 40\% relative to the sample mean leverage. However, this
result comes with an important caveat, captured in our second finding: the
effect is highly heterogeneous and varies depending on the specific rating. For
AAA and AA ratings, the effect is negative, reducing leverage by about 5
percentage points. For A and BBB ratings, the effect is approximately zero.
From BB ratings onwards, the effect becomes positive, exceeding 10 percentage
points. Third, contrary to what the second finding might imply at first glance,
the change from no effect to a positive effect does not occur abruptly at the
boundary between investment and speculative grade ratings. Rather, it is
gradual, taking place across the granular rating notches ("+/-") within the BBB
and BB categories.},
 author = {Helmut Wasserbacher and Martin Spindler},
 comment = {288 pages, 13 figures},
 doi = {},
 eprint = {2406.18936v1},
 journal = {arXiv preprint},
 title = {Credit Ratings: Heterogeneous Effect on Capital Structure},
 url = {http://arxiv.org/abs/2406.18936v1},
 year = {2024}
}

@article{2406.19958v1,
 abstract = {Bayesian Additive Regression Trees (BART) is a popular Bayesian
non-parametric regression model that is commonly used in causal inference and
beyond. Its strong predictive performance is supported by theoretical
guarantees that its posterior distribution concentrates around the true
regression function at optimal rates under various data generative settings and
for appropriate prior choices. In this paper, we show that the BART sampler
often converges slowly, confirming empirical observations by other researchers.
Assuming discrete covariates, we show that, while the BART posterior
concentrates on a set comprising all optimal tree structures (smallest bias and
complexity), the Markov chain's hitting time for this set increases with $n$
(training sample size), under several common data generative settings. As $n$
increases, the approximate BART posterior thus becomes increasingly different
from the exact posterior (for the same number of MCMC samples), contrasting
with earlier concentration results on the exact posterior. This contrast is
highlighted by our simulations showing worsening frequentist undercoverage for
approximate posterior intervals and a growing ratio between the MSE of the
approximate posterior and that obtainable by artificially improving convergence
via averaging multiple sampler chains. Finally, based on our theoretical
insights, possibilities are discussed to improve the BART sampler convergence
performance.},
 author = {Yan Shuo Tan and Omer Ronen and Theo Saarinen and Bin Yu},
 comment = {},
 doi = {},
 eprint = {2406.19958v1},
 journal = {arXiv preprint},
 title = {The Computational Curse of Big Data for Bayesian Additive Regression Trees: A Hitting Time Analysis},
 url = {http://arxiv.org/abs/2406.19958v1},
 year = {2024}
}

@article{2407.00271v2,
 abstract = {Constructing sparse, effective reduced-order models (ROMs) for
high-dimensional dynamical data is an active area of research in applied
sciences. In this work, we study an efficient approach to identifying such
sparse ROMs using an information-theoretic indicator called causation entropy.
Given a feature library of possible building block terms for the sought ROMs,
the causation entropy ranks the importance of each term to the dynamics
conveyed by the training data before a parameter estimation procedure is
performed. It thus allows for an efficient construction of a hierarchy of ROMs
with varying degrees of sparsity to effectively handle different tasks. This
article examines the ability of the causation entropy to identify skillful
sparse ROMs when a relatively high-dimensional ROM is required to emulate the
dynamics conveyed by the training dataset. We demonstrate that a Gaussian
approximation of the causation entropy still performs exceptionally well even
in presence of highly non-Gaussian statistics. Such approximations provide an
efficient way to access the otherwise hard to compute causation entropies when
the selected feature library contains a large number of candidate functions.
Besides recovering long-term statistics, we also demonstrate good performance
of the obtained ROMs in recovering unobserved dynamics via data assimilation
with partial observations, a test that has not been done before for
causation-based ROMs of partial differential equations. The paradigmatic
Kuramoto-Sivashinsky equation placed in a chaotic regime with highly skewed,
multimodal statistics is utilized for these purposes.},
 author = {Nan Chen and Honghu Liu},
 comment = {},
 doi = {},
 eprint = {2407.00271v2},
 journal = {arXiv preprint},
 title = {Minimum Reduced-Order Models via Causal Inference},
 url = {http://arxiv.org/abs/2407.00271v2},
 year = {2024}
}

@article{2407.00364v2,
 abstract = {The goal of precision medicine is to provide individualized treatment at each
stage of chronic diseases, a concept formalized by Dynamic Treatment Regimes
(DTR). These regimes adapt treatment strategies based on decision rules learned
from clinical data to enhance therapeutic effectiveness. Reinforcement Learning
(RL) algorithms allow to determine these decision rules conditioned by
individual patient data and their medical history. The integration of medical
expertise into these models makes possible to increase confidence in treatment
recommendations and facilitate the adoption of this approach by healthcare
professionals and patients. In this work, we examine the mathematical
foundations of RL, contextualize its application in the field of DTR, and
present an overview of methods to improve its effectiveness by integrating
medical expertise.},
 author = {Sophia Yazzourh and Nicolas Savy and Philippe Saint-Pierre and Michael R. Kosorok},
 comment = {},
 doi = {10.1111/insr.12617},
 eprint = {2407.00364v2},
 journal = {arXiv preprint},
 title = {Medical Knowledge Integration into Reinforcement Learning Algorithms for Dynamic Treatment Regimes},
 url = {http://arxiv.org/abs/2407.00364v2},
 year = {2024}
}

@article{2407.00806v1,
 abstract = {In many reinforcement learning (RL) applications one cannot easily let the
agent act in the world; this is true for autonomous vehicles, healthcare
applications, and even some recommender systems, to name a few examples.
Offline RL provides a way to train agents without real-world exploration, but
is often faced with biases due to data distribution shifts, limited coverage,
and incomplete representation of the environment. To address these issues,
practical applications have tried to combine simulators with grounded offline
data, using so-called hybrid methods. However, constructing a reliable
simulator is in itself often challenging due to intricate system complexities
as well as missing or incomplete information. In this work, we outline four
principal challenges for combining offline data with imperfect simulators in
RL: simulator modeling error, partial observability, state and action
discrepancies, and hidden confounding. To help drive the RL community to pursue
these problems, we construct ``Benchmarks for Mechanistic Offline Reinforcement
Learning'' (B4MRL), which provide dataset-simulator benchmarks for the
aforementioned challenges. Our results suggest the key necessity of such
benchmarks for future research.},
 author = {Ori Linial and Guy Tennenholtz and Uri Shalit},
 comment = {},
 doi = {},
 eprint = {2407.00806v1},
 journal = {arXiv preprint},
 title = {Benchmarks for Reinforcement Learning with Biased Offline Data and Imperfect Simulators},
 url = {http://arxiv.org/abs/2407.00806v1},
 year = {2024}
}

@article{2407.00978v2,
 abstract = {Secure data management and effective data sharing have become paramount in
the rapidly evolving healthcare landscape, especially with the growing
integration of the Internet of Medical Things (IoMT). The rise of generative
artificial intelligence has further elevated Multi-modal Large Language Models
(MLLMs) as essential tools for managing and optimizing healthcare data in IoMT.
MLLMs can support multi-modal inputs and generate diverse types of content by
leveraging large-scale training on vast amounts of multi-modal data. However,
critical challenges persist in developing medical MLLMs, including security and
freshness issues of healthcare data, affecting the output quality of MLLMs. To
this end, in this paper, we propose a hybrid Retrieval-Augmented Generation
(RAG)-empowered medical MLLM framework for healthcare data management. This
framework leverages a hierarchical cross-chain architecture to facilitate
secure data training. Moreover, it enhances the output quality of MLLMs through
hybrid RAG, which employs multi-modal metrics to filter various unimodal RAG
results and incorporates these retrieval results as additional inputs to MLLMs.
Additionally, we employ age of information to indirectly evaluate the data
freshness impact of MLLMs and utilize contract theory to incentivize healthcare
data holders to share their fresh data, mitigating information asymmetry during
data sharing. Finally, we utilize a generative diffusion model-based deep
reinforcement learning algorithm to identify the optimal contract for efficient
data sharing. Numerical results demonstrate the effectiveness of the proposed
schemes, which achieve secure and efficient healthcare data management.},
 author = {Cheng Su and Jinbo Wen and Jiawen Kang and Yonghua Wang and Yuanjia Su and Hudan Pan and Zishao Zhong and M. Shamim Hossain},
 comment = {13 pages, 7 figures},
 doi = {},
 eprint = {2407.00978v2},
 journal = {arXiv preprint},
 title = {Hybrid RAG-empowered Multi-modal LLM for Secure Data Management in Internet of Medical Things: A Diffusion-based Contract Approach},
 url = {http://arxiv.org/abs/2407.00978v2},
 year = {2024}
}

@article{2407.01004v1,
 abstract = {In causal inference, estimating heterogeneous treatment effects (HTE) is
critical for identifying how different subgroups respond to interventions, with
broad applications in fields such as precision medicine and personalized
advertising. Although HTE estimation methods aim to improve accuracy, how to
provide explicit subgroup descriptions remains unclear, hindering data
interpretation and strategic intervention management. In this paper, we propose
CURLS, a novel rule learning method leveraging HTE, which can effectively
describe subgroups with significant treatment effects. Specifically, we frame
causal rule learning as a discrete optimization problem, finely balancing
treatment effect with variance and considering the rule interpretability. We
design an iterative procedure based on the minorize-maximization algorithm and
solve a submodular lower bound as an approximation for the original.
Quantitative experiments and qualitative case studies verify that compared with
state-of-the-art methods, CURLS can find subgroups where the estimated and true
effects are 16.1% and 13.8% higher and the variance is 12.0% smaller, while
maintaining similar or better estimation accuracy and rule interpretability.
Code is available at https://osf.io/zwp2k/.},
 author = {Jiehui Zhou and Linxiao Yang and Xingyu Liu and Xinyue Gu and Liang Sun and Wei Chen},
 comment = {12 pages, 3 figures},
 doi = {},
 eprint = {2407.01004v1},
 journal = {arXiv preprint},
 title = {CURLS: Causal Rule Learning for Subgroups with Significant Treatment Effect},
 url = {http://arxiv.org/abs/2407.01004v1},
 year = {2024}
}

@article{2407.02825v1,
 abstract = {Conditional Generative Adversarial Nets (CGAN) is often used to improve
conditional image generation performance. However, there is little research on
Representation learning with CGAN for causal inference. This paper proposes a
new method for finding representation learning functions by adopting the
adversarial idea. We apply the pattern of CGAN and theoretically emonstrate the
feasibility of finding a suitable representation function in the context of two
distributions being balanced. The theoretical result shows that when two
distributions are balanced, the ideal representation function can be found and
thus can be used to further research.},
 author = {Zhaotian Weng and Jianbo Hong and Lan Wang},
 comment = {Proceedings of the 3rd International Conference on Signal Processing
  and Machine Learning},
 doi = {10.54254/2755-2721/6/20230436},
 eprint = {2407.02825v1},
 journal = {arXiv preprint},
 title = {Representation learning with CGAN for casual inference},
 url = {http://arxiv.org/abs/2407.02825v1},
 year = {2024}
}

@article{2407.05625v3,
 abstract = {Modeling and analysis for event series generated by users of heterogeneous
behavioral patterns are closely involved in our daily lives, including credit
card fraud detection, online platform user recommendation, and social network
analysis. The most commonly adopted approach to this task is to assign users to
behavior-based categories and analyze each of them separately. However, this
requires extensive data to fully understand the user behavior, presenting
challenges in modeling newcomers without significant historical knowledge. In
this work, we propose a novel discrete event prediction framework for new users
with limited history, without needing to know the user's category. We treat the
user event history as the "treatment" for future events and the user category
as the key confounder. Thus, the prediction problem can be framed as
counterfactual outcome estimation, where each event is re-weighted by its
inverse propensity score. We demonstrate the improved performance of the
proposed framework with a numerical simulation study and two real-world
applications, including Netflix rating prediction and seller contact prediction
for customer support at Amazon.},
 author = {Henry Shaowu Yuchi and Shixiang Zhu and Li Dong and Yigit M. Arisoy and Matthew C. Spencer},
 comment = {},
 doi = {},
 eprint = {2407.05625v3},
 journal = {arXiv preprint},
 title = {New User Event Prediction Through the Lens of Causal Inference},
 url = {http://arxiv.org/abs/2407.05625v3},
 year = {2024}
}

@article{2407.08029v1,
 abstract = {Numerous benchmarks aim to evaluate the capabilities of Large Language Models
(LLMs) for causal inference and reasoning. However, many of them can likely be
solved through the retrieval of domain knowledge, questioning whether they
achieve their purpose. In this review, we present a comprehensive overview of
LLM benchmarks for causality. We highlight how recent benchmarks move towards a
more thorough definition of causal reasoning by incorporating interventional or
counterfactual reasoning. We derive a set of criteria that a useful benchmark
or set of benchmarks should aim to satisfy. We hope this work will pave the way
towards a general framework for the assessment of causal understanding in LLMs
and the design of novel benchmarks.},
 author = {Linying Yang and Vik Shirvaikar and Oscar Clivio and Fabian Falck},
 comment = {AAAI 2024 Workshop on ''Are Large Language Models Simply Causal
  Parrots?''},
 doi = {},
 eprint = {2407.08029v1},
 journal = {arXiv preprint},
 title = {A Critical Review of Causal Reasoning Benchmarks for Large Language Models},
 url = {http://arxiv.org/abs/2407.08029v1},
 year = {2024}
}

@article{2407.08560v1,
 abstract = {Deep neural networks (DNNs) have demonstrated remarkable empirical
performance in large-scale supervised learning problems, particularly in
scenarios where both the sample size $n$ and the dimension of covariates $p$
are large. This study delves into the application of DNNs across a wide
spectrum of intricate causal inference tasks, where direct estimation falls
short and necessitates multi-stage learning. Examples include estimating the
conditional average treatment effect and dynamic treatment effect. In this
framework, DNNs are constructed sequentially, with subsequent stages building
upon preceding ones. To mitigate the impact of estimation errors from early
stages on subsequent ones, we integrate DNNs in a doubly robust manner. In
contrast to previous research, our study offers theoretical assurances
regarding the effectiveness of DNNs in settings where the dimensionality $p$
expands with the sample size. These findings are significant independently and
extend to degenerate single-stage learning problems.},
 author = {Yuqian Zhang and Jelena Bradic},
 comment = {},
 doi = {},
 eprint = {2407.08560v1},
 journal = {arXiv preprint},
 title = {Causal inference through multi-stage learning and doubly robust deep neural networks},
 url = {http://arxiv.org/abs/2407.08560v1},
 year = {2024}
}

@article{2407.09378v1,
 abstract = {Graph neural network (GNN) explainers identify the important subgraph that
ensures the prediction for a given graph. Until now, almost all GNN explainers
are based on association, which is prone to spurious correlations. We propose
{\name}, a GNN causal explainer via causal inference. Our explainer is based on
the observation that a graph often consists of a causal underlying subgraph.
{\name} includes three main steps: 1) It builds causal structure and the
corresponding structural causal model (SCM) for a graph, which enables the
cause-effect calculation among nodes. 2) Directly calculating the cause-effect
in real-world graphs is computationally challenging. It is then enlightened by
the recent neural causal model (NCM), a special type of SCM that is trainable,
and design customized NCMs for GNNs. By training these GNN NCMs, the
cause-effect can be easily calculated. 3) It uncovers the subgraph that
causally explains the GNN predictions via the optimized GNN-NCMs. Evaluation
results on multiple synthetic and real-world graphs validate that {\name}
significantly outperforms existing GNN explainers in exact groundtruth
explanation identification},
 author = {Arman Behnam and Binghui Wang},
 comment = {},
 doi = {},
 eprint = {2407.09378v1},
 journal = {arXiv preprint},
 title = {Graph Neural Network Causal Explanation via Neural Causal Models},
 url = {http://arxiv.org/abs/2407.09378v1},
 year = {2024}
}

@article{2407.10014v1,
 abstract = {Additive noise models (ANMs) are an important setting studied in causal
inference. Most of the existing works on ANMs assume causal sufficiency, i.e.,
there are no unobserved confounders. This paper focuses on confounded ANMs,
where a set of treatment variables and a target variable are affected by an
unobserved confounder that follows a multivariate Gaussian distribution. We
introduce a novel approach for estimating the average causal effects (ACEs) of
any subset of the treatment variables on the outcome and demonstrate that a
small set of interventional distributions is sufficient to estimate all of
them. In addition, we propose a randomized algorithm that further reduces the
number of required interventions to poly-logarithmic in the number of nodes.
Finally, we demonstrate that these interventions are also sufficient to recover
the causal structure between the observed variables. This establishes that a
poly-logarithmic number of interventions is sufficient to infer the causal
effects of any subset of treatments on the outcome in confounded ANMs with high
probability, even when the causal structure between treatments is unknown. The
simulation results indicate that our method can accurately estimate all ACEs in
the finite-sample regime. We also demonstrate the practical significance of our
algorithm by evaluating it on semi-synthetic data.},
 author = {Muhammad Qasim Elahi and Mahsa Ghasemi and Murat Kocaoglu},
 comment = {},
 doi = {},
 eprint = {2407.10014v1},
 journal = {arXiv preprint},
 title = {Identification of Average Causal Effects in Confounded Additive Noise Models},
 url = {http://arxiv.org/abs/2407.10014v1},
 year = {2024}
}

@article{2407.11032v1,
 abstract = {Collaborative causal inference (CCI) is a federated learning method for
pooling data from multiple, often self-interested, parties, to achieve a common
learning goal over causal structures, e.g. estimation and optimization of
treatment variables in a medical setting. Since obtaining data can be costly
for the participants and sharing unique data poses the risk of losing
competitive advantages, motivating the participation of all parties through
equitable rewards and incentives is necessary. This paper devises an evaluation
scheme to measure the value of each party's data contribution to the common
learning task, tailored to causal inference's statistical demands, by comparing
completed partially directed acyclic graphs (CPDAGs) inferred from
observational data contributed by the participants. The Data Valuation Scheme
thus obtained can then be used to introduce mechanisms that incentivize the
agents to contribute data. It can be leveraged to reward agents fairly,
according to the quality of their data, or to maximize all agents' data
contributions.},
 author = {Björn Filter and Ralf Möller and Özgür Lütfü Özçep},
 comment = {},
 doi = {},
 eprint = {2407.11032v1},
 journal = {arXiv preprint},
 title = {Mechanisms for Data Sharing in Collaborative Causal Inference (Extended Version)},
 url = {http://arxiv.org/abs/2407.11032v1},
 year = {2024}
}

@article{2407.11056v1,
 abstract = {This paper describes the development of a counterfactual Root Cause Analysis
diagnosis approach for an industrial multivariate time series environment. It
drives the attention toward the Point of Incipient Failure, which is the moment
in time when the anomalous behavior is first observed, and where the root cause
is assumed to be found before the issue propagates. The paper presents the
elementary but essential concepts of the solution and illustrates them
experimentally on a simulated setting. Finally, it discusses avenues of
improvement for the maturity of the causal technology to meet the robustness
challenges of increasingly complex environments in the industry.},
 author = {Alexandre Trilla and Rajesh Rajendran and Ossee Yiboe and Quentin Possamaï and Nenad Mijatovic and Jordi Vitrià},
 comment = {Accepted for the Causal Inference for Time Series Data Workshop at
  the 40th Conference on Uncertainty in Artificial Intelligence (CI4TS 2024)},
 doi = {},
 eprint = {2407.11056v1},
 journal = {arXiv preprint},
 title = {Industrial-Grade Time-Dependent Counterfactual Root Cause Analysis through the Unanticipated Point of Incipient Failure: a Proof of Concept},
 url = {http://arxiv.org/abs/2407.11056v1},
 year = {2024}
}

@article{2407.13313v3,
 abstract = {Evaluating the performance of causal discovery algorithms that aim to find
causal relationships between time-dependent processes remains a challenging
topic. In this paper, we show that certain characteristics of datasets, such as
varsortability (Reisach et al. 2021) and $R^2$-sortability (Reisach et al.
2023), also occur in datasets for autocorrelated stationary time series. We
illustrate this empirically using four types of data: simulated data based on
SVAR models and Erd\H{o}s-R\'enyi graphs, the data used in the 2019
causality-for-climate challenge (Runge et al. 2019), real-world river stream
datasets, and real-world data generated by the Causal Chamber of (Gamella et
al. 2024). To do this, we adapt var- and $R^2$-sortability to time series data.
We also investigate the extent to which the performance of score-based causal
discovery methods goes hand in hand with high sortability. Arguably, our most
surprising finding is that the investigated real-world datasets exhibit high
varsortability and low $R^2$-sortability indicating that scales may carry a
significant amount of causal information.},
 author = {Christopher Lohse and Jonas Wahl},
 comment = {Published in Transactions on Machine Learning Research, also
  presented at the Causal Inference for Time Series Data Workshop at the 40th
  Conference on Uncertainty in Artificial Intelligence (CI4TS 2024)},
 doi = {},
 eprint = {2407.13313v3},
 journal = {arXiv preprint},
 title = {Sortability of Time Series Data},
 url = {http://arxiv.org/abs/2407.13313v3},
 year = {2024}
}

@article{2407.13699v2,
 abstract = {Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends\footnote. The survey
resources are available in the public GitHub repository
https://github.com/VectorInstitute/Recommender-Systems-Survey. (Recommender
systems, large language models, chatgpt, responsible AI)},
 author = {Shaina Raza and Mizanur Rahman and Safiullah Kamawal and Armin Toroghi and Ananya Raval and Farshad Navah and Amirmohammad Kazemeini},
 comment = {we quarterly update of this literature},
 doi = {},
 eprint = {2407.13699v2},
 journal = {arXiv preprint},
 title = {A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice},
 url = {http://arxiv.org/abs/2407.13699v2},
 year = {2024}
}

@article{2407.14022v1,
 abstract = {Causal inference plays an important role in explanatory analysis and decision
making across various fields like statistics, marketing, health care, and
education. Its main task is to estimate treatment effects and make intervention
policies. Traditionally, most of the previous works typically focus on the
binary treatment setting that there is only one treatment for a unit to adopt
or not. However, in practice, the treatment can be much more complex,
encompassing multi-valued, continuous, or bundle options. In this paper, we
refer to these as complex treatments and systematically and comprehensively
review the causal inference methods for addressing them. First, we formally
revisit the problem definition, the basic assumptions, and their possible
variations under specific conditions. Second, we sequentially review the
related methods for multi-valued, continuous, and bundled treatment settings.
In each situation, we tentatively divide the methods into two categories: those
conforming to the unconfoundedness assumption and those violating it.
Subsequently, we discuss the available datasets and open-source codes. Finally,
we provide a brief summary of these works and suggest potential directions for
future research.},
 author = {Yingrong Wang and Haoxuan Li and Minqin Zhu and Anpeng Wu and Ruoxuan Xiong and Fei Wu and Kun Kuang},
 comment = {},
 doi = {},
 eprint = {2407.14022v1},
 journal = {arXiv preprint},
 title = {Causal Inference with Complex Treatments: A Survey},
 url = {http://arxiv.org/abs/2407.14022v1},
 year = {2024}
}

@article{2407.16062v1,
 abstract = {Precision health, increasingly supported by digital technologies, is a domain
of research that broadens the paradigm of precision medicine, advancing
everyday healthcare. This vision goes hand in hand with the groundbreaking
advent of artificial intelligence (AI), which is reshaping the way we diagnose,
treat, and monitor both clinical subjects and the general population. AI tools
powered by machine learning have shown considerable improvements in a variety
of healthcare domains. In particular, reinforcement learning (RL) holds great
promise for sequential and dynamic problems such as dynamic treatment regimes
and just-in-time adaptive interventions in digital health. In this work, we
discuss the opportunity offered by AI, more specifically RL, to current trends
in healthcare, providing a methodological survey of RL methods in the context
of precision and digital health. Focusing on the area of adaptive
interventions, we expand the methodological survey with illustrative case
studies that used RL in real practice.
  This invited article has undergone anonymous review and is intended as a book
chapter for the volume "Frontiers of Statistics and Data Science" edited by
Subhashis Ghoshal and Anindya Roy for the International Indian Statistical
Association Series on Statistics and Data Science, published by Springer. It
covers the material from a short course titled "Artificial Intelligence in
Precision and Digital Health" taught by the author Bibhas Chakraborty at the
IISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science,
Bengaluru.},
 author = {Nina Deliu and Bibhas Chakraborty},
 comment = {This contribution is a part of the volume "Frontiers of Statistics
  and Data Science" edited by Subhashis Ghoshal and Anindya Roy for the
  International Indian Statistical Association Series on Statistics and Data
  Science, published by Springer. It covers the material from a short course
  titled "Artificial Intelligence in Precision and Digital Health" (IISA 2022
  Conference) and includes parts of arXiv:2203.02605},
 doi = {},
 eprint = {2407.16062v1},
 journal = {arXiv preprint},
 title = {Artificial Intelligence-based Decision Support Systems for Precision and Digital Health},
 url = {http://arxiv.org/abs/2407.16062v1},
 year = {2024}
}

@article{2407.17385v3,
 abstract = {The standard approach to causal modelling especially in social and health
sciences is the potential outcomes framework due to Neyman and Rubin. In this
framework, observations are thought to be drawn from a distribution over
variables of interest, and the goal is to identify parameters of this
distribution. Even though the stated goal is often to inform decision making on
some target population, there is no straightforward way to include these target
populations in the framework. Instead of modelling the relationship between the
observed sample and the target population, the inductive assumptions in this
framework take the form of abstract sampling and independence assumptions. In
this paper, we develop a version of this framework that construes causal
inference as treatment-wise predictions for finite populations where all
assumptions are testable in retrospect; this means that one can not only test
predictions themselves (without any fundamental problem) but also investigate
sources of error when they fail. Due to close connections to the original
framework, established methods can still be be analysed under the new
framework.},
 author = {Benedikt Höltgen and Robert C. Williamson},
 comment = {Presented at the Humans, Algorithmic Decision-Making and Society
  Workshop at ICML 2024},
 doi = {},
 eprint = {2407.17385v3},
 journal = {arXiv preprint},
 title = {Formalising causal inference as prediction on a target population},
 url = {http://arxiv.org/abs/2407.17385v3},
 year = {2024}
}

@article{2407.17464v1,
 abstract = {With recent advancements in AI and computation tools, intelligent paradigms
emerged to empower different fields such as healthcare robots with new
capabilities. Advanced AI robotic algorithms (e.g., reinforcement learning) can
be trained and developed to autonomously make individual decisions to achieve a
desired and usually fixed goal. However, such independent decisions and goal
achievements might not be ideal for a healthcare robot that usually interacts
with a dynamic end-user or a patient. In such a complex human-robot interaction
(teaming) framework, the dynamic user continuously wants to be involved in
decision-making as well as introducing new goals while interacting with their
present environment in real-time. To address this challenge, an adaptive shared
autonomy AI paradigm is required to be developed for the two interactive agents
(Human & AI agents) with a foundation based on human-centered factors to avoid
any possible ethical issues and guarantee no harm to humanity.},
 author = {Reza Abiri and Ali Rabiee and Sima Ghafoori and Anna Cetera},
 comment = {5 pages, 1 figure},
 doi = {},
 eprint = {2407.17464v1},
 journal = {arXiv preprint},
 title = {Toward human-centered shared autonomy AI paradigms for human-robot teaming in healthcare},
 url = {http://arxiv.org/abs/2407.17464v1},
 year = {2024}
}

@article{2407.18937v1,
 abstract = {Using 286 research papers collected from Web of Science, ScienceDirect,
SpringerLink, arXiv, and Google Scholar databases, a systematic review
methodology was adopted to review and summarize the current challenges and
potential future developments in data, algorithms, and evaluation aspects of
RSs. It was found that RSs involve five major research topics, namely
algorithmic improvement, domain applications, user behavior & cognition, data
processing & modeling, and social impact & ethics. Collaborative filtering and
hybrid recommendation techniques are mainstream. The performance of RSs is
jointly limited by four types of eight data issues, two types of twelve
algorithmic issues, and two evaluation issues. Notably, data-related issues
such as cold start, data sparsity, and data poisoning, algorithmic issues like
interest drift, device-cloud collaboration, non-causal driven, and multitask
conflicts, along with evaluation issues such as offline data leakage and
multi-objective balancing, have prominent impacts. Fusing physiological signals
for multimodal modeling, defending against data poisoning through user
information behavior, evaluating generative recommendations via social
experiments, fine-tuning pre-trained large models to schedule device-cloud
resource, enhancing causal inference with deep reinforcement learning, training
multi-task models based on probability distributions, using cross-temporal
dataset partitioning, and evaluating recommendation objectives across the full
lifecycle are feasible solutions to address the aforementioned prominent
challenges and unlock the power and value of RSs.The collected literature is
mainly based on major international databases, and future research will further
expand upon it.},
 author = {Xin Ma and Mingyue Li and Xuguang Liu},
 comment = {24 pages, 10 figures, 3 tables},
 doi = {},
 eprint = {2407.18937v1},
 journal = {arXiv preprint},
 title = {Advancements in Recommender Systems: A Comprehensive Analysis Based on Data, Algorithms, and Evaluation},
 url = {http://arxiv.org/abs/2407.18937v1},
 year = {2024}
}

@article{2407.19078v1,
 abstract = {Budget allocation of marketplace levers, such as incentives for drivers and
promotions for riders, has long been a technical and business challenge at
Uber; understanding lever budget changes' impact and estimating cost efficiency
to achieve predefined budgets is crucial, with the goal of optimal allocations
that maximize business value; we introduce an end-to-end machine learning and
optimization procedure to automate budget decision-making for cities, relying
on feature store, model training and serving, optimizers, and backtesting;
proposing state-of-the-art deep learning (DL) estimator based on S-Learner and
a novel tensor B-Spline regression model, we solve high-dimensional
optimization with ADMM and primal-dual interior point convex optimization,
substantially improving Uber's resource allocation efficiency.},
 author = {Bobby Chen and Siyu Chen and Jason Dowlatabadi and Yu Xuan Hong and Vinayak Iyer and Uday Mantripragada and Rishabh Narang and Apoorv Pandey and Zijun Qin and Abrar Sheikh and Hongtao Sun and Jiaqi Sun and Matthew Walker and Kaichen Wei and Chen Xu and Jingnan Yang and Allen T. Zhang and Guoqing Zhang},
 comment = {To be published in the 2nd Workshop on Causal Inference and Machine
  Learning in Practice, KDD 2024, August 25 to 29, 2024, Barcelona, Spain, 10
  pages},
 doi = {},
 eprint = {2407.19078v1},
 journal = {arXiv preprint},
 title = {Practical Marketplace Optimization at Uber Using Causally-Informed Machine Learning},
 url = {http://arxiv.org/abs/2407.19078v1},
 year = {2024}
}

@article{2407.20447v1,
 abstract = {Despite advancements in causal inference and prescriptive AI, its adoption in
enterprise settings remains hindered primarily due to its technical complexity.
Many users lack the necessary knowledge and appropriate tools to effectively
leverage these technologies. This work at the MIT-IBM Watson AI Lab focuses on
developing the proof-of-concept agent, PrecAIse, a domain-adaptable
conversational agent equipped with a suite of causal and prescriptive tools to
help enterprise users make better business decisions. The objective is to make
advanced, novel causal inference and prescriptive tools widely accessible
through natural language interactions. The presented Natural Language User
Interface (NLUI) enables users with limited expertise in machine learning and
data science to harness prescriptive analytics in their decision-making
processes without requiring intensive computing resources. We present an agent
capable of function calling, maintaining faithful, interactive, and dynamic
conversations, and supporting new domains.},
 author = {Piero Orderique and Wei Sun and Kristjan Greenewald},
 comment = {},
 doi = {},
 eprint = {2407.20447v1},
 journal = {arXiv preprint},
 title = {Domain Adaptable Prescriptive AI Agent for Enterprise},
 url = {http://arxiv.org/abs/2407.20447v1},
 year = {2024}
}

@article{2407.20700v1,
 abstract = {This paper describes the development of a causal diagnosis approach for
troubleshooting an industrial environment on the basis of the technical
language expressed in Return on Experience records. The proposed method
leverages the vectorized linguistic knowledge contained in the distributed
representation of a Large Language Model, and the causal associations entailed
by the embedded failure modes and mechanisms of the industrial assets. The
paper presents the elementary but essential concepts of the solution, which is
conceived as a causality-aware retrieval augmented generation system, and
illustrates them experimentally on a real-world Predictive Maintenance setting.
Finally, it discusses avenues of improvement for the maturity of the utilized
causal technology to meet the robustness challenges of increasingly complex
scenarios in the industry.},
 author = {Alexandre Trilla and Ossee Yiboe and Nenad Mijatovic and Jordi Vitrià},
 comment = {2nd Workshop on Causal Inference and Machine Learning in Practice at
  the KDD 2024 Conference. arXiv admin note: text overlap with arXiv:2407.11056},
 doi = {},
 eprint = {2407.20700v1},
 journal = {arXiv preprint},
 title = {Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concept},
 url = {http://arxiv.org/abs/2407.20700v1},
 year = {2024}
}

@article{2407.21770v3,
 abstract = {We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)
architecture designed for pre-training mixed-modal, early-fusion language
models. MoMa processes images and text in arbitrary sequences by dividing
expert modules into modality-specific groups. These groups exclusively process
designated tokens while employing learned routing within each group to maintain
semantically informed adaptivity. Our empirical results reveal substantial
pre-training efficiency gains through this modality-specific parameter
allocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,
featuring 4 text experts and 4 image experts, achieves impressive FLOPs
savings: 3.7x overall, with 2.6x for text and 5.2x for image processing
compared to a compute-equivalent dense baseline, measured by pre-training loss.
This outperforms the standard expert-choice MoE with 8 mixed-modal experts,
which achieves 3x overall FLOPs savings (3x for text, 2.8x for image).
Combining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPs
savings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination
hurts performance in causal inference due to increased sensitivity to router
accuracy. These results demonstrate MoMa's potential to significantly advance
the efficiency of mixed-modal, early-fusion language model pre-training, paving
the way for more resource-efficient and capable multimodal AI systems.},
 author = {Xi Victoria Lin and Akshat Shrivastava and Liang Luo and Srinivasan Iyer and Mike Lewis and Gargi Ghosh and Luke Zettlemoyer and Armen Aghajanyan},
 comment = {v2 -> update related work section v3 -> fix spelling},
 doi = {},
 eprint = {2407.21770v3},
 journal = {arXiv preprint},
 title = {MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts},
 url = {http://arxiv.org/abs/2407.21770v3},
 year = {2024}
}

@article{2408.01445v1,
 abstract = {To enhance therapeutic outcomes from a pharmacological perspective, we
propose MiranDa, designed for medication recommendation, which is the first
actionable model capable of providing the estimated length of stay in hospitals
(ELOS) as counterfactual outcomes that guide clinical practice and model
training. In detail, MiranDa emulates the educational trajectory of doctors
through two gradient-scaling phases shifted by ELOS: an Evidence-based Training
Phase that utilizes supervised learning and a Therapeutic Optimization Phase
grounds in reinforcement learning within the gradient space, explores optimal
medications by perturbations from ELOS. Evaluation of the Medical Information
Mart for Intensive Care III dataset and IV dataset, showcased the superior
results of our model across five metrics, particularly in reducing the ELOS.
Surprisingly, our model provides structural attributes of medication
combinations proved in hyperbolic space and advocated "procedure-specific"
medication combinations. These findings posit that MiranDa enhanced medication
efficacy. Notably, our paradigm can be applied to nearly all medical tasks and
those with information to evaluate predicted outcomes. The source code of the
MiranDa model is available at https://github.com/azusakou/MiranDa.},
 author = {Ziheng Wang and Xinhe Li and Haruki Momma and Ryoichi Nagatomi},
 comment = {},
 doi = {},
 eprint = {2408.01445v1},
 journal = {arXiv preprint},
 title = {MiranDa: Mimicking the Learning Processes of Human Doctors to Achieve Causal Inference for Medication Recommendation},
 url = {http://arxiv.org/abs/2408.01445v1},
 year = {2024}
}

@article{2408.02045v1,
 abstract = {Semiparametric statistics play a pivotal role in a wide range of domains,
including but not limited to missing data, causal inference, and transfer
learning, to name a few. In many settings, semiparametric theory leads to
(nearly) statistically optimal procedures that yet involve numerically solving
Fredholm integral equations of the second kind. Traditional numerical methods,
such as polynomial or spline approximations, are difficult to scale to
multi-dimensional problems. Alternatively, statisticians may choose to
approximate the original integral equations by ones with closed-form solutions,
resulting in computationally more efficient, but statistically suboptimal or
even incorrect procedures. To bridge this gap, we propose a novel framework by
formulating the semiparametric estimation problem as a bi-level optimization
problem; and then we develop a scalable algorithm called Deep Neural-Nets
Assisted Semiparametric Estimation (DNA-SE) by leveraging the universal
approximation property of Deep Neural-Nets (DNN) to streamline semiparametric
procedures. Through extensive numerical experiments and a real data analysis,
we demonstrate the numerical and statistical advantages of $\dnase$ over
traditional methods. To the best of our knowledge, we are the first to bring
DNN into semiparametric statistics as a numerical solver of integral equations
in our proposed general framework.},
 author = {Qinshuo Liu and Zixin Wang and Xi-An Li and Xinyao Ji and Lei Zhang and Lin Liu and Zhonghua Liu},
 comment = {semiparametric statistics, missing data, causal inference, Fredholm
  integral equations of the second kind, bi-level optimization, deep learning,
  AI for science},
 doi = {},
 eprint = {2408.02045v1},
 journal = {arXiv preprint},
 title = {DNA-SE: Towards Deep Neural-Nets Assisted Semiparametric Estimation},
 url = {http://arxiv.org/abs/2408.02045v1},
 year = {2024}
}

@article{2408.02065v1,
 abstract = {In the ride-hailing industry, subsidies are predominantly employed to
incentivize consumers to place more orders, thereby fostering market growth.
Causal inference techniques are employed to estimate the consumer elasticity
with different subsidy levels. However, the presence of confounding effects
poses challenges in achieving an unbiased estimate of the uplift effect. We
introduce a consumer subsidizing system to capture relationships between
subsidy propensity and the treatment effect, which proves effective while
maintaining a lightweight online environment.},
 author = {Zhe Yu and Chi Xia and Shaosheng Cao and Lin Zhou},
 comment = {},
 doi = {},
 eprint = {2408.02065v1},
 journal = {arXiv preprint},
 title = {A Multi-class Ride-hailing Service Subsidy System Utilizing Deep Causal Networks},
 url = {http://arxiv.org/abs/2408.02065v1},
 year = {2024}
}

@article{2408.02349v4,
 abstract = {Osteoarthritis (OA) is the most common musculoskeletal disease, with knee OA
(KOA) being one of the leading causes of disability and a significant economic
burden. Predicting KOA progression is crucial for improving patient outcomes,
optimizing healthcare resources, studying the disease, and developing new
treatments. The latter application particularly requires one to understand the
disease progression in order to collect the most informative data at the right
time. Existing methods, however, are limited by their static nature and their
focus on individual joints, leading to suboptimal predictive performance and
downstream utility. Our study proposes a new method that allows to dynamically
monitor patients rather than individual joints with KOA using a novel Active
Sensing (AS) approach powered by Reinforcement Learning (RL). Our key idea is
to directly optimize for the downstream task by training an agent that
maximizes informative data collection while minimizing overall costs. Our
RL-based method leverages a specially designed reward function to monitor
disease progression across multiple body parts, employs multimodal deep
learning, and requires no human input during testing. Extensive numerical
experiments demonstrate that our approach outperforms current state-of-the-art
models, paving the way for the next generation of KOA trials.},
 author = {Khanh Nguyen and Huy Hoang Nguyen and Egor Panfilov and Aleksei Tiulpin},
 comment = {},
 doi = {},
 eprint = {2408.02349v4},
 journal = {arXiv preprint},
 title = {Toward Cost-efficient Adaptive Clinical Trials in Knee Osteoarthritis with Reinforcement Learning},
 url = {http://arxiv.org/abs/2408.02349v4},
 year = {2024}
}

@article{2408.02938v1,
 abstract = {Deep Reinforcement Learning (DRL) techniques have been successfully applied
for solving complex decision-making and control tasks in multiple fields
including robotics, autonomous driving, healthcare and natural language
processing. The ability of DRL agents to learn from experience and utilize
real-time data for making decisions makes it an ideal candidate for dealing
with the complexities associated with the problem of workflow scheduling in
highly dynamic cloud and edge computing environments. Despite the benefits of
DRL, there are multiple challenges associated with the application of DRL
techniques including multi-objectivity, curse of dimensionality, partial
observability and multi-agent coordination. In this paper, we comprehensively
analyze the challenges and opportunities associated with the design and
implementation of DRL oriented solutions for workflow scheduling in cloud and
edge computing environments. Based on the identified characteristics, we
propose a taxonomy of workflow scheduling with DRL. We map reviewed works with
respect to the taxonomy to identify their strengths and weaknesses. Based on
taxonomy driven analysis, we propose novel future research directions for the
field.},
 author = {Amanda Jayanetti and Saman Halgamuge and Rajkumar Buyya},
 comment = {},
 doi = {},
 eprint = {2408.02938v1},
 journal = {arXiv preprint},
 title = {Reinforcement Learning based Workflow Scheduling in Cloud and Edge Computing Environments: A Taxonomy, Review and Future Directions},
 url = {http://arxiv.org/abs/2408.02938v1},
 year = {2024}
}

@article{2408.04638v2,
 abstract = {Affective Computing (AC) integrates computer science, psychology, and
cognitive science to enable machines to recognize, interpret, and simulate
human emotions across domains such as social media, finance, healthcare, and
education. AC commonly centers on two task families: Affective Understanding
(AU) and Affective Generation (AG). While fine-tuned pre-trained language
models (PLMs) have achieved solid AU performance, they often generalize poorly
across tasks and remain limited for AG, especially in producing diverse,
emotionally appropriate responses. The advent of Large Language Models (LLMs)
(e.g., ChatGPT and LLaMA) has catalyzed a paradigm shift by offering in-context
learning, broader world knowledge, and stronger sequence generation. This
survey presents an NLP-oriented overview of AC in the LLM era. We (i)
consolidate traditional AC tasks and preliminary LLM-based studies; (ii) review
adaptation techniques that improve AU/AG, including Instruction Tuning (full
and parameter-efficient methods such as LoRA, P-/Prompt-Tuning), Prompt
Engineering (zero/few-shot, chain-of-thought, agent-based prompting), and
Reinforcement Learning. For the latter, we summarize RL from human preferences
(RLHF), verifiable/programmatic rewards (RLVR), and AI feedback (RLAIF), which
provide preference- or rule-grounded optimization signals that can help steer
AU/AG toward empathy, safety, and planning, achieving finer-grained or
multi-objective control. To assess progress, we compile benchmarks and
evaluation practices for both AU and AG. We also discuss open challenges-from
ethics, data quality, and safety to robust evaluation and resource
efficiency-and outline research directions. We hope this survey clarifies the
landscape and offers practical guidance for building affect-aware, reliable,
and responsible LLM systems.},
 author = {Yiqun Zhang and Xiaocui Yang and Xingle Xu and Zeran Gao and Yijie Huang and Shiyi Mu and Shi Feng and Daling Wang and Yifei Zhang and Kaisong Song and Ge Yu},
 comment = {Compared with the previous version, reinforcement learning has been
  added (as a new section), including RLHF, RLVR, and RLAIF},
 doi = {},
 eprint = {2408.04638v2},
 journal = {arXiv preprint},
 title = {Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective},
 url = {http://arxiv.org/abs/2408.04638v2},
 year = {2024}
}

@article{2408.04796v1,
 abstract = {The estimation of the ratio of two density probability functions is of great
interest in many statistics fields, including causal inference. In this study,
we develop an ensemble estimator of density ratios with a novel loss function
based on super learning. We show that this novel loss function is qualified for
building super learners. Two simulations corresponding to mediation analysis
and longitudinal modified treatment policy in causal inference, where density
ratios are nuisance parameters, are conducted to show our density ratio super
learner's performance empirically.},
 author = {Wencheng Wu and David Benkeser},
 comment = {10 pages, 3 figures, 2 tables},
 doi = {},
 eprint = {2408.04796v1},
 journal = {arXiv preprint},
 title = {A Density Ratio Super Learner},
 url = {http://arxiv.org/abs/2408.04796v1},
 year = {2024}
}

@article{2408.05428v2,
 abstract = {In causal inference, encouragement designs (EDs) are widely used to analyze
causal effects, when randomized controlled trials (RCTs) are impractical or
compliance to treatment cannot be perfectly enforced. Unlike RCTs, which
directly allocate treatments, EDs randomly assign encouragement policies that
positively motivate individuals to engage in a specific treatment. These random
encouragements act as instrumental variables (IVs), facilitating the
identification of causal effects through leveraging exogenous perturbations in
discrete treatment scenarios. However, real-world applications of encouragement
designs often face challenges such as incomplete randomization, limited
experimental data, and significantly fewer encouragements compared to
treatments, hindering precise causal effect estimation. To address this, this
paper introduces novel theories and algorithms for identifying the Conditional
Average Treatment Effect (CATE) using variations in encouragement. Further, by
leveraging both observational and encouragement data, we propose a generalized
IV estimator, named Encouragement-based Counterfactual Regression (EnCounteR),
to effectively estimate the causal effects. Extensive experiments on both
synthetic and real-world datasets demonstrate the superiority of EnCounteR over
existing methods.},
 author = {Anpeng Wu and Kun Kuang and Ruoxuan Xiong and Xiangwei Chen and Zexu Sun and Fei Wu and Kun Zhang},
 comment = {},
 doi = {},
 eprint = {2408.05428v2},
 journal = {arXiv preprint},
 title = {Generalized Encouragement-Based Instrumental Variables for Counterfactual Regression},
 url = {http://arxiv.org/abs/2408.05428v2},
 year = {2024}
}

@article{2408.05584v1,
 abstract = {Causality inference is prone to spurious causal interactions, due to the
substantial confounders in a complex system. While many existing methods based
on the statistical methods or dynamical methods attempt to address
misidentification challenges, there remains a notable lack of effective methods
to infer causality, in particular in the presence of invisible/unobservable
confounders. As a result, accurately inferring causation with invisible
confounders remains a largely unexplored and outstanding issue in data science
and AI fields. In this work, we propose a method to overcome such challenges to
infer dynamical causality under invisible confounders (CIC method) and further
reconstruct the invisible confounders from time-series data by developing an
orthogonal decomposition theorem in a delay embedding space. The core of our
CIC method lies in its ability to decompose the observed variables not in their
original space but in their delay embedding space into the common and private
subspaces respectively, thereby quantifying causality between those variables
both theoretically and computationally. This theoretical foundation ensures the
causal detection for any high-dimensional system even with only two observed
variables under many invisible confounders, which is actually a long-standing
problem in the field. In addition to the invisible confounder problem, such a
decomposition actually makes the intertwined variables separable in the
embedding space, thus also solving the non-separability problem of causal
inference. Extensive validation of the CIC method is carried out using various
real datasets, and the experimental results demonstrates its effectiveness to
reconstruct real biological networks even with unobserved confounders.},
 author = {Jinling Yan and Shao-Wu Zhang and Chihao Zhang and Weitian Huang and Jifan Shi and Luonan Chen},
 comment = {23 pages, 5 figures},
 doi = {},
 eprint = {2408.05584v1},
 journal = {arXiv preprint},
 title = {Dynamical causality under invisible confounders},
 url = {http://arxiv.org/abs/2408.05584v1},
 year = {2024}
}

@article{2408.06464v1,
 abstract = {Causal inference methods for observational data are increasingly recognized
as a valuable complement to randomized clinical trials (RCTs). They can, under
strong assumptions, emulate RCTs or help refine their focus. Our approach to
causal inference uses causal directed acyclic graphs (DAGs). We are motivated
by a concern that many observational studies in medicine begin without a clear
definition of their objectives, without awareness of the scientific potential,
and without tools to identify the necessary in itinere adjustments. We present
and illustrate methods that provide "midway insights" during study's course,
identify meaningful causal questions within the study's reach and point to the
necessary data base enhancements for these questions to be meaningfully
tackled. The method hinges on concepts of identification and positivity.
Concepts are illustrated through an analysis of data generated by patients with
aneurysmal Subarachnoid Hemorrhage (aSAH) halfway through a study, focusing in
particular on the consequences of external ventricular drain (EVD) in strata of
the aSAH population. In addition, we propose a method for multicenter studies,
to monitor the impact of changes in practice at an individual center's level,
by leveraging principles of instrumental variable (IV) inference.},
 author = {Carlo Berzuini and Davide Luciani and Hiren C. Patel},
 comment = {30 pages in 13pt font. 4 TIKZ figures. 9 PDF figures},
 doi = {},
 eprint = {2408.06464v1},
 journal = {arXiv preprint},
 title = {Causal Graph Aided Causal Discovery in an Observational Aneurysmal Subarachnoid Hemorrhage Study},
 url = {http://arxiv.org/abs/2408.06464v1},
 year = {2024}
}

@article{2408.07545v1,
 abstract = {Causal inference in hybrid domains, characterized by a mixture of discrete
and continuous variables, presents a formidable challenge. We take a step
towards this direction and propose Characteristic Interventional Sum-Product
Network ($\chi$SPN) that is capable of estimating interventional distributions
in presence of random variables drawn from mixed distributions. $\chi$SPN uses
characteristic functions in the leaves of an interventional SPN (iSPN) thereby
providing a unified view for discrete and continuous random variables through
the Fourier-Stieltjes transform of the probability measures. A neural network
is used to estimate the parameters of the learned iSPN using the intervened
data. Our experiments on 3 synthetic heterogeneous datasets suggest that
$\chi$SPN can effectively capture the interventional distributions for both
discrete and continuous variables while being expressive and causally adequate.
We also show that $\chi$SPN generalize to multiple interventions while being
trained only on a single intervention data.},
 author = {Harsh Poonia and Moritz Willig and Zhongjie Yu and Matej Zečević and Kristian Kersting and Devendra Singh Dhami},
 comment = {17 pages, 11 figures. Accepted as poster at UAI (Uncertainty in
  Artificial Intelligence) 2024},
 doi = {},
 eprint = {2408.07545v1},
 journal = {arXiv preprint},
 title = {$χ$SPN: Characteristic Interventional Sum-Product Networks for Causal Inference in Hybrid Domains},
 url = {http://arxiv.org/abs/2408.07545v1},
 year = {2024}
}

@article{2408.07569v1,
 abstract = {Learning electronic health records (EHRs) has received emerging attention
because of its capability to facilitate accurate medical diagnosis. Since the
EHRs contain enriched information specifying complex interactions between
entities, modeling EHRs with graphs is shown to be effective in practice. The
EHRs, however, present a great degree of heterogeneity, sparsity, and
complexity, which hamper the performance of most of the models applied to them.
Moreover, existing approaches modeling EHRs often focus on learning the
representations for a single task, overlooking the multi-task nature of EHR
analysis problems and resulting in limited generalizability across different
tasks. In view of these limitations, we propose a novel framework for EHR
modeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous
graph to mine the complex relations and model the heterogeneity in the EHRs. To
mitigate the large degree of noise, we introduce a denoising module based on
the causal inference framework to adjust for severe confounding effects and
reduce noise in the EHR data. Additionally, since our model adopts a single
graph neural network for simultaneous multi-task prediction, we design a
multi-task learning module to leverage the inter-task knowledge to regularize
the training process. Extensive empirical studies on MIMIC-III and MIMIC-IV
datasets validate that the proposed method consistently outperforms the
state-of-the-art designs in four popular EHR analysis tasks -- drug
recommendation, and predictions of the length of stay, mortality, and
readmission. Thorough ablation studies demonstrate the robustness of our method
upon variations to key components and hyperparameters.},
 author = {Tsai Hor Chan and Guosheng Yin and Kyongtae Bae and Lequan Yu},
 comment = {Accepted by Neural Networks},
 doi = {},
 eprint = {2408.07569v1},
 journal = {arXiv preprint},
 title = {Multi-task Heterogeneous Graph Learning on Electronic Health Records},
 url = {http://arxiv.org/abs/2408.07569v1},
 year = {2024}
}

@article{2408.07629v1,
 abstract = {By providing evidence-based clinical decision support, digital tools and
electronic health records can revolutionize patient management, especially in
resource-poor settings where fewer health workers are available and often need
more training. When these tools are integrated with AI, they can offer
personalized support and adaptive interventions, effectively connecting
community health workers (CHWs) and healthcare facilities. The CHARM (Community
Health Access & Resource Management) app is an AI-native mobile app for CHWs.
Developed through a joint partnership of Causal Foundry (CF) and
mothers2mothers (m2m), CHARM empowers CHWs, mainly local women, by streamlining
case management, enhancing learning, and improving communication. This paper
details CHARM's development, integration, and upcoming reinforcement
learning-based adaptive interventions, all aimed at enhancing health worker
engagement, efficiency, and patient outcomes, thereby enhancing CHWs'
capabilities and community health.},
 author = {África Periáñez and Kathrin Schmitz and Lazola Makhupula and Moiz Hassan and Moeti Moleko and Ana Fernández del Río and Ivan Nazarov and Aditya Rastogi and Dexian Tang},
 comment = {Presented at the 7th epiDAMIK ACM SIGKDD International Workshop on
  Epidemiology meets Data Mining and Knowledge Discovery, August 26, 2024,
  Barcelona, Spain},
 doi = {},
 eprint = {2408.07629v1},
 journal = {arXiv preprint},
 title = {Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings},
 url = {http://arxiv.org/abs/2408.07629v1},
 year = {2024}
}

@article{2408.07647v1,
 abstract = {Pharmacies are critical in healthcare systems, particularly in low- and
middle-income countries. Procuring pharmacists with the right behavioral
interventions or nudges can enhance their skills, public health awareness, and
pharmacy inventory management, ensuring access to essential medicines that
ultimately benefit their patients. We introduce a reinforcement learning
operational system to deliver personalized behavioral interventions through
mobile health applications. We illustrate its potential by discussing a series
of initial experiments run with SwipeRx, an all-in-one app for pharmacists,
including B2B e-commerce, in Indonesia. The proposed method has broader
applications extending beyond pharmacy operations to optimize healthcare
delivery.},
 author = {Ana Fernández del Río and Michael Brennan Leong and Paulo Saraiva and Ivan Nazarov and Aditya Rastogi and Moiz Hassan and Dexian Tang and África Periáñez},
 comment = {Presented at The First Workshop on AI Behavioral Science (AIBS'24) at
  KDD 2024, August 25, Barcelona, Spain},
 doi = {},
 eprint = {2408.07647v1},
 journal = {arXiv preprint},
 title = {Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services},
 url = {http://arxiv.org/abs/2408.07647v1},
 year = {2024}
}

@article{2408.08024v1,
 abstract = {This paper introduces a reinforcement learning (RL) platform that enhances
end-to-end user journeys in healthcare digital tools through personalization.
We explore a case study with SwipeRx, the most popular all-in-one app for
pharmacists in Southeast Asia, demonstrating how the platform can be used to
personalize and adapt user experiences. Our RL framework is tested through a
series of experiments with product recommendations tailored to each pharmacy
based on real-time information on their purchasing history and in-app
engagement, showing a significant increase in basket size. By integrating
adaptive interventions into existing mobile health solutions and enriching user
journeys, our platform offers a scalable solution to improve pharmaceutical
supply chain management, health worker capacity building, and clinical decision
and patient care, ultimately contributing to better healthcare outcomes.},
 author = {Ana Fernández del Río and Michael Brennan Leong and Paulo Saraiva and Ivan Nazarov and Aditya Rastogi and Moiz Hassan and Dexian Tang and África Periáñez},
 comment = {Presented at the Third Workshop on End-to-End Customer Journey
  Optimization at KDD 2024 (KDD CJ Workshop '24), August 26, Barcelona, Spain},
 doi = {},
 eprint = {2408.08024v1},
 journal = {arXiv preprint},
 title = {Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx},
 url = {http://arxiv.org/abs/2408.08024v1},
 year = {2024}
}

@article{2408.10091v1,
 abstract = {Objectives: Highly flexible nonparametric estimators have gained popularity
in causal inference and epidemiology. Popular examples of such estimators
include targeted maximum likelihood estimators (TMLE) and double machine
learning (DML). TMLE is often argued or suggested to be better than DML
estimators and several other estimators in small to moderate samples -- even if
they share the same large-sample properties -- because TMLE is a plug-in
estimator and respects the known bounds on the parameter, while other
estimators might fall outside the known bounds and yield absurd estimates.
However, this argument is not a rigorously proven result and may fail in
certain cases. Methods: In a carefully chosen simulation setting, I compare the
performance of several versions of TMLE and DML estimators of the average
treatment effect among treated in small to moderate samples. Results: In this
simulation setting, DML estimators outperforms some versions of TMLE in small
samples. TMLE fluctuations are unstable, and hence empirically checking the
magnitude of the TMLE fluctuation might alert cases where TMLE might perform
poorly. Conclusions: As a plug-in estimator, TMLE is not guaranteed to
outperform non-plug-in counterparts such as DML estimators in small samples.
Checking the fluctuation magnitude might be a useful diagnosis for TMLE. More
rigorous theoretical justification is needed to understand and compare the
finite-sample performance of these highly flexible estimators in general.},
 author = {Hongxiang Qiu},
 comment = {},
 doi = {},
 eprint = {2408.10091v1},
 journal = {arXiv preprint},
 title = {Non-Plug-In Estimators Could Outperform Plug-In Estimators: a Cautionary Note and a Diagnosis},
 url = {http://arxiv.org/abs/2408.10091v1},
 year = {2024}
}

@article{2408.11623v2,
 abstract = {In modern online platforms, incentives are essential factors that enhance
user engagement and increase platform revenue. Over recent years, uplift
modeling has been introduced as a strategic approach to assign incentives to
individual customers. Especially in many real-world applications, online
platforms can only incentivize customers with specific budget constraints. This
problem can be reformulated as the multi-choice knapsack problem. This
optimization aims to select the optimal incentive for each customer to maximize
the return on investment. Recent works in this field frequently tackle the
budget allocation problem using a two-stage approach. However, this solution is
confronted with the following challenges: (1) The causal inference methods
often ignore the domain knowledge in online marketing, where the expected
response curve of a customer should be monotonic and smooth as the incentive
increases. (2) An optimality gap between the two stages results in inferior
sub-optimal allocation performance due to the loss of the incentive
recommendation information for the uplift prediction under the limited budget
constraint. To address these challenges, we propose a novel End-to-End
Cost-Effective Incentive Recommendation (E3IR) model under budget constraints.
Specifically, our methods consist of two modules, i.e., the uplift prediction
module and the differentiable allocation module. In the uplift prediction
module, we construct prediction heads to capture the incremental improvement
between adjacent treatments with the marketing domain constraints (i.e.,
monotonic and smooth). We incorporate integer linear programming (ILP) as a
differentiable layer input in the allocation module. Furthermore, we conduct
extensive experiments on public and real product datasets, demonstrating that
our E3IR improves allocation performance compared to existing two-stage
approaches.},
 author = {Zexu Sun and Hao Yang and Dugang Liu and Yunpeng Weng and Xing Tang and Xiuqiang He},
 comment = {Accepted by RecSys 2024},
 doi = {},
 eprint = {2408.11623v2},
 journal = {arXiv preprint},
 title = {End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling},
 url = {http://arxiv.org/abs/2408.11623v2},
 year = {2024}
}

@article{2408.12803v1,
 abstract = {As a key component in boosting online user growth, uplift modeling aims to
measure individual user responses (e.g., whether to play the game) to various
treatments, such as gaming bonuses, thereby enhancing business outcomes.
However, previous research typically considers a single-task, single-treatment
setting, where only one treatment exists and the overall treatment effect is
measured by a single type of user response. In this paper, we propose a
Multi-Treatment Multi-Task (MTMT) uplift network to estimate treatment effects
in a multi-task scenario. We identify the multi-treatment problem as a causal
inference problem with a tiered response, comprising a base effect (from
offering a treatment) and an incremental effect (from offering a specific type
of treatment), where the base effect can be numerically much larger than the
incremental effect. Specifically, MTMT separately encodes user features and
treatments. The user feature encoder uses a multi-gate mixture of experts
(MMOE) network to encode relevant user features, explicitly learning inter-task
relations. The resultant embeddings are used to measure natural responses per
task. Furthermore, we introduce a treatment-user feature interaction module to
model correlations between each treatment and user feature. Consequently, we
separately measure the base and incremental treatment effect for each task
based on the produced treatment-aware representations. Experimental results
based on an offline public dataset and an online proprietary dataset
demonstrate the effectiveness of MTMT in single/multi-treatment and
single/multi-task settings. Additionally, MTMT has been deployed in our gaming
platform to improve user experience.},
 author = {Yuxiang Wei and Zhaoxin Qiu and Yingjie Li and Yuke Sun and Xiaoling Li},
 comment = {},
 doi = {},
 eprint = {2408.12803v1},
 journal = {arXiv preprint},
 title = {Multi-Treatment Multi-Task Uplift Modeling for Enhancing User Growth},
 url = {http://arxiv.org/abs/2408.12803v1},
 year = {2024}
}

@article{2408.13002v4,
 abstract = {Causal machine learning holds promise for estimating individual treatment
effects from complex data. For successful real-world applications of machine
learning methods, it is of paramount importance to obtain reliable insights
into which variables drive heterogeneity in the response to treatment. We
propose PermuCATE, an algorithm based on the Conditional Permutation Importance
(CPI) method, for statistically rigorous global variable importance assessment
in the estimation of the Conditional Average Treatment Effect (CATE).
Theoretical analysis of the finite sample regime and empirical studies show
that PermuCATE has lower variance than the Leave-One-Covariate-Out (LOCO)
reference method and provides a reliable measure of variable importance. This
property increases statistical power, which is crucial for causal inference in
the limited-data regime common to biomedical applications. We empirically
demonstrate the benefits of PermuCATE in simulated and real-world health
datasets, including settings with up to hundreds of correlated variables.},
 author = {Joseph Paillard and Angel Reyero Lobo and Vitaliy Kolodyazhniy and Bertrand Thirion and Denis A. Engemann},
 comment = {},
 doi = {},
 eprint = {2408.13002v4},
 journal = {arXiv preprint},
 title = {Measuring Variable Importance in Heterogeneous Treatment Effects with Confidence},
 url = {http://arxiv.org/abs/2408.13002v4},
 year = {2024}
}

@article{2408.13071v1,
 abstract = {Healthcare alert systems (HAS) are undergoing rapid evolution, propelled by
advancements in artificial intelligence (AI), Internet of Things (IoT)
technologies, and increasing health consciousness. Despite significant
progress, a fundamental challenge remains: balancing the accuracy of
personalized health alerts with stringent privacy protection in HAS
environments constrained by resources. To address this issue, we introduce a
uniform framework, LLM-HAS, which incorporates Large Language Models (LLM) into
HAS to significantly boost the accuracy, ensure user privacy, and enhance
personalized health service, while also improving the subjective quality of
experience (QoE) for users. Our innovative framework leverages a Mixture of
Experts (MoE) approach, augmented with LLM, to analyze users' personalized
preferences and potential health risks from additional textual job
descriptions. This analysis guides the selection of specialized Deep
Reinforcement Learning (DDPG) experts, tasked with making precise health
alerts. Moreover, LLM-HAS can process Conversational User Feedback, which not
only allows fine-tuning of DDPG but also deepen user engagement, thereby
enhancing both the accuracy and personalization of health management
strategies. Simulation results validate the effectiveness of the LLM-HAS
framework, highlighting its potential as a groundbreaking approach for
employing generative AI (GAI) to provide highly accurate and reliable alerts.},
 author = {Yulan Gao and Ziqiang Ye and Ming Xiao and Yue Xiao and Dong In Kim},
 comment = {},
 doi = {},
 eprint = {2408.13071v1},
 journal = {arXiv preprint},
 title = {Guiding IoT-Based Healthcare Alert Systems with Large Language Models},
 url = {http://arxiv.org/abs/2408.13071v1},
 year = {2024}
}

@article{2408.14620v2,
 abstract = {Causal mediation analyses investigate the mechanisms through which causes
exert their effects, and are therefore central to scientific progress. The
literature on the non-parametric definition and identification of mediational
effects in rigourous causal models has grown significantly in recent years, and
there has been important progress to address challenges in the interpretation
and identification of such effects. Despite great progress in the causal
inference front, statistical methodology for non-parametric estimation has
lagged behind, with few or no methods available for tackling non-parametric
estimation in the presence of multiple, continuous, or high-dimensional
mediators. In this paper we show that the identification formulas for six
popular non-parametric approaches to mediation analysis proposed in recent
years can be recovered from just two statistical estimands. We leverage this
finding to propose an all-purpose one-step estimation algorithm that can be
coupled with machine learning in any mediation study that uses any of these six
definitions of mediation. The estimators have desirable properties, such as
$\sqrt{n}$-convergence and asymptotic normality. Estimating the first-order
correction for the one-step estimator requires estimation of complex density
ratios on the potentially high-dimensional mediators, a challenge that is
solved using recent advancements in so-called Riesz learning. We illustrate the
properties of our methods in a simulation study and illustrate its use on real
data to estimate the extent to which pain management practices mediate the
total effect of having a chronic pain disorder on opioid use disorder.},
 author = {Richard Liu and Nicholas T. Williams and Kara E. Rudolph and Iván Díaz},
 comment = {},
 doi = {},
 eprint = {2408.14620v2},
 journal = {arXiv preprint},
 title = {General targeted machine learning for modern causal mediation analysis},
 url = {http://arxiv.org/abs/2408.14620v2},
 year = {2024}
}

@article{2408.14915v3,
 abstract = {How can Transformers model and learn enumerative geometry? What is a robust
procedure for using Transformers in abductive knowledge discovery within a
mathematician-machine collaboration? In this work, we introduce a
Transformer-based approach to computational enumerative geometry, specifically
targeting the computation of $\psi$-class intersection numbers on the moduli
space of curves. By reformulating the problem as a continuous optimization
task, we compute intersection numbers across a wide value range from $10^{-45}$
to $10^{45}$. To capture the recursive nature inherent in these intersection
numbers, we propose the Dynamic Range Activator (DRA), a new activation
function that enhances the Transformer's ability to model recursive patterns
and handle severe heteroscedasticity. Given precision requirements for
computing the intersections, we quantify the uncertainty of the predictions
using Conformal Prediction with a dynamic sliding window adaptive to the
partitions of equivalent number of marked points. To the best of our knowledge,
there has been no prior work on modeling recursive functions with such a
high-variance and factorial growth. Beyond simply computing intersection
numbers, we explore the enumerative "world-model" of Transformers. Our
interpretability analysis reveals that the network is implicitly modeling the
Virasoro constraints in a purely data-driven manner. Moreover, through
abductive hypothesis testing, probing, and causal inference, we uncover
evidence of an emergent internal representation of the the large-genus
asymptotic of $\psi$-class intersection numbers. These findings suggest that
the network internalizes the parameters of the asymptotic closed-form and the
polynomiality phenomenon of intersection numbers in a non-linear manner. This
opens up new possibilities in inferring asymptotic closed-form expressions
directly from limited amount of data.},
 author = {Baran Hashemi and Roderic G. Corominas and Alessandro Giacchetto},
 comment = {Published at ICLR 2025},
 doi = {},
 eprint = {2408.14915v3},
 journal = {arXiv preprint},
 title = {Can Transformers Do Enumerative Geometry?},
 url = {http://arxiv.org/abs/2408.14915v3},
 year = {2024}
}

@article{2408.15055v1,
 abstract = {Understanding and inferencing Heterogeneous Treatment Effects (HTE) and
Conditional Average Treatment Effects (CATE) are vital for developing
personalized treatment recommendations. Many state-of-the-art approaches
achieve inspiring performance in estimating HTE on benchmark datasets or
simulation studies. However, the indirect predicting manner and complex model
architecture reduce the interpretability of these approaches. To mitigate the
gap between predictive performance and heterogeneity interpretability, we
introduce the Causal Rule Forest (CRF), a novel approach to learning hidden
patterns from data and transforming the patterns into interpretable multi-level
Boolean rules. By training the other interpretable causal inference models with
data representation learned by CRF, we can reduce the predictive errors of
these models in estimating HTE and CATE, while keeping their interpretability
for identifying subgroups that a treatment is more effective. Our experiments
underscore the potential of CRF to advance personalized interventions and
policies, paving the way for future research to enhance its scalability and
application across complex causal inference challenges.},
 author = {Chan Hsu and Jun-Ting Wu and Yihuang Kang},
 comment = {The 25th IEEE International Conference on Information Reuse and
  Integration for Data Science (IRI 2024)},
 doi = {},
 eprint = {2408.15055v1},
 journal = {arXiv preprint},
 title = {Causal Rule Forest: Toward Interpretable and Precise Treatment Effect Estimation},
 url = {http://arxiv.org/abs/2408.15055v1},
 year = {2024}
}

@article{2408.15133v1,
 abstract = {Causality is vital for understanding true cause-and-effect relationships
between variables within predictive models, rather than relying on mere
correlations, making it highly relevant in the field of Explainable AI. In an
automated decision-making scenario, causal inference methods can analyze the
underlying data-generation process, enabling explanations of a model's decision
by manipulating features and creating counterfactual examples. These
counterfactuals explore hypothetical scenarios where a minimal number of
factors are altered, providing end-users with valuable information on how to
change their situation. However, interpreting a set of multiple counterfactuals
can be challenging for end-users who are not used to analyzing raw data
records. In our work, we propose a novel multi-step pipeline that uses
counterfactuals to generate natural language explanations of actions that will
lead to a change in outcome in classifiers of tabular data using LLMs. This
pipeline is designed to guide the LLM through smaller tasks that mimic human
reasoning when explaining a decision based on counterfactual cases. We
conducted various experiments using a public dataset and proposed a method of
closed-loop evaluation to assess the coherence of the final explanation with
the counterfactuals, as well as the quality of the content. Results are
promising, although further experiments with other datasets and human
evaluations should be carried out.},
 author = {Arturo Fredes and Jordi Vitria},
 comment = {Presented as a poster in the 2nd Workshop on Causal Inference and
  Machine Learning in Practice at KDD 2024},
 doi = {},
 eprint = {2408.15133v1},
 journal = {arXiv preprint},
 title = {Using LLMs for Explaining Sets of Counterfactual Examples to Final Users},
 url = {http://arxiv.org/abs/2408.15133v1},
 year = {2024}
}

@article{2408.17053v2,
 abstract = {Estimating the conditional average treatment effects (CATE) is very important
in causal inference and has a wide range of applications across many fields. In
the estimation process of CATE, the unconfoundedness assumption is typically
required to ensure the identifiability of the regression problems. When
estimating CATE using high-dimensional data, there have been many variable
selection methods and neural network approaches based on representation
learning, while these methods do not provide a way to verify whether the subset
of variables after dimensionality reduction or the learned representations
still satisfy the unconfoundedness assumption during the estimation process,
which can lead to ineffective estimates of the treatment effects. Additionally,
these methods typically use data from only the treatment or control group when
estimating the regression functions for each group. This paper proposes a novel
neural network approach named \textbf{CrossNet} to learn a sufficient
representation for the features, based on which we then estimate the CATE,
where cross indicates that in estimating the regression functions, we used data
from their own group as well as cross-utilized data from another group.
Numerical simulations and empirical results demonstrate that our method
outperforms the competitive approaches.},
 author = {Pengfei Shi and Wei Zhong and Xinyu Zhang and Ningtao Wang and Xing Fu and Weiqiang Wang and Yin Jin},
 comment = {},
 doi = {},
 eprint = {2408.17053v2},
 journal = {arXiv preprint},
 title = {Estimating Conditional Average Treatment Effects via Sufficient Representation Learning},
 url = {http://arxiv.org/abs/2408.17053v2},
 year = {2024}
}

@article{2408.17183v2,
 abstract = {Context: Software Quality Assurance (SQA) is a fundamental part of software
engineering to ensure stakeholders that software products work as expected
after release in operation. Machine Learning (ML) has proven to be able to
boost SQA activities and contribute to the development of quality software
systems. In this context, Causal Reasoning is gaining increasing interest as a
methodology to go beyond a purely data-driven approach by exploiting the use of
causality for more effective SQA strategies. Objective: Provide a broad and
detailed overview of the use of causal reasoning for SQA activities, in order
to support researchers to access this research field, identifying room for
application, main challenges and research opportunities. Methods: A systematic
review of the scientific literature on causal reasoning for SQA. The study has
found, classified, and analyzed 86 articles, according to established
guidelines for software engineering secondary studies. Results: Results
highlight the primary areas within SQA where causal reasoning has been applied,
the predominant methodologies used, and the level of maturity of the proposed
solutions. Fault localization is the activity where causal reasoning is more
exploited, especially in the web services/microservices domain, but other tasks
like testing are rapidly gaining popularity. Both causal inference and causal
discovery are exploited, with the Pearl's graphical formulation of causality
being preferred, likely due to its intuitiveness. Tools to favour their
application are appearing at a fast pace - most of them after 2021.
Conclusions: The findings show that causal reasoning is a valuable means for
SQA tasks with respect to multiple quality attributes, especially during V&V,
evolution and maintenance to ensure reliability, while it is not yet fully
exploited for phases like ...},
 author = {Luca Giamattei and Antonio Guerriero and Roberto Pietrantuono and Stefano Russo},
 comment = {Accepted to Information and Software Technology journal},
 doi = {10.1016/j.infsof.2024.107599},
 eprint = {2408.17183v2},
 journal = {arXiv preprint},
 title = {Causal Reasoning in Software Quality Assurance: A Systematic Review},
 url = {http://arxiv.org/abs/2408.17183v2},
 year = {2024}
}

@article{2409.02097v3,
 abstract = {Modern diffusion models, particularly those utilizing a Transformer-based
UNet for denoising, rely heavily on self-attention operations to manage complex
spatial relationships, thus achieving impressive generation performance.
However, this existing paradigm faces significant challenges in generating
high-resolution visual content due to its quadratic time and memory complexity
with respect to the number of spatial tokens. To address this limitation, we
aim at a novel linear attention mechanism as an alternative in this paper.
Specifically, we begin our exploration from recently introduced models with
linear complexity, e.g., Mamba2, RWKV6, Gated Linear Attention, etc, and
identify two key features--attention normalization and non-causal
inference--that enhance high-resolution visual generation performance. Building
on these insights, we introduce a generalized linear attention paradigm, which
serves as a low-rank approximation of a wide spectrum of popular linear token
mixers. To save the training cost and better leverage pre-trained models, we
initialize our models and distill the knowledge from pre-trained
StableDiffusion (SD). We find that the distilled model, termed LinFusion,
achieves performance on par with or superior to the original SD after only
modest training, while significantly reducing time and memory complexity.
Extensive experiments on SD-v1.5, SD-v2.1, and SD-XL demonstrate that LinFusion
enables satisfactory and efficient zero-shot cross-resolution generation,
accommodating ultra-resolution images like 16K on a single GPU. Moreover, it is
highly compatible with pre-trained SD components and pipelines, such as
ControlNet, IP-Adapter, DemoFusion, DistriFusion, etc, requiring no adaptation
efforts. Codes are available at https://github.com/Huage001/LinFusion.},
 author = {Songhua Liu and Weihao Yu and Zhenxiong Tan and Xinchao Wang},
 comment = {Work in Progress. Codes are available at
  https://github.com/Huage001/LinFusion},
 doi = {},
 eprint = {2409.02097v3},
 journal = {arXiv preprint},
 title = {LinFusion: 1 GPU, 1 Minute, 16K Image},
 url = {http://arxiv.org/abs/2409.02097v3},
 year = {2024}
}

@article{2409.02604v2,
 abstract = {Scientific discovery catalyzes human intellectual advances, driven by the
cycle of hypothesis generation, experimental design, evaluation, and assumption
refinement. Central to this process is causal inference, uncovering the
mechanisms behind observed phenomena. While randomized experiments provide
strong inferences, they are often infeasible due to ethical or practical
constraints. However, observational studies are prone to confounding or
mediating biases. While crucial, identifying such backdoor paths is expensive
and heavily depends on scientists' domain knowledge to generate hypotheses. We
introduce a novel benchmark where the objective is to complete a partial causal
graph. We design a benchmark with varying difficulty levels with over 4000
queries. We show the strong ability of LLMs to hypothesize the backdoor
variables between a cause and its effect. Unlike simple knowledge memorization
of fixed associations, our task requires the LLM to reason according to the
context of the entire graph.},
 author = {Ivaxi Sheth and Sahar Abdelnabi and Mario Fritz},
 comment = {EMNLP'25 Findings},
 doi = {},
 eprint = {2409.02604v2},
 journal = {arXiv preprint},
 title = {Context-Aware Reasoning On Parametric Knowledge for Inferring Causal Variables},
 url = {http://arxiv.org/abs/2409.02604v2},
 year = {2024}
}

@article{2409.04140v2,
 abstract = {Inference and inverse problems are closely related concepts, both
fundamentally involving the deduction of unknown causes or parameters from
observed data. Bayesian inference, a powerful class of methods, is often
employed to solve a variety of problems, including those related to causal
inference. Variational inference, a subset of Bayesian inference, is primarily
used to efficiently approximate complex posterior distributions. Variational
Autoencoders (VAEs), which combine variational inference with deep learning,
have become widely applied across various domains. This study explores the
potential of VAEs for solving inverse problems, such as Independent Component
Analysis (ICA), without relying on an explicit inverse mapping process. Unlike
other VAE-based ICA methods, this approach discards the encoder in the VAE
architecture, directly setting the latent variables as trainable parameters. In
other words, the latent variables are no longer outputs of the encoder but are
instead optimized directly through the objective function to converge to
appropriate values. We find that, with a suitable prior setup, the latent
variables, represented by trainable parameters, can exhibit mutually
independent properties as the parameters converge, all without the need for an
encoding process. This approach, referred to as the Half-VAE, bypasses the
inverse mapping process by eliminating the encoder. This study demonstrates the
feasibility of using the Half-VAE to solve ICA without the need for an explicit
inverse mapping process.},
 author = {Yuan-Hao Wei and Yan-Jie Sun and Chen Zhang},
 comment = {},
 doi = {},
 eprint = {2409.04140v2},
 journal = {arXiv preprint},
 title = {Half-VAE: An Encoder-Free VAE to Bypass Explicit Inverse Mapping},
 url = {http://arxiv.org/abs/2409.04140v2},
 year = {2024}
}

@article{2409.04174v1,
 abstract = {In this study, we evaluate causal inference estimators for online controlled
bipartite graph experiments in a real marketplace setting. Our novel
contribution is constructing a bipartite graph using in-experiment data, rather
than relying on prior knowledge or historical data, the common approach in the
literature published to date. We build the bipartite graph from various
interactions between buyers and sellers in the marketplace, establishing a
novel research direction at the intersection of bipartite experiments and
mediation analysis. This approach is crucial for modern marketplaces aiming to
evaluate seller-side causal effects in buyer-side experiments, or vice versa.
We demonstrate our method using historical buyer-side experiments conducted at
Vinted, the largest second-hand marketplace in Europe with over 80M users.},
 author = {Vaiva Pilkauskaitė and Jevgenij Gamper and Rasa Giniūnaitė and Agne Reklaitė},
 comment = {5 pages, 3 figures, this work was presented at the KDD 2024
  Conference Undergraduate Consortium},
 doi = {},
 eprint = {2409.04174v1},
 journal = {arXiv preprint},
 title = {Towards Measuring Sell Side Outcomes in Buy Side Marketplace Experiments using In-Experiment Bipartite Graph},
 url = {http://arxiv.org/abs/2409.04174v1},
 year = {2024}
}

@article{2409.04224v2,
 abstract = {In healthcare, multi-organ system diseases pose unique and significant
challenges as they impact multiple physiological systems concurrently,
demanding complex and coordinated treatment strategies. Despite recent
advancements in the AI based clinical decision support systems, these solutions
only focus on individual organ systems, failing to account for complex
interdependencies between them. This narrow focus greatly hinders their
effectiveness in recommending holistic and clinically actionable treatments in
the real world setting. To address this critical gap, we propose a novel
Hierarchical Multi-Agent Reinforcement Learning (HMARL) framework. Our
architecture deploys specialized and dedicated agents for each organ system and
facilitates inter-agent communication to enable synergistic decision-making
across organ systems. Furthermore, we introduce a dual-layer state
representation technique that contextualizes patient conditions at both global
and organ-specific levels, improving the accuracy and relevance of treatment
decisions. We evaluate our HMARL solution on the task of sepsis management, a
common and critical multi-organ disease, using both qualitative and
quantitative metrics. Our method learns effective, clinically aligned treatment
policies that considerably improve patient survival. We believe this framework
represents a significant advancement in clinical decision support systems,
introducing the first RL solution explicitly designed for multi-organ treatment
recommendations. Our solution moves beyond prevailing simplified, single-organ
models that fall short in addressing the complexity of multi-organ diseases.},
 author = {Daniel J. Tan and Qianyi Xu and Kay Choong See and Dilruk Perera and Mengling Feng},
 comment = {},
 doi = {},
 eprint = {2409.04224v2},
 journal = {arXiv preprint},
 title = {Advancing Multi-Organ Disease Care: A Hierarchical Multi-Agent Reinforcement Learning Framework},
 url = {http://arxiv.org/abs/2409.04224v2},
 year = {2024}
}

@article{2409.05459v2,
 abstract = {Matching is a popular approach in causal inference to estimate treatment
effects by pairing treated and control units that are most similar in terms of
their covariate information. However, classic matching methods completely
ignore the geometry of the data manifold, which is crucial to define a
meaningful distance for matching, and struggle when covariates are noisy and
high-dimensional. In this work, we propose GeoMatching, a matching method to
estimate treatment effects that takes into account the intrinsic data geometry
induced by existing causal mechanisms among the confounding variables. First,
we learn a low-dimensional, latent Riemannian manifold that accounts for
uncertainty and geometry of the original input data. Second, we estimate
treatment effects via matching in the latent space based on the learned latent
Riemannian metric. We provide theoretical insights and empirical results in
synthetic and real-world scenarios, demonstrating that GeoMatching yields more
effective treatment effect estimators, even as we increase input
dimensionality, in the presence of outliers, or in semi-supervised scenarios.},
 author = {Melanie F. Pradier and Javier González},
 comment = {},
 doi = {},
 eprint = {2409.05459v2},
 journal = {arXiv preprint},
 title = {Beyond Flatland: A Geometric Take on Matching Methods for Treatment Effect Estimation},
 url = {http://arxiv.org/abs/2409.05459v2},
 year = {2024}
}

@article{2409.05665v1,
 abstract = {This research aims to propose and evaluate a novel model named K-Fold Causal
Bayesian Additive Regression Trees (K-Fold Causal BART) for improved estimation
of Average Treatment Effects (ATE) and Conditional Average Treatment Effects
(CATE). The study employs synthetic and semi-synthetic datasets, including the
widely recognized Infant Health and Development Program (IHDP) benchmark
dataset, to validate the model's performance. Despite promising results in
synthetic scenarios, the IHDP dataset reveals that the proposed model is not
state-of-the-art for ATE and CATE estimation. Nonetheless, the research
provides several novel insights: 1. The ps-BART model is likely the preferred
choice for CATE and ATE estimation due to better generalization compared to the
other benchmark models - including the Bayesian Causal Forest (BCF) model,
which is considered by many the current best model for CATE estimation, 2. The
BCF model's performance deteriorates significantly with increasing treatment
effect heterogeneity, while the ps-BART model remains robust, 3. Models tend to
be overconfident in CATE uncertainty quantification when treatment effect
heterogeneity is low, 4. A second K-Fold method is unnecessary for avoiding
overfitting in CATE estimation, as it adds computational costs without
improving performance, 5. Detailed analysis reveals the importance of
understanding dataset characteristics and using nuanced evaluation methods, 6.
The conclusion of Curth et al. (2021) that indirect strategies for CATE
estimation are superior for the IHDP dataset is contradicted by the results of
this research. These findings challenge existing assumptions and suggest
directions for future research to enhance causal inference methodologies.},
 author = {Hugo Gobato Souto and Francisco Louzada Neto},
 comment = {},
 doi = {},
 eprint = {2409.05665v1},
 journal = {arXiv preprint},
 title = {K-Fold Causal BART for CATE Estimation},
 url = {http://arxiv.org/abs/2409.05665v1},
 year = {2024}
}

@article{2409.06593v1,
 abstract = {This paper introduces a generalized ps-BART model for the estimation of
Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE)
in continuous treatments, addressing limitations of the Bayesian Causal Forest
(BCF) model. The ps-BART model's nonparametric nature allows for flexibility in
capturing nonlinear relationships between treatment and outcome variables.
Across three distinct sets of Data Generating Processes (DGPs), the ps-BART
model consistently outperforms the BCF model, particularly in highly nonlinear
settings. The ps-BART model's robustness in uncertainty estimation and accuracy
in both point-wise and probabilistic estimation demonstrate its utility for
real-world applications. This research fills a crucial gap in causal inference
literature, providing a tool better suited for nonlinear treatment-outcome
relationships and opening avenues for further exploration in the domain of
continuous treatment effect estimation.},
 author = {Hugo Gobato Souto and Francisco Louzada Neto},
 comment = {},
 doi = {},
 eprint = {2409.06593v1},
 journal = {arXiv preprint},
 title = {Advancing Causal Inference: A Nonparametric Approach to ATE and CATE Estimation with Continuous Treatments},
 url = {http://arxiv.org/abs/2409.06593v1},
 year = {2024}
}

@article{2409.08295v2,
 abstract = {The description of the dynamics of complex systems, in particular the capture
of the interaction structure and causal relationships between elements of the
system, is one of the central questions of interdisciplinary research. While
the characterization of pairwise causal interactions is a relatively ripe field
with established theoretical concepts and the current focus is on technical
issues of their efficient estimation, it turns out that the standard concepts
such as Granger causality or transfer entropy may not faithfully reflect
possible synergies or interactions of higher orders, phenomena highly relevant
for many real-world complex systems. In this paper, we propose a generalization
and refinement of the information-theoretic approach to causal inference,
enabling the description of truly multivariate, rather than multiple pairwise,
causal interactions, and moving thus from causal networks to causal
hypernetworks. In particular, while keeping the ability to control for
mediating variables or common causes, in case of purely synergetic interactions
such as the exclusive disjunction, it ascribes the causal role to the
multivariate causal set but \emph{not} to individual inputs, distinguishing it
thus from the case of e.g. two additive univariate causes. We demonstrate this
concept by application to illustrative theoretical examples as well as a
biophysically realistic simulation of biological neuronal dynamics recently
reported to employ synergetic computations.},
 author = {Jakub Kořenek and Pavel Sanda and Jaroslav Hlinka},
 comment = {},
 doi = {10.1103/PhysRevE.111.L042302},
 eprint = {2409.08295v2},
 journal = {arXiv preprint},
 title = {Higher order definition of causality by optimally conditioned transfer entropy},
 url = {http://arxiv.org/abs/2409.08295v2},
 year = {2024}
}

@article{2409.08544v1,
 abstract = {As network data applications continue to expand, causal inference within
networks has garnered increasing attention. However, hidden confounders
complicate the estimation of causal effects. Most methods rely on the strong
ignorability assumption, which presumes the absence of hidden confounders-an
assumption that is both difficult to validate and often unrealistic in
practice. To address this issue, we propose CgNN, a novel approach that
leverages network structure as instrumental variables (IVs), combined with
graph neural networks (GNNs) and attention mechanisms, to mitigate hidden
confounder bias and improve causal effect estimation. By utilizing network
structure as IVs, we reduce confounder bias while preserving the correlation
with treatment. Our integration of attention mechanisms enhances robustness and
improves the identification of important nodes. Validated on two real-world
datasets, our results demonstrate that CgNN effectively mitigates hidden
confounder bias and offers a robust GNN-driven IV framework for causal
inference in complex network data.},
 author = {Xiaojing Du and Feiyu Yang and Wentao Gao and Xiongren Chen},
 comment = {},
 doi = {},
 eprint = {2409.08544v1},
 journal = {arXiv preprint},
 title = {Causal GNNs: A GNN-Driven Instrumental Variable Approach for Causal Inference in Networks},
 url = {http://arxiv.org/abs/2409.08544v1},
 year = {2024}
}

@article{2409.11265v2,
 abstract = {Background: Advanced methods for causal inference, such as targeted maximum
likelihood estimation (TMLE), require certain conditions for statistical
inference. However, in situations where there is not differentiability due to
data sparsity or near-positivity violations, the Donsker class condition is
violated. In such situations, TMLE variance can suffer from inflation of the
type I error and poor coverage, leading to conservative confidence intervals.
Cross-validation of the TMLE algorithm (CVTMLE) has been suggested to improve
on performance compared to TMLE in settings of positivity or Donsker class
violations. We aim to investigate the performance of CVTMLE compared to TMLE in
various settings.
  Methods: We utilised the data-generating mechanism as described in Leger et
al. (2022) to run a Monte Carlo experiment under different Donsker class
violations. Then, we evaluated the respective statistical performances of TMLE
and CVTMLE with different super learner libraries, with and without regression
tree methods.
  Results: We found that CVTMLE vastly improves confidence interval coverage
without adversely affecting bias, particularly in settings with small sample
sizes and near-positivity violations. Furthermore, incorporating regression
trees using standard TMLE with ensemble super learner-based initial estimates
increases bias and variance leading to invalid statistical inference.
  Conclusions: It has been shown that when using CVTMLE the Donsker class
condition is no longer necessary to obtain valid statistical inference when
using regression trees and under either data sparsity or near-positivity
violations. We show through simulations that CVTMLE is much less sensitive to
the choice of the super learner library and thereby provides better estimation
and inference in cases where the super learner library uses more flexible
candidates and is prone to overfitting.},
 author = {Matthew J. Smith and Rachael V. Phillips and Camille Maringe and Miguel Angel Luque-Fernandez},
 comment = {20 pages, 3 figures, 1 table},
 doi = {},
 eprint = {2409.11265v2},
 journal = {arXiv preprint},
 title = {Performance of Cross-Validated Targeted Maximum Likelihood Estimation},
 url = {http://arxiv.org/abs/2409.11265v2},
 year = {2024}
}

@article{2409.11967v2,
 abstract = {Causal inference problems often involve continuous treatments, such as dose,
duration, or frequency. However, identifying and estimating standard
dose-response estimands requires that everyone has some chance of receiving any
level of the exposure (i.e., positivity). To avoid this assumption, we consider
stochastic interventions based on exponentially tilting the treatment
distribution by some parameter $\delta$ (i.e. an incremental effect); this
increases or decreases the likelihood a unit receives a given treatment level.
We derive the efficient influence function and semiparametric efficiency bound
for these incremental effects under continuous exposures. We then show
estimation depends on the size of the tilt, as measured by $\delta$. In
particular, we derive new minimax lower bounds illustrating how the best
possible root mean squared error scales with an effective sample size of $n /
\delta$, instead of $n$. Further, we establish new convergence rates and bounds
on the bias of double machine learning-style estimators. Our novel analysis
gives a better dependence on $\delta$ compared to standard analyses by using
mixed supremum and $L_2$ norms. Finally, we show that taking $\delta \to
\infty$ gives a new estimator of the dose-response curve at the edge of the
support, and give a detailed study of convergence rates in this regime.},
 author = {Kyle Schindl and Shuying Shen and Edward H. Kennedy},
 comment = {},
 doi = {},
 eprint = {2409.11967v2},
 journal = {arXiv preprint},
 title = {Incremental effects for continuous exposures},
 url = {http://arxiv.org/abs/2409.11967v2},
 year = {2024}
}

@article{2409.14202v3,
 abstract = {The instrumental variables (IVs) method is a leading empirical strategy for
causal inference. Finding IVs is a heuristic and creative process, and
justifying its validity -- especially exclusion restrictions -- is largely
rhetorical. We propose using large language models (LLMs) to search for new IVs
through narratives and counterfactual reasoning, similar to how a human
researcher would. The stark difference, however, is that LLMs can dramatically
accelerate this process and explore an extremely large search space. We
demonstrate how to construct prompts to search for potentially valid IVs. We
contend that multi-step and role-playing prompting strategies are effective for
simulating the endogenous decision-making processes of economic agents and for
navigating language models through the realm of real-world scenarios, rather
than anchoring them within the narrow realm of academic discourses on IVs. We
apply our method to three well-known examples in economics: returns to
schooling, supply and demand, and peer effects. We then extend our strategy to
finding (i) control variables in regression and difference-in-differences and
(ii) running variables in regression discontinuity designs.},
 author = {Sukjin Han},
 comment = {},
 doi = {},
 eprint = {2409.14202v3},
 journal = {arXiv preprint},
 title = {Mining Causality: AI-Assisted Search for Instrumental Variables},
 url = {http://arxiv.org/abs/2409.14202v3},
 year = {2024}
}

@article{2409.14593v2,
 abstract = {Testing a hypothesized causal model against observational data is a key
prerequisite for many causal inference tasks. A natural approach is to test
whether the conditional independence relations (CIs) assumed in the model hold
in the data. While a model can assume exponentially many CIs (with respect to
the number of variables), testing all of them is both impractical and
unnecessary. Causal graphs, which encode these CIs in polynomial space, give
rise to local Markov properties that enable model testing with a significantly
smaller subset of CIs. Model testing based on local properties requires an
algorithm to list the relevant CIs. However, existing algorithms for realistic
settings with hidden variables and non-parametric distributions can take
exponential time to produce even a single CI constraint. In this paper, we
introduce the c-component local Markov property (C-LMP) for causal graphs with
hidden variables. Since C-LMP can still invoke an exponential number of CIs, we
develop a polynomial delay algorithm to list these CIs in poly-time intervals.
To our knowledge, this is the first algorithm that enables poly-delay testing
of CIs in causal graphs with hidden variables against arbitrary data
distributions. Experiments on real-world and synthetic data demonstrate the
practicality of our algorithm.},
 author = {Hyunchai Jeong and Adiba Ejaz and Jin Tian and Elias Bareinboim},
 comment = {34 total pages, 14 figures},
 doi = {10.1609/aaai.v39i25.34885},
 eprint = {2409.14593v2},
 journal = {arXiv preprint},
 title = {Testing Causal Models with Hidden Variables in Polynomial Delay via Conditional Independencies},
 url = {http://arxiv.org/abs/2409.14593v2},
 year = {2024}
}

@article{2409.15503v3,
 abstract = {One of the central goals of causal machine learning is the accurate
estimation of heterogeneous treatment effects from observational data. In
recent years, meta-learning has emerged as a flexible, model-agnostic paradigm
for estimating conditional average treatment effects (CATE) using any
supervised model. This paper examines the performance of meta-learners when the
confounding variables are expressed in text. Through synthetic data
experiments, we show that learners using pre-trained text representations of
confounders, in addition to tabular background variables, achieve improved CATE
estimates compared to those relying solely on the tabular variables,
particularly when sufficient data is available. However, due to the entangled
nature of the text embeddings, these models do not fully match the performance
of meta-learners with perfect confounder knowledge. These findings highlight
both the potential and the limitations of pre-trained text representations for
causal inference and open up interesting avenues for future research.},
 author = {Henri Arno and Paloma Rabaey and Thomas Demeester},
 comment = {Presented at the NeurIPS 2024 Workshop on Causal Representation
  Learning},
 doi = {},
 eprint = {2409.15503v3},
 journal = {arXiv preprint},
 title = {From Text to Treatment Effects: A Meta-Learning Approach to Handling Text-Based Confounding},
 url = {http://arxiv.org/abs/2409.15503v3},
 year = {2024}
}

@article{2409.15564v4,
 abstract = {Traditional machine learning methods for movement recognition often struggle
with limited model interpretability and a lack of insight into human movement
dynamics. This study introduces a novel representation learning framework based
on causal inference to address these challenges. Our two-stage approach
combines the Peter-Clark (PC) algorithm and Kullback-Leibler (KL) divergence to
identify and quantify causal relationships between human joints. By capturing
joint interactions, the proposed causal Graph Convolutional Network (GCN)
produces interpretable and robust representations. Experimental results on the
EmoPain dataset demonstrate that the causal GCN outperforms traditional GCNs in
accuracy, F1 score, and recall, particularly in detecting protective behaviors.
This work contributes to advancing human motion analysis and lays a foundation
for adaptive and intelligent healthcare solutions.},
 author = {Xingrui Gu and Chuyi Jiang and Erte Wang and Qiang Cui and Leimin Tian and Lianlong Wu and Siyang Song and Chuang Yu},
 comment = {},
 doi = {},
 eprint = {2409.15564v4},
 journal = {arXiv preprint},
 title = {CauSkelNet: Causal Representation Learning for Human Behaviour Analysis},
 url = {http://arxiv.org/abs/2409.15564v4},
 year = {2024}
}

@article{2409.15682v1,
 abstract = {Interference, a key concept in causal inference, extends the reward modeling
process by accounting for the impact of one unit's actions on the rewards of
others. In contextual bandit (CB) settings, where multiple units are present in
the same round, potential interference can significantly affect the estimation
of expected rewards for different arms, thereby influencing the decision-making
process. Although some prior work has explored multi-agent and adversarial
bandits in interference-aware settings, the effect of interference in CB, as
well as the underlying theory, remains significantly underexplored. In this
paper, we introduce a systematic framework to address interference in Linear CB
(LinCB), bridging the gap between causal inference and online decision-making.
We propose a series of algorithms that explicitly quantify the interference
effect in the reward modeling process and provide comprehensive theoretical
guarantees, including sublinear regret bounds, finite sample upper bounds, and
asymptotic properties. The effectiveness of our approach is demonstrated
through simulations and a synthetic data generated based on MovieLens data.},
 author = {Yang Xu and Wenbin Lu and Rui Song},
 comment = {},
 doi = {},
 eprint = {2409.15682v1},
 journal = {arXiv preprint},
 title = {Linear Contextual Bandits with Interference},
 url = {http://arxiv.org/abs/2409.15682v1},
 year = {2024}
}

@article{2409.16407v1,
 abstract = {Reweighting a distribution to minimize a distance to a target distribution is
a powerful and flexible strategy for estimating a wide range of causal effects,
but can be challenging in practice because optimal weights typically depend on
knowledge of the underlying data generating process. In this paper, we focus on
design-based weights, which do not incorporate outcome information; prominent
examples include prospective cohort studies, survey weighting, and the
weighting portion of augmented weighting estimators. In such applications, we
explore the central role of representation learning in finding desirable
weights in practice. Unlike the common approach of assuming a well-specified
representation, we highlight the error due to the choice of a representation
and outline a general framework for finding suitable representations that
minimize this error. Building on recent work that combines balancing weights
and neural networks, we propose an end-to-end estimation procedure that learns
a flexible representation, while retaining promising theoretical properties. We
show that this approach is competitive in a range of common causal inference
tasks.},
 author = {Oscar Clivio and Avi Feller and Chris Holmes},
 comment = {UAI 2024, typos in UAI version fixed},
 doi = {},
 eprint = {2409.16407v1},
 journal = {arXiv preprint},
 title = {Towards Representation Learning for Weighting Problems in Design-Based Causal Inference},
 url = {http://arxiv.org/abs/2409.16407v1},
 year = {2024}
}

@article{2409.18581v3,
 abstract = {Existing causal inference (CI) models are often restricted to data with
low-dimensional confounders and singleton actions. We propose an autoregressive
(AR) CI framework capable of handling complex confounders and sequential
actions commonly found in modern applications. Our approach accomplishes this
using {\em sequencification}, which transforms data from an underlying causal
diagram into a sequence of tokens. Sequencification not only accommodates
training with data generated from a large class of DAGs, but also extends
existing CI capabilities to estimate multiple causal quantities using a {\em
single} model. We can directly compute probabilities from interventional
distributions, simplifying inference and improving outcome prediction accuracy.
We demonstrate that an AR model adapted for CI is efficient and effective in
various complex applications such as navigating mazes, playing chess endgames,
and evaluating the impact of certain keywords on paper acceptance rates, where
we consider causal queries beyond standard reinforcement learning-type
questions.},
 author = {Daniel Jiwoong Im and Kevin Zhang and Nakul Verma and Kyunghyun Cho},
 comment = {},
 doi = {},
 eprint = {2409.18581v3},
 journal = {arXiv preprint},
 title = {Deep Autoregressive Models as Causal Inference Engines},
 url = {http://arxiv.org/abs/2409.18581v3},
 year = {2024}
}

@article{2409.19377v2,
 abstract = {Nonlinear causal discovery from observational data imposes strict
identifiability assumptions on the formulation of structural equations utilized
in the data generating process. The evaluation of structure learning methods
under assumption violations requires a rigorous and interpretable approach,
which quantifies both the structural similarity of the estimation with the
ground truth and the capacity of the discovered graphs to be used for causal
inference. Motivated by the lack of unified performance assessment framework,
we introduce an interpretable, six-dimensional evaluation metric, i.e.,
distance to optimal solution (DOS), which is specifically tailored to the field
of causal discovery. Furthermore, this is the first research to assess the
performance of structure learning algorithms from seven different families on
increasing percentage of non-identifiable, nonlinear causal patterns, inspired
by real-world processes. Our large-scale simulation study, which incorporates
seven experimental factors, shows that besides causal order-based methods,
amortized causal discovery delivers results with comparatively high proximity
to the optimal solution.},
 author = {Georg Velev and Stefan Lessmann},
 comment = {},
 doi = {},
 eprint = {2409.19377v2},
 journal = {arXiv preprint},
 title = {Interpretable, multi-dimensional Evaluation Framework for Causal Discovery from observational i.i.d. Data},
 url = {http://arxiv.org/abs/2409.19377v2},
 year = {2024}
}

@article{2409.19993v1,
 abstract = {The advancement of Large Language Models (LLMs) has significantly impacted
various domains, including Web search, healthcare, and software development.
However, as these models scale, they become more vulnerable to cybersecurity
risks, particularly backdoor attacks. By exploiting the potent memorization
capacity of LLMs, adversaries can easily inject backdoors into LLMs by
manipulating a small portion of training data, leading to malicious behaviors
in downstream applications whenever the hidden backdoor is activated by the
pre-defined triggers. Moreover, emerging learning paradigms like instruction
tuning and reinforcement learning from human feedback (RLHF) exacerbate these
risks as they rely heavily on crowdsourced data and human feedback, which are
not fully controlled. In this paper, we present a comprehensive survey of
emerging backdoor threats to LLMs that appear during LLM development or
inference, and cover recent advancement in both defense and detection
strategies for mitigating backdoor threats to LLMs. We also outline key
challenges in addressing these threats, highlighting areas for future research.},
 author = {Qin Liu and Wenjie Mo and Terry Tong and Jiashu Xu and Fei Wang and Chaowei Xiao and Muhao Chen},
 comment = {The 60th Annual Allerton Conference (Invited Paper). The arXiv
  version is a pre-IEEE Press publication version},
 doi = {},
 eprint = {2409.19993v1},
 journal = {arXiv preprint},
 title = {Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges},
 url = {http://arxiv.org/abs/2409.19993v1},
 year = {2024}
}

@article{2410.00240v1,
 abstract = {Active inference is a mathematical framework for understanding how agents
(biological or artificial) interact with their environments, enabling continual
adaptation and decision-making. It combines Bayesian inference and free energy
minimization to model perception, action, and learning in uncertain and dynamic
contexts. Unlike reinforcement learning, active inference integrates
exploration and exploitation seamlessly by minimizing expected free energy. In
this paper, we present a continual learning framework for agents operating in
discrete time environments, using active inference as the foundation. We derive
the mathematical formulations of variational and expected free energy and apply
them to the design of a self-learning research agent. This agent updates its
beliefs and adapts its actions based on new data without manual intervention.
Through experiments in changing environments, we demonstrate the agent's
ability to relearn and refine its models efficiently, making it suitable for
complex domains like finance and healthcare. The paper concludes by discussing
how the proposed framework generalizes to other systems, positioning active
inference as a flexible approach for adaptive AI.},
 author = {Rithvik Prakki},
 comment = {13 pages, 3 figures},
 doi = {},
 eprint = {2410.00240v1},
 journal = {arXiv preprint},
 title = {Demonstrating the Continual Learning Capabilities and Practical Application of Discrete-Time Active Inference},
 url = {http://arxiv.org/abs/2410.00240v1},
 year = {2024}
}

@article{2410.00903v4,
 abstract = {In this paper, we demonstrate how to enhance the validity of causal inference
with unstructured high-dimensional treatments like texts, by leveraging the
power of generative Artificial Intelligence (GenAI). Specifically, we propose
to use a deep generative model such as large language models (LLMs) to
efficiently generate treatments and use their internal representation for
subsequent causal effect estimation. We show that the knowledge of this true
internal representation helps disentangle the treatment features of interest,
such as specific sentiments and certain topics, from other possibly unknown
confounding features. Unlike existing methods, the proposed GenAI-Powered
Inference (GPI) methodology eliminates the need to learn causal representation
from the data, and hence produces more accurate and efficient estimates. We
formally establish the conditions required for the nonparametric identification
of the average treatment effect, propose an estimation strategy that avoids the
violation of the overlap assumption, and derive the asymptotic properties of
the proposed estimator through the application of double machine learning.
Finally, using an instrumental variables approach, we extend the proposed GPI
methodology to the settings in which the treatment feature is based on human
perception. The GPI is also applicable to text reuse where an LLM is used to
regenerate existing texts. We conduct simulation and empirical studies, using
the generated text data from an open-source LLM, Llama~3, to illustrate the
advantages of our estimator over state-of-the-art causal representation
learning algorithms.},
 author = {Kosuke Imai and Kentaro Nakamura},
 comment = {},
 doi = {},
 eprint = {2410.00903v4},
 journal = {arXiv preprint},
 title = {Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments},
 url = {http://arxiv.org/abs/2410.00903v4},
 year = {2024}
}

@article{2410.01268v2,
 abstract = {Artificial intelligence (AI), machine learning, and deep learning have become
transformative forces in big data analytics and management, enabling
groundbreaking advancements across diverse industries. This article delves into
the foundational concepts and cutting-edge developments in these fields, with a
particular focus on large language models (LLMs) and their role in natural
language processing, multimodal reasoning, and autonomous decision-making.
Highlighting tools such as ChatGPT, Claude, and Gemini, the discussion explores
their applications in data analysis, model design, and optimization.
  The integration of advanced algorithms like neural networks, reinforcement
learning, and generative models has enhanced the capabilities of AI systems to
process, visualize, and interpret complex datasets. Additionally, the emergence
of technologies like edge computing and automated machine learning (AutoML)
democratizes access to AI, empowering users across skill levels to engage with
intelligent systems. This work also underscores the importance of ethical
considerations, transparency, and fairness in the deployment of AI
technologies, paving the way for responsible innovation.
  Through practical insights into hardware configurations, software
environments, and real-world applications, this article serves as a
comprehensive resource for researchers and practitioners. By bridging
theoretical underpinnings with actionable strategies, it showcases the
potential of AI and LLMs to revolutionize big data management and drive
meaningful advancements across domains such as healthcare, finance, and
autonomous systems.},
 author = {Pohsun Feng and Ziqian Bi and Yizhu Wen and Xuanhe Pan and Benji Peng and Ming Liu and Jiawei Xu and Keyu Chen and Junyu Liu and Caitlyn Heqi Yin and Sen Zhang and Jinlang Wang and Qian Niu and Ming Li and Tianyang Wang},
 comment = {This book contains 155 pages and 9 figures},
 doi = {},
 eprint = {2410.01268v2},
 journal = {arXiv preprint},
 title = {Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Unveiling AI's Potential Through Tools, Techniques, and Applications},
 url = {http://arxiv.org/abs/2410.01268v2},
 year = {2024}
}

@article{2410.01392v1,
 abstract = {We present a comprehensive framework for applying rigorous statistical
techniques from econometrics to analyze and improve machine learning systems.
We introduce key statistical methods such as Ordinary Least Squares (OLS)
regression, Analysis of Variance (ANOVA), and logistic regression, explaining
their theoretical foundations and practical applications in machine learning
evaluation. The document serves as a guide for researchers and practitioners,
detailing how these techniques can provide deeper insights into model behavior,
performance, and fairness. We cover the mathematical principles behind each
method, discuss their assumptions and limitations, and provide step-by-step
instructions for their implementation. The paper also addresses how to
interpret results, emphasizing the importance of statistical significance and
effect size. Through illustrative examples, we demonstrate how these tools can
reveal subtle patterns and interactions in machine learning models that are not
apparent from traditional evaluation metrics. By connecting the fields of
econometrics and machine learning, this work aims to equip readers with
powerful analytical tools for more rigorous and comprehensive evaluation of AI
systems. The framework presented here contributes to developing more robust,
interpretable, and fair machine learning technologies.},
 author = {Michaël Soumm},
 comment = {},
 doi = {},
 eprint = {2410.01392v1},
 journal = {arXiv preprint},
 title = {Causal Inference Tools for a Better Evaluation of Machine Learning},
 url = {http://arxiv.org/abs/2410.01392v1},
 year = {2024}
}

@article{2410.01658v1,
 abstract = {Inverse propensity-score weighted (IPW) estimators are prevalent in causal
inference for estimating average treatment effects in observational studies.
Under unconfoundedness, given accurate propensity scores and $n$ samples, the
size of confidence intervals of IPW estimators scales down with $n$, and,
several of their variants improve the rate of scaling. However, neither IPW
estimators nor their variants are robust to inaccuracies: even if a single
covariate has an $\varepsilon>0$ additive error in the propensity score, the
size of confidence intervals of these estimators can increase arbitrarily.
Moreover, even without errors, the rate with which the confidence intervals of
these estimators go to zero with $n$ can be arbitrarily slow in the presence of
extreme propensity scores (those close to 0 or 1).
  We introduce a family of Coarse IPW (CIPW) estimators that captures existing
IPW estimators and their variants. Each CIPW estimator is an IPW estimator on a
coarsened covariate space, where certain covariates are merged. Under mild
assumptions, e.g., Lipschitzness in expected outcomes and sparsity of extreme
propensity scores, we give an efficient algorithm to find a robust estimator:
given $\varepsilon$-inaccurate propensity scores and $n$ samples, its
confidence interval size scales with $\varepsilon+1/\sqrt{n}$. In contrast,
under the same assumptions, existing estimators' confidence interval sizes are
$\Omega(1)$ irrespective of $\varepsilon$ and $n$. Crucially, our estimator is
data-dependent and we show that no data-independent CIPW estimator can be
robust to inaccuracies.},
 author = {Alkis Kalavasis and Anay Mehrotra and Manolis Zampetakis},
 comment = {Accepted for presentation at the 37th Conference on Learning Theory
  (COLT) 2024},
 doi = {},
 eprint = {2410.01658v1},
 journal = {arXiv preprint},
 title = {Smaller Confidence Intervals From IPW Estimators via Data-Dependent Coarsening},
 url = {http://arxiv.org/abs/2410.01658v1},
 year = {2024}
}

@article{2410.02172v1,
 abstract = {Evaluating policies using off-policy data is crucial for applying
reinforcement learning to real-world problems such as healthcare and autonomous
driving. Previous methods for off-policy evaluation (OPE) generally suffer from
high variance or irreducible bias, leading to unacceptably high prediction
errors. In this work, we introduce STAR, a framework for OPE that encompasses a
broad range of estimators -- which include existing OPE methods as special
cases -- that achieve lower mean squared prediction errors. STAR leverages
state abstraction to distill complex, potentially continuous problems into
compact, discrete models which we call abstract reward processes (ARPs).
Predictions from ARPs estimated from off-policy data are provably consistent
(asymptotically correct). Rather than proposing a specific estimator, we
present a new framework for OPE and empirically demonstrate that estimators
within STAR outperform existing methods. The best STAR estimator outperforms
baselines in all twelve cases studied, and even the median STAR estimator
surpasses the baselines in seven out of the twelve cases.},
 author = {Shreyas Chaudhari and Ameet Deshpande and Bruno Castro da Silva and Philip S. Thomas},
 comment = {Accepted at the Thirty-eighth Annual Conference on Neural Information
  Processing Systems (NeurIPS 2024)},
 doi = {},
 eprint = {2410.02172v1},
 journal = {arXiv preprint},
 title = {Abstract Reward Processes: Leveraging State Abstraction for Consistent Off-Policy Evaluation},
 url = {http://arxiv.org/abs/2410.02172v1},
 year = {2024}
}

@article{2410.04112v1,
 abstract = {This research examines the use of Reinforcement Learning from AI Feedback
(RLAIF) techniques to improve healthcare dialogue models, with the aim of
tackling the challenges of preference-aligned data annotation while reducing
the reliance on medical experts. We argue that the primary challenges in
current RLAIF research for healthcare are the limitations of automated
evaluation methods and the difficulties in accurately representing physician
preferences. To address these challenges, we present a new evaluation framework
based on standardized patient examinations. This framework is designed to
objectively assess the effectiveness of large language models (LLMs) in guiding
users and following instructions, enabling a comprehensive comparison across
different models. Furthermore, our investigation of effective ways to express
physician preferences using Constitutional AI algorithms highlighted the
particular effectiveness of flowcharts. Utilizing this finding, we introduce an
innovative agent-based approach for annotating preference data. This approach
autonomously creates medical dialogue flows tailored to the patient's
condition, demonstrates strong generalization abilities, and reduces the need
for expert involvement. Our results show that the agent-based approach
outperforms existing RLAIF annotation methods in standardized patient
examinations and surpasses current open source medical dialogue LLMs in various
test scenarios.},
 author = {Chengfeng Dou and Ying Zhang and Zhi Jin and Wenpin Jiao and Haiyan Zhao and Yongqiang Zhao and Zhengwei Tao},
 comment = {14 Pages, 12 figures},
 doi = {},
 eprint = {2410.04112v1},
 journal = {arXiv preprint},
 title = {Exploring LLM-based Data Annotation Strategies for Medical Dialogue Preference Alignment},
 url = {http://arxiv.org/abs/2410.04112v1},
 year = {2024}
}

@article{2410.04217v2,
 abstract = {In Reinforcement Learning (RL), multi-armed Bandit (MAB) problems have found
applications across diverse domains such as recommender systems, healthcare,
and finance. Traditional MAB algorithms typically assume stationary reward
distributions, which limits their effectiveness in real-world scenarios
characterized by non-stationary dynamics. This paper addresses this limitation
by introducing and evaluating novel Bandit algorithms designed for
non-stationary environments. First, we present the Adaptive Discounted Thompson
Sampling (ADTS) algorithm, which enhances adaptability through relaxed
discounting and sliding window mechanisms to better respond to changes in
reward distributions. We then extend this approach to the Portfolio
Optimization problem by introducing the Combinatorial Adaptive Discounted
Thompson Sampling (CADTS) algorithm, which addresses computational challenges
within Combinatorial Bandits and improves dynamic asset allocation.
Additionally, we propose a novel architecture called Bandit Networks, which
integrates the outputs of ADTS and CADTS, thereby mitigating computational
limitations in stock selection. Through extensive experiments using real
financial market data, we demonstrate the potential of these algorithms and
architectures in adapting to dynamic environments and optimizing
decision-making processes. For instance, the proposed bandit network instances
present superior performance when compared to classic portfolio optimization
approaches, such as capital asset pricing model, equal weights, risk parity,
and Markovitz, with the best network presenting an out-of-sample Sharpe Ratio
20% higher than the best performing classical model.},
 author = {Gustavo de Freitas Fonseca and Lucas Coelho e Silva and Paulo André Lima de Castro},
 comment = {},
 doi = {},
 eprint = {2410.04217v2},
 journal = {arXiv preprint},
 title = {Improving Portfolio Optimization Results with Bandit Networks},
 url = {http://arxiv.org/abs/2410.04217v2},
 year = {2024}
}

@article{2410.05484v1,
 abstract = {Despite their success and widespread adoption, the opaque nature of deep
neural networks (DNNs) continues to hinder trust, especially in critical
applications. Current interpretability solutions often yield inconsistent or
oversimplified explanations, or require model changes that compromise
performance. In this work, we introduce TRACER, a novel method grounded in
causal inference theory designed to estimate the causal dynamics underpinning
DNN decisions without altering their architecture or compromising their
performance. Our approach systematically intervenes on input features to
observe how specific changes propagate through the network, affecting internal
activations and final outputs. Based on this analysis, we determine the
importance of individual features, and construct a high-level causal map by
grouping functionally similar layers into cohesive causal nodes, providing a
structured and interpretable view of how different parts of the network
influence the decisions. TRACER further enhances explainability by generating
counterfactuals that reveal possible model biases and offer contrastive
explanations for misclassifications. Through comprehensive evaluations across
diverse datasets, we demonstrate TRACER's effectiveness over existing methods
and show its potential for creating highly compressed yet accurate models,
illustrating its dual versatility in both understanding and optimizing DNNs.},
 author = {Alec F. Diallo and Vaishak Belle and Paul Patras},
 comment = {},
 doi = {},
 eprint = {2410.05484v1},
 journal = {arXiv preprint},
 title = {Neural Networks Decoded: Targeted and Robust Analysis of Neural Network Decisions via Causal Explanations and Reasoning},
 url = {http://arxiv.org/abs/2410.05484v1},
 year = {2024}
}

@article{2410.06238v2,
 abstract = {Despite their success in many domains, large language models (LLMs) remain
under-studied in scenarios requiring optimal decision-making under uncertainty.
This is crucial as many real-world applications, ranging from personalized
recommendations to healthcare interventions, demand that LLMs not only predict
but also actively learn to make optimal decisions through exploration. In this
work, we measure LLMs' (in)ability to make optimal decisions in bandits, a
state-less reinforcement learning setting relevant to many applications. We
develop a comprehensive suite of environments, including both context-free and
contextual bandits with varying task difficulties, to benchmark LLMs'
performance. Motivated by the existence of optimal exploration algorithms, we
propose efficient ways to integrate this algorithmic knowledge into LLMs: by
providing explicit algorithm-guided support during inference; and through
algorithm distillation via in-context demonstrations and fine-tuning, using
synthetic data generated from these algorithms. Impressively, these techniques
allow us to achieve superior exploration performance with smaller models,
surpassing larger models on various tasks. We conducted an extensive ablation
study to shed light on various factors, such as task difficulty and data
representation, that influence the efficiency of LLM exploration. Additionally,
we conduct a rigorous analysis of the LLM's exploration efficiency using the
concept of regret, linking its ability to explore to the model size and
underlying algorithm.},
 author = {Allen Nie and Yi Su and Bo Chang and Jonathan N. Lee and Ed H. Chi and Quoc V. Le and Minmin Chen},
 comment = {28 pages. Published at ICML 2025},
 doi = {},
 eprint = {2410.06238v2},
 journal = {arXiv preprint},
 title = {EVOLvE: Evaluating and Optimizing LLMs For In-Context Exploration},
 url = {http://arxiv.org/abs/2410.06238v2},
 year = {2024}
}

@article{2410.06392v1,
 abstract = {Causal structure discovery methods are commonly applied to structured data
where the causal variables are known and where statistical testing can be used
to assess the causal relationships. By contrast, recovering a causal structure
from unstructured natural language data such as news articles contains numerous
challenges due to the absence of known variables or counterfactual data to
estimate the causal links. Large Language Models (LLMs) have shown promising
results in this direction but also exhibit limitations. This work investigates
LLM's abilities to build causal graphs from text documents and perform
counterfactual causal inference. We propose an end-to-end causal structure
discovery and causal inference method from natural language: we first use an
LLM to extract the instantiated causal variables from text data and build a
causal graph. We merge causal graphs from multiple data sources to represent
the most exhaustive set of causes possible. We then conduct counterfactual
inference on the estimated graph. The causal graph conditioning allows
reduction of LLM biases and better represents the causal estimands. We use our
method to show that the limitations of LLMs in counterfactual causal reasoning
come from prediction errors and propose directions to mitigate them. We
demonstrate the applicability of our method on real-world news articles.},
 author = {Gaël Gendron and Jože M. Rožanec and Michael Witbrock and Gillian Dobbie},
 comment = {22 pages, 10 pages for the main paper, 12 pages for the references
  and appendix, 5 figures},
 doi = {},
 eprint = {2410.06392v1},
 journal = {arXiv preprint},
 title = {Counterfactual Causal Inference in Natural Language with Large Language Models},
 url = {http://arxiv.org/abs/2410.06392v1},
 year = {2024}
}

@article{2410.07021v2,
 abstract = {We present unexpected findings from a large-scale benchmark study evaluating
Conditional Average Treatment Effect (CATE) estimation algorithms, i.e., CATE
models. By running 16 modern CATE models on 12 datasets and 43,200 sampled
variants generated through diverse observational sampling strategies, we find
that: (a) 62\% of CATE estimates have a higher Mean Squared Error (MSE) than a
trivial zero-effect predictor, rendering them ineffective; (b) in datasets with
at least one useful CATE estimate, 80\% still have higher MSE than a
constant-effect model; and (c) Orthogonality-based models outperform other
models only 30\% of the time, despite widespread optimism about their
performance. These findings highlight significant challenges in current CATE
models and underscore the need for broader evaluation and methodological
improvements.
  Our findings stem from a novel application of \textit{observational
sampling}, originally developed to evaluate Average Treatment Effect (ATE)
estimates from observational methods with experiment data. To adapt
observational sampling for CATE evaluation, we introduce a statistical
parameter, $Q$, equal to MSE minus a constant and preserves the ranking of
models by their MSE. We then derive a family of sample statistics, collectively
called $\hat{Q}$, that can be computed from real-world data. When used in
observational sampling, $\hat{Q}$ is an unbiased estimator of $Q$ and
asymptotically selects the model with the smallest MSE. To ensure the benchmark
reflects real-world heterogeneity, we handpick datasets where outcomes come
from field rather than simulation. By integrating observational sampling, new
statistics, and real-world datasets, the benchmark provides new insights into
CATE model performance and reveals gaps in capturing real-world heterogeneity,
emphasizing the need for more robust benchmarks.},
 author = {Haining Yu and Yizhou Sun},
 comment = {},
 doi = {},
 eprint = {2410.07021v2},
 journal = {arXiv preprint},
 title = {Do Contemporary Causal Inference Models Capture Real-World Heterogeneity? Findings from a Large-Scale Benchmark},
 url = {http://arxiv.org/abs/2410.07021v2},
 year = {2024}
}

@article{2410.07135v1,
 abstract = {One way to quantify exposure to air pollution and its constituents in
epidemiologic studies is to use an individual's nearest monitor. This strategy
results in potential inaccuracy in the actual personal exposure, introducing
bias in estimating the health effects of air pollution and its constituents,
especially when evaluating the causal effects of correlated multi-pollutant
constituents measured with correlated error. This paper addresses estimation
and inference for the causal effect of one constituent in the presence of other
PM2.5 constituents, accounting for measurement error and correlations. We used
a linear regression calibration model, fitted with generalized estimating
equations in an external validation study, and extended a double/debiased
machine learning (DML) approach to correct for measurement error and estimate
the effect of interest in the main study. We demonstrated that the DML
estimator with regression calibration is consistent and derived its asymptotic
variance. Simulations showed that the proposed estimator reduced bias and
attained nominal coverage probability across most simulation settings. We
applied this method to assess the causal effects of PM2.5 constituents on
cognitive function in the Nurses' Health Study and identified two PM2.5
constituents, Br and Mn, that showed a negative causal effect on cognitive
function after measurement error correction.},
 author = {Gang Xu and Xin Zhou and Molin Wang and Boya Zhang and Wenhao Jiang and Francine Laden and Helen H. Suh and Adam A. Szpiro and Donna Spiegelman and Zuoheng Wang},
 comment = {},
 doi = {},
 eprint = {2410.07135v1},
 journal = {arXiv preprint},
 title = {Causal Inference with Double/Debiased Machine Learning for Evaluating the Health Effects of Multiple Mismeasured Pollutants},
 url = {http://arxiv.org/abs/2410.07135v1},
 year = {2024}
}

@article{2410.07525v2,
 abstract = {Reinforcement Learning (RL) applied in healthcare can lead to unsafe medical
decisions and treatment, such as excessive dosages or abrupt changes, often due
to agents overlooking common-sense constraints. Consequently, Constrained
Reinforcement Learning (CRL) is a natural choice for safe decisions. However,
specifying the exact cost function is inherently difficult in healthcare.
Recent Inverse Constrained Reinforcement Learning (ICRL) is a promising
approach that infers constraints from expert demonstrations. ICRL algorithms
model Markovian decisions in an interactive environment. These settings do not
align with the practical requirement of a decision-making system in healthcare,
where decisions rely on historical treatment recorded in an offline dataset. To
tackle these issues, we propose the Constraint Transformer (CT). Specifically,
1) we utilize a causal attention mechanism to incorporate historical decisions
and observations into the constraint modeling, while employing a Non-Markovian
layer for weighted constraints to capture critical states. 2) A generative
world model is used to perform exploratory data augmentation, enabling offline
RL methods to simulate unsafe decision sequences. In multiple medical
scenarios, empirical results demonstrate that CT can capture unsafe states and
achieve strategies that approximate lower mortality rates, reducing the
occurrence probability of unsafe behaviors.},
 author = {Nan Fang and Guiliang Liu and Wei Gong},
 comment = {},
 doi = {},
 eprint = {2410.07525v2},
 journal = {arXiv preprint},
 title = {Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare},
 url = {http://arxiv.org/abs/2410.07525v2},
 year = {2024}
}

@article{2410.07673v1,
 abstract = {This paper focuses on detecting clickbait posts on the Web. These posts often
use eye-catching disinformation in mixed modalities to mislead users to click
for profit. That affects the user experience and thus would be blocked by
content provider. To escape detection, malicious creators use tricks to add
some irrelevant non-bait content into bait posts, dressing them up as legal to
fool the detector. This content often has biased relations with non-bait
labels, yet traditional detectors tend to make predictions based on simple
co-occurrence rather than grasping inherent factors that lead to malicious
behavior. This spurious bias would easily cause misjudgments. To address this
problem, we propose a new debiased method based on causal inference. We first
employ a set of features in multiple modalities to characterize the posts.
Considering these features are often mixed up with unknown biases, we then
disentangle three kinds of latent factors from them, including the invariant
factor that indicates intrinsic bait intention; the causal factor which
reflects deceptive patterns in a certain scenario, and non-causal noise. By
eliminating the noise that causes bias, we can use invariant and causal factors
to build a robust model with good generalization ability. Experiments on three
popular datasets show the effectiveness of our approach.},
 author = {Jianxing Yu and Shiqi Wang and Han Yin and Zhenlong Sun and Ruobing Xie and Bo Zhang and Yanghui Rao},
 comment = {},
 doi = {},
 eprint = {2410.07673v1},
 journal = {arXiv preprint},
 title = {Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference},
 url = {http://arxiv.org/abs/2410.07673v1},
 year = {2024}
}

@article{2410.08924v1,
 abstract = {Predicting potential outcomes of interventions from observational data is
crucial for decision-making in medicine, but the task is challenging due to the
fundamental problem of causal inference. Existing methods are largely limited
to point estimates of potential outcomes with no uncertain quantification;
thus, the full information about the distributions of potential outcomes is
typically ignored. In this paper, we propose a novel causal diffusion model
called DiffPO, which is carefully designed for reliable inferences in medicine
by learning the distribution of potential outcomes. In our DiffPO, we leverage
a tailored conditional denoising diffusion model to learn complex
distributions, where we address the selection bias through a novel orthogonal
diffusion loss. Another strength of our DiffPO method is that it is highly
flexible (e.g., it can also be used to estimate different causal quantities
such as CATE). Across a wide range of experiments, we show that our method
achieves state-of-the-art performance.},
 author = {Yuchen Ma and Valentyn Melnychuk and Jonas Schweisthal and Stefan Feuerriegel},
 comment = {},
 doi = {},
 eprint = {2410.08924v1},
 journal = {arXiv preprint},
 title = {DiffPO: A causal diffusion model for learning distributions of potential outcomes},
 url = {http://arxiv.org/abs/2410.08924v1},
 year = {2024}
}

@article{2410.08976v2,
 abstract = {Reliable estimation of treatment effects from observational data is important
in many disciplines such as medicine. However, estimation is challenging when
unconfoundedness as a standard assumption in the causal inference literature is
violated. In this work, we leverage arbitrary (potentially high-dimensional)
instruments to estimate bounds on the conditional average treatment effect
(CATE). Our contributions are three-fold: (1) We propose a novel approach for
partial identification through a mapping of instruments to a discrete
representation space so that we yield valid bounds on the CATE. This is crucial
for reliable decision-making in real-world applications. (2) We derive a
two-step procedure that learns tight bounds using a tailored neural
partitioning of the latent instrument space. As a result, we avoid instability
issues due to numerical approximations or adversarial training. Furthermore,
our procedure aims to reduce the estimation variance in finite-sample settings
to yield more reliable estimates. (3) We show theoretically that our procedure
obtains valid bounds while reducing estimation variance. We further perform
extensive experiments to demonstrate the effectiveness across various settings.
Overall, our procedure offers a novel path for practitioners to make use of
potentially high-dimensional instruments (e.g., as in Mendelian randomization).},
 author = {Jonas Schweisthal and Dennis Frauen and Maresa Schröder and Konstantin Hess and Niki Kilbertus and Stefan Feuerriegel},
 comment = {},
 doi = {},
 eprint = {2410.08976v2},
 journal = {arXiv preprint},
 title = {Learning Representations of Instruments for Partial Identification of Treatment Effects},
 url = {http://arxiv.org/abs/2410.08976v2},
 year = {2024}
}

@article{2410.09186v3,
 abstract = {In this paper, we discuss learning algorithms and their importance in
different types of applications which includes training to identify important
patterns and features in a straightforward, easy-to-understand manner. We will
review the main concepts of artificial intelligence (AI), machine learning
(ML), deep learning (DL), and hybrid models. Some important subsets of Machine
Learning algorithms such as supervised, unsupervised, and reinforcement
learning are also discussed in this paper. These techniques can be used for
some important tasks like prediction, classification, and segmentation.
Convolutional Neural Networks (CNNs) are used for image and video processing
and many more applications. We dive into the architecture of CNNs and how to
integrate CNNs with ML algorithms to build hybrid models. This paper explores
the vulnerability of learning algorithms to noise, leading to
misclassification. We further discuss the integration of learning algorithms
with Large Language Models (LLM) to generate coherent responses applicable to
many domains such as healthcare, marketing, and finance by learning important
patterns from large volumes of data. Furthermore, we discuss the next
generation of learning algorithms and how we may have an unified Adaptive and
Dynamic Network to perform important tasks. Overall, this article provides
brief overview of learning algorithms, exploring their current state,
applications and future direction.},
 author = {Noorbakhsh Amiri Golilarz and Elias Hossain and Abdoljalil Addeh and Keyan Alexander Rahimi},
 comment = {},
 doi = {},
 eprint = {2410.09186v3},
 journal = {arXiv preprint},
 title = {AI Learning Algorithms: Deep Learning, Hybrid Models, and Large-Scale Model Integration},
 url = {http://arxiv.org/abs/2410.09186v3},
 year = {2024}
}

@article{2410.10044v2,
 abstract = {Causal inference is a critical task across fields such as healthcare,
economics, and the social sciences. While recent advances in machine learning,
especially those based on the deep-learning architectures, have shown potential
in estimating causal effects, existing approaches often fall short in handling
complex causal structures and lack adaptability across various causal
scenarios. In this paper, we present a novel transformer-based method for
causal inference that overcomes these challenges. The core innovation of our
model lies in its integration of causal Directed Acyclic Graphs (DAGs) directly
into the attention mechanism, enabling it to accurately model the underlying
causal structure. This allows for flexible estimation of both average treatment
effects (ATE) and conditional average treatment effects (CATE). Extensive
experiments on both synthetic and real-world datasets demonstrate that our
approach surpasses existing methods in estimating causal effects across a wide
range of scenarios. The flexibility and robustness of our model make it a
valuable tool for researchers and practitioners tackling complex causal
inference problems.},
 author = {Manqing Liu and David R. Bellamy and Andrew L. Beam},
 comment = {},
 doi = {},
 eprint = {2410.10044v2},
 journal = {arXiv preprint},
 title = {DAG-aware Transformer for Causal Effect Estimation},
 url = {http://arxiv.org/abs/2410.10044v2},
 year = {2024}
}

@article{2410.10502v1,
 abstract = {In this paper, we focus on estimating the causal effect of an intervention
over time on a dynamical system. To that end, we formally define causal
interventions and their effects over time on discrete-time stochastic processes
(DSPs). Then, we show under which conditions the equilibrium states of a DSP,
both before and after a causal intervention, can be captured by a structural
causal model (SCM). With such an equivalence at hand, we provide an explicit
mapping from vector autoregressive models (VARs), broadly applied in
econometrics, to linear, but potentially cyclic and/or affected by unmeasured
confounders, SCMs. The resulting causal VAR framework allows us to perform
causal inference over time from observational time series data. Our experiments
on synthetic and real-world datasets show that the proposed framework achieves
strong performance in terms of observational forecasting while enabling
accurate estimation of the causal effect of interventions on dynamical systems.
We demonstrate, through a case study, the potential practical questions that
can be addressed using the proposed causal VAR framework.},
 author = {Martina Cinquini and Isacco Beretta and Salvatore Ruggieri and Isabel Valera},
 comment = {},
 doi = {10.1609/aaai.v39i14.33626},
 eprint = {2410.10502v1},
 journal = {arXiv preprint},
 title = {A Practical Approach to Causal Inference over Time},
 url = {http://arxiv.org/abs/2410.10502v1},
 year = {2024}
}

@article{2410.12730v3,
 abstract = {Estimating an individual's counterfactual outcomes under interventions is a
challenging task for traditional causal inference and supervised learning
approaches when the outcome is high-dimensional (e.g. gene expressions, facial
images) and covariates are relatively limited. In this case, to predict one's
outcomes under counterfactual treatments, it is crucial to leverage individual
information contained in the observed outcome in addition to the covariates.
Prior works using variational inference in counterfactual generative modeling
have been focusing on neural adaptations and model variants within the
conditional variational autoencoder formulation, which we argue is
fundamentally ill-suited to the notion of counterfactual in causal inference.
In this work, we present a novel variational Bayesian causal inference
framework and its theoretical backings to properly handle counterfactual
generative modeling tasks, through which we are able to conduct counterfactual
supervision end-to-end during training without any counterfactual samples, and
encourage disentangled exogenous noise abduction that aids the correct
identification of causal effect in counterfactual generations. In experiments,
we demonstrate the advantage of our framework compared to state-of-the-art
models in counterfactual generative modeling on multiple benchmarks.},
 author = {Yulun Wu and Louie McConnell and Claudia Iriondo},
 comment = {Published as a conference paper at ICLR 2025},
 doi = {},
 eprint = {2410.12730v3},
 journal = {arXiv preprint},
 title = {Counterfactual Generative Modeling with Variational Causal Inference},
 url = {http://arxiv.org/abs/2410.12730v3},
 year = {2024}
}

@article{2410.14127v1,
 abstract = {A central question in human immunology is how a patient's repertoire of T
cells impacts disease. Here, we introduce a method to infer the causal effects
of T cell receptor (TCR) sequences on patient outcomes using observational TCR
repertoire sequencing data and clinical outcomes data. Our approach corrects
for unobserved confounders, such as a patient's environment and life history,
by using the patient's immature, pre-selection TCR repertoire. The
pre-selection repertoire can be estimated from nonproductive TCR data, which is
widely available. It is generated by a randomized mutational process, V(D)J
recombination, which provides a natural experiment. We show formally how to use
the pre-selection repertoire to draw causal inferences, and develop a scalable
neural-network estimator for our identification formula. Our method produces an
estimate of the effect of interventions that add a specific TCR sequence to
patient repertoires. As a demonstration, we use it to analyze the effects of
TCRs on COVID-19 severity, uncovering potentially therapeutic TCRs that are (1)
observed in patients, (2) bind SARS-CoV-2 antigens in vitro and (3) have strong
positive effects on clinical outcomes.},
 author = {Eli N. Weinstein and Elizabeth B. Wood and David M. Blei},
 comment = {},
 doi = {},
 eprint = {2410.14127v1},
 journal = {arXiv preprint},
 title = {Estimating the Causal Effects of T Cell Receptors},
 url = {http://arxiv.org/abs/2410.14127v1},
 year = {2024}
}

@article{2410.14789v2,
 abstract = {Differential privacy is the leading mathematical framework for privacy
protection, providing a probabilistic guarantee that safeguards individuals'
private information when publishing statistics from a dataset. This guarantee
is achieved by applying a randomized algorithm to the original data, which
introduces unique challenges in data analysis by distorting inherent patterns.
In particular, causal inference using observational data in privacy-sensitive
contexts is challenging because it requires covariate balance between treatment
groups, yet checking the true covariates is prohibited to prevent leakage of
sensitive information. In this article, we present a differentially private
two-stage covariate balancing weighting estimator to infer causal effects from
observational data. Our algorithm produces both point and interval estimators
with statistical guarantees, such as consistency and rate optimality, under a
given privacy budget.},
 author = {Yuki Ohnishi and Jordan Awan},
 comment = {31 pages},
 doi = {},
 eprint = {2410.14789v2},
 journal = {arXiv preprint},
 title = {Differentially Private Covariate Balancing Causal Inference},
 url = {http://arxiv.org/abs/2410.14789v2},
 year = {2024}
}

@article{2410.15655v1,
 abstract = {Many applications of causal inference require using treatment effects
estimated on a study population to make decisions in a separate target
population. We consider the challenging setting where there are covariates that
are observed in the target population that were not seen in the original study.
Our goal is to estimate the tightest possible bounds on heterogeneous treatment
effects conditioned on such newly observed covariates. We introduce a novel
partial identification strategy based on ideas from ecological inference; the
main idea is that estimates of conditional treatment effects for the full
covariate set must marginalize correctly when restricted to only the covariates
observed in both populations. Furthermore, we introduce a bias-corrected
estimator for these bounds and prove that it enjoys fast convergence rates and
statistical guarantees (e.g., asymptotic normality). Experimental results on
both real and synthetic data demonstrate that our framework can produce bounds
that are much tighter than would otherwise be possible.},
 author = {Khurram Yamin and Vibhhu Sharma and Ed Kennedy and Bryan Wilder},
 comment = {},
 doi = {},
 eprint = {2410.15655v1},
 journal = {arXiv preprint},
 title = {Accounting for Missing Covariates in Heterogeneous Treatment Estimation},
 url = {http://arxiv.org/abs/2410.15655v1},
 year = {2024}
}

@article{2410.16004v2,
 abstract = {Faithfulness is a ubiquitous assumption in causal inference, often motivated
by the fact that the faithful parameters of linear Gaussian and discrete
Bayesian networks are typical, and the folklore belief that this should also
hold for other classes of Bayesian networks. We address this open question by
showing that among all Bayesian networks over a given DAG, the faithful
Bayesian networks are indeed `typical': they constitute a dense, open set with
respect to the total variation metric. However, this does not imply that
faithfulness is typical in restricted classes of Bayesian networks, as are
often considered in statistical applications. To this end we consider the class
of Bayesian networks parametrised by conditional exponential families, for
which we show that under mild regularity conditions, the faithful parameters
constitute a dense, open set and the unfaithful parameters have Lebesgue
measure zero, extending the existing results for linear Gaussian and discrete
Bayesian networks. Finally, we show that the aforementioned results also hold
for Bayesian networks with latent variables.},
 author = {Philip Boeken and Patrick Forré and Joris M. Mooij},
 comment = {},
 doi = {},
 eprint = {2410.16004v2},
 journal = {arXiv preprint},
 title = {Are Bayesian networks typically faithful?},
 url = {http://arxiv.org/abs/2410.16004v2},
 year = {2024}
}

@article{2410.16638v4,
 abstract = {Despite the success of Large Language Models (LLMs) across various fields,
their potential to generate untruthful, biased and harmful responses poses
significant risks, particularly in critical applications. This highlights the
urgent need for systematic methods to detect and prevent such misbehavior.
While existing approaches target specific issues such as harmful responses,
this work introduces LLMScan, an innovative LLM monitoring technique based on
causality analysis, offering a comprehensive solution. LLMScan systematically
monitors the inner workings of an LLM through the lens of causal inference,
operating on the premise that the LLM's `brain' behaves differently when
misbehaving. By analyzing the causal contributions of the LLM's input tokens
and transformer layers, LLMScan effectively detects misbehavior. Extensive
experiments across various tasks and models reveal clear distinctions in the
causal distributions between normal behavior and misbehavior, enabling the
development of accurate, lightweight detectors for a variety of misbehavior
detection tasks.},
 author = {Mengdi Zhang and Kai Kiat Goh and Peixin Zhang and Jun Sun and Rose Lin Xin and Hongyu Zhang},
 comment = {},
 doi = {},
 eprint = {2410.16638v4},
 journal = {arXiv preprint},
 title = {LLMScan: Causal Scan for LLM Misbehavior Detection},
 url = {http://arxiv.org/abs/2410.16638v4},
 year = {2024}
}

@article{2410.16870v2,
 abstract = {We study Federated Causal Inference, an approach to estimate treatment
effects from decentralized data across centers. We compare three classes of
Average Treatment Effect (ATE) estimators derived from the Plug-in G-Formula,
ranging from simple meta-analysis to one-shot and multi-shot federated
learning, the latter leveraging the full data to learn the outcome model
(albeit requiring more communication). Focusing on Randomized Controlled Trials
(RCTs), we derive the asymptotic variance of these estimators for linear
models. Our results provide practical guidance on selecting the appropriate
estimator for various scenarios, including heterogeneity in sample sizes,
covariate distributions, treatment assignment schemes, and center effects. We
validate these findings with a simulation study.},
 author = {Rémi Khellaf and Aurélien Bellet and Julie Josse},
 comment = {},
 doi = {},
 eprint = {2410.16870v2},
 journal = {arXiv preprint},
 title = {Federated Causal Inference: Multi-Study ATE Estimation beyond Meta-Analysis},
 url = {http://arxiv.org/abs/2410.16870v2},
 year = {2024}
}

@article{2410.17709v1,
 abstract = {The presence of unhealthy nodes in cloud infrastructure signals the potential
failure of machines, which can significantly impact the availability and
reliability of cloud services, resulting in negative customer experiences.
Effectively addressing unhealthy node mitigation is therefore vital for
sustaining cloud system performance. This paper introduces Deoxys, a causal
inference engine tailored to recommending mitigation actions for unhealthy node
in cloud systems to minimize virtual machine downtime and interruptions during
unhealthy events. It employs double machine learning combined with causal
forest to produce precise and reliable mitigation recommendations based solely
on limited observational data collected from the historical unhealthy events.
To enhance the causal inference model, Deoxys further incorporates a policy
fallback mechanism based on model uncertainty and action overriding mechanisms
to (i) improve the reliability of the system, and (ii) strike a good tradeoff
between downtime reduction and resource utilization, thereby enhancing the
overall system performance.
  After deploying Deoxys in a large-scale cloud infrastructure at Microsoft,
our observations demonstrate that Deoxys significantly reduces average VM
downtime by 53% compared to a legacy policy, while leading to 49.5% lower VM
interruption rate. This substantial improvement enhances the reliability and
stability of cloud platforms, resulting in a seamless customer experience.},
 author = {Chaoyun Zhang and Randolph Yao and Si Qin and Ze Li and Shekhar Agrawal and Binit R. Mishra and Tri Tran and Minghua Ma and Qingwei Lin and Murali Chintalapati and Dongmei Zhang},
 comment = {},
 doi = {},
 eprint = {2410.17709v1},
 journal = {arXiv preprint},
 title = {Deoxys: A Causal Inference Engine for Unhealthy Node Mitigation in Large-scale Cloud Infrastructure},
 url = {http://arxiv.org/abs/2410.17709v1},
 year = {2024}
}

@article{2410.19179v1,
 abstract = {Causal inference provides an analytical framework to identify and quantify
cause-and-effect relationships among a network of interacting agents. This
paper offers a novel framework for analyzing cascading failures in power
transmission networks. This framework generates a directed latent graph in
which the nodes represent the transmission lines and the directed edges encode
the cause-effect relationships. This graph has a structure distinct from the
system's topology, signifying the intricate fact that both local and non-local
interdependencies exist among transmission lines, which are more general than
only the local interdependencies that topological graphs can present. This
paper formalizes a causal inference framework for predicting how an emerging
anomaly propagates throughout the system. Using this framework, two algorithms
are designed, providing an analytical framework to identify the most likely and
most costly cascading scenarios. The framework's effectiveness is evaluated
compared to the pertinent literature on the IEEE 14-bus, 39-bus, and 118-bus
systems.},
 author = {Shiuli Subhra Ghosh and Anmol Dwivedi and Ali Tajer and Kyongmin Yeo and Wesley M. Gifford},
 comment = {},
 doi = {},
 eprint = {2410.19179v1},
 journal = {arXiv preprint},
 title = {Cascading Failure Prediction via Causal Inference},
 url = {http://arxiv.org/abs/2410.19179v1},
 year = {2024}
}

@article{2410.19870v1,
 abstract = {In this paper, we consider the problem of causal order discovery within the
framework of monotonic Structural Causal Models (SCMs), which have gained
attention for their potential to enable causal inference and causal discovery
from observational data. While existing approaches either assume prior
knowledge about the causal order or use complex optimization techniques to
impose sparsity in the Jacobian of Triangular Monotonic Increasing maps, our
work introduces a novel sequential procedure that directly identifies the
causal order by iteratively detecting the root variable. This method eliminates
the need for sparsity assumptions and the associated optimization challenges,
enabling the identification of a unique SCM without the need for multiple
independence tests to break the Markov equivalence class. We demonstrate the
effectiveness of our approach in sequentially finding the root variable,
comparing it to methods that maximize Jacobian sparsity.},
 author = {Ali Izadi and Martin Ester},
 comment = {Accepted to the NeurIPS 2024 Workshop on Causal Representation
  Learning},
 doi = {},
 eprint = {2410.19870v1},
 journal = {arXiv preprint},
 title = {Causal Order Discovery based on Monotonic SCMs},
 url = {http://arxiv.org/abs/2410.19870v1},
 year = {2024}
}

@article{2410.19923v1,
 abstract = {Large Language Models (LLMs) have recently shown great promise in planning
and reasoning applications. These tasks demand robust systems, which arguably
require a causal understanding of the environment. While LLMs can acquire and
reflect common sense causal knowledge from their pretraining data, this
information is often incomplete, incorrect, or inapplicable to a specific
environment. In contrast, causal representation learning (CRL) focuses on
identifying the underlying causal structure within a given environment. We
propose a framework that integrates CRLs with LLMs to enable causally-aware
reasoning and planning. This framework learns a causal world model, with causal
variables linked to natural language expressions. This mapping provides LLMs
with a flexible interface to process and generate descriptions of actions and
states in text form. Effectively, the causal world model acts as a simulator
that the LLM can query and interact with. We evaluate the framework on causal
inference and planning tasks across temporal scales and environmental
complexities. Our experiments demonstrate the effectiveness of the approach,
with the causally-aware method outperforming LLM-based reasoners, especially
for longer planning horizons.},
 author = {John Gkountouras and Matthias Lindemann and Phillip Lippe and Efstratios Gavves and Ivan Titov},
 comment = {Project page: https://j0hngou.github.io/LLMCWM/},
 doi = {},
 eprint = {2410.19923v1},
 journal = {arXiv preprint},
 title = {Language Agents Meet Causality -- Bridging LLMs and Causal World Models},
 url = {http://arxiv.org/abs/2410.19923v1},
 year = {2024}
}

@article{2410.20017v1,
 abstract = {In human-centric tasks such as healthcare and education, the heterogeneity
among patients and students necessitates personalized treatments and
instructional interventions. While reinforcement learning (RL) has been
utilized in those tasks, off-policy selection (OPS) is pivotal to close the
loop by offline evaluating and selecting policies without online interactions,
yet current OPS methods often overlook the heterogeneity among participants.
Our work is centered on resolving a pivotal challenge in human-centric systems
(HCSs): how to select a policy to deploy when a new participant joining the
cohort, without having access to any prior offline data collected over the
participant? We introduce First-Glance Off-Policy Selection (FPS), a novel
approach that systematically addresses participant heterogeneity through
sub-group segmentation and tailored OPS criteria to each sub-group. By grouping
individuals with similar traits, FPS facilitates personalized policy selection
aligned with unique characteristics of each participant or group of
participants. FPS is evaluated via two important but challenging applications,
intelligent tutoring systems and a healthcare application for sepsis treatment
and intervention. FPS presents significant advancement in enhancing learning
outcomes of students and in-hospital care outcomes.},
 author = {Ge Gao and Xi Yang and Qitong Gao and Song Ju and Miroslav Pajic and Min Chi},
 comment = {},
 doi = {},
 eprint = {2410.20017v1},
 journal = {arXiv preprint},
 title = {Off-Policy Selection for Initiating Human-Centric Experimental Design},
 url = {http://arxiv.org/abs/2410.20017v1},
 year = {2024}
}

@article{2410.20057v1,
 abstract = {A major limitation of machine learning (ML) prediction models is that they
recover associational, rather than causal, predictive relationships between
variables. In high-stakes automation applications of ML this is problematic, as
the model often learns spurious, non-causal associations. This paper proposes
mechanism learning, a simple method which uses front-door causal bootstrapping
to deconfound observational data such that any appropriate ML model is forced
to learn predictive relationships between effects and their causes (reverse
causal inference), despite the potential presence of multiple unknown and
unmeasured confounding. Effect variables can be very high dimensional, and the
predictive relationship nonlinear, as is common in ML applications. This novel
method is widely applicable, the only requirement is the existence of a
mechanism variable mediating the cause (prediction target) and effect (feature
data), which is independent of the (unmeasured) confounding variables. We test
our method on fully synthetic, semi-synthetic and real-world datasets,
demonstrating that it can discover reliable, unbiased, causal ML predictors
where by contrast, the same ML predictor trained naively using classical
supervised learning on the original observational data, is heavily biased by
spurious associations. We provide code to implement the results in the paper,
online.},
 author = {Jianqiao Mao and Max A. Little},
 comment = {12 pages, 6 figures},
 doi = {},
 eprint = {2410.20057v1},
 journal = {arXiv preprint},
 title = {Mechanism learning: Reverse causal inference in the presence of multiple unknown confounding through front-door causal bootstrapping},
 url = {http://arxiv.org/abs/2410.20057v1},
 year = {2024}
}

@article{2410.21531v1,
 abstract = {The g-formula can be used to estimate causal effects of sustained treatment
strategies using observational data under the identifying assumptions of
consistency, positivity, and exchangeability. The non-iterative conditional
expectation (NICE) estimator of the g-formula also requires correct estimation
of the conditional distribution of the time-varying treatment, confounders, and
outcome. Parametric models, which have been traditionally used for this
purpose, are subject to model misspecification, which may result in biased
causal estimates. Here, we propose a unified deep learning framework for the
NICE g-formula estimator that uses multitask recurrent neural networks for
estimation of the joint conditional distributions. Using simulated data, we
evaluated our model's bias and compared it with that of the parametric
g-formula estimator. We found lower bias in the estimates of the causal effect
of sustained treatment strategies on a survival outcome when using the deep
learning estimator compared with the parametric NICE estimator in settings with
simple and complex temporal dependencies between covariates. These findings
suggest that our Deep Learning g-formula estimator may be less sensitive to
model misspecification than the classical parametric NICE estimator when
estimating the causal effect of sustained treatment strategies from complex
observational data.},
 author = {Sophia M Rein and Jing Li and Miguel Hernan and Andrew Beam},
 comment = {},
 doi = {},
 eprint = {2410.21531v1},
 journal = {arXiv preprint},
 title = {Deep Learning Methods for the Noniterative Conditional Expectation G-Formula for Causal Inference from Complex Observational Data},
 url = {http://arxiv.org/abs/2410.21531v1},
 year = {2024}
}

@article{2410.21917v2,
 abstract = {The identifiability analysis of linear Ordinary Differential Equation (ODE)
systems is a necessary prerequisite for making reliable causal inferences about
these systems. While identifiability has been well studied in scenarios where
the system is fully observable, the conditions for identifiability remain
unexplored when latent variables interact with the system. This paper aims to
address this gap by presenting a systematic analysis of identifiability in
linear ODE systems incorporating hidden confounders. Specifically, we
investigate two cases of such systems. In the first case, latent confounders
exhibit no causal relationships, yet their evolution adheres to specific
functional forms, such as polynomial functions of time $t$. Subsequently, we
extend this analysis to encompass scenarios where hidden confounders exhibit
causal dependencies, with the causal structure of latent variables described by
a Directed Acyclic Graph (DAG). The second case represents a more intricate
variation of the first case, prompting a more comprehensive identifiability
analysis. Accordingly, we conduct detailed identifiability analyses of the
second system under various observation conditions, including both continuous
and discrete observations from single or multiple trajectories. To validate our
theoretical results, we perform a series of simulations, which support and
substantiate our findings.},
 author = {Yuanyuan Wang and Biwei Huang and Wei Huang and Xi Geng and Mingming Gong},
 comment = {38th Conference on Neural Information Processing Systems (NeurIPS
  2024)},
 doi = {},
 eprint = {2410.21917v2},
 journal = {arXiv preprint},
 title = {Identifiability Analysis of Linear ODE Systems with Hidden Confounders},
 url = {http://arxiv.org/abs/2410.21917v2},
 year = {2024}
}

@article{2410.22382v2,
 abstract = {Alternative data provides valuable insights for lenders to evaluate a
borrower's creditworthiness, which could help expand credit access to
underserved groups and lower costs for borrowers. But some forms of alternative
data have historically been excluded from credit underwriting because it could
act as an illegal proxy for a protected class like race or gender, causing
redlining. We propose a method for applying causal inference to a supervised
machine learning model to debias alternative data so that it might be used for
credit underwriting. We demonstrate how our algorithm can be used against a
public credit dataset to improve model accuracy across different racial groups,
while providing theoretically robust nondiscrimination guarantees.},
 author = {Chris Lam},
 comment = {},
 doi = {},
 eprint = {2410.22382v2},
 journal = {arXiv preprint},
 title = {Debiasing Alternative Data for Credit Underwriting Using Causal Inference},
 url = {http://arxiv.org/abs/2410.22382v2},
 year = {2024}
}

@article{2410.22481v1,
 abstract = {Like many chronic diseases, human immunodeficiency virus (HIV) is managed
over time at regular clinic visits. At each visit, patient features are
assessed, treatments are prescribed, and a subsequent visit is scheduled. There
is a need for data-driven methods for both predicting retention and
recommending scheduling decisions that optimize retention. Prediction models
can be useful for estimating retention rates across a range of scheduling
options. However, training such models with electronic health records (EHR)
involves several complexities. First, formal causal inference methods are
needed to adjust for observed confounding when estimating retention rates under
counterfactual scheduling decisions. Second, competing events such as death
preclude retention, while censoring events render retention missing. Third,
inconsistent monitoring of features such as viral load and CD4 count lead to
covariate missingness. This paper presents an all-in-one approach for both
predicting HIV retention and optimizing scheduling while accounting for these
complexities. We formulate and identify causal retention estimands in terms of
potential return-time under a hypothetical scheduling decision. Flexible
Bayesian approaches are used to model the observed return-time distribution
while accounting for competing and censoring events and form posterior point
and uncertainty estimates for these estimands. We address the urgent need for
data-driven decision support in HIV care by applying our method to EHR from the
Academic Model Providing Access to Healthcare (AMPATH) - a consortium of
clinics that treat HIV in Western Kenya.},
 author = {Arman Oganisian and Joseph Hogan and Edwin Sang and Allison DeLong and Ben Mosong and Hamish Fraser and Ann Mwangi},
 comment = {},
 doi = {},
 eprint = {2410.22481v1},
 journal = {arXiv preprint},
 title = {Bayesian Counterfactual Prediction Models for HIV Care Retention with Incomplete Outcome and Covariate Information},
 url = {http://arxiv.org/abs/2410.22481v1},
 year = {2024}
}

@article{2410.22754v1,
 abstract = {Kernel embeddings have emerged as a powerful tool for representing
probability measures in a variety of statistical inference problems. By mapping
probability measures into a reproducing kernel Hilbert space (RKHS), kernel
embeddings enable flexible representations of complex relationships between
variables. They serve as a mechanism for efficiently transferring the
representation of a distribution downstream to other tasks, such as hypothesis
testing or causal effect estimation. In the context of causal inference, the
main challenges include identifying causal associations and estimating the
average treatment effect from observational data, where confounding variables
may obscure direct cause-and-effect relationships. Kernel embeddings provide a
robust nonparametric framework for addressing these challenges. They allow for
the representations of distributions of observational data and their seamless
transformation into representations of interventional distributions to estimate
relevant causal quantities. We overview recent research that leverages the
expressiveness of kernel embeddings in tandem with causal inference.},
 author = {Dino Sejdinovic},
 comment = {},
 doi = {},
 eprint = {2410.22754v1},
 journal = {arXiv preprint},
 title = {An Overview of Causal Inference using Kernel Embeddings},
 url = {http://arxiv.org/abs/2410.22754v1},
 year = {2024}
}

@article{2410.23494v2,
 abstract = {Robustness audits of deep neural networks (DNN) provide a means to uncover
model sensitivities to the challenging real-world imaging conditions that
significantly degrade DNN performance in-the-wild. Such conditions are often
the result of multiple interacting factors inherent to the environment, sensor,
or processing pipeline and may lead to complex image distortions that are not
easily categorized. When robustness audits are limited to a set of isolated
imaging effects or distortions, the results cannot be (easily) transferred to
real-world conditions where image corruptions may be more complex or nuanced.
To address this challenge, we present a new alternative robustness auditing
method that uses causal inference to measure DNN sensitivities to the factors
of the imaging process that cause complex distortions. Our approach uses causal
models to explicitly encode assumptions about the domain-relevant factors and
their interactions. Then, through extensive experiments on natural and rendered
images across multiple vision tasks, we show that our approach reliably
estimates causal effects of each factor on DNN performance using only
observational domain data. These causal effects directly tie DNN sensitivities
to observable properties of the imaging pipeline in the domain of interest
towards reducing the risk of unexpected DNN failures when deployed in that
domain.},
 author = {Nathan Drenkow and William Paul and Chris Ribaudo and Mathias Unberath},
 comment = {},
 doi = {},
 eprint = {2410.23494v2},
 journal = {arXiv preprint},
 title = {Causality-Driven Audits of Model Robustness},
 url = {http://arxiv.org/abs/2410.23494v2},
 year = {2024}
}

@article{2410.23499v1,
 abstract = {Causal discovery with time series data remains a challenging yet increasingly
important task across many scientific domains. Convergent cross mapping (CCM)
and related methods have been proposed to study time series that are generated
by dynamical systems, where traditional approaches like Granger causality are
unreliable. However, CCM often yields inaccurate results depending upon the
quality of the data. We propose the Tangent Space Causal Inference (TSCI)
method for detecting causalities in dynamical systems. TSCI works by
considering vector fields as explicit representations of the systems' dynamics
and checks for the degree of synchronization between the learned vector fields.
The TSCI approach is model-agnostic and can be used as a drop-in replacement
for CCM and its generalizations. We first present a basic version of the TSCI
algorithm, which is shown to be more effective than the basic CCM algorithm
with very little additional computation. We additionally present augmented
versions of TSCI that leverage the expressive power of latent variable models
and deep learning. We validate our theory on standard systems, and we
demonstrate improved causal inference performance across a number of benchmark
tasks.},
 author = {Kurt Butler and Daniel Waxman and Petar M. Djurić},
 comment = {18 pages, 7 figures. Accepted to NeurIPS 2024},
 doi = {},
 eprint = {2410.23499v1},
 journal = {arXiv preprint},
 title = {Tangent Space Causal Inference: Leveraging Vector Fields for Causal Discovery in Dynamical Systems},
 url = {http://arxiv.org/abs/2410.23499v1},
 year = {2024}
}

@article{2410.23569v4,
 abstract = {Reinforcement Learning from Human Feedback (RLHF) has recently surged in
popularity, particularly for aligning large language models and other AI
systems with human intentions. At its core, RLHF can be viewed as a specialized
instance of Preference-based Reinforcement Learning (PbRL), where the
preferences specifically originate from human judgments rather than arbitrary
evaluators. Despite this connection, most existing approaches in both RLHF and
PbRL primarily focus on optimizing a mean reward objective, neglecting
scenarios that necessitate risk-awareness, such as AI safety, healthcare, and
autonomous driving. These scenarios often operate under a one-episode-reward
setting, which makes conventional risk-sensitive objectives inapplicable. To
address this, we explore and prove the applicability of two risk-aware
objectives to PbRL : nested and static quantile risk objectives. We also
introduce Risk-AwarePbRL (RA-PbRL), an algorithm designed to optimize both
nested and static objectives. Additionally, we provide a theoretical analysis
of the regret upper bounds, demonstrating that they are sublinear with respect
to the number of episodes, and present empirical results to support our
findings. Our code is available in
https://github.com/aguilarjose11/PbRLNeurips.},
 author = {Yujie Zhao and Jose Efraim Aguilar Escamill and Weyl Lu and Huazheng Wang},
 comment = {},
 doi = {},
 eprint = {2410.23569v4},
 journal = {arXiv preprint},
 title = {RA-PbRL: Provably Efficient Risk-Aware Preference-Based Reinforcement Learning},
 url = {http://arxiv.org/abs/2410.23569v4},
 year = {2024}
}

@article{2410.23884v5,
 abstract = {The ability to robustly identify causal relationships is essential for
autonomous decision-making and adaptation to novel scenarios. However,
accurately inferring causal structure requires integrating both world knowledge
and abstract logical reasoning. In this work, we investigate the interaction
between these two capabilities through the representative task of causal
reasoning over narratives. Through controlled synthetic, semi-synthetic, and
real-world experiments, we find that state-of-the-art large language models
(LLMs) often rely on superficial heuristics -- for example, inferring causality
from event order or recalling memorized world knowledge without attending to
context. Furthermore, we show that simple reformulations of the task can elicit
more robust reasoning behavior. Our evaluation spans a range of causal
structures, from linear chains to complex graphs involving colliders and forks.
These findings uncover systematic patterns in how LLMs perform causal reasoning
and lay the groundwork for developing methods that better align LLM behavior
with principled causal inference.},
 author = {Khurram Yamin and Shantanu Gupta and Gaurav R. Ghosal and Zachary C. Lipton and Bryan Wilder},
 comment = {ICML 2025 Workshop on Scaling up Intervention Models},
 doi = {},
 eprint = {2410.23884v5},
 journal = {arXiv preprint},
 title = {Failure Modes of LLMs for Causal Reasoning on Narratives},
 url = {http://arxiv.org/abs/2410.23884v5},
 year = {2024}
}

@article{2411.00950v1,
 abstract = {In causal inference, an important problem is to quantify the effects of
interventions or treatments. Many studies focus on estimating the mean causal
effects; however, these estimands may offer limited insight since two
distributions can share the same mean yet exhibit significant differences.
Examining the causal effects from a distributional perspective provides a more
thorough understanding. In this paper, we employ a semiparametric density ratio
model (DRM) to characterize the counterfactual distributions, introducing a
framework that assumes a latent structure shared by these distributions. Our
model offers flexibility by avoiding strict parametric assumptions on the
counterfactual distributions. Specifically, the DRM incorporates a
nonparametric component that can be estimated through the method of empirical
likelihood (EL), using the data from all the groups stemming from multiple
interventions. Consequently, the EL-DRM framework enables inference of the
counterfactual distribution functions and their functionals, facilitating
direct and transparent causal inference from a distributional perspective.
Numerical studies on both synthetic and real-world data validate the
effectiveness of our approach.},
 author = {Archer Gong Zhang and Nancy Reid and Qiang Sun},
 comment = {},
 doi = {},
 eprint = {2411.00950v1},
 journal = {arXiv preprint},
 title = {A Semiparametric Approach to Causal Inference},
 url = {http://arxiv.org/abs/2411.00950v1},
 year = {2024}
}

@article{2411.01498v1,
 abstract = {This study examines the educational effect of the Academic Support Center at
Kogakuin University. Following the initial assessment, it was suggested that
group bias had led to an underestimation of the Center's true impact. To
address this issue, the authors applied the theory of causal inference. By
using T-learner, the conditional average treatment effect (CATE) of the
Center's face-to-face (F2F) personal assistance program was evaluated.
Extending T-learner, the authors produced a new CATE function that depends on
the number of treatments (F2F sessions) and used the estimated function to
predict the CATE performance of F2F assistance.},
 author = {Tomoko Nagai and Takayuki Okuda and Tomoya Nakamura and Yuichiro Sato and Yusuke Sato and Kensaku Kinjo and Kengo Kawamura and Shin Kikuta and Naoto Kumano-go},
 comment = {12 pages, 7 figures},
 doi = {},
 eprint = {2411.01498v1},
 journal = {arXiv preprint},
 title = {Educational Effects in Mathematics: Conditional Average Treatment Effect depending on the Number of Treatments},
 url = {http://arxiv.org/abs/2411.01498v1},
 year = {2024}
}

@article{2411.02134v2,
 abstract = {Earth Observation (EO) data are increasingly used in policy analysis by
enabling granular estimation of conditional average treatment effects (CATE).
However, a challenge in EO-based causal inference is determining the scale of
the input satellite imagery -- balancing the trade-off between capturing
fine-grained individual heterogeneity in smaller images and broader contextual
information in larger ones. This paper introduces Multi-Scale Representation
Concatenation, a set of composable procedures that transform arbitrary
single-scale EO-based CATE estimation algorithms into multi-scale ones. We
benchmark the performance of Multi-Scale Representation Concatenation on a CATE
estimation pipeline that combines Vision Transformer (ViT) models (which encode
images) with Causal Forests (CFs) to obtain CATE estimates from those
encodings. We first perform simulation studies where the causal mechanism is
known, showing that our multi-scale approach captures information relevant to
effect heterogeneity that single-scale ViT models fail to capture as measured
by $R^2$. We then apply the multi-scale method to two randomized controlled
trials (RCTs) conducted in Peru and Uganda using Landsat satellite imagery. As
we do not have access to ground truth CATEs in the RCT analysis, the Rank
Average Treatment Effect Ratio (RATE Ratio) measure is employed to assess
performance. Results indicate that Multi-Scale Representation Concatenation
improves the performance of deep learning models in EO-based CATE estimation
without the complexity of designing new multi-scale architectures for a
specific use case. The application of Multi-Scale Representation Concatenation
could have meaningful policy benefits -- e.g., potentially increasing the
impact of poverty alleviation programs without additional resource expenditure.},
 author = {Fucheng Warren Zhu and Connor T. Jerzak and Adel Daoud},
 comment = {To appear in: Conference on Causal Learning and Reasoning, 2025},
 doi = {},
 eprint = {2411.02134v2},
 journal = {arXiv preprint},
 title = {Optimizing Multi-Scale Representations to Detect Effect Heterogeneity Using Earth Observation and Computer Vision: Applications to Two Anti-Poverty RCTs},
 url = {http://arxiv.org/abs/2411.02134v2},
 year = {2024}
}

@article{2411.02345v1,
 abstract = {Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.},
 author = {Shahab Kavousinejad},
 comment = {The source code for this simulation is available on GitHub:
  https://github.com/SHAHAB-K93/cancer-and-smart-nanorobot},
 doi = {},
 eprint = {2411.02345v1},
 journal = {arXiv preprint},
 title = {Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking},
 url = {http://arxiv.org/abs/2411.02345v1},
 year = {2024}
}

@article{2411.03004v1,
 abstract = {Causal understanding is a fundamental goal of evidence-based medicine. When
randomization is impossible, causal inference methods allow the estimation of
treatment effects from retrospective analysis of observational data. However,
such analyses rely on a number of assumptions, often including that of no
unobserved confounding. In many practical settings, this assumption is violated
when important variables are not explicitly measured in the clinical record.
Prior work has proposed to address unobserved confounding with machine learning
by imputing unobserved variables and then correcting for the classifier's
mismeasurement. When such a classifier can be trained and the necessary
assumptions are met, this method can recover an unbiased estimate of a causal
effect. However, such work has been limited to synthetic data, simple
classifiers, and binary variables. This paper extends this methodology by using
a large language model trained on clinical notes to predict patients' smoking
status, which would otherwise be an unobserved confounder. We then apply a
measurement error correction on the categorical predicted smoking status to
estimate the causal effect of transthoracic echocardiography on mortality in
the MIMIC dataset.},
 author = {Samuel Lee and Zach Wood-Doughty},
 comment = {Advancements In Medical Foundation Models: Explainability,
  Robustness, Security, and Beyond (AIM-FM) at NeurIPS 2024},
 doi = {},
 eprint = {2411.03004v1},
 journal = {arXiv preprint},
 title = {Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status},
 url = {http://arxiv.org/abs/2411.03004v1},
 year = {2024}
}

@article{2411.03021v2,
 abstract = {Ensuring robust model performance in diverse real-world scenarios requires
addressing generalizability across domains with covariate shifts. However, no
formal procedure exists for statistically evaluating generalizability in
machine learning algorithms. Existing predictive metrics like mean squared
error (MSE) help to quantify the relative performance between models, but do
not directly answer whether a model can or cannot generalize. To address this
gap in the domain of causal inference, we propose a systematic framework for
statistically evaluating the generalizability of high-dimensional causal
inference models. Our approach uses the frugal parameterization to flexibly
simulate from fully and semi-synthetic causal benchmarks, offering a
comprehensive evaluation for both mean and distributional regression methods.
Grounded in real-world data, our method ensures more realistic evaluations,
which is often missing in current work relying on simplified datasets.
Furthermore, using simulations and statistical testing, our framework is robust
and avoids over-reliance on conventional metrics, providing statistical
safeguards for decision making.},
 author = {Daniel de Vassimon Manela and Linying Yang and Robin J. Evans},
 comment = {17 pages, 10 figures, In Proceedings for UAI 2025},
 doi = {},
 eprint = {2411.03021v2},
 journal = {arXiv preprint},
 title = {Testing Generalizability in Causal Inference},
 url = {http://arxiv.org/abs/2411.03021v2},
 year = {2024}
}

@article{2411.03919v1,
 abstract = {Precision rehabilitation offers the promise of an evidence-based approach for
optimizing individual rehabilitation to improve long-term functional outcomes.
Emerging techniques, including those driven by artificial intelligence, are
rapidly expanding our ability to quantify the different domains of function
during rehabilitation, other encounters with healthcare, and in the community.
While this seems poised to usher rehabilitation into the era of big data and
should be a powerful driver of precision rehabilitation, our field lacks a
coherent framework to utilize these data and deliver on this promise. We
propose a framework that builds upon multiple existing pillars to fill this
gap. Our framework aims to identify the Optimal Dynamic Treatment Regimens
(ODTR), or the decision-making strategy that takes in the range of available
measurements and biomarkers to identify interventions likely to maximize
long-term function. This is achieved by designing and fitting causal models,
which extend the Computational Neurorehabilitation framework using tools from
causal inference. These causal models can learn from heterogeneous data from
different silos, which must include detailed documentation of interventions,
such as using the Rehabilitation Treatment Specification System. The models
then serve as digital twins of patient recovery trajectories, which can be used
to learn the ODTR. Our causal modeling framework also emphasizes quantitatively
linking changes across levels of the functioning to ensure that interventions
can be precisely selected based on careful measurement of impairments while
also being selected to maximize outcomes that are meaningful to patients and
stakeholders. We believe this approach can provide a unifying framework to
leverage growing big rehabilitation data and AI-powered measurements to produce
precision rehabilitation treatments that can improve clinical outcomes.},
 author = {R. James Cotton and Bryant A. Seamon and Richard L. Segal and Randal D. Davis and Amrita Sahu and Michelle M. McLeod and Pablo Celnik and Sharon L. Ramey},
 comment = {keywords: rehabilitation; precision rehabilitation; causal inference;
  international classification of functioning; rehabilitation treatment
  specification system; computational neurorehabilitation},
 doi = {},
 eprint = {2411.03919v1},
 journal = {arXiv preprint},
 title = {A Causal Framework for Precision Rehabilitation},
 url = {http://arxiv.org/abs/2411.03919v1},
 year = {2024}
}

@article{2411.04285v1,
 abstract = {The task of predicting long-term patient outcomes using supervised machine
learning is a challenging one, in part because of the high variance of each
patient's trajectory, which can result in the model over-fitting to the
training data. Temporal difference (TD) learning, a common reinforcement
learning technique, may reduce variance by generalising learning to the pattern
of state transitions rather than terminal outcomes. However, in healthcare this
method requires several strong assumptions about patient states, and there
appears to be limited literature evaluating the performance of TD learning
against traditional supervised learning methods for long-term health outcome
prediction tasks. In this study, we define a framework for applying TD learning
to real-time irregularly sampled time series data using a Semi-Markov Reward
Process. We evaluate the model framework in predicting intensive care mortality
and show that TD learning under this framework can result in improved model
robustness compared to standard supervised learning methods. and that this
robustness is maintained even when validated on external datasets. This
approach may offer a more reliable method when learning to predict patient
outcomes using high-variance irregular time series data.},
 author = {Thomas Frost and Kezhi Li and Steve Harris},
 comment = {To be published in the Proceedings of the 4th Machine Learning for
  Health symposium, Proceedings of Machine Learning Research (PMLR)},
 doi = {},
 eprint = {2411.04285v1},
 journal = {arXiv preprint},
 title = {Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning},
 url = {http://arxiv.org/abs/2411.04285v1},
 year = {2024}
}

@article{2411.04312v4,
 abstract = {We study causal inference in sample selection models where a continuous or
multivalued treatment affects both outcomes and their observability (e.g.,
employment or survey responses). We generalized the widely used Lee (2009)'s
bounds for binary treatment effects. Our key innovation is a sufficient
treatment values assumption that imposes weak restrictions on selection
heterogeneity and is implicit in separable threshold-crossing models, including
monotone effects on selection. Our double debiased machine learning estimator
enables nonparametric and high-dimensional methods, using covariates to tighten
the bounds and capture heterogeneity. Applications to Job Corps and CCC program
evaluations reinforce prior findings under weaker assumptions.},
 author = {Ying-Ying Lee and Chu-An Liu},
 comment = {},
 doi = {},
 eprint = {2411.04312v4},
 journal = {arXiv preprint},
 title = {Lee Bounds with a Continuous Treatment in Sample Selection},
 url = {http://arxiv.org/abs/2411.04312v4},
 year = {2024}
}

@article{2411.05174v1,
 abstract = {We consider the problem of estimating the transition dynamics $T^*$ from
near-optimal expert trajectories in the context of offline model-based
reinforcement learning. We develop a novel constraint-based method, Inverse
Transition Learning, that treats the limited coverage of the expert
trajectories as a \emph{feature}: we use the fact that the expert is
near-optimal to inform our estimate of $T^*$. We integrate our constraints into
a Bayesian approach. Across both synthetic environments and real healthcare
scenarios like Intensive Care Unit (ICU) patient management in hypotension, we
demonstrate not only significant improvements in decision-making, but that our
posterior can inform when transfer will be successful.},
 author = {Leo Benac and Abhishek Sharma and Sonali Parbhoo and Finale Doshi-Velez},
 comment = {},
 doi = {},
 eprint = {2411.05174v1},
 journal = {arXiv preprint},
 title = {Inverse Transition Learning: Learning Dynamics from Demonstrations},
 url = {http://arxiv.org/abs/2411.05174v1},
 year = {2024}
}

@article{2411.05194v1,
 abstract = {Recent progress on large language models (LLMs) has enabled dialogue agents
to generate highly naturalistic and plausible text. However, current LLM
language generation focuses on responding accurately to questions and requests
with a single effective response. In reality, many real dialogues are
interactive, meaning an agent's utterances will influence their conversational
partner, elicit information, or change their opinion. Accounting for how an
agent can effectively steer a conversation is a crucial ability in many
dialogue tasks, from healthcare to preference elicitation. Existing methods for
fine-tuning dialogue agents to accomplish such tasks would rely on curating
some amount of expert data. However, doing so often requires understanding the
underlying cognitive processes of the conversational partner, which is a skill
neither humans nor LLMs trained on human data can reliably do. Our key insight
is that while LLMs may not be adept at identifying effective strategies for
steering conversations a priori, or in the middle of an ongoing conversation,
they can do so post-hoc, or in hindsight, after seeing how their conversational
partner responds. We use this fact to rewrite and augment existing suboptimal
data, and train via offline reinforcement learning (RL) an agent that
outperforms both prompting and learning from unaltered human demonstrations. We
apply our approach to two domains that require understanding human mental
state, intelligent interaction, and persuasion: mental health support, and
soliciting charitable donations. Our results in a user study with real humans
show that our approach greatly outperforms existing state-of-the-art dialogue
agents.},
 author = {Joey Hong and Jessica Lin and Anca Dragan and Sergey Levine},
 comment = {23 pages, 5 figures},
 doi = {},
 eprint = {2411.05194v1},
 journal = {arXiv preprint},
 title = {Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations},
 url = {http://arxiv.org/abs/2411.05194v1},
 year = {2024}
}

@article{2411.06338v1,
 abstract = {Causal inference and model interpretability are gaining increasing attention,
particularly in the biomedical domain. Despite recent advance, decorrelating
features in nonlinear environments with human-interpretable representations
remains underexplored. In this study, we introduce a novel method called causal
rule generation with target trial emulation framework (CRTRE), which applies
randomize trial design principles to estimate the causal effect of association
rules. We then incorporate such association rules for the downstream
applications such as prediction of disease onsets. Extensive experiments on six
healthcare datasets, including synthetic data, real-world disease collections,
and MIMIC-III/IV, demonstrate the model's superior performance. Specifically,
our method achieved a $\beta$ error of 0.907, outperforming DWR (1.024) and SVM
(1.141). On real-world datasets, our model achieved accuracies of 0.789, 0.920,
and 0.300 for Esophageal Cancer, Heart Disease, and Cauda Equina Syndrome
prediction task, respectively, consistently surpassing baseline models. On the
ICD code prediction tasks, it achieved AUC Macro scores of 92.8 on MIMIC-III
and 96.7 on MIMIC-IV, outperforming the state-of-the-art models KEPT and MSMN.
Expert evaluations further validate the model's effectiveness, causality, and
interpretability.},
 author = {Junda Wang and Weijian Li and Han Wang and Hanjia Lyu and Caroline P. Thirukumaran and Addisu Mesfin and Hong Yu and Jiebo Luo},
 comment = {},
 doi = {},
 eprint = {2411.06338v1},
 journal = {arXiv preprint},
 title = {CRTRE: Causal Rule Generation with Target Trial Emulation Framework},
 url = {http://arxiv.org/abs/2411.06338v1},
 year = {2024}
}

@article{2411.06342v3,
 abstract = {Inverse weighting with an estimated propensity score is widely used by
estimation methods in causal inference to adjust for confounding bias. However,
directly inverting propensity score estimates can lead to instability, bias,
and excessive variability due to large inverse weights, especially when
treatment overlap is limited. In this work, we propose a post-hoc calibration
algorithm for inverse propensity weights that generates well-calibrated,
stabilized weights from user-supplied, cross-fitted propensity score estimates.
Our approach employs a variant of isotonic regression with a loss function
specifically tailored to the inverse propensity weights. Through theoretical
analysis and empirical studies, we demonstrate that isotonic calibration
improves the performance of doubly robust estimators of the average treatment
effect.},
 author = {Lars van der Laan and Ziming Lin and Marco Carone and Alex Luedtke},
 comment = {Accepted to CLeaR conference (2025). Companion paper: Automatic
  doubly robust inference for linear functionals via calibrated debiased
  machine learning, arXiv:2411.02771},
 doi = {},
 eprint = {2411.06342v3},
 journal = {arXiv preprint},
 title = {Stabilized Inverse Probability Weighting via Isotonic Calibration},
 url = {http://arxiv.org/abs/2411.06342v3},
 year = {2024}
}

@article{2411.07006v1,
 abstract = {Lifting uses a representative of indistinguishable individuals to exploit
symmetries in probabilistic relational models, denoted as parametric factor
graphs, to speed up inference while maintaining exact answers. In this paper,
we show how lifting can be applied to causal inference in partially directed
graphs, i.e., graphs that contain both directed and undirected edges to
represent causal relationships between random variables. We present partially
directed parametric causal factor graphs (PPCFGs) as a generalisation of
previously introduced parametric causal factor graphs, which require a fully
directed graph. We further show how causal inference can be performed on a
lifted level in PPCFGs, thereby extending the applicability of lifted causal
inference to a broader range of models requiring less prior knowledge about
causal relationships.},
 author = {Malte Luttermann and Tanya Braun and Ralf Möller and Marcel Gehrke},
 comment = {Accepted to the Proceedings of the 16th International Conference on
  Scalable Uncertainty Management (SUM 2024)},
 doi = {},
 eprint = {2411.07006v1},
 journal = {arXiv preprint},
 title = {Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs},
 url = {http://arxiv.org/abs/2411.07006v1},
 year = {2024}
}

@article{2411.07087v4,
 abstract = {In many practical applications, decision-making processes must balance the
costs of acquiring information with the benefits it provides. Traditional
control systems often assume full observability, an unrealistic assumption when
observations are expensive. We tackle the challenge of simultaneously learning
observation and control strategies in such cost-sensitive environments by
introducing the Observation-Constrained Markov Decision Process (OCMDP), where
the policy influences the observability of the true state. To manage the
complexity arising from the combined observation and control actions, we
develop an iterative, model-free deep reinforcement learning algorithm that
separates the sensing and control components of the policy. This decomposition
enables efficient learning in the expanded action space by focusing on when and
what to observe, as well as determining optimal control actions, without
requiring knowledge of the environment's dynamics. We validate our approach on
a simulated diagnostic task and a realistic healthcare environment using
HeartPole. Given both scenarios, the experimental results demonstrate that our
model achieves a substantial reduction in observation costs on average,
significantly outperforming baseline methods by a notable margin in efficiency.},
 author = {Taiyi Wang and Jianheng Liu and Bryan Lee and Zhihao Wu and Yu Wu},
 comment = {Full paper, 14 Pages},
 doi = {},
 eprint = {2411.07087v4},
 journal = {arXiv preprint},
 title = {OCMDP: Observation-Constrained Markov Decision Process},
 url = {http://arxiv.org/abs/2411.07087v4},
 year = {2024}
}

@article{2411.07372v2,
 abstract = {Sepsis is a life-threatening condition defined by end-organ dysfunction due
to a dysregulated host response to infection. Although the Surviving Sepsis
Campaign has launched and has been releasing sepsis treatment guidelines to
unify and normalize the care for sepsis patients, it has been reported in
numerous studies that disparities in care exist across the trajectory of
patient stay in the emergency department and intensive care unit. Here, we
apply a number of reinforcement learning techniques including behavioral
cloning, imitation learning, and inverse reinforcement learning, to learn the
optimal policy in the management of septic patient subgroups using expert
demonstrations. Then we estimate the counterfactual optimal policies by
applying the model to another subset of unseen medical populations and identify
the difference in cure by comparing it to the real policy. Our data comes from
the sepsis cohort of MIMIC-IV and the clinical data warehouses of the Mass
General Brigham healthcare system. The ultimate objective of this work is to
use the optimal learned policy function to estimate the counterfactual
treatment policy and identify deviations across sub-populations of interest. We
hope this approach would help us identify any disparities in care and also
changes in cure in response to the publication of national sepsis treatment
guidelines.},
 author = {Hyewon Jeong and Siddharth Nayak and Taylor Killian and Sanjat Kanjilal},
 comment = {},
 doi = {},
 eprint = {2411.07372v2},
 journal = {arXiv preprint},
 title = {Identifying Differential Patient Care Through Inverse Intent Inference},
 url = {http://arxiv.org/abs/2411.07372v2},
 year = {2024}
}

@article{2411.08019v2,
 abstract = {In this work, we present sequence-driven structural causal models (SD-SCMs),
a framework for specifying causal models with user-defined structure and
language-model-defined mechanisms. We characterize how an SD-SCM enables
sampling from observational, interventional, and counterfactual distributions
according to the desired causal structure. We then leverage this procedure to
propose a new type of benchmark for causal inference methods, generating
individual-level counterfactual data to test treatment effect estimation. We
create an example benchmark consisting of thousands of datasets, and test a
suite of popular estimation methods for average, conditional average, and
individual treatment effect estimation. We find under this benchmark that (1)
causal methods outperform non-causal methods and that (2) even state-of-the-art
methods struggle with individualized effect estimation, suggesting this
benchmark captures some inherent difficulties in causal estimation. Apart from
generating data, this same technique can underpin the auditing of language
models for (un)desirable causal effects, such as misinformation or
discrimination. We believe SD-SCMs can serve as a useful tool in any
application that would benefit from sequential data with controllable causal
structure.},
 author = {Lucius E. J. Bynum and Kyunghyun Cho},
 comment = {},
 doi = {},
 eprint = {2411.08019v2},
 journal = {arXiv preprint},
 title = {Language Models as Causal Effect Generators},
 url = {http://arxiv.org/abs/2411.08019v2},
 year = {2024}
}

@article{2411.08392v1,
 abstract = {Reinforcement Learning (RL) is a rapidly growing area of machine learning
that finds its application in a broad range of domains, from finance and
healthcare to robotics and gaming. Compared to other machine learning
techniques, RL agents learn from their own experiences using trial and error,
and improve their performance over time. However, assessing RL models can be
challenging, which makes it difficult to interpret their behaviour. While
reward is a widely used metric to evaluate RL models, it may not always provide
an accurate measure of training performance. In some cases, the reward may seem
increasing while the model's performance is actually decreasing, leading to
misleading conclusions about the effectiveness of the training. To overcome
this limitation, we have developed RLInspect - an interactive visual analytic
tool, that takes into account different components of the RL model - state,
action, agent architecture and reward, and provides a more comprehensive view
of the RL training. By using RLInspect, users can gain insights into the
model's behaviour, identify issues during training, and potentially correct
them effectively, leading to a more robust and reliable RL system.},
 author = {Geetansh Kalra and Divye Singh and Justin Jose},
 comment = {},
 doi = {},
 eprint = {2411.08392v1},
 journal = {arXiv preprint},
 title = {RLInspect: An Interactive Visual Approach to Assess Reinforcement Learning Algorithm},
 url = {http://arxiv.org/abs/2411.08392v1},
 year = {2024}
}

@article{2411.10959v2,
 abstract = {Economists often estimate treatment effects in experiments using remotely
sensed variables (RSVs), e.g. satellite images or mobile phone activity, in
place of directly measured economic outcomes. A common practice is to use an
observational sample to train a predictor of the economic outcome from the RSV,
and then to use its predictions as the outcomes in the experiment. We show that
this method is biased whenever the RSV is post-outcome, i.e. if variation in
the economic outcome causes variation in the RSV. In program evaluation,
changes in poverty or environmental quality cause changes in satellite images,
but not vice versa. As our main result, we nonparametrically identify the
treatment effect by formalizing the intuition that underlies common practice:
the conditional distribution of the RSV given the outcome and treatment is
stable across the samples.Based on our identifying formula, we find that the
efficient representation of RSVs for causal inference requires three
predictions rather than one. Valid inference does not require any rate
conditions on RSV predictions, justifying the use of complex deep learning
algorithms with unknown statistical properties. We re-analyze the effect of an
anti-poverty program in India using satellite images.},
 author = {Ashesh Rambachan and Rahul Singh and Davide Viviano},
 comment = {},
 doi = {},
 eprint = {2411.10959v2},
 journal = {arXiv preprint},
 title = {Program Evaluation with Remotely Sensed Outcomes},
 url = {http://arxiv.org/abs/2411.10959v2},
 year = {2024}
}

@article{2411.12786v1,
 abstract = {We consider estimation of a linear functional of the treatment effect using
adaptively collected data. This task finds a variety of applications including
the off-policy evaluation (\textsf{OPE}) in contextual bandits, and estimation
of the average treatment effect (\textsf{ATE}) in causal inference. While a
certain class of augmented inverse propensity weighting (\textsf{AIPW})
estimators enjoys desirable asymptotic properties including the semi-parametric
efficiency, much less is known about their non-asymptotic theory with
adaptively collected data. To fill in the gap, we first establish generic upper
bounds on the mean-squared error of the class of AIPW estimators that crucially
depends on a sequentially weighted error between the treatment effect and its
estimates. Motivated by this, we also propose a general reduction scheme that
allows one to produce a sequence of estimates for the treatment effect via
online learning to minimize the sequentially weighted estimation error. To
illustrate this, we provide three concrete instantiations in (\romannumeral 1)
the tabular case; (\romannumeral 2) the case of linear function approximation;
and (\romannumeral 3) the case of general function approximation for the
outcome model. We then provide a local minimax lower bound to show the
instance-dependent optimality of the \textsf{AIPW} estimator using no-regret
online learning algorithms.},
 author = {Jeonghwan Lee and Cong Ma},
 comment = {37 pages. Accepted to the 38th Annual Conference on Neural
  Information Processing Systems (NeurIPS 2024), Vancouver, British Columbia,
  Canada},
 doi = {},
 eprint = {2411.12786v1},
 journal = {arXiv preprint},
 title = {Off-policy estimation with adaptively collected data: the power of online learning},
 url = {http://arxiv.org/abs/2411.12786v1},
 year = {2024}
}

@article{2411.13598v1,
 abstract = {The offline reinforcement learning (RL) problem aims to learn an optimal
policy from historical data collected by one or more behavioural policies
(experts) by interacting with an environment. However, the individual experts
may be privacy-sensitive in that the learnt policy may retain information about
their precise choices. In some domains like personalized retrieval, advertising
and healthcare, the expert choices are considered sensitive data. To provably
protect the privacy of such experts, we propose a novel consensus-based
expert-level differentially private offline RL training approach compatible
with any existing offline RL algorithm. We prove rigorous differential privacy
guarantees, while maintaining strong empirical performance. Unlike existing
work in differentially private RL, we supplement the theory with
proof-of-concept experiments on classic RL environments featuring large
continuous state spaces, demonstrating substantial improvements over a natural
baseline across multiple tasks.},
 author = {Navodita Sharma and Vishnu Vinod and Abhradeep Thakurta and Alekh Agarwal and Borja Balle and Christoph Dann and Aravindan Raghuveer},
 comment = {},
 doi = {},
 eprint = {2411.13598v1},
 journal = {arXiv preprint},
 title = {Preserving Expert-Level Privacy in Offline Reinforcement Learning},
 url = {http://arxiv.org/abs/2411.13598v1},
 year = {2024}
}

@article{2411.13821v2,
 abstract = {In this work, we discover that causal inference provides a promising approach
to capture heterophilic message-passing in Graph Neural Network (GNN). By
leveraging cause-effect analysis, we can discern heterophilic edges based on
asymmetric node dependency. The learned causal structure offers more accurate
relationships among nodes. To reduce the computational complexity, we introduce
intervention-based causal inference in graph learning. We first simplify causal
analysis on graphs by formulating it as a structural learning model and define
the optimization problem within the Bayesian scheme. We then present an
analysis of decomposing the optimization target into a consistency penalty and
a structure modification based on cause-effect relations. We then estimate this
target by conditional entropy and present insights into how conditional entropy
quantifies the heterophily. Accordingly, we propose CausalMP, a causal
message-passing discovery network for heterophilic graph learning, that
iteratively learns the explicit causal structure of input graphs. We conduct
extensive experiments in both heterophilic and homophilic graph settings. The
result demonstrates that the our model achieves superior link prediction
performance. Training on causal structure can also enhance node representation
in classification task across different base models.},
 author = {Botao Wang and Jia Li and Heng Chang and Keli Zhang and Fugee Tsung},
 comment = {},
 doi = {10.1145/3701551.3703568},
 eprint = {2411.13821v2},
 journal = {arXiv preprint},
 title = {Heterophilic Graph Neural Networks Optimization with Causal Message-passing},
 url = {http://arxiv.org/abs/2411.13821v2},
 year = {2024}
}

@article{2411.14003v2,
 abstract = {We consider the problem of predicting perturbation effects via causal models.
In many applications, it is a priori unknown which mechanisms of a system are
modified by an external perturbation, even though the features of the
perturbation are available. For example, in genomics, some properties of a drug
may be known, but not their causal effects on the regulatory pathways of cells.
We propose a generative intervention model (GIM) that learns to map these
perturbation features to distributions over atomic interventions in a
jointly-estimated causal model. Contrary to prior approaches, this enables us
to predict the distribution shifts of unseen perturbation features while
gaining insights about their mechanistic effects in the underlying
data-generating process. On synthetic data and scRNA-seq drug perturbation
data, GIMs achieve robust out-of-distribution predictions on par with
unstructured approaches, while effectively inferring the underlying
perturbation mechanisms, often better than other causal inference methods.},
 author = {Nora Schneider and Lars Lorch and Niki Kilbertus and Bernhard Schölkopf and Andreas Krause},
 comment = {},
 doi = {},
 eprint = {2411.14003v2},
 journal = {arXiv preprint},
 title = {Generative Intervention Models for Causal Perturbation Modeling},
 url = {http://arxiv.org/abs/2411.14003v2},
 year = {2024}
}

@article{2411.14341v1,
 abstract = {Estimation of the Average Treatment Effect (ATE) is a core problem in causal
inference with strong connections to Off-Policy Evaluation in Reinforcement
Learning. This paper considers the problem of adaptively selecting the
treatment allocation probability in order to improve estimation of the ATE. The
majority of prior work on adaptive ATE estimation focus on asymptotic
guarantees, and in turn overlooks important practical considerations such as
the difficulty of learning the optimal treatment allocation as well as
hyper-parameter selection. Existing non-asymptotic methods are limited by poor
empirical performance and exponential scaling of the Neyman regret with respect
to problem parameters. In order to address these gaps, we propose and analyze
the Clipped Second Moment Tracking (ClipSMT) algorithm, a variant of an
existing algorithm with strong asymptotic optimality guarantees, and provide
finite sample bounds on its Neyman regret. Our analysis shows that ClipSMT
achieves exponential improvements in Neyman regret on two fronts: improving the
dependence on $T$ from $O(\sqrt{T})$ to $O(\log T)$, as well as reducing the
exponential dependence on problem parameters to a polynomial dependence.
Finally, we conclude with simulations which show the marked improvement of
ClipSMT over existing approaches.},
 author = {Ojash Neopane and Aaditya Ramdas and Aarti Singh},
 comment = {12 pages, 2 figures. Submitted to AISTATS 2025},
 doi = {},
 eprint = {2411.14341v1},
 journal = {arXiv preprint},
 title = {Logarithmic Neyman Regret for Adaptive Estimation of the Average Treatment Effect},
 url = {http://arxiv.org/abs/2411.14341v1},
 year = {2024}
}

@article{2411.14665v1,
 abstract = {Adaptive causal representation learning from observational data is presented,
integrated with an efficient sample splitting technique within the
semiparametric estimating equation framework. The support points sample
splitting (SPSS), a subsampling method based on energy distance, is employed
for efficient double machine learning (DML) in causal inference. The support
points are selected and split as optimal representative points of the full raw
data in a random sample, in contrast to the traditional random splitting, and
providing an optimal sub-representation of the underlying data generating
distribution. They offer the best representation of a full big dataset, whereas
the unit structural information of the underlying distribution via the
traditional random data splitting is most likely not preserved. Three machine
learning estimators were adopted for causal inference, support vector machine
(SVM), deep learning (DL), and a hybrid super learner (SL) with deep learning
(SDL), using SPSS. A comparative study is conducted between the proposed SVM,
DL, and SDL representations using SPSS, and the benchmark results from
Chernozhukov et al. (2018), which employed random forest, neural network, and
regression trees with a random k-fold cross-fitting technique on the
401(k)-pension plan real data. The simulations show that DL with SPSS and the
hybrid methods of DL and SL with SPSS outperform SVM with SPSS in terms of
computational efficiency and the estimation quality, respectively.},
 author = {Lynda Aouar and Han Yu},
 comment = {},
 doi = {},
 eprint = {2411.14665v1},
 journal = {arXiv preprint},
 title = {Double Machine Learning for Adaptive Causal Representation in High-Dimensional Data},
 url = {http://arxiv.org/abs/2411.14665v1},
 year = {2024}
}

@article{2411.17542v1,
 abstract = {Instrumental Variable (IV) provides a source of treatment randomization that
is conditionally independent of the outcomes, responding to the challenges of
counterfactual and confounding biases. In finance, IV construction typically
relies on pre-designed synthetic IVs, with effectiveness measured by specific
algorithms. This classic paradigm cannot be generalized to address broader
issues that require more and specific IVs. Therefore, we propose an
expertise-driven model (ETE-FinCa) to optimize the source of expertise,
instantiate IVs by the expertise concept, and interpret the cause-effect
relationship by integrating concept with real economic data. The results show
that the feature selection based on causal knowledge graphs improves the
classification performance than others, with up to a 11.7% increase in accuracy
and a 23.0% increase in F1-score. Furthermore, the high-quality IVs we defined
can identify causal relationships between the treatment and outcome variables
in the Two-Stage Least Squares Regression model with statistical significance.},
 author = {Ying Chen and Ziwei Xu and Kotaro Inoue and Ryutaro Ichise},
 comment = {23rd International Conference on Machine Learning and Applications
  (ICMLA)},
 doi = {},
 eprint = {2411.17542v1},
 journal = {arXiv preprint},
 title = {Causal Inference in Finance: An Expertise-Driven Model for Instrument Variables Identification and Interpretation},
 url = {http://arxiv.org/abs/2411.17542v1},
 year = {2024}
}

@article{2411.19500v1,
 abstract = {Large Language Models (LLMs) have shown state-of-the-art performance in a
variety of tasks, including arithmetic and reasoning; however, to gauge the
intellectual capabilities of LLMs, causal reasoning has become a reliable proxy
for validating a general understanding of the mechanics and intricacies of the
world similar to humans. Previous works in natural language processing (NLP)
have either focused on open-ended causal reasoning via causal commonsense
reasoning (CCR) or framed a symbolic representation-based question answering
for theoretically backed-up analysis via a causal inference engine. The former
adds an advantage of real-world grounding but lacks theoretically backed-up
analysis/validation, whereas the latter is far from real-world grounding. In
this work, we bridge this gap by proposing the COLD (Causal reasOning in cLosed
Daily activities) framework, which is built upon human understanding of daily
real-world activities to reason about the causal nature of events. We show that
the proposed framework facilitates the creation of enormous causal queries (~ 9
million) and comes close to the mini-turing test, simulating causal reasoning
to evaluate the understanding of a daily real-world task. We evaluate multiple
LLMs on the created causal queries and find that causal reasoning is
challenging even for activities trivial to humans. We further explore (the
causal reasoning abilities of LLMs) using the backdoor criterion to determine
the causal strength between events.},
 author = {Abhinav Joshi and Areeb Ahmad and Ashutosh Modi},
 comment = {Paper accepted at NeurIPS 2024; Total 37 Pages},
 doi = {},
 eprint = {2411.19500v1},
 journal = {arXiv preprint},
 title = {COLD: Causal reasOning in cLosed Daily activities},
 url = {http://arxiv.org/abs/2411.19500v1},
 year = {2024}
}

@article{2412.00800v2,
 abstract = {Explainable Artificial Intelligence (XAI) addresses the growing need for
transparency and interpretability in AI systems, enabling trust and
accountability in decision-making processes. This book offers a comprehensive
guide to XAI, bridging foundational concepts with advanced methodologies. It
explores interpretability in traditional models such as Decision Trees, Linear
Regression, and Support Vector Machines, alongside the challenges of explaining
deep learning architectures like CNNs, RNNs, and Large Language Models (LLMs),
including BERT, GPT, and T5. The book presents practical techniques such as
SHAP, LIME, Grad-CAM, counterfactual explanations, and causal inference,
supported by Python code examples for real-world applications.
  Case studies illustrate XAI's role in healthcare, finance, and policymaking,
demonstrating its impact on fairness and decision support. The book also covers
evaluation metrics for explanation quality, an overview of cutting-edge XAI
tools and frameworks, and emerging research directions, such as
interpretability in federated learning and ethical AI considerations. Designed
for a broad audience, this resource equips readers with the theoretical
insights and practical skills needed to master XAI. Hands-on examples and
additional resources are available at the companion GitHub repository:
https://github.com/Echoslayer/XAI_From_Classical_Models_to_LLMs.},
 author = {Weiche Hsieh and Ziqian Bi and Chuanqi Jiang and Junyu Liu and Benji Peng and Sen Zhang and Xuanhe Pan and Jiawei Xu and Jinlang Wang and Keyu Chen and Pohsun Feng and Yizhu Wen and Xinyuan Song and Tianyang Wang and Ming Liu and Junjie Yang and Ming Li and Bowen Jing and Jintao Ren and Junhao Song and Hong-Ming Tseng and Yichao Zhang and Lawrence K. Q. Yan and Qian Niu and Silin Chen and Yunze Wang and Chia Xin Liang},
 comment = {},
 doi = {},
 eprint = {2412.00800v2},
 journal = {arXiv preprint},
 title = {A Comprehensive Guide to Explainable AI: From Classical Models to LLMs},
 url = {http://arxiv.org/abs/2412.00800v2},
 year = {2024}
}

@article{2412.01056v1,
 abstract = {Accurate diagnosis of gait impairments is often hindered by subjective or
costly assessment methods, with current solutions requiring either expensive
multi-camera equipment or relying on subjective clinical observation. There is
a critical need for accessible, objective tools that can aid in gait assessment
while preserving patient privacy. In this work, we present a mobile
phone-based, privacy-preserving artificial intelligence (AI) system for
classifying gait impairments and introduce a novel dataset of 743 videos
capturing seven distinct gait patterns. The dataset consists of frontal and
sagittal views of trained subjects simulating normal gait and six types of
pathological gait (circumduction, Trendelenburg, antalgic, crouch,
Parkinsonian, and vaulting), recorded using standard mobile phone cameras. Our
system achieved 86.5% accuracy using combined frontal and sagittal views, with
sagittal views generally outperforming frontal views except for specific gait
patterns like Circumduction. Model feature importance analysis revealed that
frequency-domain features and entropy measures were critical for classifcation
performance, specifically lower limb keypoints proved most important for
classification, aligning with clinical understanding of gait assessment. These
findings demonstrate that mobile phone-based systems can effectively classify
diverse gait patterns while preserving privacy through on-device processing.
The high accuracy achieved using simulated gait data suggests their potential
for rapid prototyping of gait analysis systems, though clinical validation with
patient data remains necessary. This work represents a significant step toward
accessible, objective gait assessment tools for clinical, community, and
tele-rehabilitation settings},
 author = {Lauhitya Reddy and Ketan Anand and Shoibolina Kaushik and Corey Rodrigo and J. Lucas McKay and Trisha M. Kesar and Hyeokhyen Kwon},
 comment = {21 pages, 4 Figures, 4 Tables, Submitted to PLOS Digital Health},
 doi = {},
 eprint = {2412.01056v1},
 journal = {arXiv preprint},
 title = {Classifying Simulated Gait Impairments using Privacy-preserving Explainable Artificial Intelligence and Mobile Phone Videos},
 url = {http://arxiv.org/abs/2412.01056v1},
 year = {2024}
}

@article{2412.01344v3,
 abstract = {This paper studies the performative policy learning problem, where agents
adjust their features in response to a released policy to improve their
potential outcomes, inducing an endogenous distribution shift. There has been
growing interest in training machine learning models in strategic environments,
including strategic classification and performative prediction. However,
existing approaches often rely on restrictive parametric assumptions:
micro-level utility models in strategic classification and macro-level data
distribution maps in performative prediction, severely limiting scalability and
generalizability. We approach this problem as a complex causal inference task,
relaxing parametric assumptions on both micro-level agent behavior and
macro-level data distribution. Leveraging bounded rationality, we uncover a
practical low-dimensional structure in distribution shifts and construct an
effective mediator in the causal path from the deployed model to the shifted
data. We then propose a gradient-based policy optimization algorithm with a
differentiable classifier as a substitute for the high-dimensional distribution
map. Our algorithm efficiently utilizes batch feedback and limited manipulation
patterns. Our approach achieves high sample efficiency compared to methods
reliant on bandit feedback or zero-order optimization. We also provide
theoretical guarantees for algorithmic convergence. Extensive and challenging
experiments on high-dimensional settings demonstrate our method's practical
efficacy.},
 author = {Qianyi Chen and Ying Chen and Bo Li},
 comment = {},
 doi = {},
 eprint = {2412.01344v3},
 journal = {arXiv preprint},
 title = {Practical Performative Policy Learning with Strategic Agents},
 url = {http://arxiv.org/abs/2412.01344v3},
 year = {2024}
}

@article{2412.02155v2,
 abstract = {Large-scale human mobility exhibits spatial and temporal patterns that can
assist policymakers in decision making. Although traditional prediction models
attempt to capture these patterns, they often interfered by non-periodic public
events, such as disasters and occasional celebrations. Since regular human
mobility patterns are heavily affected by these events, estimating their causal
effects is critical to accurate mobility predictions. Although news articles
provide unique perspectives on these events in an unstructured format,
processing is a challenge. In this study, we propose a causality-augmented
prediction model, called CausalMob, to analyze the causal effects of public
events. We first utilize large language models (LLMs) to extract human
intentions from news articles and transform them into features that act as
causal treatments. Next, the model learns representations of spatio-temporal
regional covariates from multiple data sources to serve as confounders for
causal inference. Finally, we present a causal effect estimation framework to
ensure event features remain independent of confounders during prediction.
Based on large-scale real-world data, the experimental results show that the
proposed model excels in human mobility prediction, outperforming
state-of-the-art models.},
 author = {Xiaojie Yang and Hangli Ge and Jiawei Wang and Zipei Fan and Renhe Jiang and Ryosuke Shibasaki and Noboru Koshizuka},
 comment = {Accepted by KDD 2025},
 doi = {10.1145/3690624.3709231},
 eprint = {2412.02155v2},
 journal = {arXiv preprint},
 title = {CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events},
 url = {http://arxiv.org/abs/2412.02155v2},
 year = {2024}
}

@article{2412.02439v1,
 abstract = {Understanding how galaxies form and evolve is at the heart of modern
astronomy. With the advent of large-scale surveys and simulations, remarkable
progress has been made in the last few decades. Despite this, the physical
processes behind the phenomena, and particularly their importance, remain far
from known, as correlations have primarily been established rather than the
underlying causality. We address this challenge by applying the causal
inference framework. Specifically, we tackle the fundamental open question of
whether galaxy formation and evolution depends more on nature (i.e., internal
processes) or nurture (i.e., external processes), by estimating the causal
effect of environment on star-formation rate in the IllustrisTNG simulations.
To do so, we develop a comprehensive causal model and employ cutting-edge
techniques from epidemiology to overcome the long-standing problem of
disentangling nature and nurture. We find that the causal effect is negative
and substantial, with environment suppressing the SFR by a maximal factor of
$\sim100$. While the overall effect at $z=0$ is negative, in the early
universe, environment is discovered to have a positive impact, boosting star
formation by a factor of $\sim10$ at $z\sim1$ and by even greater amounts at
higher redshifts. Furthermore, we show that: (i) nature also plays an important
role, as ignoring it underestimates the causal effect in intermediate-density
environments by a factor of $\sim2$, (ii) controlling for the stellar mass at a
snapshot in time, as is common in the literature, is not only insufficient to
disentangle nature and nurture but actually has an adverse effect, though (iii)
stellar mass is an adequate proxy of the effects of nature. Finally, this work
may prove a useful blueprint for extracting causal insights in other fields
that deal with dynamical systems with closed feedback loops, such as the
Earth's climate.},
 author = {Sunil Mucesh and William G. Hartley and Ciarán M. Gilligan-Lee and Ofer Lahav},
 comment = {16 pages, 4 figures},
 doi = {},
 eprint = {2412.02439v1},
 journal = {arXiv preprint},
 title = {Nature versus nurture in galaxy formation: the effect of environment on star formation with causal machine learning},
 url = {http://arxiv.org/abs/2412.02439v1},
 year = {2024}
}

@article{2412.03009v1,
 abstract = {Machine learning systems are increasingly being used in critical decision
making such as healthcare, finance, and criminal justice. Concerns around their
fairness have resulted in several bias mitigation techniques that emphasize the
need for high-quality data to ensure fairer decisions. However, the role of
earlier stages of machine learning pipelines in mitigating model bias has not
been explored well. In this paper, we focus on the task of acquiring additional
labeled data points for training the downstream machine learning model to
rapidly improve its fairness. Since not all data points in a data pool are
equally beneficial to the task of fairness, we generate an ordering in which
data points should be acquired. We present DataSift, a data acquisition
framework based on the idea of data valuation that relies on partitioning and
multi-armed bandits to determine the most valuable data points to acquire. Over
several iterations, DataSift selects a partition and randomly samples a batch
of data points from the selected partition, evaluates the benefit of acquiring
the batch on model fairness, and updates the utility of partitions depending on
the benefit. To further improve the effectiveness and efficiency of evaluating
batches, we leverage influence functions that estimate the effect of acquiring
a batch without retraining the model. We empirically evaluate DataSift on
several real-world and synthetic datasets and show that the fairness of a
machine learning model can be significantly improved even while acquiring a few
data points.},
 author = {Jahid Hasan and Romila Pradhan},
 comment = {19 pages, 9 figures},
 doi = {},
 eprint = {2412.03009v1},
 journal = {arXiv preprint},
 title = {Data Acquisition for Improving Model Fairness using Reinforcement Learning},
 url = {http://arxiv.org/abs/2412.03009v1},
 year = {2024}
}

@article{2412.03727v3,
 abstract = {Network interference has attracted significant attention in the field of
causal inference, encapsulating various sociological behaviors where the
treatment assigned to one individual within a network may affect the outcomes
of others, such as their neighbors. A key challenge in this setting is that
standard causal inference methods often assume independent treatment effects
among individuals, which may not hold in networked environments. To estimate
interference-aware causal effects, a traditional approach is to inherit the
independent settings, where practitioners randomly assign experimental
participants into different groups and compare their outcomes. While effective
in offline settings, this strategy becomes problematic in sequential
experiments, where suboptimal decision persists, leading to substantial regret.
To address this issue, we introduce a unified interference-aware framework for
online experimental design. Compared to existing studies, we extend the
definition of arm space by utilizing the statistical concept of exposure
mapping, which allows for a more flexible and context-aware representation of
treatment effects in networked settings. Crucially, we establish a
Pareto-optimal trade-off between estimation accuracy and regret under the
network concerning both time period and arm space, which remains superior to
baseline models even without network interference. Furthermore, we propose an
algorithmic implementation and discuss its generalization across different
learning settings and network topology.},
 author = {Zhiheng Zhang and Zichen Wang},
 comment = {36 pages},
 doi = {},
 eprint = {2412.03727v3},
 journal = {arXiv preprint},
 title = {Online Experimental Design With Estimation-Regret Trade-off Under Network Interference},
 url = {http://arxiv.org/abs/2412.03727v3},
 year = {2024}
}

@article{2412.03913v1,
 abstract = {Estimating individual treatment effects (ITE) from observational data is a
critical task across various domains. However, many existing works on ITE
estimation overlook the influence of hidden confounders, which remain
unobserved at the individual unit level. To address this limitation,
researchers have utilized graph neural networks to aggregate neighbors'
features to capture the hidden confounders and mitigate confounding bias by
minimizing the discrepancy of confounder representations between the treated
and control groups. Despite the success of these approaches, practical
scenarios often treat all features as confounders and involve substantial
differences in feature distributions between the treated and control groups.
Confusing the adjustment and confounder and enforcing strict balance on the
confounder representations could potentially undermine the effectiveness of
outcome prediction. To mitigate this issue, we propose a novel framework called
the \textit{Graph Disentangle Causal model} (GDC) to conduct ITE estimation in
the network setting. GDC utilizes a causal disentangle module to separate unit
features into adjustment and confounder representations. Then we design a graph
aggregation module consisting of three distinct graph aggregators to obtain
adjustment, confounder, and counterfactual confounder representations. Finally,
a causal constraint module is employed to enforce the disentangled
representations as true causal factors. The effectiveness of our proposed
method is demonstrated by conducting comprehensive experiments on two networked
datasets.},
 author = {Binbin Hu and Zhicheng An and Zhengwei Wu and Ke Tu and Ziqi Liu and Zhiqiang Zhang and Jun Zhou and Yufei Feng and Jiawei Chen},
 comment = {Accepted by WSDM 2025},
 doi = {},
 eprint = {2412.03913v1},
 journal = {arXiv preprint},
 title = {Graph Disentangle Causal Model: Enhancing Causal Inference in Networked Observational Data},
 url = {http://arxiv.org/abs/2412.03913v1},
 year = {2024}
}

@article{2412.04285v1,
 abstract = {Causal reasoning is often challenging with spatial data, particularly when
handling high-dimensional inputs. To address this, we propose a neural network
(NN) based framework integrated with an approximate Gaussian process to manage
spatial interference and unobserved confounding. Additionally, we adopt a
generalized propensity-score-based approach to address partially observed
outcomes when estimating causal effects with continuous treatments. We evaluate
our framework using synthetic, semi-synthetic, and real-world data inferred
from satellite imagery. Our results demonstrate that NN-based models
significantly outperform linear spatial regression models in estimating causal
effects. Furthermore, in real-world case studies, NN-based models offer more
reasonable predictions of causal effects, facilitating decision-making in
relevant applications.},
 author = {Ziyang Jiang and Zach Calhoun and Yiling Liu and Lei Duan and David Carlson},
 comment = {16 pages, 4 figures, 5 tables},
 doi = {},
 eprint = {2412.04285v1},
 journal = {arXiv preprint},
 title = {Deep Causal Inference for Point-referenced Spatial Data with Continuous Treatments},
 url = {http://arxiv.org/abs/2412.04285v1},
 year = {2024}
}

@article{2412.04641v1,
 abstract = {Latent confounders are a fundamental challenge for inferring causal effects
from observational data. The instrumental variable (IV) approach is a practical
way to address this challenge. Existing IV based estimators need a known IV or
other strong assumptions, such as the existence of two or more IVs in the
system, which limits the application of the IV approach. In this paper, we
consider a relaxed requirement, which assumes there is an IV proxy in the
system without knowing which variable is the proxy. We propose a Variational
AutoEncoder (VAE) based disentangled representation learning method to learn an
IV representation from a dataset with latent confounders and then utilise the
IV representation to obtain an unbiased estimation of the causal effect from
the data. Extensive experiments on synthetic and real-world data have
demonstrated that the proposed algorithm outperforms the existing IV based
estimators and VAE-based estimators.},
 author = {Debo Cheng and Jiuyong Li and Lin Liu and Ziqi Xu and Weijia Zhang and Jixue Liu and Thuc Duy Le},
 comment = {14 pages, 13 figures and 5 tables. Accepted by TNNLS},
 doi = {},
 eprint = {2412.04641v1},
 journal = {arXiv preprint},
 title = {Disentangled Representation Learning for Causal Inference with Instruments},
 url = {http://arxiv.org/abs/2412.04641v1},
 year = {2024}
}

@article{2412.05481v2,
 abstract = {Circuits based on sum-product structure have become a ubiquitous
representation to compactly encode knowledge, from Boolean functions to
probability distributions. By imposing constraints on the structure of such
circuits, certain inference queries become tractable, such as model counting
and most probable configuration. Recent works have explored analyzing
probabilistic and causal inference queries as compositions of basic operators
to derive tractability conditions. In this paper, we take an algebraic
perspective for compositional inference, and show that a large class of queries
- including marginal MAP, probabilistic answer set programming inference, and
causal backdoor adjustment - correspond to a combination of basic operators
over semirings: aggregation, product, and elementwise mapping. Using this
framework, we uncover simple and general sufficient conditions for tractable
composition of these operators, in terms of circuit properties (e.g., marginal
determinism, compatibility) and conditions on the elementwise mappings.
Applying our analysis, we derive novel tractability conditions for many such
compositional queries. Our results unify tractability conditions for existing
problems on circuits, while providing a blueprint for analysing novel
compositional inference queries.},
 author = {Benjie Wang and Denis Deratani Mauá and Guy Van den Broeck and YooJung Choi},
 comment = {NeurIPS 2024},
 doi = {},
 eprint = {2412.05481v2},
 journal = {arXiv preprint},
 title = {A Compositional Atlas for Algebraic Circuits},
 url = {http://arxiv.org/abs/2412.05481v2},
 year = {2024}
}

@article{2412.09843v1,
 abstract = {In this study, we address causal inference when only observational data and a
valid causal ordering from the causal graph are available. We introduce a set
of flow models that can recover component-wise, invertible transformation of
exogenous variables. Our flow-based methods offer flexible model design while
maintaining causal consistency regardless of the number of discretization
steps. We propose design improvements that enable simultaneous learning of all
causal mechanisms and reduce abduction and prediction complexity to linear O(n)
relative to the number of layers, independent of the number of causal
variables. Empirically, we demonstrate that our method outperforms previous
state-of-the-art approaches and delivers consistent performance across a wide
range of structural causal models in answering observational, interventional,
and counterfactual questions. Additionally, our method achieves a significant
reduction in computational time compared to existing diffusion-based
techniques, making it practical for large structural causal models.},
 author = {Minh Khoa Le and Kien Do and Truyen Tran},
 comment = {Accepted at AAAI 2025},
 doi = {},
 eprint = {2412.09843v1},
 journal = {arXiv preprint},
 title = {Learning Structural Causal Models from Ordering: Identifiable Flow Models},
 url = {http://arxiv.org/abs/2412.09843v1},
 year = {2024}
}

@article{2412.10119v1,
 abstract = {Prediction models frequently face the challenge of concept drift, in which
the underlying data distribution changes over time, weakening performance.
Examples can include models which predict loan default, or those used in
healthcare contexts. Typical management strategies involve regular model
updates or updates triggered by concept drift detection. However, these simple
policies do not necessarily balance the cost of model updating with improved
classifier performance. We present AMUSE (Adaptive Model Updating using a
Simulated Environment), a novel method leveraging reinforcement learning
trained within a simulated data generating environment, to determine update
timings for classifiers. The optimal updating policy depends on the current
data generating process and ongoing drift process. Our key idea is that we can
train an arbitrarily complex model updating policy by creating a training
environment in which possible episodes of drift are simulated by a parametric
model, which represents expectations of possible drift patterns. As a result,
AMUSE proactively recommends updates based on estimated performance
improvements, learning a policy that balances maintaining model performance
with minimizing update costs. Empirical results confirm the effectiveness of
AMUSE in simulated data.},
 author = {Louis Chislett and Catalina A. Vallejos and Timothy I. Cannings and James Liley},
 comment = {12 pages, 2 tables. Submitted to AIStats 2025 (under review)},
 doi = {},
 eprint = {2412.10119v1},
 journal = {arXiv preprint},
 title = {AMUSE: Adaptive Model Updating using a Simulated Environment},
 url = {http://arxiv.org/abs/2412.10119v1},
 year = {2024}
}

@article{2412.10509v1,
 abstract = {Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this
research, we investigate whether large language models (LLMs) develop causal
illusions, both in real-world and controlled laboratory contexts of causal
learning and inference. To this end, we built a dataset of over 2K samples
including purely correlational cases, situations with null contingency, and
cases where temporal information excludes the possibility of causality by
placing the potential effect before the cause. We then prompted the models to
make statements or answer causal questions to evaluate their tendencies to
infer causation erroneously in these structured settings. Our findings show a
strong presence of causal illusion bias in LLMs. Specifically, in open-ended
generation tasks involving spurious correlations, the models displayed bias at
levels comparable to, or even lower than, those observed in similar studies on
human subjects. However, when faced with null-contingency scenarios or temporal
cues that negate causal relationships, where it was required to respond on a
0-100 scale, the models exhibited significantly higher bias. These findings
suggest that the models have not uniformly, consistently, or reliably
internalized the normative principles essential for accurate causal learning.},
 author = {Maria Victoria Carro and Francisca Gauna Selasco and Denise Alejandra Mester and Margarita Gonzales and Mario A. Leiva and Maria Vanina Martinez and Gerardo I. Simari},
 comment = {15 pages, 6 figures},
 doi = {},
 eprint = {2412.10509v1},
 journal = {arXiv preprint},
 title = {Do Large Language Models Show Biases in Causal Learning?},
 url = {http://arxiv.org/abs/2412.10509v1},
 year = {2024}
}

@article{2412.10683v2,
 abstract = {Parametric Bayesian modeling offers a powerful and flexible toolbox for
scientific data analysis. Yet the model, however detailed, may still be wrong,
and this can make inferences untrustworthy. In this paper we study
nonparametrically perturbed parametric (NPP) Bayesian models, in which a
parametric Bayesian model is relaxed via a distortion of its likelihood. We
analyze the properties of NPP models when the target of inference is the true
data distribution or some functional of it, such as in causal inference. We
show that NPP models can offer the robustness of nonparametric models while
retaining the data efficiency of parametric models, achieving fast convergence
when the parametric model is close to true. To efficiently analyze data with an
NPP model, we develop a generalized Bayes procedure to approximate its
posterior. We demonstrate our method by estimating causal effects of gene
expression from single cell RNA sequencing data. NPP modeling offers an
efficient approach to robust Bayesian inference and can be used to robustify
any parametric Bayesian model.},
 author = {Bohan Wu and Eli N. Weinstein and Sohrab Salehi and Yixin Wang and David M. Blei},
 comment = {},
 doi = {},
 eprint = {2412.10683v2},
 journal = {arXiv preprint},
 title = {Adaptive Nonparametric Perturbations of Parametric Bayesian Models},
 url = {http://arxiv.org/abs/2412.10683v2},
 year = {2024}
}

@article{2412.11104v1,
 abstract = {In causal inference, randomized experiment is a de facto method to overcome
various theoretical issues in observational study. However, the experimental
design requires expensive costs, so an efficient experimental design is
necessary. We propose ABC3, a Bayesian active learning policy for causal
inference. We show a policy minimizing an estimation error on conditional
average treatment effect is equivalent to minimizing an integrated posterior
variance, similar to Cohn criteria \citep{cohn1994active}. We theoretically
prove ABC3 also minimizes an imbalance between the treatment and control groups
and the type 1 error probability. Imbalance-minimizing characteristic is
especially notable as several works have emphasized the importance of achieving
balance. Through extensive experiments on real-world data sets, ABC3 achieves
the highest efficiency, while empirically showing the theoretical results hold.},
 author = {Taehun Cha and Donghun Lee},
 comment = {AAAI 2025},
 doi = {},
 eprint = {2412.11104v1},
 journal = {arXiv preprint},
 title = {ABC3: Active Bayesian Causal Inference with Cohn Criteria in Randomized Experiments},
 url = {http://arxiv.org/abs/2412.11104v1},
 year = {2024}
}

@article{2412.11790v1,
 abstract = {Treatment effect heterogeneity plays an important role in many areas of
causal inference and within recent years, estimation of the conditional average
treatment effect (CATE) has received much attention in the statistical
community. While accurate estimation of the CATE-function through flexible
machine learning procedures provides a tool for prediction of the individual
treatment effect, it does not provide further insight into the driving features
of potential treatment effect heterogeneity. Recent papers have addressed this
problem by providing variable importance measures for treatment effect
heterogeneity. Most of the suggestions have been developed for continuous or
binary outcome, while little attention has been given to censored time-to-event
outcome. In this paper, we extend the treatment effect variable importance
measure (TE-VIM) proposed in Hines et al. (2022) to the survival setting with
censored outcome. We derive an estimator for the TE-VIM for two different CATE
functions based on the survival function and RMST, respectively. Along with the
TE-VIM, we propose a new measure of treatment effect heterogeneity based on the
best partially linear projection of the CATE and suggest accompanying
estimators for that projection. All estimators are based on semiparametric
efficiency theory, and we give conditions under which they are asymptotically
linear. The finite sample performance of the derived estimators are
investigated in a simulation study. Finally, the estimators are applied and
contrasted in two real data examples.},
 author = {Simon Christoffer Ziersen and Torben Martinussen},
 comment = {},
 doi = {},
 eprint = {2412.11790v1},
 journal = {arXiv preprint},
 title = {Variable importance measures for heterogeneous treatment effects with survival outcome},
 url = {http://arxiv.org/abs/2412.11790v1},
 year = {2024}
}

@article{2412.12365v2,
 abstract = {Learning the Individual Treatment Effect (ITE) is essential for personalized
decision-making, yet causal inference has traditionally focused on aggregated
treatment effects. While integrating conformal prediction with causal inference
can provide valid uncertainty quantification for ITEs, the resulting prediction
intervals are often excessively wide, limiting their practical utility. To
address this limitation, we introduce \underline{S}urrogate-assisted
\underline{C}onformal \underline{I}nference for \underline{E}fficient
I\underline{N}dividual \underline{C}ausal \underline{E}ffects (SCIENCE), a
framework designed to construct more efficient prediction intervals for ITEs.
SCIENCE accommodates the covariate shifts between source data and target data
and applies to various data configurations, including semi-supervised and
surrogate-assisted semi-supervised learning. Leveraging semi-parametric
efficiency theory, SCIENCE produces rate double-robust prediction intervals
under mild rate convergence conditions, permitting the use of flexible
non-parametric models to estimate nuisance functions. We quantify efficiency
gains by comparing semi-parametric efficiency bounds with and without the
surrogates. Simulation studies demonstrate that our surrogate-assisted
intervals offer substantial efficiency improvements over existing methods while
maintaining valid group-conditional coverage. Applied to the phase 3 Moderna
COVE COVID-19 vaccine trial, SCIENCE illustrates how multiple surrogate markers
can be leveraged to generate more efficient prediction intervals.},
 author = {Chenyin Gao and Peter B. Gilbert and Larry Han},
 comment = {},
 doi = {},
 eprint = {2412.12365v2},
 journal = {arXiv preprint},
 title = {On the Role of Surrogates in Conformal Inference of Individual Causal Effects},
 url = {http://arxiv.org/abs/2412.12365v2},
 year = {2024}
}

@article{2412.12401v1,
 abstract = {Causal inconsistency arises when the underlying causal graphs captured by
generative models like \textit{Normalizing Flows} (NFs) are inconsistent with
those specified in causal models like \textit{Struct Causal Models} (SCMs).
This inconsistency can cause unwanted issues including the unfairness problem.
Prior works to achieve causal consistency inevitably compromise the
expressiveness of their models by disallowing hidden layers. In this work, we
introduce a new approach: \textbf{C}ausally \textbf{C}onsistent
\textbf{N}ormalizing \textbf{F}low (CCNF). To the best of our knowledge, CCNF
is the first causally consistent generative model that can approximate any
distribution with multiple layers. CCNF relies on two novel constructs: a
sequential representation of SCMs and partial causal transformations. These
constructs allow CCNF to inherently maintain causal consistency without
sacrificing expressiveness. CCNF can handle all forms of causal inference
tasks, including interventions and counterfactuals. Through experiments, we
show that CCNF outperforms current approaches in causal inference. We also
empirically validate the practical utility of CCNF by applying it to real-world
datasets and show how CCNF addresses challenges like unfairness effectively.},
 author = {Qingyang Zhou and Kangjie Lu and Meng Xu},
 comment = {extended version of "Causally Consistent Normalizing Flow" accepted
  by AAAI25},
 doi = {},
 eprint = {2412.12401v1},
 journal = {arXiv preprint},
 title = {Causally Consistent Normalizing Flow},
 url = {http://arxiv.org/abs/2412.12401v1},
 year = {2024}
}

@article{2412.12597v1,
 abstract = {Mechanical Ventilation (MV) is a critical life-support intervention in
intensive care units (ICUs). However, optimal ventilator settings are
challenging to determine because of the complexity of balancing
patient-specific physiological needs with the risks of adverse outcomes that
impact morbidity, mortality, and healthcare costs. This study introduces
ConformalDQN, a novel distribution-free conformal deep Q-learning approach for
optimizing mechanical ventilation in intensive care units. By integrating
conformal prediction with deep reinforcement learning, our method provides
reliable uncertainty quantification, addressing the challenges of Q-value
overestimation and out-of-distribution actions in offline settings. We trained
and evaluated our model using ICU patient records from the MIMIC-IV database.
ConformalDQN extends the Double DQN architecture with a conformal predictor and
employs a composite loss function that balances Q-learning with well-calibrated
probability estimation. This enables uncertainty-aware action selection,
allowing the model to avoid potentially harmful actions in unfamiliar states
and handle distribution shifts by being more conservative in
out-of-distribution scenarios. Evaluation against baseline models, including
physician policies, policy constraint methods, and behavior cloning,
demonstrates that ConformalDQN consistently makes recommendations within
clinically safe and relevant ranges, outperforming other methods by increasing
the 90-day survival rate. Notably, our approach provides an interpretable
measure of confidence in its decisions, which is crucial for clinical adoption
and potential human-in-the-loop implementations.},
 author = {Niloufar Eghbali and Tuka Alhanai and Mohammad M. Ghassemi},
 comment = {},
 doi = {},
 eprint = {2412.12597v1},
 journal = {arXiv preprint},
 title = {Distribution-Free Uncertainty Quantification in Mechanical Ventilation Treatment: A Conformal Deep Q-Learning Framework},
 url = {http://arxiv.org/abs/2412.12597v1},
 year = {2024}
}

@article{2412.13574v2,
 abstract = {In real-world driving scenarios, multiple states occur simultaneously due to
individual differences and environmental factors, complicating the analysis and
estimation of driver states. Previous studies, limited by experimental design
and analytical methods, may not be able to disentangle the relationships among
multiple driver states and environmental factors. This paper introduces the
Double Machine Learning (DML) analysis method to the field of driver state
analysis to tackle this challenge. To train and test the DML model, a driving
simulator experiment with 42 participants was conducted. All participants drove
SAE level-3 vehicles and conducted three types of cognitive tasks in a 3-hour
driving experiment. Drivers' subjective cognitive load and drowsiness levels
were collected throughout the experiment. Then, we isolated individual and
environmental factors affecting driver state variations and the factors
affecting drivers' physiological and eye-tracking metrics when they are under
specific states. The results show that our approach successfully decoupled and
inferred the complex causal relationships between multiple types of drowsiness
and cognitive load. Additionally, we identified key physiological and
eye-tracking indicators in the presence of multiple driver states and under the
influence of a single state, excluding the influence of other driver states,
environmental factors, and individual characteristics. Our causal inference
analytical framework can offer new insights for subsequent analysis of drivers'
states. Further, the updated causal relation graph based on the DML analysis
can provide theoretical bases for driver state monitoring based on
physiological and eye-tracking measures.},
 author = {Jiyao Wang and Ange Wang and Song Yan and Dengbo He and Kaishun Wu},
 comment = {},
 doi = {},
 eprint = {2412.13574v2},
 journal = {arXiv preprint},
 title = {Revisiting Interactions of Multiple Driver States in Heterogenous Population and Cognitive Tasks},
 url = {http://arxiv.org/abs/2412.13574v2},
 year = {2024}
}

@article{2412.14039v1,
 abstract = {Large-scale crises, including wars and pandemics, have repeatedly shaped
human history, and their simultaneous occurrence presents profound challenges
to societies. Understanding the dynamics of epidemic spread during warfare is
essential for developing effective containment strategies in complex conflict
zones. While research has explored epidemic models in various settings, the
impact of warfare on epidemic dynamics remains underexplored. In this study, we
proposed a novel mathematical model that integrates the epidemiological SIR
(susceptible-infected-recovered) model with the war dynamics Lanchester model
to explore the dual influence of war and pandemic on a population's mortality.
Moreover, we consider a dual-use military and civil healthcare system that aims
to reduce the overall mortality rate which can use different administration
policies. Using an agent-based simulation to generate in silico data, we
trained a deep reinforcement learning model for healthcare administration
policy and conducted an intensive investigation on its performance. Our results
show that a pandemic during war conduces chaotic dynamics where the healthcare
system should either prioritize war-injured soldiers or pandemic-infected
civilians based on the immediate amount of mortality from each option, ignoring
long-term objectives. Our findings highlight the importance of integrating
conflict-related factors into epidemic modeling to enhance preparedness and
response strategies in conflict-affected areas.},
 author = {Adi Shuchami and Teddy Lazebnik},
 comment = {},
 doi = {10.1017/dmp.2025.10062},
 eprint = {2412.14039v1},
 journal = {arXiv preprint},
 title = {Spatio-Temporal SIR Model of Pandemic Spread During Warfare with Optimal Dual-use Healthcare System Administration using Deep Reinforcement Learning},
 url = {http://arxiv.org/abs/2412.14039v1},
 year = {2024}
}

@article{2412.15957v1,
 abstract = {The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.},
 author = {Ruize Shi and Hong Huang and Wei Zhou and Kehan Yin and Kai Zhao and Yun Zhao},
 comment = {},
 doi = {},
 eprint = {2412.15957v1},
 journal = {arXiv preprint},
 title = {From General to Specific: Tailoring Large Language Models for Personalized Healthcare},
 url = {http://arxiv.org/abs/2412.15957v1},
 year = {2024}
}

@article{2412.16641v5,
 abstract = {Systems thinking provides us with a way to model the algorithmic fairness
problem by allowing us to encode prior knowledge and assumptions about where we
believe bias might exist in the data generating process. We can then encode
these beliefs as a series of causal graphs, enabling us to link AI/ML systems
to politics and the law. This allows us to combine techniques from machine
learning, causal inference, and system dynamics in order to capture different
emergent aspects of the fairness problem. We can use systems thinking to help
policymakers on both sides of the political aisle to understand the complex
trade-offs that exist from different types of fairness policies, providing a
sociotechnical foundation for designing AI policy that is aligned to their
political agendas and with society's shared democratic values.},
 author = {Chris Lam},
 comment = {},
 doi = {},
 eprint = {2412.16641v5},
 journal = {arXiv preprint},
 title = {A Systems Thinking Approach to Algorithmic Fairness},
 url = {http://arxiv.org/abs/2412.16641v5},
 year = {2024}
}

@article{2412.16691v1,
 abstract = {This research presents a three-step causal inference framework that
integrates correlation analysis, machine learning-based causality discovery,
and LLM-driven interpretations to identify socioeconomic factors influencing
carbon emissions and contributing to climate change. The approach begins with
identifying correlations, progresses to causal analysis, and enhances decision
making through LLM-generated inquiries about the context of climate change. The
proposed framework offers adaptable solutions that support data-driven
policy-making and strategic decision-making in climate-related contexts,
uncovering causal relationships within the climate change domain.},
 author = {Shan Shan},
 comment = {},
 doi = {},
 eprint = {2412.16691v1},
 journal = {arXiv preprint},
 title = {From Correlation to Causation: Understanding Climate Change through Causal Analysis and LLM Interpretations},
 url = {http://arxiv.org/abs/2412.16691v1},
 year = {2024}
}

@article{2412.18568v1,
 abstract = {The problem of evaluating the effectiveness of a treatment or policy commonly
appears in causal inference applications under network interference. In this
paper, we suggest the new method of high-dimensional network causal inference
(HNCI) that provides both valid confidence interval on the average direct
treatment effect on the treated (ADET) and valid confidence set for the
neighborhood size for interference effect. We exploit the model setting in
Belloni et al. (2022) and allow certain type of heterogeneity in node
interference neighborhood sizes. We propose a linear regression formulation of
potential outcomes, where the regression coefficients correspond to the
underlying true interference function values of nodes and exhibit a latent
homogeneous structure. Such a formulation allows us to leverage existing
literature from linear regression and homogeneity pursuit to conduct valid
statistical inferences with theoretical guarantees. The resulting confidence
intervals for the ADET are formally justified through asymptotic normalities
with estimable variances. We further provide the confidence set for the
neighborhood size with theoretical guarantees exploiting the repro samples
approach. The practical utilities of the newly suggested methods are
demonstrated through simulation and real data examples.},
 author = {Wenqin Du and Rundong Ding and Yingying Fan and Jinchi Lv},
 comment = {89 pages, 7 figures},
 doi = {},
 eprint = {2412.18568v1},
 journal = {arXiv preprint},
 title = {HNCI: High-Dimensional Network Causal Inference},
 url = {http://arxiv.org/abs/2412.18568v1},
 year = {2024}
}

@article{2412.18925v1,
 abstract = {The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning
to improve LLM. Yet, most research in reasoning has focused on mathematical
tasks, leaving domains like medicine underexplored. The medical domain, though
distinct from mathematics, also demands robust reasoning to provide reliable
answers, given the high standards of healthcare. However, verifying medical
reasoning is challenging, unlike those in mathematics. To address this, we
propose verifiable medical problems with a medical verifier to check the
correctness of model outputs. This verifiable nature enables advancements in
medical reasoning through a two-stage approach: (1) using the verifier to guide
the search for a complex reasoning trajectory for fine-tuning LLMs, (2)
applying reinforcement learning (RL) with verifier-based rewards to enhance
complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM
capable of complex reasoning, which outperforms general and medical-specific
baselines using only 40K verifiable problems. Experiments show complex
reasoning improves medical problem-solving and benefits more from RL. We hope
our approach inspires advancements in reasoning across medical and other
specialized domains.},
 author = {Junying Chen and Zhenyang Cai and Ke Ji and Xidong Wang and Wanlong Liu and Rongsheng Wang and Jianye Hou and Benyou Wang},
 comment = {},
 doi = {},
 eprint = {2412.18925v1},
 journal = {arXiv preprint},
 title = {HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs},
 url = {http://arxiv.org/abs/2412.18925v1},
 year = {2024}
}

@article{2412.18947v4,
 abstract = {Medical Large Language Models (MLLMs) have demonstrated potential in
healthcare applications, yet their propensity for hallucinations -- generating
medically implausible or inaccurate information -- presents substantial risks
to patient care. This paper introduces MedHallBench, a comprehensive benchmark
framework for evaluating and mitigating hallucinations in MLLMs. Our
methodology integrates expert-validated medical case scenarios with established
medical databases to create a robust evaluation dataset. The framework employs
a sophisticated measurement system that combines automated ACHMI (Automatic
Caption Hallucination Measurement in Medical Imaging) scoring with rigorous
clinical expert evaluations and utilizes reinforcement learning methods to
achieve automatic annotation. Through an optimized reinforcement learning from
human feedback (RLHF) training pipeline specifically designed for medical
applications, MedHallBench enables thorough evaluation of MLLMs across diverse
clinical contexts while maintaining stringent accuracy standards. We conducted
comparative experiments involving various models, utilizing the benchmark to
establish a baseline for widely adopted large language models (LLMs). Our
findings indicate that ACHMI provides a more nuanced understanding of the
effects of hallucinations compared to traditional metrics, thereby highlighting
its advantages in hallucination assessment. This research establishes a
foundational framework for enhancing MLLMs' reliability in healthcare settings
and presents actionable strategies for addressing the critical challenge of AI
hallucinations in medical applications.},
 author = {Kaiwen Zuo and Yirui Jiang},
 comment = {Published to AAAI-25 Bridge Program},
 doi = {},
 eprint = {2412.18947v4},
 journal = {arXiv preprint},
 title = {MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models},
 url = {http://arxiv.org/abs/2412.18947v4},
 year = {2024}
}

@article{2501.00382v1,
 abstract = {This paper advances empirical demand analysis by integrating multimodal
product representations derived from artificial intelligence (AI). Using a
detailed dataset of toy cars on \textit{Amazon.com}, we combine text
descriptions, images, and tabular covariates to represent each product using
transformer-based embedding models. These embeddings capture nuanced
attributes, such as quality, branding, and visual characteristics, that
traditional methods often struggle to summarize. Moreover, we fine-tune these
embeddings for causal inference tasks. We show that the resulting embeddings
substantially improve the predictive accuracy of sales ranks and prices and
that they lead to more credible causal estimates of price elasticity. Notably,
we uncover strong heterogeneity in price elasticity driven by these
product-specific features. Our findings illustrate that AI-driven
representations can enrich and modernize empirical demand analysis. The
insights generated may also prove valuable for applied causal inference more
broadly.},
 author = {Philipp Bach and Victor Chernozhukov and Sven Klaassen and Martin Spindler and Jan Teichert-Kluge and Suhas Vijaykumar},
 comment = {42 pages, 9 figures},
 doi = {},
 eprint = {2501.00382v1},
 journal = {arXiv preprint},
 title = {Adventures in Demand Analysis Using AI},
 url = {http://arxiv.org/abs/2501.00382v1},
 year = {2024}
}

@article{2501.00755v2,
 abstract = {Causal inference in observational studies with high-dimensional covariates
presents significant challenges. We introduce CausalBGM, an AI-powered Bayesian
generative modeling approach that captures the causal relationship among
covariates, treatment, and outcome variables. The core innovation of CausalBGM
lies in its ability to estimate the individual treatment effect (ITE) by
learning individual-specific distributions of a low-dimensional latent feature
set (e.g., latent confounders) that drives changes in both treatment and
outcome. This approach not only effectively mitigates confounding effects but
also provides comprehensive uncertainty quantification, offering reliable and
interpretable causal effect estimates at the individual level. CausalBGM adopts
a Bayesian model and uses a novel iterative algorithm to update the model
parameters and the posterior distribution of latent features until convergence.
This framework leverages the power of AI to capture complex dependencies among
variables while adhering to the Bayesian principles. Extensive experiments
demonstrate that CausalBGM consistently outperforms state-of-the-art methods,
particularly in scenarios with high-dimensional covariates and large-scale
datasets. Its Bayesian foundation ensures statistical rigor, providing robust
and well-calibrated posterior intervals. By addressing key limitations of
existing methods, CausalBGM emerges as a robust and promising framework for
advancing causal inference in modern applications in fields such as genomics,
healthcare, and social sciences. CausalBGM is maintained at the website
https://causalbgm.readthedocs.io/.},
 author = {Qiao Liu and Wing Hung Wong},
 comment = {},
 doi = {},
 eprint = {2501.00755v2},
 journal = {arXiv preprint},
 title = {An AI-powered Bayesian generative modeling approach for causal inference in observational studies},
 url = {http://arxiv.org/abs/2501.00755v2},
 year = {2025}
}

@article{2501.00854v1,
 abstract = {Sequential decision problems are widely studied across many areas of science.
A key challenge when learning policies from historical data - a practice
commonly referred to as off-policy learning - is how to ``identify'' the impact
of a policy of interest when the observed data are not randomized. Off-policy
learning has mainly been studied in two settings: dynamic treatment regimes
(DTRs), where the focus is on controlling confounding in medical problems with
short decision horizons, and offline reinforcement learning (RL), where the
focus is on dimension reduction in closed systems such as games. The gap
between these two well studied settings has limited the wider application of
off-policy learning to many real-world problems. Using the theory for causal
inference based on acyclic directed mixed graph (ADMGs), we provide a set of
graphical identification criteria in general decision processes that encompass
both DTRs and MDPs. We discuss how our results relate to the often implicit
causal assumptions made in the DTR and RL literatures and further clarify
several common misconceptions. Finally, we present a realistic simulation study
for the dynamic pricing problem encountered in container logistics, and
demonstrate how violations of our graphical criteria can lead to suboptimal
policies.},
 author = {Joakim Blach Andersen and Qingyuan Zhao},
 comment = {25 pages (not including appendix and references), 10 figures, 2
  tables},
 doi = {},
 eprint = {2501.00854v1},
 journal = {arXiv preprint},
 title = {A Graphical Approach to State Variable Selection in Off-policy Learning},
 url = {http://arxiv.org/abs/2501.00854v1},
 year = {2025}
}

@article{2501.02087v2,
 abstract = {In domains such as finance, healthcare, and robotics, managing worst-case
scenarios is critical, as failure to do so can lead to catastrophic outcomes.
Distributional Reinforcement Learning (DRL) provides a natural framework to
incorporate risk sensitivity into decision-making processes. However, existing
approaches face two key limitations: (1) the use of fixed risk measures at each
decision step often results in overly conservative policies, and (2) the
interpretation and theoretical properties of the learned policies remain
unclear. While optimizing a static risk measure addresses these issues, its use
in the DRL framework has been limited to the simple static CVaR risk measure.
In this paper, we present a novel DRL algorithm with convergence guarantees
that optimizes for a broader class of static Spectral Risk Measures (SRM).
Additionally, we provide a clear interpretation of the learned policy by
leveraging the distribution of returns in DRL and the decomposition of static
coherent risk measures. Extensive experiments demonstrate that our model learns
policies aligned with the SRM objective, and outperforms existing risk-neutral
and risk-sensitive DRL models in various settings.},
 author = {Mehrdad Moghimi and Hyejin Ku},
 comment = {Accepted at ICML 2025},
 doi = {},
 eprint = {2501.02087v2},
 journal = {arXiv preprint},
 title = {Beyond CVaR: Leveraging Static Spectral Risk Measures for Enhanced Decision-Making in Distributional Reinforcement Learning},
 url = {http://arxiv.org/abs/2501.02087v2},
 year = {2025}
}

@article{2501.02961v1,
 abstract = {This paper provides a formalism for an important class of causal inference
problems inspired by user-advertiser interaction in online advertiser. Then
this formalism is specialized to an extension of temporal marked point
processes and the neural point processes are suggested as practical solutions
to some interesting special cases.},
 author = {Alexander Merkov and David Rohde},
 comment = {13 pages},
 doi = {},
 eprint = {2501.02961v1},
 journal = {arXiv preprint},
 title = {A Point Process Model for Optimizing Repeated Personalized Action Delivery to Users},
 url = {http://arxiv.org/abs/2501.02961v1},
 year = {2025}
}

@article{2501.03129v2,
 abstract = {There has been widespread use of causal inference methods for the rigorous
analysis of observational studies and to identify policy evaluations. In this
article, we consider a class of generalized coarsened procedures for
confounding. At a high level, these procedures can be viewed as performing a
clustering of confounding variables, followed by treatment effect and attendant
variance estimation using the confounder strata. In addition, we propose two
new algorithms for generalized coarsened confounding. While Iacus et al. (2011)
developed some statistical properties for one special case in our class of
procedures, we instead develop a general asymptotic framework. We provide
asymptotic results for the average causal effect estimator as well as providing
conditions for consistency. In addition, we provide an asymptotic justification
for the variance formulae in Iacus et al. (2011). A bias correction technique
is proposed, and we apply the proposed methodology to data from two well-known
observational studies.},
 author = {Debashis Ghosh and Lei Wang},
 comment = {arXiv admin note: text overlap with arXiv:2301.00889},
 doi = {},
 eprint = {2501.03129v2},
 journal = {arXiv preprint},
 title = {Generalized coarsened confounding for causal effects: a large-sample framework},
 url = {http://arxiv.org/abs/2501.03129v2},
 year = {2025}
}

@article{2501.03405v1,
 abstract = {Advancements in robotics have opened possibilities to automate tasks in
various fields such as manufacturing, emergency response and healthcare.
However, a significant challenge that prevents robots from operating in
real-world environments effectively is out-of-distribution (OOD) situations,
wherein robots encounter unforseen situations. One major OOD situations is when
robots encounter faults, making fault adaptation essential for real-world
operation for robots. Current state-of-the-art reinforcement learning
algorithms show promising results but suffer from sample inefficiency, leading
to low adaptation speed due to their limited ability to generalize to OOD
situations. Our research is a step towards adding hardware fault tolerance and
fast fault adaptability to machines. In this research, our primary focus is to
investigate the efficacy of generative flow networks in robotic environments,
particularly in the domain of machine fault adaptation. We simulated a robotic
environment called Reacher in our experiments. We modify this environment to
introduce four distinct fault environments that replicate real-world
machines/robot malfunctions. The empirical evaluation of this research
indicates that continuous generative flow networks (CFlowNets) indeed have the
capability to add adaptive behaviors in machines under adversarial conditions.
Furthermore, the comparative analysis of CFlowNets with reinforcement learning
algorithms also provides some key insights into the performance in terms of
adaptation speed and sample efficiency. Additionally, a separate study
investigates the implications of transferring knowledge from pre-fault task to
post-fault environments. Our experiments confirm that CFlowNets has the
potential to be deployed in a real-world machine and it can demonstrate
adaptability in case of malfunctions to maintain functionality.},
 author = {Zahin Sufiyan and Shadan Golestan and Shotaro Miwa and Yoshihiro Mitsuka and Osmar Zaiane},
 comment = {},
 doi = {},
 eprint = {2501.03405v1},
 journal = {arXiv preprint},
 title = {A Study of the Efficacy of Generative Flow Networks for Robotics and Machine Fault-Adaptation},
 url = {http://arxiv.org/abs/2501.03405v1},
 year = {2025}
}

@article{2501.04724v1,
 abstract = {This study explores how causal inference models, specifically the Linear
Non-Gaussian Acyclic Model (LiNGAM), can extract causal relationships between
demographic factors, treatments, conditions, and outcomes from observational
patient data, enabling insights beyond correlation. Unlike traditional
randomized controlled trials (RCTs), which establish causal relationships
within narrowly defined populations, our method leverages broader observational
data, improving generalizability. Using over 40 features in the Duke MRI Breast
Cancer dataset, we found that Adjuvant Anti-Her2 Neu Therapy increased local
recurrence-free survival by 169 days, while Skin/Nipple involvement reduced it
by 351 days. These findings highlight the therapy's importance for
Her2-positive patients and the need for targeted interventions for high-risk
cases, informing personalized treatment strategies.},
 author = {Joe Omatoi and Abdul M Mohammed and Dennis Trujillo},
 comment = {},
 doi = {},
 eprint = {2501.04724v1},
 journal = {arXiv preprint},
 title = {Guiding Treatment Strategies: The Role of Adjuvant Anti-Her2 Neu Therapy and Skin/Nipple Involvement in Local Recurrence-Free Survival in Breast Cancer Patients},
 url = {http://arxiv.org/abs/2501.04724v1},
 year = {2025}
}

@article{2501.04870v2,
 abstract = {In dynamic decision-making scenarios across business and healthcare,
leveraging sample trajectories from diverse populations can significantly
enhance reinforcement learning (RL) performance for specific target
populations, especially when sample sizes are limited. While existing transfer
learning methods primarily focus on linear regression settings, they lack
direct applicability to reinforcement learning algorithms. This paper pioneers
the study of transfer learning for dynamic decision scenarios modeled by
non-stationary finite-horizon Markov decision processes, utilizing neural
networks as powerful function approximators and backward inductive learning. We
demonstrate that naive sample pooling strategies, effective in regression
settings, fail in Markov decision processes.To address this challenge, we
introduce a novel ``re-weighted targeting procedure'' to construct
``transferable RL samples'' and propose ``transfer deep $Q^*$-learning'',
enabling neural network approximation with theoretical guarantees. We assume
that the reward functions are transferable and deal with both situations in
which the transition densities are transferable or nontransferable. Our
analytical techniques for transfer learning in neural network approximation and
transition density transfers have broader implications, extending to supervised
transfer learning with neural networks and domain shift scenarios. Empirical
experiments on both synthetic and real datasets corroborate the advantages of
our method, showcasing its potential for improving decision-making through
strategically constructing transferable RL samples in non-stationary
reinforcement learning contexts.},
 author = {Jinhang Chai and Elynn Chen and Jianqing Fan},
 comment = {},
 doi = {},
 eprint = {2501.04870v2},
 journal = {arXiv preprint},
 title = {Deep Transfer $Q$-Learning for Offline Non-Stationary Reinforcement Learning},
 url = {http://arxiv.org/abs/2501.04870v2},
 year = {2025}
}

@article{2501.05197v1,
 abstract = {The new era of large-scale data collection and analysis presents an
opportunity for diagnosing and understanding the causes of health inequities.
In this study, we describe a framework for systematically analyzing health
disparities using causal inference. The framework is illustrated by
investigating racial and ethnic disparities in intensive care unit (ICU)
outcome between majority and minority groups in Australia (Indigenous vs.
Non-Indigenous) and the United States (African-American vs. White). We
demonstrate that commonly used statistical measures for quantifying inequity
are insufficient, and focus on attributing the observed disparity to the causal
mechanisms that generate it. We find that minority patients are younger at
admission, have worse chronic health, are more likely to be admitted for urgent
and non-elective reasons, and have higher illness severity. At the same time,
however, we find a protective direct effect of belonging to a minority group,
with minority patients showing improved survival compared to their majority
counterparts, with all other variables kept equal. We demonstrate that this
protective effect is related to the increased probability of being admitted to
ICU, with minority patients having an increased risk of ICU admission. We also
find that minority patients, while showing improved survival, are more likely
to be readmitted to ICU. Thus, due to worse access to primary health care,
minority patients are more likely to end up in ICU for preventable conditions,
causing a reduction in the mortality rates and creating an effect that appears
to be protective. Since the baseline risk of ICU admission may serve as proxy
for lack of access to primary care, we developed the Indigenous Intensive Care
Equity (IICE) Radar, a monitoring system for tracking the over-utilization of
ICU resources by the Indigenous population of Australia across geographical
areas.},
 author = {Drago Plecko and Paul Secombe and Andrea Clarke and Amelia Fiske and Samarra Toby and Donisha Duff and David Pilcher and Leo Anthony Celi and Rinaldo Bellomo and Elias Bareinboim},
 comment = {},
 doi = {},
 eprint = {2501.05197v1},
 journal = {arXiv preprint},
 title = {An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes},
 url = {http://arxiv.org/abs/2501.05197v1},
 year = {2025}
}

@article{2501.06077v1,
 abstract = {Causal inference has recently gained notable attention across various fields
like biology, healthcare, and environmental science, especially within
explainable artificial intelligence (xAI) systems, for uncovering the causal
relationships among multiple variables and outcomes. Yet, it has not been fully
recognized and deployed in the manufacturing systems. In this paper, we
introduce an explainable, scalable, and flexible federated Bayesian learning
framework, \texttt{xFBCI}, designed to explore causality through treatment
effect estimation in distributed manufacturing systems. By leveraging federated
Bayesian learning, we efficiently estimate posterior of local parameters to
derive the propensity score for each client without accessing local private
data. These scores are then used to estimate the treatment effect using
propensity score matching (PSM). Through simulations on various datasets and a
real-world Electrohydrodynamic (EHD) printing data, we demonstrate that our
approach outperforms standard Bayesian causal inference methods and several
state-of-the-art federated learning benchmarks.},
 author = {Xiaofeng Xiao and Khawlah Alharbi and Pengyu Zhang and Hantang Qin and Xubo Yue},
 comment = {26 pages},
 doi = {},
 eprint = {2501.06077v1},
 journal = {arXiv preprint},
 title = {Explainable Federated Bayesian Causal Inference and Its Application in Advanced Manufacturing},
 url = {http://arxiv.org/abs/2501.06077v1},
 year = {2025}
}

@article{2501.06366v2,
 abstract = {When applied in healthcare, reinforcement learning (RL) seeks to dynamically
match the right interventions to subjects to maximize population benefit.
However, the learned policy may disproportionately allocate efficacious actions
to one subpopulation, creating or exacerbating disparities in other
socioeconomically-disadvantaged subgroups. These biases tend to occur in
multi-stage decision making and can be self-perpetuating, which if unaccounted
for could cause serious unintended consequences that limit access to care or
treatment benefit. Counterfactual fairness (CF) offers a promising statistical
tool grounded in causal inference to formulate and study fairness. In this
paper, we propose a general framework for fair sequential decision making. We
theoretically characterize the optimal CF policy and prove its stationarity,
which greatly simplifies the search for optimal CF policies by leveraging
existing RL algorithms. The theory also motivates a sequential data
preprocessing algorithm to achieve CF decision making under an additive noise
assumption. We prove and then validate our policy learning approach in
controlling unfairness and attaining optimal value through simulations.
Analysis of a digital health dataset designed to reduce opioid misuse shows
that our proposal greatly enhances fair access to counseling.},
 author = {Jitao Wang and Chengchun Shi and John D. Piette and Joshua R. Loftus and Donglin Zeng and Zhenke Wu},
 comment = {},
 doi = {},
 eprint = {2501.06366v2},
 journal = {arXiv preprint},
 title = {Counterfactually Fair Reinforcement Learning via Sequential Data Preprocessing},
 url = {http://arxiv.org/abs/2501.06366v2},
 year = {2025}
}

@article{2501.06366v2,
 abstract = {When applied in healthcare, reinforcement learning (RL) seeks to dynamically
match the right interventions to subjects to maximize population benefit.
However, the learned policy may disproportionately allocate efficacious actions
to one subpopulation, creating or exacerbating disparities in other
socioeconomically-disadvantaged subgroups. These biases tend to occur in
multi-stage decision making and can be self-perpetuating, which if unaccounted
for could cause serious unintended consequences that limit access to care or
treatment benefit. Counterfactual fairness (CF) offers a promising statistical
tool grounded in causal inference to formulate and study fairness. In this
paper, we propose a general framework for fair sequential decision making. We
theoretically characterize the optimal CF policy and prove its stationarity,
which greatly simplifies the search for optimal CF policies by leveraging
existing RL algorithms. The theory also motivates a sequential data
preprocessing algorithm to achieve CF decision making under an additive noise
assumption. We prove and then validate our policy learning approach in
controlling unfairness and attaining optimal value through simulations.
Analysis of a digital health dataset designed to reduce opioid misuse shows
that our proposal greatly enhances fair access to counseling.},
 author = {Jitao Wang and Chengchun Shi and John D. Piette and Joshua R. Loftus and Donglin Zeng and Zhenke Wu},
 comment = {},
 doi = {},
 eprint = {2501.06366v2},
 journal = {arXiv preprint},
 title = {Counterfactually Fair Reinforcement Learning via Sequential Data Preprocessing},
 url = {http://arxiv.org/abs/2501.06366v2},
 year = {2025}
}

@article{2501.06926v3,
 abstract = {Long-term causal effects often must be estimated from short-term data due to
limited follow-up in healthcare, economics, and online platforms. Markov
Decision Processes (MDPs) provide a natural framework for capturing such
long-term dynamics through sequences of states, actions, and rewards. Double
Reinforcement Learning (DRL) enables efficient inference on policy values in
MDPs, but nonparametric implementations require strong intertemporal overlap
assumptions and often exhibit high variance and instability. We propose a
semiparametric extension of DRL for efficient inference on linear functionals
of the Q-function--such as policy values--in infinite-horizon, time-homogeneous
MDPs. By imposing structural restrictions on the Q-function, our approach
relaxes the strong overlap conditions required by nonparametric methods and
improves statistical efficiency. Under model misspecification, our estimators
target the functional of the best-approximating Q-function, with only
second-order bias. We provide conditions for valid inference using sieve
methods and data-driven model selection. A central challenge in DRL is the
estimation of nuisance functions, such as density ratios, which often involve
difficult minimax optimization. To address this, we introduce a novel plug-in
estimator based on isotonic Bellman calibration, which combines fitted
Q-iteration with an isotonic regression adjustment. The estimator is debiased
without requiring estimation of additional nuisance functions and reduces
high-dimensional overlap assumptions to a one-dimensional condition. Bellman
calibration extends isotonic calibration--widely used in prediction and
classification--to the MDP setting and may be of independent interest.},
 author = {Lars van der Laan and David Hubbard and Allen Tran and Nathan Kallus and Aurélien Bibaut},
 comment = {},
 doi = {},
 eprint = {2501.06926v3},
 journal = {arXiv preprint},
 title = {Semiparametric Double Reinforcement Learning with Applications to Long-Term Causal Inference},
 url = {http://arxiv.org/abs/2501.06926v3},
 year = {2025}
}

@article{2501.06926v3,
 abstract = {Long-term causal effects often must be estimated from short-term data due to
limited follow-up in healthcare, economics, and online platforms. Markov
Decision Processes (MDPs) provide a natural framework for capturing such
long-term dynamics through sequences of states, actions, and rewards. Double
Reinforcement Learning (DRL) enables efficient inference on policy values in
MDPs, but nonparametric implementations require strong intertemporal overlap
assumptions and often exhibit high variance and instability. We propose a
semiparametric extension of DRL for efficient inference on linear functionals
of the Q-function--such as policy values--in infinite-horizon, time-homogeneous
MDPs. By imposing structural restrictions on the Q-function, our approach
relaxes the strong overlap conditions required by nonparametric methods and
improves statistical efficiency. Under model misspecification, our estimators
target the functional of the best-approximating Q-function, with only
second-order bias. We provide conditions for valid inference using sieve
methods and data-driven model selection. A central challenge in DRL is the
estimation of nuisance functions, such as density ratios, which often involve
difficult minimax optimization. To address this, we introduce a novel plug-in
estimator based on isotonic Bellman calibration, which combines fitted
Q-iteration with an isotonic regression adjustment. The estimator is debiased
without requiring estimation of additional nuisance functions and reduces
high-dimensional overlap assumptions to a one-dimensional condition. Bellman
calibration extends isotonic calibration--widely used in prediction and
classification--to the MDP setting and may be of independent interest.},
 author = {Lars van der Laan and David Hubbard and Allen Tran and Nathan Kallus and Aurélien Bibaut},
 comment = {},
 doi = {},
 eprint = {2501.06926v3},
 journal = {arXiv preprint},
 title = {Semiparametric Double Reinforcement Learning with Applications to Long-Term Causal Inference},
 url = {http://arxiv.org/abs/2501.06926v3},
 year = {2025}
}

@article{2501.06969v2,
 abstract = {Statistical methods for causal inference with continuous treatments mainly
focus on estimating the mean potential outcome function, commonly known as the
dose-response curve. However, it is often not the dose-response curve but its
derivative function that signals the treatment effect. In this paper, we
investigate nonparametric inference on the derivative of the dose-response
curve with and without the positivity condition. Under the positivity and other
regularity conditions, we propose a doubly robust (DR) inference method for
estimating the derivative of the dose-response curve using kernel smoothing.
When the positivity condition is violated, we demonstrate the inconsistency of
conventional inverse probability weighting (IPW) and DR estimators, and
introduce novel bias-corrected IPW and DR estimators. In all settings, our DR
estimator achieves asymptotic normality at the standard nonparametric rate of
convergence with nonparametric efficiency guarantees. Additionally, our
approach reveals an interesting connection to nonparametric support and level
set estimation problems. Finally, we demonstrate the applicability of our
proposed estimators through simulations and a case study of evaluating a job
training program.},
 author = {Yikun Zhang and Yen-Chi Chen},
 comment = {Revision with added nonparametric efficiency theory. The updated
  version has 117 pages (25 pages for the main paper), 10 figures},
 doi = {},
 eprint = {2501.06969v2},
 journal = {arXiv preprint},
 title = {Doubly Robust Inference on Causal Derivative Effects for Continuous Treatments},
 url = {http://arxiv.org/abs/2501.06969v2},
 year = {2025}
}

@article{2501.06980v1,
 abstract = {Reinforcement learning (RL) is increasingly being used in the healthcare
domain, particularly for the development of personalized health adaptive
interventions. Inspired by the success of Large Language Models (LLMs), we are
interested in using LLMs to update the RL policy in real time, with the goal of
accelerating personalization. We use the text-based user preference to
influence the action selection on the fly, in order to immediately incorporate
the user preference. We use the term "user preference" as a broad term to refer
to a user personal preference, constraint, health status, or a statement
expressing like or dislike, etc. Our novel approach is a hybrid method that
combines the LLM response and the RL action selection to improve the RL policy.
Given an LLM prompt that incorporates the user preference, the LLM acts as a
filter in the typical RL action selection. We investigate different prompting
strategies and action selection strategies. To evaluate our approach, we
implement a simulation environment that generates the text-based user
preferences and models the constraints that impact behavioral dynamics. We show
that our approach is able to take into account the text-based user preferences,
while improving the RL policy, thus improving personalization in adaptive
intervention.},
 author = {Karine Karine and Benjamin M. Marlin},
 comment = {},
 doi = {},
 eprint = {2501.06980v1},
 journal = {arXiv preprint},
 title = {Combining LLM decision and RL action selection to improve RL policy for adaptive interventions},
 url = {http://arxiv.org/abs/2501.06980v1},
 year = {2025}
}

@article{2501.07722v1,
 abstract = {Experimentation is widely utilized for causal inference and data-driven
decision-making across disciplines. In an A/B experiment, for example, an
online business randomizes two different treatments (e.g., website designs) to
their customers and then aims to infer which treatment is better. In this
paper, we construct randomization tests for complex treatment effects,
including heterogeneity and interference. A key feature of our approach is the
use of flexible machine learning (ML) models, where the test statistic is
defined as the difference between the cross-validation errors from two ML
models, one including the treatment variable and the other without it. This
approach combines the predictive power of modern ML tools with the
finite-sample validity of randomization procedures, enabling a robust and
efficient way to detect complex treatment effects in experimental settings. We
demonstrate this combined benefit both theoretically and empirically through
applied examples.},
 author = {Wenxuan Guo and JungHo Lee and Panos Toulis},
 comment = {},
 doi = {},
 eprint = {2501.07722v1},
 journal = {arXiv preprint},
 title = {ML-assisted Randomization Tests for Detecting Treatment Effects in A/B Experiments},
 url = {http://arxiv.org/abs/2501.07722v1},
 year = {2025}
}

@article{2501.07789v1,
 abstract = {Identifying optimal medical treatments to improve survival has long been a
critical goal of pharmacoepidemiology. Traditionally, we use an average
treatment effect measure to compare outcomes between treatment plans. However,
new methods leveraging advantages of machine learning combined with the
foundational tenets of causal inference are offering an alternative to the
average treatment effect. Here, we use three unique, precision medicine
algorithms (random forests, residual weighted learning, efficient augmentation
relaxed learning) to identify optimal treatment rules where patients receive
the optimal treatment as indicated by their clinical history. First, we present
a simple hypothetical example and a real-world application among heart failure
patients using Medicare claims data. We next demonstrate how the optimal
treatment rule improves the absolute risk in a hypothetical, three-modifier
setting. Finally, we identify an optimal treatment rule that optimizes the time
to outcome in a real-world heart failure setting. In both examples, we compare
the average time to death under the optimized, tailored treatment rule with the
average time to death under a universal treatment rule to show the benefit of
precision medicine methods. The improvement under the optimal treatment rule in
the real-world setting is greatest (additional ~9 days under the tailored rule)
for survival time free of heart failure readmission.},
 author = {Arti Virkud and Jessie K. Edwards and Michele Jonsson Funk and Patricia Chang and Abhijit V. Kshirsagar and Emily W. Gower and Michael R. Kosorok},
 comment = {},
 doi = {},
 eprint = {2501.07789v1},
 journal = {arXiv preprint},
 title = {Using Statistical Precision Medicine to Identify Optimal Treatments in a Heart Failure Setting},
 url = {http://arxiv.org/abs/2501.07789v1},
 year = {2025}
}

@article{2501.08079v2,
 abstract = {We address the characterization of genuine network nonlocal correlations,
which remains highly challenging due to the non-convex nature of local
correlations even in the simplest scenario, and increasingly so when derived
from entangled states that deviate from their ideal forms. We introduce a
scalable causally-inferred Bayesian learning framework called the LHV layered
neural network, which introduces the rank parameter of the non-ideal combined
source state as an untapped resource to learn the local statistics in Bell
tests. This reveals these correlations to persist close to the Bell states,
with a noise robustness of 0.94-0.95 in the triangle scenario, additionally
requiring all sources to send only entangled states with joint entangled
measurements as resources. Further, we study the robustness of the genuineness
to shared randomness in the network scenario. Apart from the results, the work
succeeds in showing that machine learning approaches with foundational
domain-specific constraints can greatly benefit the field of quantum
foundations.},
 author = {Anantha Krishnan Sunilkumar and Anil Shaji and Debashis Saha},
 comment = {16 pages, 16 figures. Presented at the 16th International Conference
  on Quantum Communication, Measurement and Computing (QCMC 24). For associated
  code file, see https://github.com/ananthrishna/GNN-LHV-k-triangle},
 doi = {},
 eprint = {2501.08079v2},
 journal = {arXiv preprint},
 title = {Learning non-ideal genuine network nonlocality using causally inferred Bayesian neural network algorithms},
 url = {http://arxiv.org/abs/2501.08079v2},
 year = {2025}
}

@article{2501.08888v2,
 abstract = {Estimating the conditional average treatment effect (CATE) from observational
data plays a crucial role in areas such as e-commerce, healthcare, and
economics. Existing studies mainly rely on the strong ignorability assumption
that there are no hidden confounders, whose existence cannot be tested from
observational data and can invalidate any causal conclusion. In contrast, data
collected from randomized controlled trials (RCT) do not suffer from
confounding but are usually limited by a small sample size. To avoid
overfitting caused by the small-scale RCT data, we propose a novel two-stage
pretraining-finetuning (TSPF) framework with a partial parameter initialization
strategy to estimate the CATE in the presence of hidden confounding. In the
first stage, a foundational representation of covariates is trained to estimate
counterfactual outcomes through large-scale observational data. In the second
stage, we propose to train an augmented representation of the covariates, which
is concatenated with the foundational representation obtained in the first
stage to adjust for the hidden confounding. Rather than training a separate
network from scratch, part of the prediction heads are initialized from the
first stage. The superiority of our approach is validated on two datasets with
extensive experiments.},
 author = {Chuan Zhou and Yaxuan Li and Chunyuan Zheng and Haiteng Zhang and Haoxuan Li and Mingming Gong},
 comment = {Presented as a poster in the 2nd Workshop on Causal Inference and
  Machine Learning in Practice at KDD 2024},
 doi = {},
 eprint = {2501.08888v2},
 journal = {arXiv preprint},
 title = {A Partial Initialization Strategy to Mitigate the Overfitting Problem in CATE Estimation with Hidden Confounding},
 url = {http://arxiv.org/abs/2501.08888v2},
 year = {2025}
}

@article{2501.08958v2,
 abstract = {We propose the Granger causality inference Kolmogorov-Arnold Networks
(KANGCI), a novel architecture that extends the recently proposed
Kolmogorov-Arnold Networks (KAN) to the domain of causal inference. By
extracting base weights from KAN layers and incorporating the sparsity-inducing
penalty and ridge regularization, KANGCI effectively infers the Granger
causality from time series. Additionally, we propose an algorithm based on
time-reversed Granger causality that automatically selects causal relationships
with better inference performance from the original or time-reversed time
series or integrates the results to mitigate spurious connectivities.
Comprehensive experiments conducted on Lorenz-96, Gene regulatory networks,
fMRI BOLD signals, VAR, and real-world EEG datasets demonstrate that the
proposed model achieves competitive performance to state-of-the-art methods in
inferring Granger causality from nonlinear, high-dimensional, and
limited-sample time series.},
 author = {Meiliang Liu and Yunfang Xu and Zijin Li and Zhengye Si and Xiaoxiao Yang and Xinyue Yang and Zhiwen Zhao},
 comment = {},
 doi = {},
 eprint = {2501.08958v2},
 journal = {arXiv preprint},
 title = {Kolmogorov-Arnold Networks for Time Series Granger Causality Inference},
 url = {http://arxiv.org/abs/2501.08958v2},
 year = {2025}
}

@article{2501.10423v1,
 abstract = {The energy transition is profoundly reshaping electricity market dynamics. It
makes it essential to understand how renewable energy generation actually
impacts electricity prices, among all other market drivers. These insights are
critical to design policies and market interventions that ensure affordable,
reliable, and sustainable energy systems. However, identifying causal effects
from observational data is a major challenge, requiring innovative causal
inference approaches that go beyond conventional regression analysis only. We
build upon the state of the art by developing and applying a local partially
linear double machine learning approach. Its application yields the first
robust causal evidence on the distinct and non-linear effects of wind and solar
power generation on UK wholesale electricity prices, revealing key insights
that have eluded previous analyses. We find that, over 2018-2024, wind power
generation has a U-shaped effect on prices: at low penetration levels, a 1 GWh
increase in energy generation reduces prices by up to 7 GBP/MWh, but this
effect gets close to none at mid-penetration levels (20-30%) before
intensifying again. Solar power places substantial downward pressure on prices
at very low penetration levels (up to 9 GBP/MWh per 1 GWh increase in energy
generation), though its impact weakens quite rapidly. We also uncover a
critical trend where the price-reducing effects of both wind and solar power
have become more pronounced over time (from 2018 to 2024), highlighting their
growing influence on electricity markets amid rising penetration. Our study
provides both novel analysis approaches and actionable insights to guide
policymakers in appraising the way renewables impact electricity markets.},
 author = {Davide Cacciarelli and Pierre Pinson and Filip Panagiotopoulos and David Dixon and Lizzie Blaxland},
 comment = {},
 doi = {},
 eprint = {2501.10423v1},
 journal = {arXiv preprint},
 title = {Do we actually understand the impact of renewables on electricity prices? A causal inference approach},
 url = {http://arxiv.org/abs/2501.10423v1},
 year = {2025}
}

@article{2501.10543v2,
 abstract = {The application of artificial intelligence and machine learning in business
process management has advanced significantly, however, the full potential of
these technologies remains largely unexplored, primarily due to challenges
related to data quality and availability. We present a novel framework called
Fine-Tuned Offline Reinforcement Learning Augmented Process Sequence
Optimization (FORLAPS), which aims to identify optimal execution paths in
business processes by leveraging reinforcement learning enhanced with a
state-dependent reward shaping mechanism, thereby enabling context-sensitive
prescriptions. Additionally, to compare FORLAPS with the existing models
(Permutation Feature Importance and multi-task Long Short Term Memory model),
we experimented to evaluate its effectiveness in terms of resource savings and
process time reduction. The experimental results on real-life event logs
validate that FORLAPS achieves 31% savings in resource time spent and a 23%
reduction in process time span. To further enhance learning, we introduce an
innovative process-aware data augmentation technique that selectively increases
the average estimated Q-values in sampled batches, enabling automatic
fine-tuning of the reinforcement learning model. Robustness was assessed
through both prefix-level and trace-level evaluations, using the
Damerau-Levenshtein distance as the primary metric. Finally, the model's
adaptability across industries was further validated through diverse case
studies, including healthcare treatment pathways, financial services workflows,
permit applications from regulatory bodies, and operations management. In each
domain, the proposed model demonstrated exceptional performance, outperforming
existing state-of-the-art approaches in prescriptive decision-making,
demonstrating its capability to prescribe optimal next steps and predict the
best next activities within a process trace.},
 author = {Mostafa Abbasi and Maziyar Khadivi and Maryam Ahang and Patricia Lasserre and Yves Lucet and Homayoun Najjaran},
 comment = {},
 doi = {},
 eprint = {2501.10543v2},
 journal = {arXiv preprint},
 title = {An Innovative Data-Driven and Adaptive Reinforcement Learning Approach for Context-Aware Prescriptive Process Monitoring},
 url = {http://arxiv.org/abs/2501.10543v2},
 year = {2025}
}

@article{2501.11868v1,
 abstract = {We propose a unified framework for automatic debiased machine learning
(autoDML) to perform inference on smooth functionals of infinite-dimensional
M-estimands, defined as population risk minimizers over Hilbert spaces. By
automating debiased estimation and inference procedures in causal inference and
semiparametric statistics, our framework enables practitioners to construct
valid estimators for complex parameters without requiring specialized
expertise. The framework supports Neyman-orthogonal loss functions with unknown
nuisance parameters requiring data-driven estimation, as well as vector-valued
M-estimands involving simultaneous loss minimization across multiple Hilbert
space models. We formalize the class of parameters efficiently estimable by
autoDML as a novel class of nonparametric projection parameters, defined via
orthogonal minimum loss objectives. We introduce three autoDML estimators based
on one-step estimation, targeted minimum loss-based estimation, and the method
of sieves. For data-driven model selection, we derive a novel decomposition of
model approximation error for smooth functionals of M-estimands and propose
adaptive debiased machine learning estimators that are superefficient and
adaptive to the functional form of the M-estimand. Finally, we illustrate the
flexibility of our framework by constructing autoDML estimators for the
long-term survival under a beta-geometric model.},
 author = {Lars van der Laan and Aurelien Bibaut and Nathan Kallus and Alex Luedtke},
 comment = {},
 doi = {},
 eprint = {2501.11868v1},
 journal = {arXiv preprint},
 title = {Automatic Debiased Machine Learning for Smooth Functionals of Nonparametric M-Estimands},
 url = {http://arxiv.org/abs/2501.11868v1},
 year = {2025}
}

@article{2501.12706v1,
 abstract = {Explainability techniques hold significant potential for enhancing the causal
discovery process, which is crucial for understanding complex systems in areas
like healthcare, economics, and artificial intelligence. However, no causal
discovery methods currently incorporate explainability into their models to
derive causal graphs. Thus, in this paper we explore this innovative approach,
as it offers substantial potential and represents a promising new direction
worth investigating. Specifically, we introduce REX, a causal discovery method
that leverages machine learning (ML) models coupled with explainability
techniques, specifically Shapley values, to identify and interpret significant
causal relationships among variables.
  Comparative evaluations on synthetic datasets comprising continuous tabular
data reveal that REX outperforms state-of-the-art causal discovery methods
across diverse data generation processes, including non-linear and additive
noise models. Moreover, REX was tested on the Sachs single-cell
protein-signaling dataset, achieving a precision of 0.952 and recovering key
causal relationships with no incorrect edges. Taking together, these results
showcase REX's effectiveness in accurately recovering true causal structures
while minimizing false positive predictions, its robustness across diverse
datasets, and its applicability to real-world problems. By combining ML and
explainability techniques with causal discovery, REX bridges the gap between
predictive modeling and causal inference, offering an effective tool for
understanding complex causal structures. REX is publicly available at
https://github.com/renero/causalgraph.},
 author = {Jesus Renero and Idoia Ochoa and Roberto Maestre},
 comment = {22 pages, 30 figures, Submitted to Elsevier's Pattern Recognition},
 doi = {},
 eprint = {2501.12706v1},
 journal = {arXiv preprint},
 title = {REX: Causal Discovery based on Machine Learning and Explainability techniques},
 url = {http://arxiv.org/abs/2501.12706v1},
 year = {2025}
}

@article{2501.16399v1,
 abstract = {Clinical decisions to treat and diagnose patients are affected by implicit
biases formed by racism, ableism, sexism, and other stereotypes. These biases
reflect broader systemic discrimination in healthcare and risk marginalizing
already disadvantaged groups. Existing methods for measuring implicit biases
require controlled randomized testing and only capture individual attitudes
rather than outcomes. However, the "big-data" revolution has led to the
availability of large observational medical datasets, like EHRs and biobanks,
that provide the opportunity to investigate discrepancies in patient health
outcomes. In this work, we propose a causal inference approach to detect the
effect of clinician implicit biases on patient outcomes in large-scale medical
data. Specifically, our method uses proximal mediation to disentangle
pathway-specific effects of a patient's sociodemographic attribute on a
clinician's diagnosis decision. We test our method on real-world data from the
UK Biobank. Our work can serve as a tool that initiates conversation and brings
awareness to unequal health outcomes caused by implicit biases.},
 author = {Kara Liu and Russ Altman and Vasilis Syrgkanis},
 comment = {The ~64 pages of the appendix IS UNPUBLISHED and novel content},
 doi = {10.1142/9789819807024_0024},
 eprint = {2501.16399v1},
 journal = {arXiv preprint},
 title = {Detecting clinician implicit biases in diagnoses using proximal causal inference},
 url = {http://arxiv.org/abs/2501.16399v1},
 year = {2025}
}

@article{2501.16549v1,
 abstract = {Many machine learning applications predict individual probabilities, such as
the likelihood that a person develops a particular illness. Since these
probabilities are unknown, a key question is how to address situations in which
different models trained on the same dataset produce varying predictions for
certain individuals. This issue is exemplified by the model multiplicity (MM)
phenomenon, where a set of comparable models yield inconsistent predictions.
Roth, Tolbert, and Weinstein recently introduced a reconciliation procedure,
the Reconcile algorithm, to address this problem. Given two disagreeing models,
the algorithm leverages their disagreement to falsify and improve at least one
of the models. In this paper, we empirically analyze the Reconcile algorithm
using five widely-used fairness datasets: COMPAS, Communities and Crime, Adult,
Statlog (German Credit Data), and the ACS Dataset. We examine how Reconcile
fits within the model multiplicity literature and compare it to existing MM
solutions, demonstrating its effectiveness. We also discuss potential
improvements to the Reconcile algorithm theoretically and practically. Finally,
we extend the Reconcile algorithm to the setting of causal inference, given
that different competing estimators can again disagree on specific causal
average treatment effect (CATE) values. We present the first extension of the
Reconcile algorithm in causal inference, analyze its theoretical properties,
and conduct empirical tests. Our results confirm the practical effectiveness of
Reconcile and its applicability across various domains.},
 author = {Tina Behzad and Sílvia Casacuberta and Emily Ruth Diana and Alexander Williams Tolbert},
 comment = {Presented at the ICML workshop on Humans, Algorithmic Decision-Making
  and Society: Modeling Interactions and Impact 2024},
 doi = {},
 eprint = {2501.16549v1},
 journal = {arXiv preprint},
 title = {Reconciling Predictive Multiplicity in Practice},
 url = {http://arxiv.org/abs/2501.16549v1},
 year = {2025}
}

@article{2501.17711v3,
 abstract = {This paper proposes a novel hybrid model, STGCN-LSTM, to forecast Olympic
medal distributions by integrating the spatio-temporal relationships among
countries and the long-term dependencies of national performance. The
Spatial-Temporal Graph Convolution Network (STGCN) captures geographic and
interactive factors-such as coaching exchange and socio-economic links-while
the Long Short-Term Memory (LSTM) module models historical trends in medal
counts, economic data, and demographics. To address zero-inflated outputs
(i.e., the disparity between countries that consistently yield wins and those
never having won medals), a Zero-Inflated Compound Poisson (ZICP) framework is
incorporated to separate random zeros from structural zeros, providing a
clearer view of potential breakthrough performances. Validation includes
historical backtracking, policy shock simulations, and causal inference checks,
confirming the robustness of the proposed method. Results shed light on the
influence of coaching mobility, event specialization, and strategic investment
on medal forecasts, offering a data-driven foundation for optimizing sports
policies and resource allocation in diverse Olympic contexts.},
 author = {Yiquan Wang and Jiaying Wang and Tin-Yeh Huang and Jingyi Yang and Zihao Xu},
 comment = {18pages, 7figures},
 doi = {},
 eprint = {2501.17711v3},
 journal = {arXiv preprint},
 title = {STGCN-LSTM for Olympic Medal Prediction: Dynamic Power Modeling and Causal Policy Optimization},
 url = {http://arxiv.org/abs/2501.17711v3},
 year = {2025}
}

@article{2501.18337v1,
 abstract = {Faithfulness is the foundation of probability distribution and graph in
causal discovery and causal inference. In this paper, several unfaithful
probability distribution examples are constructed in three--vertices binary
causality directed acyclic graph (DAG) structure, which are not faithful to
causal DAGs described in J.M.,Robins,et al. Uniform consistency in causal
inference. Biometrika (2003),90(3): 491--515. And the general unfaithful
probability distribution with multiple independence and conditional
independence in binary triple causal DAG is given.},
 author = {Jingwei Liu},
 comment = {},
 doi = {},
 eprint = {2501.18337v1},
 journal = {arXiv preprint},
 title = {Unfaithful Probability Distributions in Binary Triple of Causality Directed Acyclic Graph},
 url = {http://arxiv.org/abs/2501.18337v1},
 year = {2025}
}

@article{2501.18417v2,
 abstract = {Anomaly detection is essential for identifying rare and significant events
across diverse domains such as finance, cybersecurity, and network monitoring.
This paper presents Synthetic Anomaly Monitoring (SAM), an innovative approach
that applies synthetic control methods from causal inference to improve both
the accuracy and interpretability of anomaly detection processes. By modeling
normal behavior through the treatment of each feature as a control unit, SAM
identifies anomalies as deviations within this causal framework. We conducted
extensive experiments comparing SAM with established benchmark models,
including Isolation Forest, Local Outlier Factor (LOF), k-Nearest Neighbors
(kNN), and One-Class Support Vector Machine (SVM), across five diverse
datasets, including Credit Card Fraud, HTTP Dataset CSIC 2010, and KDD Cup
1999, among others. Our results demonstrate that SAM consistently delivers
robust performance, highlighting its potential as a powerful tool for real-time
anomaly detection in dynamic and complex environments.},
 author = {Emanuele Luzio and Moacir Antonelli Ponti},
 comment = {19 pages, 3 figures, submitted for publication},
 doi = {},
 eprint = {2501.18417v2},
 journal = {arXiv preprint},
 title = {Real-Time Anomaly Detection with Synthetic Anomaly Monitoring (SAM)},
 url = {http://arxiv.org/abs/2501.18417v2},
 year = {2025}
}

@article{2501.18798v2,
 abstract = {Causal inference across multiple data sources offers a promising avenue to
enhance the generalizability and replicability of scientific findings. However,
data integration methods for time-to-event outcomes, common in biomedical
research, are underdeveloped. Existing approaches focus on binary or continuous
outcomes but fail to address the unique challenges of survival analysis, such
as censoring and the integration of discrete and continuous time. To bridge
this gap, we propose two novel methods for estimating target site-specific
causal effects in multi-source settings. First, we develop a semiparametric
efficient estimator for settings where individual-level data can be shared
across sites. Second, we introduce a federated learning framework designed for
privacy-constrained environments, which dynamically reweights source-specific
contributions to account for discrepancies with the target population. Both
methods leverage flexible, nonparametric machine learning models to improve
robustness and efficiency. We illustrate the utility of our approaches through
simulation studies and an application to multi-site randomized trials of
monoclonal neutralizing antibodies for HIV-1 prevention, conducted among
cisgender men and transgender persons in the United States, Brazil, Peru, and
Switzerland, as well as among women in sub-Saharan Africa. Our findings
underscore the potential of these methods to enable efficient,
privacy-preserving causal inference for time-to-event outcomes under
distribution shift.},
 author = {Yi Liu and Alexander W. Levis and Ke Zhu and Shu Yang and Peter B. Gilbert and Larry Han},
 comment = {},
 doi = {},
 eprint = {2501.18798v2},
 journal = {arXiv preprint},
 title = {Targeted Data Fusion for Causal Survival Analysis Under Distribution Shift},
 url = {http://arxiv.org/abs/2501.18798v2},
 year = {2025}
}

@article{2501.19055v1,
 abstract = {This paper adds to the growing literature of reinforcement learning (RL) for
healthcare by proposing a novel paradigm: augmenting any predictor with
Rule-based RL Layer (RRLL) that corrects the model's physiologically impossible
predictions. Specifically, RRLL takes as input states predicted labels and
outputs corrected labels as actions. The reward of the state-action pair is
evaluated by a set of general rules. RRLL is efficient, general and
lightweight: it does not require heavy expert knowledge like prior work but
only a set of impossible transitions. This set is much smaller than all
possible transitions; yet it can effectively reduce physiologically impossible
mistakes made by the state-of-the-art predictor models. We verify the utility
of RRLL on a variety of important healthcare classification problems and
observe significant improvements using the same setup, with only the
domain-specific set of impossibility changed. In-depth analysis shows that RRLL
indeed improves accuracy by effectively reducing the presence of
physiologically impossible predictions.},
 author = {Lingwei Zhu and Zheng Chen and Yukie Nagai and Jimeng Sun},
 comment = {},
 doi = {},
 eprint = {2501.19055v1},
 journal = {arXiv preprint},
 title = {Towards Physiologically Sensible Predictions via the Rule-based Reinforcement Learning Layer},
 url = {http://arxiv.org/abs/2501.19055v1},
 year = {2025}
}

@article{2501.19345v2,
 abstract = {The estimation of average treatment effects (ATEs), defined as the difference
in expected outcomes between treatment and control groups, is a central topic
in causal inference. This study develops semiparametric efficient estimators
for ATE in a setting where only a treatment group and an unlabeled group,
consisting of units whose treatment status is unknown, are observed. This
scenario constitutes a variant of learning from positive and unlabeled data (PU
learning) and can be viewed as a special case of ATE estimation with missing
data. For this setting, we derive the semiparametric efficiency bounds, which
characterize the lowest achievable asymptotic variance for regular estimators.
We then construct semiparametric efficient ATE estimators that attain these
bounds. Our results contribute to the literature on causal inference with
missing data and weakly supervised learning.},
 author = {Masahiro Kato and Fumiaki Kozai and Ryo Inokuchi},
 comment = {},
 doi = {},
 eprint = {2501.19345v2},
 journal = {arXiv preprint},
 title = {PUATE: Efficient Average Treatment Effect Estimation from Treated (Positive) and Unlabeled Units},
 url = {http://arxiv.org/abs/2501.19345v2},
 year = {2025}
}

@article{2502.00501v1,
 abstract = {Feature selection is an important but challenging task in causal inference
for obtaining unbiased estimates of causal quantities. Properly selected
features in causal inference not only significantly reduce the time required to
implement a matching algorithm but, more importantly, can also reduce the bias
and variance when estimating causal quantities. When feature selection
techniques are applied in causal inference, the crucial criterion is to select
variables that, when used for matching, can achieve an unbiased and robust
estimation of causal quantities. Recent research suggests that balancing only
on treatment-associated variables introduces bias while balancing on spurious
variables increases variance. To address this issue, we propose an enhanced
three-stage framework that shows a significant improvement in selecting the
desired subset of variables compared to the existing state-of-the-art feature
selection framework for causal inference, resulting in lower bias and variance
in estimating the causal quantity. We evaluated our proposed framework using a
state-of-the-art synthetic data across various settings and observed superior
performance within a feasible computation time, ensuring scalability for
large-scale datasets. Finally, to demonstrate the applicability of our proposed
methodology using large-scale real-world data, we evaluated an important US
healthcare policy related to the opioid epidemic crisis: whether opioid use
disorder has a causal relationship with suicidal behavior.},
 author = {Tianyu Yang and Md. Noor-E-Alam},
 comment = {},
 doi = {},
 eprint = {2502.00501v1},
 journal = {arXiv preprint},
 title = {Optimizing Feature Selection in Causal Inference: A Three-Stage Computational Framework for Unbiased Estimation},
 url = {http://arxiv.org/abs/2502.00501v1},
 year = {2025}
}

@article{2502.01106v1,
 abstract = {In experimental settings with network interference, a unit's treatment can
influence outcomes of other units, challenging both causal effect estimation
and its validation. Classic validation approaches fail as outcomes are only
observable under one treatment scenario and exhibit complex correlation
patterns due to interference. To address these challenges, we introduce a new
framework enabling cross-validation for counterfactual estimation. At its core
is our distribution-preserving network bootstrap method -- a
theoretically-grounded approach inspired by approximate message passing. This
method creates multiple subpopulations while preserving the underlying
distribution of network effects. We extend recent causal message-passing
developments by incorporating heterogeneous unit-level characteristics and
varying local interactions, ensuring reliable finite-sample performance through
non-asymptotic analysis. We also develop and publicly release a comprehensive
benchmark toolbox with diverse experimental environments, from networks of
interacting AI agents to opinion formation in real-world communities and
ride-sharing applications. These environments provide known ground truth values
while maintaining realistic complexities, enabling systematic examination of
causal inference methods. Extensive evaluation across these environments
demonstrates our method's robustness to diverse forms of network interference.
Our work provides researchers with both a practical estimation framework and a
standardized platform for testing future methodological developments.},
 author = {Sadegh Shirani and Yuwei Luo and William Overman and Ruoxuan Xiong and Mohsen Bayati},
 comment = {},
 doi = {},
 eprint = {2502.01106v1},
 journal = {arXiv preprint},
 title = {Can We Validate Counterfactual Estimations in the Presence of General Network Interference?},
 url = {http://arxiv.org/abs/2502.01106v1},
 year = {2025}
}

@article{2502.01575v3,
 abstract = {Tailoring treatments to individual needs is a central goal in fields such as
medicine. A key step toward this goal is estimating Heterogeneous Treatment
Effects (HTE) - the way treatments impact different subgroups. While crucial,
HTE estimation is challenging with survival data, where time until an event
(e.g., death) is key. Existing methods often assume complete observation, an
assumption violated in survival data due to right-censoring, leading to bias
and inefficiency. Cui et al. (2023) proposed a doubly-robust method for HTE
estimation in survival data under no hidden confounders, combining a causal
survival forest with an augmented inverse-censoring weighting estimator.
However, we find it struggles under heavy censoring, which is common in
rare-outcome problems such as Amyotrophic lateral sclerosis (ALS). Moreover,
most current methods cannot handle instrumental variables, which are a crucial
tool in the causal inference arsenal. We introduce Multiple Imputation for
Survival Treatment Response (MISTR), a novel, general, and non-parametric
method for estimating HTE in survival data. MISTR uses recursively imputed
survival trees to handle censoring without directly modeling the censoring
mechanism. Through extensive simulations and analysis of two real-world
datasets-the AIDS Clinical Trials Group Protocol 175 and the Illinois
unemployment dataset we show that MISTR outperforms prior methods under heavy
censoring in the no-hidden-confounders setting, and extends to the instrumental
variable setting. To our knowledge, MISTR is the first non-parametric approach
for HTE estimation with unobserved confounders via instrumental variables.},
 author = {Tomer Meir and Uri Shalit and Malka Gorfine},
 comment = {},
 doi = {},
 eprint = {2502.01575v3},
 journal = {arXiv preprint},
 title = {Heterogeneous Treatment Effect in Time-to-Event Outcomes: Harnessing Censored Data with Recursively Imputed Trees},
 url = {http://arxiv.org/abs/2502.01575v3},
 year = {2025}
}

@article{2502.02701v1,
 abstract = {In the estimation of causal effects, one common method for removing the
influence of confounders is to adjust the variables that satisfy the back-door
criterion. However, it is not always possible to uniquely determine sets of
such variables. Moreover, real-world data is almost always limited, which means
it may be insufficient for statistical estimation. Therefore, we propose
criteria for selecting variables from a list of candidate adjustment variables
along with an algorithm to prevent accuracy degradation in causal effect
estimation. We initially focus on directed acyclic graphs (DAGs) and then
outlines specific steps for applying this method to completed partially
directed acyclic graphs (CPDAGs). We also present and prove a theorem on causal
effect computation possibility in CPDAGs. Finally, we demonstrate the practical
utility of our method using both existing and artificial data.},
 author = {Atsushi Noda and Takashi Isozaki},
 comment = {20 pages, 8 figures},
 doi = {10.1088/2632-072X/ada861},
 eprint = {2502.02701v1},
 journal = {arXiv preprint},
 title = {Practically Effective Adjustment Variable Selection in Causal Inference},
 url = {http://arxiv.org/abs/2502.02701v1},
 year = {2025}
}

@article{2502.04673v1,
 abstract = {Estimation and inference for the Average Treatment Effect (ATE) is a
cornerstone of causal inference and often serves as the foundation for
developing procedures for more complicated settings. Although traditionally
analyzed in a batch setting, recent advances in martingale theory have paved
the way for adaptive methods that can enhance the power of downstream
inference. Despite these advances, progress in understanding and developing
adaptive algorithms remains in its early stages. Existing work either focus on
asymptotic analyses that overlook exploration-exploitation tradeoffs relevant
in finite-sample regimes or rely on simpler but suboptimal estimators. In this
work, we address these limitations by studying adaptive sampling procedures
that take advantage of the asymptotically optimal Augmented Inverse Probability
Weighting (AIPW) estimator. Our analysis uncovers challenges obscured by
asymptotic approaches and introduces a novel algorithmic design principle
reminiscent of optimism in multiarmed bandits. This principled approach enables
our algorithm to achieve significant theoretical and empirical gains compared
to prior methods. Our findings mark a step forward in advancing adaptive causal
inference methods in theory and practice.},
 author = {Ojash Neopane and Aaditya Ramdas and Aarti Singh},
 comment = {15 pages, 2 Figures},
 doi = {},
 eprint = {2502.04673v1},
 journal = {arXiv preprint},
 title = {Optimistic Algorithms for Adaptive Estimation of the Average Treatment Effect},
 url = {http://arxiv.org/abs/2502.04673v1},
 year = {2025}
}

@article{2502.05295v1,
 abstract = {Estimating causal effects from spatiotemporal data is a key challenge in
fields such as public health, social policy, and environmental science, where
controlled experiments are often infeasible. However, existing causal inference
methods relying on observational data face significant limitations: they depend
on strong structural assumptions to address spatiotemporal challenges
$\unicode{x2013}$ such as interference, spatial confounding, and temporal
carryover effects $\unicode{x2013}$ or fail to account for
$\textit{time-varying confounders}$. These confounders, influenced by past
treatments and outcomes, can themselves shape future treatments and outcomes,
creating feedback loops that complicate traditional adjustment strategies. To
address these challenges, we introduce the $\textbf{GST-UNet}$
($\textbf{G}$-computation $\textbf{S}$patio-$\textbf{T}$emporal
$\textbf{UNet}$), a novel end-to-end neural network framework designed to
estimate treatment effects in complex spatial and temporal settings. The
GST-UNet leverages regression-based iterative G-computation to explicitly
adjust for time-varying confounders, providing valid estimates of potential
outcomes and treatment effects. To the best of our knowledge, the GST-UNet is
the first neural model to account for complex, non-linear dynamics and
time-varying confounders in spatiotemporal interventions. We demonstrate the
effectiveness of the GST-UNet through extensive simulation studies and showcase
its practical utility with a real-world analysis of the impact of wildfire
smoke on respiratory hospitalizations during the 2018 California Camp Fire. Our
results highlight the potential of GST-UNet to advance spatiotemporal causal
inference across a wide range of policy-driven and scientific applications.},
 author = {Miruna Oprescu and David K. Park and Xihaier Luo and Shinjae Yoo and Nathan Kallus},
 comment = {17 pages, 6 figures, 2 tables},
 doi = {},
 eprint = {2502.05295v1},
 journal = {arXiv preprint},
 title = {GST-UNet: Spatiotemporal Causal Inference with Time-Varying Confounders},
 url = {http://arxiv.org/abs/2502.05295v1},
 year = {2025}
}

@article{2502.05363v1,
 abstract = {Epidemiologists increasingly use causal inference methods that rely on
machine learning, as these approaches can relax unnecessary model specification
assumptions. While deriving and studying asymptotic properties of such
estimators is a task usually associated with statisticians, it is useful for
epidemiologists to understand the steps involved, as epidemiologists are often
at the forefront of defining important new research questions and translating
them into new parameters to be estimated. In this paper, our goal was to
provide a relatively accessible guide through the process of (i) deriving an
estimator based on the so-called efficient influence function (which we define
and explain), and (ii) showing such an estimator's ability to validly
incorporate machine learning, by demonstrating the so-called rate double
robustness property. The derivations in this paper rely mainly on algebra and
some foundational results from statistical inference, which are explained.},
 author = {Audrey Renson and Lina Montoya and Dana E. Goin and Iván Díaz and Rachael K. Ross},
 comment = {},
 doi = {},
 eprint = {2502.05363v1},
 journal = {arXiv preprint},
 title = {Pulling back the curtain: the road from statistical estimand to machine-learning based estimator for epidemiologists (no wizard required)},
 url = {http://arxiv.org/abs/2502.05363v1},
 year = {2025}
}

@article{2502.05776v3,
 abstract = {We propose a shape-constrained approach to dynamic pricing for censored data
in the linear valuation model eliminating the need for tuning parameters
commonly required by existing methods. Previous works have addressed the
challenge of unknown market noise distribution $F_0$ using strategies ranging
from kernel methods to reinforcement learning algorithms, such as bandit
techniques and upper confidence bounds (UCB), under the assumption that $F_0$
satisfies Lipschitz (or stronger) conditions. In contrast, our method relies on
isotonic regression under the weaker assumption that $F_0$ is $\alpha$-H\"older
continuous for some $\alpha \in (0,1]$, for which we derive a regret upper
bound. Simulations and experiments with real-world data obtained by Welltower
Inc (a major healthcare Real Estate Investment Trust) consistently demonstrate
that our method attains lower empirical regret in comparison to several
existing methods in the literature while offering the advantage of being
tuning-parameter free.},
 author = {Daniele Bracale and Moulinath Banerjee and Yuekai Sun and Kevin Stoll and Salam Turki},
 comment = {},
 doi = {},
 eprint = {2502.05776v3},
 journal = {arXiv preprint},
 title = {Dynamic Pricing in the Linear Valuation Model using Shape Constraints},
 url = {http://arxiv.org/abs/2502.05776v3},
 year = {2025}
}

@article{2502.06343v2,
 abstract = {In many scientific domains, the cost of data annotation limits the scale and
pace of experimentation. Yet, modern machine learning systems offer a promising
alternative, provided their predictions yield correct conclusions. We focus on
Prediction-Powered Causal Inferences (PPCI), i.e., estimating the treatment
effect in a target experiment with unlabeled factual outcomes, retrievable
zero-shot from a pre-trained model. We first identify the conditional
calibration property to guarantee valid PPCI at population level. Then, we
introduce causal lifting, a new causal lifting constraint transferring validity
across experiments, which we propose to enforce in practice in Deconfounded
Empirical Risk Minimization, our new model-agnostic training objective. We
validate our method on synthetic and real-world scientific data, offering
solutions to instances not solvable by vanilla Empirical Risk Minimization and
invariant training. In particular, we solve zero-shot PPCI on the ISTAnt
dataset for the first time, fine-tuning a foundational model on our replica
dataset of their ecological experiment with a different recording platform and
treatment.},
 author = {Riccardo Cadei and Ilker Demirel and Piersilvio De Bartolomeis and Lukas Lindorfer and Sylvia Cremer and Cordelia Schmid and Francesco Locatello},
 comment = {},
 doi = {},
 eprint = {2502.06343v2},
 journal = {arXiv preprint},
 title = {Causal Lifting of Neural Representations: Zero-Shot Generalization for Causal Inferences},
 url = {http://arxiv.org/abs/2502.06343v2},
 year = {2025}
}

@article{2502.07275v3,
 abstract = {Recent methodological developments have introduced new black-box approaches
to better estimate heterogeneous treatment effects; however, these methods fall
short of providing interpretable characterizations of the underlying
individuals who may be most at risk or benefit most from receiving the
treatment, thereby limiting their practical utility. In this work, we introduce
\textit{causal distillation trees} (CDT) to estimate interpretable subgroups.
CDT allows researchers to fit any machine learning model to estimate the
heterogeneous treatment effect, and then leverages a simple, second-stage
tree-based model to "distill" the estimated treatment effect into meaningful
subgroups. As a result, CDT inherits the improvements in predictive performance
from black-box machine learning models while preserving the interpretability of
a simple decision tree. We derive theoretical guarantees for the consistency of
the estimated subgroups using CDT, and introduce stability-driven diagnostics
for researchers to evaluate the quality of the estimated subgroups. We
illustrate our proposed method on a randomized controlled trial of
antiretroviral treatment for HIV from the AIDS Clinical Trials Group Study 175
and show that CDT out-performs state-of-the-art approaches in constructing
stable, clinically relevant subgroups.},
 author = {Melody Huang and Tiffany M. Tang and Ana M. Kenney},
 comment = {},
 doi = {},
 eprint = {2502.07275v3},
 journal = {arXiv preprint},
 title = {Distilling heterogeneous treatment effects: Stable subgroup estimation in causal inference},
 url = {http://arxiv.org/abs/2502.07275v3},
 year = {2025}
}

@article{2502.08282v2,
 abstract = {Estimating individualised treatment effect (ITE) -- that is the causal effect
of a set of variables (also called exposures, treatments, actions, policies, or
interventions), referred to as \textit{composite treatments}, on a set of
outcome variables of interest, referred to as \textit{composite outcomes}, for
a unit from observational data -- remains a fundamental problem in causal
inference with applications across disciplines, such as healthcare, economics,
education, social science, marketing, and computer science. Previous work in
causal machine learning for ITE estimation is limited to simple settings, like
single treatments and single outcomes. This hinders their use in complex
real-world scenarios; for example, consider studying the effect of different
ICU interventions, such as beta-blockers and statins for a patient admitted for
heart surgery, on different outcomes of interest such as atrial fibrillation
and in-hospital mortality. The limited research into composite treatments and
outcomes is primarily due to data scarcity for all treatments and outcomes. To
address the above challenges, we propose a novel and innovative
hypernetwork-based approach, called \emph{H-Learner}, to solve ITE estimation
under composite treatments and composite outcomes, which tackles the data
scarcity issue by dynamically sharing information across treatments and
outcomes. Our empirical analysis with binary and arbitrary composite treatments
and outcomes demonstrates the effectiveness of the proposed approach compared
to existing methods.},
 author = {Vinod Kumar Chauhan and Lei Clifton and Gaurav Nigam and David A. Clifton},
 comment = {6 pages (double column), 4 figures},
 doi = {},
 eprint = {2502.08282v2},
 journal = {arXiv preprint},
 title = {Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes},
 url = {http://arxiv.org/abs/2502.08282v2},
 year = {2025}
}

@article{2502.08828v2,
 abstract = {Tabular data is one of the most widely used data formats across various
domains such as bioinformatics, healthcare, and marketing. As artificial
intelligence moves towards a data-centric perspective, improving data quality
is essential for enhancing model performance in tabular data-driven
applications. This survey focuses on data-driven tabular data optimization,
specifically exploring reinforcement learning (RL) and generative approaches
for feature selection and feature generation as fundamental techniques for
refining data spaces. Feature selection aims to identify and retain the most
informative attributes, while feature generation constructs new features to
better capture complex data patterns. We systematically review existing
generative methods for tabular data engineering, analyzing their latest
advancements, real-world applications, and respective strengths and
limitations. This survey emphasizes how RL-based and generative techniques
contribute to the automation and intelligence of feature engineering. Finally,
we summarize the existing challenges and discuss future research directions,
aiming to provide insights that drive continued innovation in this field.},
 author = {Wangyang Ying and Cong Wei and Nanxu Gong and Xinyuan Wang and Haoyue Bai and Arun Vignesh Malarkkan and Sixun Dong and Dongjie Wang and Denghui Zhang and Yanjie Fu},
 comment = {},
 doi = {},
 eprint = {2502.08828v2},
 journal = {arXiv preprint},
 title = {A Survey on Data-Centric AI: Tabular Learning from Reinforcement Learning and Generative AI Perspective},
 url = {http://arxiv.org/abs/2502.08828v2},
 year = {2025}
}

@article{2502.10215v2,
 abstract = {Causal reasoning is a core component of intelligence. Large language models
(LLMs) have shown impressive capabilities in generating human-like text,
raising questions about whether their responses reflect true understanding or
statistical patterns. We compared causal reasoning in humans and four LLMs
using tasks based on collider graphs, rating the likelihood of a query variable
occurring given evidence from other variables. LLMs' causal inferences ranged
from often nonsensical (GPT-3.5) to human-like to often more normatively
aligned than those of humans (GPT-4o, Gemini-Pro, and Claude). Computational
model fitting showed that one reason for GPT-4o, Gemini-Pro, and Claude's
superior performance is they didn't exhibit the "associative bias" that plagues
human causal reasoning. Nevertheless, even these LLMs did not fully capture
subtler reasoning patterns associated with collider graphs, such as "explaining
away".},
 author = {Hanna M. Dettki and Brenden M. Lake and Charley M. Wu and Bob Rehder},
 comment = {},
 doi = {},
 eprint = {2502.10215v2},
 journal = {arXiv preprint},
 title = {Do Large Language Models Reason Causally Like Us? Even Better?},
 url = {http://arxiv.org/abs/2502.10215v2},
 year = {2025}
}

@article{2502.10276v2,
 abstract = {Ordinal variables, such as on the Likert scale, are common in applied
research. Yet, existing methods for causal inference tend to target nominal or
continuous data. When applied to ordinal data, this fails to account for the
inherent ordering or imposes well-defined relative magnitudes. Hence, there is
a need for specialised methods to compute interventional effects between
ordinal variables while accounting for their ordinality. One potential
framework is to presume a latent Gaussian Directed Acyclic Graph (DAG) model:
that the ordinal variables originate from marginally discretising a set of
Gaussian variables whose latent covariance matrix is constrained to satisfy the
conditional independencies inherent in a DAG. Conditioned on a given latent
covariance matrix and discretisation thresholds, we derive a closed-form
function for ordinal causal effects in terms of interventional distributions in
the latent space. Our causal estimation combines naturally with algorithms to
learn the latent DAG and its parameters, like the Ordinal Structural EM
algorithm. Simulations demonstrate the applicability of the proposed approach
in estimating ordinal causal effects both for known and unknown structures of
the latent graph. As an illustration of a real-world use case, the method is
applied to survey data of 408 patients from a study on the functional
relationships between symptoms of obsessive-compulsive disorder and depression.},
 author = {Martina Scauda and Jack Kuipers and Giusi Moffa},
 comment = {22 pages, 4 figures (plus 16 pages of appendices)},
 doi = {},
 eprint = {2502.10276v2},
 journal = {arXiv preprint},
 title = {A Latent Causal Inference Framework for Ordinal Variables},
 url = {http://arxiv.org/abs/2502.10276v2},
 year = {2025}
}

@article{2502.10605v2,
 abstract = {Estimating the causal effects of an intervention on outcomes is crucial to
policy and decision-making. But often, information about outcomes can be
missing or subject to non-standard measurement error. It may be possible to
reveal ground-truth outcome information at a cost, for example via data
annotation or follow-up; but budget constraints entail that only a fraction of
the dataset can be labeled. In this setting, we optimize which data points
should be sampled for outcome information and, therefore, efficient average
treatment effect estimation with missing data. We do so by allocating data
annotation in batches. We extend to settings where outcomes may be recorded in
unstructured data that can be annotated at a cost, such as text or images, for
example, in healthcare or social services. Our motivating application is a
collaboration with a street outreach provider with millions of case notes,
where it is possible to expertly label some, but not all, ground-truth
outcomes. We demonstrate how expert labels and noisy imputed labels can be
combined efficiently and responsibly into a doubly robust causal estimator. We
run experiments on simulated data and two real-world datasets, including one on
street outreach interventions in homelessness services, to show the versatility
of our proposed method.},
 author = {Ezinne Nwankwo and Lauri Goldkind and Angela Zhou},
 comment = {},
 doi = {},
 eprint = {2502.10605v2},
 journal = {arXiv preprint},
 title = {Batch-Adaptive Annotations for Causal Inference with Complex-Embedded Outcomes},
 url = {http://arxiv.org/abs/2502.10605v2},
 year = {2025}
}

@article{2502.10732v1,
 abstract = {Deep Reinforcement Learning (RL) is remarkably effective in addressing
sequential resource allocation problems in domains such as healthcare, public
policy, and resource management. However, deep RL policies often lack
transparency and adaptability, challenging their deployment alongside human
decision-makers. In contrast, Language Agents, powered by large language models
(LLMs), provide human-understandable reasoning but may struggle with effective
decision making. To bridge this gap, we propose Rule-Bottleneck Reinforcement
Learning (RBRL), a novel framework that jointly optimizes decision and
explanations. At each step, RBRL generates candidate rules with an LLM, selects
among them using an attention-based RL policy, and determines the environment
action with an explanation via chain-of-thought reasoning. The RL rule
selection is optimized using the environment rewards and an explainability
metric judged by the LLM. Evaluations in real-world scenarios highlight RBRL's
competitive performance with deep RL and efficiency gains over LLM fine-tuning.
A survey further confirms the enhanced quality of its explanations.},
 author = {Mauricio Tec and Guojun Xiong and Haichuan Wang and Francesca Dominici and Milind Tambe},
 comment = {},
 doi = {},
 eprint = {2502.10732v1},
 journal = {arXiv preprint},
 title = {Rule-Bottleneck Reinforcement Learning: Joint Explanation and Decision Optimization for Resource Allocation with Language Agents},
 url = {http://arxiv.org/abs/2502.10732v1},
 year = {2025}
}

@article{2502.12086v3,
 abstract = {Dynamical systems, prevalent in various scientific and engineering domains,
are susceptible to anomalies that can significantly impact their performance
and reliability. This paper addresses the critical challenges of anomaly
detection, root cause localization, and anomaly type classification in
dynamical systems governed by ordinary differential equations (ODEs). We define
two categories of anomalies: cyber anomalies, which propagate through
interconnected variables, and measurement anomalies, which remain localized to
individual variables. To address these challenges, we propose the Interpretable
Causality Ordinary Differential Equation (ICODE) Networks, a model-intrinsic
explainable learning framework. ICODE leverages Neural ODEs for anomaly
detection while employing causality inference through an explanation channel to
perform root cause analysis (RCA), elucidating why specific time periods are
flagged as anomalous. ICODE is designed to simultaneously perform anomaly
detection, RCA, and anomaly type classification within a single, interpretable
framework. Our approach is grounded in the hypothesis that anomalies alter the
underlying ODEs of the system, manifesting as changes in causal relationships
between variables. We provide a theoretical analysis of how perturbations in
learned model parameters can be utilized to identify anomalies and their root
causes in time series data. Comprehensive experimental evaluations demonstrate
the efficacy of ICODE across various dynamical systems, showcasing its ability
to accurately detect anomalies, classify their types, and pinpoint their
origins.},
 author = {Yue Sun and Rick S. Blum and Parv Venkitasubramaniam},
 comment = {Accepted by the AAAI-25 Workshop on Artificial Intelligence for Cyber
  Security (AICS)},
 doi = {},
 eprint = {2502.12086v3},
 journal = {arXiv preprint},
 title = {Unifying Explainable Anomaly Detection and Root Cause Analysis in Dynamical Systems},
 url = {http://arxiv.org/abs/2502.12086v3},
 year = {2025}
}

@article{2502.12393v1,
 abstract = {Estimating treatment effects in time series data presents a significant
challenge, especially when the control group is always unobservable. For
example, in analyzing the effects of Christmas on retail sales, we lack direct
observation of what would have occurred in late December without the Christmas
impact. To address this, we try to recover the control group in the event
period while accounting for confounders and temporal dependencies. Experimental
results on the M5 Walmart retail sales data demonstrate robust estimation of
the potential outcome of the control group as well as accurate predicted
holiday effect. Furthermore, we provided theoretical guarantees for the
estimated treatment effect, proving its consistency and asymptotic normality.
The proposed methodology is applicable not only to this always-missing control
scenario but also in other conventional time series causal inference settings.},
 author = {Juan Shu and Qiyu Han and George Chen and Xihao Cao and Kangming Luo and Dan Pallotta and Shivam Agrawal and Yuping Lu and Xiaoyu Zhang and Jawad Mansoor and Jyoti Anand},
 comment = {},
 doi = {},
 eprint = {2502.12393v1},
 journal = {arXiv preprint},
 title = {Time Series Treatment Effects Analysis with Always-Missing Controls},
 url = {http://arxiv.org/abs/2502.12393v1},
 year = {2025}
}

@article{2502.12599v1,
 abstract = {Autonomous robotic wiping is an important task in various industries, ranging
from industrial manufacturing to sanitization in healthcare. Deep reinforcement
learning (Deep RL) has emerged as a promising algorithm, however, it often
suffers from a high demand for repetitive reward engineering. Instead of
relying on manual tuning, we first analyze the convergence of quality-critical
robotic wiping, which requires both high-quality wiping and fast task
completion, to show the poor convergence of the problem and propose a new
bounded reward formulation to make the problem feasible. Then, we further
improve the learning process by proposing a novel visual-language model (VLM)
based curriculum, which actively monitors the progress and suggests
hyperparameter tuning. We demonstrate that the combined method can find a
desirable wiping policy on surfaces with various curvatures, frictions, and
waypoints, which cannot be learned with the baseline formulation. The demo of
this project can be found at: https://sites.google.com/view/highqualitywiping.},
 author = {Yihong Liu and Dongyeop Kang and Sehoon Ha},
 comment = {},
 doi = {},
 eprint = {2502.12599v1},
 journal = {arXiv preprint},
 title = {Learning a High-quality Robotic Wiping Policy Using Systematic Reward Analysis and Visual-Language Model Based Curriculum},
 url = {http://arxiv.org/abs/2502.12599v1},
 year = {2025}
}

@article{2502.14950v1,
 abstract = {Inferring causal models from observed correlations is a challenging task,
crucial to many areas of science. In order to alleviate the effort, it is
important to know whether symmetries in the observations correspond to
symmetries in the underlying realization. Via an explicit example, we answer
this question in the negative. We use a tripartite probability distribution
over binary events that is realized by using three (different) independent
sources of classical randomness. We prove that even removing the condition that
the sources distribute systems described by classical physics, the requirements
that i) the sources distribute the same physical systems, ii) these physical
systems respect relativistic causality, and iii) the correlations are the
observed ones, are incompatible.},
 author = {Christian William and Patrick Remy and Jean-Daniel Bancal and Yu Cai and Nicolas Brunner and Alejandro Pozas-Kerstjens},
 comment = {8 pages, 4 figures, RevTeX 4.2. The computational appendix is
  available at https://www.github.com/apozas/symmetric-causal},
 doi = {},
 eprint = {2502.14950v1},
 journal = {arXiv preprint},
 title = {Symmetric observations without symmetric causal explanations},
 url = {http://arxiv.org/abs/2502.14950v1},
 year = {2025}
}

@article{2502.14995v1,
 abstract = {Over the last decade, the use of machine learning (ML) approaches in
medicinal applications has increased manifold. Most of these approaches are
based on deep learning, which aims to learn representations from grid data
(like medical images). However, reinforcement learning (RL) applications in
medicine are relatively less explored. Medical applications often involve a
sequence of subtasks that form a diagnostic pipeline, and RL is uniquely suited
to optimize over such sequential decision-making tasks. Ultrasound (US) image
analysis is a quintessential example of such a sequential decision-making task,
where the raw signal captured by the US transducer undergoes a series of signal
processing and image post-processing steps, generally leading to a diagnostic
suggestion. The application of RL in US remains limited. Deep Reinforcement
Learning (DRL), that combines deep learning and RL, holds great promise in
optimizing these pipelines by enabling intelligent and sequential
decision-making. This review paper surveys the applications of RL in US over
the last decade. We provide a succinct overview of the theoretic framework of
RL and its application in US image processing and review existing work in each
aspect of the image analysis pipeline. A comprehensive search of Scopus
filtered on relevance yielded 14 papers most relevant to this topic. These
papers were further categorized based on their target applications image
classification, image segmentation, image enhancement, video summarization, and
auto navigation and path planning. We also examined the type of RL approach
used in each publication. Finally, we discuss key areas in healthcare where DRL
approaches in US could be used for sequential decision-making. We analyze the
opportunities, challenges, and limitations, providing insights into the future
potential of DRL in US image analysis.},
 author = {Maha Ezzelarab and Midhila Madhusoodanan and Shrimanti Ghosh and Geetika Vadali and Jacob Jaremko and Abhilash Hareendranathan},
 comment = {36 pages, 4 figures, 1 table},
 doi = {},
 eprint = {2502.14995v1},
 journal = {arXiv preprint},
 title = {Reinforcement Learning for Ultrasound Image Analysis A Comprehensive Review of Advances and Applications},
 url = {http://arxiv.org/abs/2502.14995v1},
 year = {2025}
}

@article{2502.15838v1,
 abstract = {The expansion of artificial intelligence (AI) has raised concerns about
transparency, accountability, and interpretability, with counterfactual
reasoning emerging as a key approach to addressing these issues. However,
current mathematical, technological, and causal methodologies rely on
externalization techniques that normalize feature relationships within a single
coordinate space, often distorting intrinsic interactions. This study proposes
the Convergent Fusion Paradigm (CFP) theory, a framework integrating
mathematical, technological, and causal perspectives to provide a more precise
and comprehensive analysis of feature relationships. CFP theory introduces
Hilbert space and backward causation to reinterpret the feature relationships
as emergent structures, offering a potential solution to the common cause
problem -- a fundamental challenge in causal modeling. From a mathematical --
technical perspective, it utilizes a Riemannian manifold-based framework,
thereby improving the structural representation of high- and low-dimensional
data interactions. From a causal inference perspective, CFP theory adopts
abduction as a methodological foundation, employing Hilbert space for a dynamic
causal reasoning approach, where causal relationships are inferred abductively,
and feature relationships evolve as emergent properties. Ultimately, CFP theory
introduces a novel AI modeling methodology that integrates Hilbert space,
backward causation, and Riemannian geometry, strengthening AI governance and
transparency in counterfactual reasoning.},
 author = {JaeHong Kim},
 comment = {59 pages, 6 figures, 2 tables},
 doi = {},
 eprint = {2502.15838v1},
 journal = {arXiv preprint},
 title = {A novel approach to the relationships between data features -- based on comprehensive examination of mathematical, technological, and causal methodology},
 url = {http://arxiv.org/abs/2502.15838v1},
 year = {2025}
}

@article{2502.16124v1,
 abstract = {Zero-Input AI (ZIA) introduces a novel framework for human-computer
interaction by enabling proactive intent prediction without explicit user
commands. It integrates gaze tracking, bio-signals (EEG, heart rate), and
contextual data (time, location, usage history) into a multi-modal model for
real-time inference, targeting <100 ms latency. The proposed architecture
employs a transformer-based model with cross-modal attention, variational
Bayesian inference for uncertainty estimation, and reinforcement learning for
adaptive optimization. To support deployment on edge devices (CPUs, TPUs,
NPUs), ZIA utilizes quantization, weight pruning, and linear attention to
reduce complexity from quadratic to linear with sequence length. Theoretical
analysis establishes an information-theoretic bound on prediction error and
demonstrates how multi-modal fusion improves accuracy over single-modal
approaches. Expected performance suggests 85-90% accuracy with EEG integration
and 60-100 ms inference latency. ZIA provides a scalable, privacy-preserving
framework for accessibility, healthcare, and consumer applications, advancing
AI toward anticipatory intelligence.},
 author = {Aditi De and NeuroBits Labs},
 comment = {},
 doi = {},
 eprint = {2502.16124v1},
 journal = {arXiv preprint},
 title = {ZIA: A Theoretical Framework for Zero-Input AI},
 url = {http://arxiv.org/abs/2502.16124v1},
 year = {2025}
}

@article{2502.16172v1,
 abstract = {This paper presents linear DML models for causal inference using the simplest
Python code on a Jupyter notebook based on an Anaconda platform and compares
the performance of different DML models. The results show that current Library
API technology is not yet sufficient to enable novice Python users to build
qualified and high-quality DML models with the simplest coding approach. Novice
users attempting to perform DML causal inference using Python still have to
improve their mathematical and computer knowledge to adapt to more flexible DML
programming. Additionally, the issue of mismatched outcome variable dimensions
is also widespread when building linear DML models in Jupyter notebook.},
 author = {Shunxin Yao},
 comment = {12 pages, 4 tables, 3 figures},
 doi = {},
 eprint = {2502.16172v1},
 journal = {arXiv preprint},
 title = {Practical programming research of Linear DML model based on the simplest Python code: From the standpoint of novice researchers},
 url = {http://arxiv.org/abs/2502.16172v1},
 year = {2025}
}

@article{2502.16195v2,
 abstract = {Reinforcement learning (RL) is concerned with how intelligence agents take
actions in a given environment to maximize the cumulative reward they receive.
In healthcare, applying RL algorithms could assist patients in improving their
health status. In ride-sharing platforms, applying RL algorithms could increase
drivers' income and customer satisfaction. For large language models, applying
RL algorithms could align their outputs with human preferences. Over the past
decade, RL has been arguably one of the most vibrant research frontiers in
machine learning. Nevertheless, statistics as a field, as opposed to computer
science, has only recently begun to engage with RL both in depth and in
breadth. This chapter presents a selective review of statistical inferential
tools for RL, covering both hypothesis testing and confidence interval
construction. Our goal is to highlight the value of statistical inference in RL
for both the statistics and machine learning communities, and to promote the
broader application of classical statistical inference tools in this vibrant
area of research.},
 author = {Chengchun Shi},
 comment = {},
 doi = {},
 eprint = {2502.16195v2},
 journal = {arXiv preprint},
 title = {Statistical Inference in Reinforcement Learning: A Selective Survey},
 url = {http://arxiv.org/abs/2502.16195v2},
 year = {2025}
}

@article{2502.16535v1,
 abstract = {Machine learning algorithms are used in diverse domains, many of which face
significant challenges due to data imbalance. Studies have explored various
approaches to address the issue, like data preprocessing, cost-sensitive
learning, and ensemble methods. Generative Adversarial Networks (GANs) showed
immense potential as a data preprocessing technique that generates good quality
synthetic data. This study employs a systematic mapping methodology to analyze
3041 papers on GAN-based sampling techniques for imbalanced data sourced from
four digital libraries. A filtering process identified 100 key studies spanning
domains such as healthcare, finance, and cybersecurity. Through comprehensive
quantitative analysis, this research introduces three categorization mappings
as application domains, GAN techniques, and GAN variants used to handle the
imbalanced nature of the data. GAN-based over-sampling emerges as an effective
preprocessing method. Advanced architectures and tailored frameworks helped
GANs to improve further in the case of data imbalance. GAN variants like
vanilla GAN, CTGAN, and CGAN show great adaptability in structured imbalanced
data cases. Interest in GANs for imbalanced data has grown tremendously,
touching a peak in recent years, with journals and conferences playing crucial
roles in transmitting foundational theories and practical applications. While
with these advances, none of the reviewed studies explicitly explore hybridized
GAN frameworks with diffusion models or reinforcement learning techniques. This
gap leads to a future research idea develop innovative approaches for
effectively handling data imbalance.},
 author = {Pankaj Yadav and Gulshan Sihag and Vivek Vijay},
 comment = {49 pages, 6 figures},
 doi = {},
 eprint = {2502.16535v1},
 journal = {arXiv preprint},
 title = {Rebalancing the Scales: A Systematic Mapping Study of Generative Adversarial Networks (GANs) in Addressing Data Imbalance},
 url = {http://arxiv.org/abs/2502.16535v1},
 year = {2025}
}

@article{2502.17292v2,
 abstract = {We study regret minimization in repeated first-price auctions (FPAs), where a
bidder observes only the realized outcome after each auction -- win or loss.
This setup reflects practical scenarios in online display advertising where the
actual value of an impression depends on the difference between two potential
outcomes, such as clicks or conversion rates, when the auction is won versus
lost. We analyze three outcome models: (1) adversarial outcomes without
features, (2) linear potential outcomes with features, and (3) linear treatment
effects in features. For each setting, we propose algorithms that jointly
estimate private values and optimize bidding strategies, achieving near-optimal
regret bounds. Notably, our framework enjoys a unique feature that the
treatments are also actively chosen, and hence eliminates the need for the
overlap condition commonly required in causal inference.},
 author = {Yuxiao Wen and Yanjun Han and Zhengyuan Zhou},
 comment = {},
 doi = {},
 eprint = {2502.17292v2},
 journal = {arXiv preprint},
 title = {Joint Value Estimation and Bidding in Repeated First-Price Auctions},
 url = {http://arxiv.org/abs/2502.17292v2},
 year = {2025}
}

@article{2502.17814v1,
 abstract = {Large Language Models (LLMs) have emerged as transformative tools in
artificial intelligence (AI), exhibiting remarkable capabilities across diverse
tasks such as text generation, reasoning, and decision-making. While their
success has primarily been driven by advances in computational power and deep
learning architectures, emerging problems -- in areas such as uncertainty
quantification, decision-making, causal inference, and distribution shift --
require a deeper engagement with the field of statistics. This paper explores
potential areas where statisticians can make important contributions to the
development of LLMs, particularly those that aim to engender trustworthiness
and transparency for human users. Thus, we focus on issues such as uncertainty
quantification, interpretability, fairness, privacy, watermarking and model
adaptation. We also consider possible roles for LLMs in statistical analysis.
By bridging AI and statistics, we aim to foster a deeper collaboration that
advances both the theoretical foundations and practical applications of LLMs,
ultimately shaping their role in addressing complex societal challenges.},
 author = {Wenlong Ji and Weizhe Yuan and Emily Getzen and Kyunghyun Cho and Michael I. Jordan and Song Mei and Jason E Weston and Weijie J. Su and Jing Xu and Linjun Zhang},
 comment = {},
 doi = {},
 eprint = {2502.17814v1},
 journal = {arXiv preprint},
 title = {An Overview of Large Language Models for Statisticians},
 url = {http://arxiv.org/abs/2502.17814v1},
 year = {2025}
}

@article{2502.18960v2,
 abstract = {Long-term causal inference has drawn increasing attention in many scientific
domains. Existing methods mainly focus on estimating average long-term causal
effects by combining long-term observational data and short-term experimental
data. However, it is still understudied how to robustly and effectively
estimate heterogeneous long-term causal effects, significantly limiting
practical applications. In this paper, we propose several two-stage style
nonparametric estimators for heterogeneous long-term causal effect estimation,
including propensity-based, regression-based, and multiple robust estimators.
We conduct a comprehensive theoretical analysis of their asymptotic properties
under mild assumptions, with the ultimate goal of building a better
understanding of the conditions under which some estimators can be expected to
perform better. Extensive experiments across several semi-synthetic and
real-world datasets validate the theoretical results and demonstrate the
effectiveness of the proposed estimators.},
 author = {Weilin Chen and Ruichu Cai and Junjie Wan and Zeqin Yang and José Miguel Hernández-Lobato},
 comment = {},
 doi = {},
 eprint = {2502.18960v2},
 journal = {arXiv preprint},
 title = {Nonparametric Heterogeneous Long-term Causal Effect Estimation via Data Combination},
 url = {http://arxiv.org/abs/2502.18960v2},
 year = {2025}
}

@article{2502.18994v2,
 abstract = {Long-term causal inference is an important but challenging problem across
various scientific domains. To solve the latent confounding problem in
long-term observational studies, existing methods leverage short-term
experimental data. Ghassami et al. propose an approach based on the Conditional
Additive Equi-Confounding Bias (CAECB) assumption, which asserts that the
confounding bias in the short-term outcome is equal to that in the long-term
outcome, so that the long-term confounding bias and the causal effects can be
identified. While effective in certain cases, this assumption is limited to
scenarios where there is only one short-term outcome with the same scale as the
long-term outcome. In this paper, we introduce a novel assumption that extends
the CAECB assumption to accommodate temporal short-term outcomes. Our proposed
assumption states a functional relationship between sequential confounding
biases across temporal short-term outcomes, under which we theoretically
establish the identification of long-term causal effects. Based on the
identification result, we develop an estimator and conduct a theoretical
analysis of its asymptotic properties. Extensive experiments validate our
theoretical results and demonstrate the effectiveness of the proposed method.},
 author = {Weilin Chen and Ruichu Cai and Yuguang Yan and Zhifeng Hao and José Miguel Hernández-Lobato},
 comment = {},
 doi = {},
 eprint = {2502.18994v2},
 journal = {arXiv preprint},
 title = {Long-term Causal Inference via Modeling Sequential Latent Confounding},
 url = {http://arxiv.org/abs/2502.18994v2},
 year = {2025}
}

@article{2502.19625v2,
 abstract = {Machine learning systems trained on electronic health records (EHRs)
increasingly guide treatment decisions, but their reliability depends on the
critical assumption that patients follow the prescribed treatments recorded in
EHRs. Using EHR data from 3,623 hypertension patients, we investigate how
treatment non-adherence introduces implicit bias that can fundamentally distort
both causal inference and predictive modeling. By extracting patient adherence
information from clinical notes using a large language model (LLM), we identify
786 patients (21.7%) with medication non-adherence. We further uncover key
demographic and clinical factors associated with non-adherence, as well as
patient-reported reasons including side effects and difficulties obtaining
refills. Our findings demonstrate that this implicit bias can not only reverse
estimated treatment effects, but also degrade model performance by up to 5%
while disproportionately affecting vulnerable populations by exacerbating
disparities in decision outcomes and model error rates. This highlights the
importance of accounting for treatment non-adherence in developing responsible
and equitable clinical machine learning systems.},
 author = {Zhongyuan Liang and Arvind Suresh and Irene Y. Chen},
 comment = {},
 doi = {},
 eprint = {2502.19625v2},
 journal = {arXiv preprint},
 title = {Revealing Treatment Non-Adherence Bias in Clinical Machine Learning Using Large Language Models},
 url = {http://arxiv.org/abs/2502.19625v2},
 year = {2025}
}

@article{2502.19788v3,
 abstract = {The triple difference causal inference framework is an extension of the
well-known difference-in-differences framework. It relaxes the parallel trends
assumption of the difference-in-differences framework through leveraging data
from an auxiliary domain. Despite being commonly applied in empirical research,
the triple difference framework has received relatively limited attention in
the statistics literature. Specifically, investigating the intricacies of
identification and the design of robust and efficient estimators for this
framework has remained largely unexplored. This work aims to address these gaps
in the literature. From the identification standpoint, we present outcome
regression and weighting methods to identify the average treatment effect on
the treated in both panel data and repeated cross-section settings. For the
latter, we relax the commonly made assumption of time-invariant composition of
units. From the estimation perspective, we develop semiparametric estimators
for the triple difference framework in both panel data and repeated
cross-sections settings. These estimators are based on the cross-fitting
technique, and flexible machine learning tools can be used to estimate the
nuisance components. We characterize conditions under which our proposed
estimators are efficient, doubly robust, root-n consistent and asymptotically
normal. As an application of our proposed methodology, we examined the effect
of mandated maternity benefits on the hourly wages of women of childbearing age
and found that these mandates result in a 2.6% drop in hourly wages.},
 author = {Sina Akbari and Negar Kiyavash and AmirEmad Ghassami},
 comment = {59 pages},
 doi = {},
 eprint = {2502.19788v3},
 journal = {arXiv preprint},
 title = {Semiparametric Triple Difference Estimators},
 url = {http://arxiv.org/abs/2502.19788v3},
 year = {2025}
}

@article{2502.19898v1,
 abstract = {This study utilizes a simulated dataset to establish Python code for Double
Machine Learning (DML) using Anaconda's Jupyter Notebook and the DML software
package from GitHub. The research focuses on causal inference experiments for
both binary and continuous treatment variables. The findings reveal that the
DML model demonstrates relatively stable performance in calculating the Average
Treatment Effect (ATE) and its robustness metrics. However, the study also
highlights that the computation of Conditional Average Treatment Effect (CATE)
remains a significant challenge for future DML modeling, particularly in the
context of continuous treatment variables. This underscores the need for
further research and development in this area to enhance the model's
applicability and accuracy.},
 author = {Shunxin Yao},
 comment = {10 pages, 5 tables and 2 figures},
 doi = {},
 eprint = {2502.19898v1},
 journal = {arXiv preprint},
 title = {Economic Causal Inference Based on DML Framework: Python Implementation of Binary and Continuous Treatment Variables},
 url = {http://arxiv.org/abs/2502.19898v1},
 year = {2025}
}

@article{2502.20153v1,
 abstract = {Transferring knowledge from one environment to another is an essential
ability of intelligent systems. Nevertheless, when two environments are
different, naively transferring all knowledge may deteriorate the performance,
a phenomenon known as negative transfer. In this paper, we address this issue
within the framework of multi-armed bandits from the perspective of causal
inference. Specifically, we consider transfer learning in latent contextual
bandits, where the actual context is hidden, but a potentially high-dimensional
proxy is observable. We further consider a covariate shift in the context
across environments. We show that naively transferring all knowledge for
classical bandit algorithms in this setting led to negative transfer. We then
leverage transportability theory from causal inference to develop algorithms
that explicitly transfer effective knowledge for estimating the causal effects
of interest in the target environment. Besides, we utilize variational
autoencoders to approximate causal effects under the presence of a
high-dimensional proxy. We test our algorithms on synthetic and semi-synthetic
datasets, empirically demonstrating consistently improved learning efficiency
across different proxies compared to baseline algorithms, showing the
effectiveness of our causal framework in transferring knowledge.},
 author = {Mingwei Deng and Ville Kyrki and Dominik Baumann},
 comment = {Accepted at the Conference of Causal Learning and Reasoning (CLeaR
  2025), will be published in the Proceedings of Machine Learning Research},
 doi = {},
 eprint = {2502.20153v1},
 journal = {arXiv preprint},
 title = {Transfer Learning in Latent Contextual Bandits with Covariate Shift Through Causal Transportability},
 url = {http://arxiv.org/abs/2502.20153v1},
 year = {2025}
}

@article{2503.00326v1,
 abstract = {BART (Bayesian additive regression trees) has been established as a leading
supervised learning method, particularly in the field of causal inference. This
paper explores the use of BART models for learning conditional average
treatment effects (CATE) from regression discontinuity designs, where treatment
assignment is based on whether an observed covariate (called the running
variable) exceeds a pre-specified threshold. A purpose-built version of BART
that uses linear regression leaf models (of the running variable and treatment
assignment dummy) is shown to out-perform off-the-shelf BART implementations as
well as a local polynomial regression approach and a CART-based approach. The
new method is evaluated in thorough simulation studies as well as an empirical
application looking at the effect of academic probation on student performance.},
 author = {Rafael Alcantara and P. Richard Hahn and Carlos Carvalho and Hedibert Lopes},
 comment = {},
 doi = {},
 eprint = {2503.00326v1},
 journal = {arXiv preprint},
 title = {Learning Conditional Average Treatment Effects in Regression Discontinuity Designs using Bayesian Additive Regression Trees},
 url = {http://arxiv.org/abs/2503.00326v1},
 year = {2025}
}

@article{2503.00725v1,
 abstract = {We propose a machine-learning tool that yields causal inference on text in
randomized trials. Based on a simple econometric framework in which text may
capture outcomes of interest, our procedure addresses three questions: First,
is the text affected by the treatment? Second, which outcomes is the effect on?
And third, how complete is our description of causal effects? To answer all
three questions, our approach uses large language models (LLMs) that suggest
systematic differences across two groups of text documents and then provides
valid inference based on costly validation. Specifically, we highlight the need
for sample splitting to allow for statistical validation of LLM outputs, as
well as the need for human labeling to validate substantive claims about how
documents differ across groups. We illustrate the tool in a proof-of-concept
application using abstracts of academic manuscripts.},
 author = {Iman Modarressi and Jann Spiess and Amar Venugopal},
 comment = {},
 doi = {},
 eprint = {2503.00725v1},
 journal = {arXiv preprint},
 title = {Causal Inference on Outcomes Learned from Text},
 url = {http://arxiv.org/abs/2503.00725v1},
 year = {2025}
}

@article{2503.00730v1,
 abstract = {This work bridges the gap between staggered adoption designs and survival
analysis to estimate causal effects in settings with time-varying treatments,
addressing a fundamental challenge in medical research exemplified by the
Stanford Heart Transplant study. In medical interventions, particularly organ
transplantation, the timing of treatment varies significantly across patients
due to factors such as donor availability and patient readiness, introducing
potential bias in treatment effect estimation if not properly accounted for. We
identify conditions under which staggered adoption assumptions can justify the
use of survival analysis techniques for causal inference with time-varying
treatments. By establishing this connection, we enable the use of existing
survival analysis methods while maintaining causal interpretability.
Furthermore, we enhance estimation performance by incorporating double machine
learning methods, improving efficiency when handling complex relationships
between patient characteristics and survival outcomes. Through both simulation
studies and application to heart transplant data, our approach demonstrates
superior performance compared to traditional methods, reducing bias and
offering theoretical guarantees for improved efficiency in survival analysis
settings.},
 author = {Xiang Meng and Iavor Bojinov},
 comment = {34 pages main text, 19 pages appendix + reference, 4 figures},
 doi = {},
 eprint = {2503.00730v1},
 journal = {arXiv preprint},
 title = {Time-Varying Causal Survival Learning},
 url = {http://arxiv.org/abs/2503.00730v1},
 year = {2025}
}

@article{2503.01290v2,
 abstract = {Predicting the distribution of outcomes under hypothetical interventions is
crucial across healthcare, economics, and policy-making. However, existing
methods often require restrictive assumptions, and are typically limited by the
lack of amortization across problem instances. We propose ACTIVA, a
transformer-based conditional variational autoencoder (VAE) architecture for
amortized causal inference, which estimates interventional distributions
directly from observational data without. ACTIVA learns a latent representation
conditioned on observational inputs and intervention queries, enabling
zero-shot inference by amortizing causal knowledge from diverse training
scenarios. We provide theoretical insights showing that ACTIVA predicts
interventional distributions as mixtures over observationally equivalent causal
models. Empirical evaluations on synthetic and semi-synthetic datasets confirm
the effectiveness of our amortized approach and highlight promising directions
for future real-world applications.},
 author = {Andreas Sauter and Saber Salehkaleybar and Aske Plaat and Erman Acar},
 comment = {},
 doi = {},
 eprint = {2503.01290v2},
 journal = {arXiv preprint},
 title = {ACTIVA: Amortized Causal Effect Estimation via Transformer-based Variational Autoencoder},
 url = {http://arxiv.org/abs/2503.01290v2},
 year = {2025}
}

@article{2503.01722v1,
 abstract = {In causal inference, interference refers to the phenomenon in which the
actions of peers in a network can influence an individual's outcome. Peer
effect refers to the difference in counterfactual outcomes of an individual for
different levels of peer exposure, the extent to which an individual is exposed
to the treatments, actions, or behaviors of peers. Estimating peer effects
requires deciding how to represent peer exposure. Typically, researchers define
an exposure mapping function that aggregates peer treatments and outputs peer
exposure. Most existing approaches for defining exposure mapping functions
assume peer exposure based on the number or fraction of treated peers. Recent
studies have investigated more complex functions of peer exposure which capture
that different peers can exert different degrees of influence. However, none of
these works have explicitly considered the problem of automatically learning
the exposure mapping function. In this work, we focus on learning this function
for the purpose of estimating heterogeneous peer effects, where heterogeneity
refers to the variation in counterfactual outcomes for the same peer exposure
but different individual's contexts. We develop EgoNetGNN, a graph neural
network (GNN)-based method, to automatically learn the appropriate exposure
mapping function allowing for complex peer influence mechanisms that, in
addition to peer treatments, can involve the local neighborhood structure and
edge attributes. We show that GNN models that use peer exposure based on the
number or fraction of treated peers or learn peer exposure naively face
difficulty accounting for such influence mechanisms. Our comprehensive
evaluation on synthetic and semi-synthetic network data shows that our method
is more robust to different unknown underlying influence mechanisms when
estimating heterogeneous peer effects when compared to state-of-the-art
baselines.},
 author = {Shishir Adhikari and Sourav Medya and Elena Zheleva},
 comment = {},
 doi = {},
 eprint = {2503.01722v1},
 journal = {arXiv preprint},
 title = {Learning Exposure Mapping Functions for Inferring Heterogeneous Peer Effects},
 url = {http://arxiv.org/abs/2503.01722v1},
 year = {2025}
}

@article{2503.03797v1,
 abstract = {This research introduces a novel AI techniques as Mixture-of-Experts
Transformers with Group Relative Policy Optimization (GRPO) for voice health
care applications on voice pathology detection. With the architectural
innovations, we adopt advanced training paradigms inspired by reinforcement
learning, namely Proximal Policy Optimization (PPO) and Group-wise Regularized
Policy Optimization (GRPO), to enhance model stability and performance.
Experiments conducted on a synthetically generated voice pathology dataset
demonstrate that our proposed models significantly improve diagnostic accuracy,
F1 score, and ROC-AUC compared to conventional approaches. These findings
underscore the potential of integrating transformer architectures with novel
training strategies to advance automated voice pathology detection and
ultimately contribute to more effective healthcare delivery. The code we used
to train and evaluate our models is available at
https://github.com/enkhtogtokh/voicegrpo},
 author = {Enkhtogtokh Togootogtokh and Christian Klasen},
 comment = {},
 doi = {},
 eprint = {2503.03797v1},
 journal = {arXiv preprint},
 title = {VoiceGRPO: Modern MoE Transformers with Group Relative Policy Optimization GRPO for AI Voice Health Care Applications on Voice Pathology Detection},
 url = {http://arxiv.org/abs/2503.03797v1},
 year = {2025}
}

@article{2503.05024v4,
 abstract = {We propose causal effect estimators based on empirical Fr\'{e}chet means and
operator-valued kernels, tailored to functional data spaces. These methods
address the challenges of high-dimensionality, sequential ordering, and model
complexity while preserving robustness to treatment misspecification. Using
structural assumptions, we obtain compact representations of potential
outcomes, enabling scalable estimation of causal effects over time and across
covariates. We provide both theoretical, regarding the consistency of
functional causal effects, as well as empirical comparison of a range of
proposed causal effect estimators.
  Applications to binary treatment settings with functional outcomes illustrate
the framework's utility in biomedical monitoring, where outcomes exhibit
complex temporal dynamics. Our estimators accommodate scenarios with registered
covariates and outcomes, aligning them to the Fr\'{e}chet means, as well as
cases requiring higher-order representations to capture intricate
covariate-outcome interactions. These advancements extend causal inference to
dynamic and non-linear domains, offering new tools for understanding complex
treatment effects in functional data settings.},
 author = {Yordan P. Raykov and Hengrui Luo and Justin D. Strait and Wasiur R. KhudaBukhsh},
 comment = {Code is available at
  https://github.com/JordanRaykov/Kernel-based-estimators-for-Functional-Causal-Effects},
 doi = {},
 eprint = {2503.05024v4},
 journal = {arXiv preprint},
 title = {Kernel-based estimators for functional causal effects},
 url = {http://arxiv.org/abs/2503.05024v4},
 year = {2025}
}

@article{2503.05321v2,
 abstract = {Riemannian metric learning is an emerging field in machine learning,
unlocking new ways to encode complex data structures beyond traditional
distance metric learning. While classical approaches rely on global distances
in Euclidean space, they often fall short in capturing intrinsic data geometry.
Enter Riemannian metric learning: a powerful generalization that leverages
differential geometry to model the data according to their underlying
Riemannian manifold. This approach has demonstrated remarkable success across
diverse domains, from causal inference and optimal transport to generative
modeling and representation learning. In this review, we bridge the gap between
classical metric learning and Riemannian geometry, providing a structured and
accessible overview of key methods, applications, and recent advances. We argue
that Riemannian metric learning is not merely a technical refinement but a
fundamental shift in how we think about data representations. Thus, this review
should serve as a valuable resource for researchers and practitioners
interested in exploring Riemannian metric learning and convince them that it is
closer to them than they might imagine-both in theory and in practice.},
 author = {Samuel Gruffaz and Josua Sassen},
 comment = {},
 doi = {},
 eprint = {2503.05321v2},
 journal = {arXiv preprint},
 title = {A Review on Riemannian Metric Learning: Closer to You than You Imagine},
 url = {http://arxiv.org/abs/2503.05321v2},
 year = {2025}
}

@article{2503.05985v1,
 abstract = {Causal inference and the estimation of causal effects plays a central role in
decision-making across many areas, including healthcare and economics.
Estimating causal effects typically requires an estimator that is tailored to
each problem of interest. But developing estimators can take significant effort
for even a single causal inference setting. For example, algorithms for
regression-based estimators, propensity score methods, and doubly robust
methods were designed across several decades to handle causal estimation with
observed confounders. Similarly, several estimators have been developed to
exploit instrumental variables (IVs), including two-stage least-squares (TSLS),
control functions, and the method-of-moments. In this work, we instead frame
causal inference as a dataset-level prediction problem, offloading algorithm
design to the learning process. The approach we introduce, called black box
causal inference (BBCI), builds estimators in a black-box manner by learning to
predict causal effects from sampled dataset-effect pairs. We demonstrate
accurate estimation of average treatment effects (ATEs) and conditional average
treatment effects (CATEs) with BBCI across several causal inference problems
with known identification, including problems with less developed estimators.},
 author = {Lucius E. J. Bynum and Aahlad Manas Puli and Diego Herrero-Quevedo and Nhi Nguyen and Carlos Fernandez-Granda and Kyunghyun Cho and Rajesh Ranganath},
 comment = {},
 doi = {},
 eprint = {2503.05985v1},
 journal = {arXiv preprint},
 title = {Black Box Causal Inference: Effect Estimation via Meta Prediction},
 url = {http://arxiv.org/abs/2503.05985v1},
 year = {2025}
}

@article{2503.06463v1,
 abstract = {As cannabis use has increased in recent years, researchers have come to rely
on sophisticated machine learning models to predict cannabis use behavior and
its impact on health. However, many artificial intelligence (AI) models lack
transparency and interpretability due to their opaque nature, limiting their
trust and adoption in real-world medical applications, such as clinical
decision support systems (CDSS). To address this issue, this paper enhances
algorithm explainability underlying CDSS by integrating multiple Explainable
Artificial Intelligence (XAI) methods and applying causal inference techniques
to clarify the model' predictive decisions under various scenarios. By
providing deeper interpretability of the XAI outputs using Large Language
Models (LLMs), we provide users with more personalized and accessible insights
to overcome the challenges posed by AI's "black box" nature. Our system
dynamically adjusts feedback based on user queries and emotional states,
combining text-based sentiment analysis with real-time facial emotion
recognition to ensure responses are empathetic, context-adaptive, and
user-centered. This approach bridges the gap between the learning demands of
interpretability and the need for intuitive understanding, enabling
non-technical users such as clinicians and clinical researchers to interact
effectively with AI models.} Ultimately, this approach improves usability,
enhances perceived trustworthiness, and increases the impact of CDSS in
healthcare applications.},
 author = {Tongze Zhang and Tammy Chung and Anind Dey and Sang Won Bae},
 comment = {},
 doi = {},
 eprint = {2503.06463v1},
 journal = {arXiv preprint},
 title = {AXAI-CDSS : An Affective Explainable AI-Driven Clinical Decision Support System for Cannabis Use},
 url = {http://arxiv.org/abs/2503.06463v1},
 year = {2025}
}

@article{2503.06690v1,
 abstract = {Dynamic Treatment Regimes (DTRs) provide a systematic approach for making
sequential treatment decisions that adapt to individual patient
characteristics, particularly in clinical contexts where survival outcomes are
of interest. Censoring-Aware Tree-Based Reinforcement Learning (CA-TRL) is a
novel framework to address the complexities associated with censored data when
estimating optimal DTRs. We explore ways to learn effective DTRs, from
observational data. By enhancing traditional tree-based reinforcement learning
methods with augmented inverse probability weighting (AIPW) and censoring-aware
modifications, CA-TRL delivers robust and interpretable treatment strategies.
We demonstrate its effectiveness through extensive simulations and real-world
applications using the SANAD epilepsy dataset, where it outperformed the
recently proposed ASCL method in key metrics such as restricted mean survival
time (RMST) and decision-making accuracy. This work represents a step forward
in advancing personalized and data-driven treatment strategies across diverse
healthcare settings.},
 author = {Animesh Kumar Paul and Russell Greiner},
 comment = {},
 doi = {},
 eprint = {2503.06690v1},
 journal = {arXiv preprint},
 title = {Censoring-Aware Tree-Based Reinforcement Learning for Estimating Dynamic Treatment Regimes with Censored Outcomes},
 url = {http://arxiv.org/abs/2503.06690v1},
 year = {2025}
}

@article{2503.07664v2,
 abstract = {The Antibiotic Resistance Microbiology Dataset (ARMD) is a de-identified
resource derived from electronic health records (EHR) that facilitates research
in antimicrobial resistance (AMR). ARMD encompasses big data from adult
patients collected from over 15 years at two academic-affiliated hospitals,
focusing on microbiological cultures, antibiotic susceptibilities, and
associated clinical and demographic features. Key attributes include organism
identification, susceptibility patterns for 55 antibiotics, implied
susceptibility rules, and de-identified patient information. This dataset
supports studies on antimicrobial stewardship, causal inference, and clinical
decision-making. ARMD is designed to be reusable and interoperable, promoting
collaboration and innovation in combating AMR. This paper describes the
dataset's acquisition, structure, and utility while detailing its
de-identification process.},
 author = {Fateme Nateghi Haredasht and Fatemeh Amrollahi and Manoj Maddali and Nicholas Marshall and Stephen P. Ma and Lauren N. Cooper and Andrew O. Johnson and Ziming Wei and Richard J. Medford and Sanjat Kanjilal and Niaz Banaei and Stanley Deresinski and Mary K. Goldstein and Steven M. Asch and Amy Chang and Jonathan H. Chen},
 comment = {},
 doi = {},
 eprint = {2503.07664v2},
 journal = {arXiv preprint},
 title = {Antibiotic Resistance Microbiology Dataset (ARMD): A Resource for Antimicrobial Resistance from EHRs},
 url = {http://arxiv.org/abs/2503.07664v2},
 year = {2025}
}

@article{2503.08961v1,
 abstract = {Single-player contextual bandits are a well-studied problem in reinforcement
learning that has seen applications in various fields such as advertising,
healthcare, and finance. In light of the recent work on \emph{information
asymmetric} bandits \cite{chang2022online, chang2023online}, we propose a novel
multiplayer information asymmetric contextual bandit framework where there are
multiple players each with their own set of actions. At every round, they
observe the same context vectors and simultaneously take an action from their
own set of actions, giving rise to a joint action. However, upon taking this
action the players are subjected to information asymmetry in (1) actions and/or
(2) rewards. We designed an algorithm \texttt{LinUCB} by modifying the
classical single-player algorithm \texttt{LinUCB} in \cite{chu2011contextual}
to achieve the optimal regret $O(\sqrt{T})$ when only one kind of asymmetry is
present. We then propose a novel algorithm \texttt{ETC} that is built on
explore-then-commit principles to achieve the same optimal regret when both
types of asymmetry are present.},
 author = {William Chang and Yuanhao Lu},
 comment = {},
 doi = {},
 eprint = {2503.08961v1},
 journal = {arXiv preprint},
 title = {Multiplayer Information Asymmetric Contextual Bandits},
 url = {http://arxiv.org/abs/2503.08961v1},
 year = {2025}
}

@article{2503.09833v1,
 abstract = {The arrival of Machine Learning (ML) completely changed how we can unlock
valuable information from data. Traditional methods, where everything was
stored in one place, had big problems with keeping information private,
handling large amounts of data, and avoiding unfair advantages. Machine
Learning has become a powerful tool that uses Artificial Intelligence (AI) to
overcome these challenges. We started by learning the basics of Machine
Learning, including the different types like supervised, unsupervised, and
reinforcement learning. We also explored the important steps involved, such as
preparing the data, choosing the right model, training it, and then checking
its performance. Next, we examined some key challenges in Machine Learning,
such as models learning too much from specific examples (overfitting), not
learning enough (underfitting), and reflecting biases in the data used. Moving
beyond centralized systems, we looked at decentralized Machine Learning and its
benefits, like keeping data private, getting answers faster, and using a wider
variety of data sources. We then focused on a specific type called federated
learning, where models are trained without directly sharing sensitive
information. Real-world examples from healthcare and finance were used to show
how collaborative Machine Learning can solve important problems while still
protecting information security. Finally, we discussed challenges like
communication efficiency, dealing with different types of data, and security.
We also explored using a Zero Trust framework, which provides an extra layer of
protection for collaborative Machine Learning systems. This approach is paving
the way for a bright future for this groundbreaking technology.},
 author = {Sarwar Saif and Md Jahirul Islam and Md. Zihad Bin Jahangir and Parag Biswas and Abdur Rashid and MD Abdullah Al Nasim and Kishor Datta Gupta},
 comment = {},
 doi = {},
 eprint = {2503.09833v1},
 journal = {arXiv preprint},
 title = {A Comprehensive Review on Understanding the Decentralized and Collaborative Approach in Machine Learning},
 url = {http://arxiv.org/abs/2503.09833v1},
 year = {2025}
}

@article{2503.11684v1,
 abstract = {One of the primary goals of Human-Robot Interaction (HRI) research is to
develop robots that can interpret human behavior and adapt their responses
accordingly. Adaptive learning models, such as continual and reinforcement
learning, play a crucial role in improving robots' ability to interact
effectively in real-world settings. However, these models face significant
challenges due to the limited availability of real-world data, particularly in
sensitive domains like healthcare and well-being. This data scarcity can hinder
a robot's ability to adapt to new situations. To address these challenges,
causality provides a structured framework for understanding and modeling the
underlying relationships between actions, events, and outcomes. By moving
beyond mere pattern recognition, causality enables robots to make more
explainable and generalizable decisions. This paper presents an exploratory
causality-based analysis through a case study of an adaptive robotic coach
delivering positive psychology exercises over four weeks in a workplace
setting. The robotic coach autonomously adapts to multimodal human behaviors,
such as facial valence and speech duration. By conducting both macro- and
micro-level causal analyses, this study aims to gain deeper insights into how
adaptability can enhance well-being during interactions. Ultimately, this
research seeks to advance our understanding of how causality can help overcome
challenges in HRI, particularly in real-world applications.},
 author = {Micol Spitale and Srikar Babu and Serhan Cakmak and Jiaee Cheong and Hatice Gunes},
 comment = {},
 doi = {},
 eprint = {2503.11684v1},
 journal = {arXiv preprint},
 title = {Exploring Causality for HRI: A Case Study on Robotic Mental Well-being Coaching},
 url = {http://arxiv.org/abs/2503.11684v1},
 year = {2025}
}

@article{2503.11989v2,
 abstract = {Large Language Models (LLMs) have revolutionized natural language processing
through their state of art reasoning capabilities. This paper explores the
convergence of LLM reasoning techniques and feature generation for machine
learning tasks. We examine four key reasoning approaches: Chain of Thought,
Tree of Thoughts, Retrieval-Augmented Generation, and Thought Space
Exploration. Our analysis reveals how these approaches can be used to identify
effective feature generation rules without having to manually specify search
spaces. The paper categorizes LLM-based feature generation methods across
various domains including finance, healthcare, and text analytics. LLMs can
extract key information from clinical notes and radiology reports in
healthcare, by enabling more efficient data utilization. In finance, LLMs
facilitate text generation, summarization, and entity extraction from complex
documents. We analyze evaluation methodologies for assessing feature quality
and downstream performance, with particular attention to OCTree's decision tree
reasoning approach that provides language-based feedback for iterative
improvements. Current challenges include hallucination, computational
efficiency, and domain adaptation. As of March 2025, emerging approaches
include inference-time compute scaling, reinforcement learning, and supervised
fine-tuning with model distillation. Future directions point toward multimodal
feature generation, self-improving systems, and neuro-symbolic approaches. This
paper provides a detailed overview of an emerging field that promises to
automate and enhance feature engineering through language model reasoning.},
 author = {Dharani Chandra},
 comment = {I just updated the format of the references in the paper},
 doi = {},
 eprint = {2503.11989v2},
 journal = {arXiv preprint},
 title = {Applications of Large Language Model Reasoning in Feature Generation},
 url = {http://arxiv.org/abs/2503.11989v2},
 year = {2025}
}

@article{2503.12330v1,
 abstract = {Metabolism plays a crucial role in sleep regulation, yet its effects are
challenging to track in real time. This study introduces a machine
learning-based framework to analyze sleep patterns and identify how metabolic
changes influence sleep at specific time points. We first established that
sleep periods in Drosophila melanogaster function independently, with no causal
relationship between different sleep episodes. Using gradient boosting models
and explainable artificial intelligence techniques, we quantified the influence
of time-dependent sleep features. Causal inference and autocorrelation analyses
further confirmed that sleep states at different times are statistically
independent, providing a robust foundation for exploring metabolic effects on
sleep. Applying this framework to flies with altered monocarboxylate
transporter 2 expression, we found that changes in ketone transport modified
sleep stability and disrupted transitions between day and night sleep. In an
Alzheimers disease model, metabolic interventions such as beta hydroxybutyrate
supplementation and intermittent fasting selectively influenced the timing of
day to night transitions rather than uniformly altering sleep duration.
Autoencoder based similarity scoring and wavelet analysis reinforced that
metabolic effects on sleep were highly time dependent. This study presents a
novel approach to studying sleep-metabolism interactions, revealing that
metabolic states exert their strongest influence at distinct time points,
shaping sleep stability and circadian transitions.},
 author = {Hao Huang and Kaijing Xu and Michael Lardelli},
 comment = {},
 doi = {},
 eprint = {2503.12330v1},
 journal = {arXiv preprint},
 title = {Computational identification of ketone metabolism as a key regulator of sleep stability and circadian dynamics via real-time metabolic profiling},
 url = {http://arxiv.org/abs/2503.12330v1},
 year = {2025}
}

@article{2503.12784v1,
 abstract = {Variable selection poses a significant challenge in causal modeling,
particularly within the social sciences, where constructs often rely on
inter-related factors such as age, socioeconomic status, gender, and race.
Indeed, it has been argued that such attributes must be modeled as macro-level
abstractions of lower-level manipulable features, in order to preserve the
modularity assumption essential to causal inference. This paper accordingly
extends the theoretical framework of Causal Feature Learning (CFL).
Empirically, we apply the CFL algorithm to diverse social science datasets,
evaluating how CFL-derived macrostates compare with traditional microstates in
downstream modeling tasks.},
 author = {Jingzhou Huang and Jiuyao Lu and Alexander Williams Tolbert},
 comment = {},
 doi = {},
 eprint = {2503.12784v1},
 journal = {arXiv preprint},
 title = {Causal Feature Learning in the Social Sciences},
 url = {http://arxiv.org/abs/2503.12784v1},
 year = {2025}
}

@article{2503.13485v1,
 abstract = {Deep learning has had a great impact on various fields of computer science by
enabling data-driven representation learning in a decade. Because science and
technology policy decisions for a nation can be made on the impact of each
technology, quantifying research impact is an important task. The number of
citations and impact factor can be used to measure the impact for individual
research. What would have happened without the research, however, is
fundamentally a counterfactual phenomenon. Thus, we propose an approach based
on causal inference to quantify the research impact of a specific technical
topic. We leverage difference-in-difference to quantify the research impact by
applying to bibliometric data. First, we identify papers of a specific
technical topic using keywords or category tags from Microsoft Academic Graph,
which is one of the largest academic publication dataset. Next, we build a
paper citation network between each technical field. Then, we aggregate the
cross-field citation count for each research field. Finally, the impact of a
specific technical topic for each research field is estimated by applying
difference-in-difference. Evaluation results show that deep learning
significantly affects computer vision and natural language processing. Besides,
deep learning significantly affects cross-field citation especially for speech
recognition to computer vision and natural language processing to computer
vision. Moreover, our method revealed that the impact of deep learning was 3.1
times of the impact of interpretability for ML models.},
 author = {Keiichi Ochiai and Yutaka Matsuo},
 comment = {},
 doi = {},
 eprint = {2503.13485v1},
 journal = {arXiv preprint},
 title = {A Causal Inference Approach for Quantifying Research Impact},
 url = {http://arxiv.org/abs/2503.13485v1},
 year = {2025}
}

@article{2503.13912v2,
 abstract = {We introduce KANITE, a framework leveraging Kolmogorov-Arnold Networks (KANs)
for Individual Treatment Effect (ITE) estimation under multiple treatments
setting in causal inference. By utilizing KAN's unique abilities to learn
univariate activation functions as opposed to learning linear weights by
Multi-Layer Perceptrons (MLPs), we improve the estimates of ITEs. The KANITE
framework comprises two key architectures: 1.Integral Probability Metric (IPM)
architecture: This employs an IPM loss in a specialized manner to effectively
align towards ITE estimation across multiple treatments. 2. Entropy Balancing
(EB) architecture: This uses weights for samples that are learned by optimizing
entropy subject to balancing the covariates across treatment groups. Extensive
evaluations on benchmark datasets demonstrate that KANITE outperforms
state-of-the-art algorithms in both $\epsilon_{\text{PEHE}}$ and
$\epsilon_{\text{ATE}}$ metrics. Our experiments highlight the advantages of
KANITE in achieving improved causal estimates, emphasizing the potential of
KANs to advance causal inference methodologies across diverse application
areas.},
 author = {Eshan Mehendale and Abhinav Thorat and Ravi Kolla and Niranjan Pedanekar},
 comment = {16 pages, 4 figures},
 doi = {},
 eprint = {2503.13912v2},
 journal = {arXiv preprint},
 title = {KANITE: Kolmogorov-Arnold Networks for ITE estimation},
 url = {http://arxiv.org/abs/2503.13912v2},
 year = {2025}
}

@article{2503.14459v1,
 abstract = {Practical and ethical constraints often require the use of observational data
for causal inference, particularly in medicine and social sciences. Yet,
observational datasets are prone to confounding, potentially compromising the
validity of causal conclusions. While it is possible to correct for biases if
the underlying causal graph is known, this is rarely a feasible ask in
practical scenarios. A common strategy is to adjust for all available
covariates, yet this approach can yield biased treatment effect estimates,
especially when post-treatment or unobserved variables are present. We propose
RAMEN, an algorithm that produces unbiased treatment effect estimates by
leveraging the heterogeneity of multiple data sources without the need to know
or learn the underlying causal graph. Notably, RAMEN achieves doubly robust
identification: it can identify the treatment effect whenever the causal
parents of the treatment or those of the outcome are observed, and the node
whose parents are observed satisfies an invariance assumption. Empirical
evaluations on synthetic and real-world datasets show that our approach
outperforms existing methods.},
 author = {Piersilvio De Bartolomeis and Julia Kostin and Javier Abad and Yixin Wang and Fanny Yang},
 comment = {Accepted for presentation at the International Conference on Learning
  Representations (ICLR) 2025},
 doi = {},
 eprint = {2503.14459v1},
 journal = {arXiv preprint},
 title = {Doubly robust identification of treatment effects from multiple environments},
 url = {http://arxiv.org/abs/2503.14459v1},
 year = {2025}
}

@article{2503.14512v1,
 abstract = {Participants: This study employed a combination of Vector Autoregression
(VAR) model and Graph Neural Networks (GNN) to systematically construct dynamic
causal inference. Multiple classic classification algorithms were compared,
including Random Forest, Logistic Regression, XGBoost, Support Vector Machine
(SVM), K-Nearest Neighbor (KNN), Gradient Boosting, and Multi Layer Perceptron
(MLP). The SMOTE algorithm was used to undersample a small number of samples
and employed Stratified K-fold Cross Validation. Results: This study included a
total of 11,789 participants, including 6,334 females (53.73%) and 5,455 males
(46.27%), with an average age of 65 years. Introduction of dynamic causal
inference features has significantly improved the performance of almost all
models. The area under the ROC curve of each model ranged from 0.78 to 0.83,
indicating significant difference (P < 0.01). Among all the models, the
Gradient Boosting model demonstrated the highest performance and stability.
Model explanation and feature importance analysis generated model
interpretation that illustrated significant contributors associated with risks
of stroke. Conclusions and Relevance: This study proposes a stroke risk
prediction method that combines dynamic causal inference with machine learning
models, significantly improving prediction accuracy and revealing key health
factors that affect stroke. The research results indicate that dynamic causal
inference features have important value in predicting stroke risk, especially
in capturing the impact of changes in health status over time on stroke risk.
By further optimizing the model and introducing more variables, this study
provides theoretical basis and practical guidance for future stroke prevention
and intervention strategies.},
 author = {Qizhi Zheng and Ayang Zhao and Xinzhu Wang and Yanhong Bai and Zikun Wang and Xiuying Wang and Xianzhang Zeng and Guanghui Dong},
 comment = {17 pages},
 doi = {},
 eprint = {2503.14512v1},
 journal = {arXiv preprint},
 title = {Machine learning algorithms to predict stroke in China based on causal inference of time series analysis},
 url = {http://arxiv.org/abs/2503.14512v1},
 year = {2025}
}

@article{2503.14663v1,
 abstract = {Sepsis is a life-threatening syndrome with high morbidity and mortality in
hospitals. Early prediction of sepsis plays a crucial role in facilitating
early interventions for septic patients. However, early sepsis prediction
systems with uncertainty quantification and adaptive learning are scarce. This
paper proposes Sepsyn-OLCP, a novel online learning algorithm for early sepsis
prediction by integrating conformal prediction for uncertainty quantification
and Bayesian bandits for adaptive decision-making. By combining the robustness
of Bayesian models with the statistical uncertainty guarantees of conformal
prediction methodologies, this algorithm delivers accurate and trustworthy
predictions, addressing the critical need for reliable and adaptive systems in
high-stakes healthcare applications such as early sepsis prediction. We
evaluate the performance of Sepsyn-OLCP in terms of regret in stochastic bandit
setting, the area under the receiver operating characteristic curve (AUROC),
and F-measure. Our results show that Sepsyn-OLCP outperforms existing
individual models, increasing AUROC of a neural network from 0.64 to 0.73
without retraining and high computational costs. And the model selection policy
converges to the optimal strategy in the long run. We propose a novel
reinforcement learning-based framework integrated with conformal prediction
techniques to provide uncertainty quantification for early sepsis prediction.
The proposed methodology delivers accurate and trustworthy predictions,
addressing a critical need in high-stakes healthcare applications like early
sepsis prediction.},
 author = {Anni Zhou and Beyah Raheem and Rishikesan Kamaleswaran and Yao Xie},
 comment = {},
 doi = {},
 eprint = {2503.14663v1},
 journal = {arXiv preprint},
 title = {Sepsyn-OLCP: An Online Learning-based Framework for Early Sepsis Prediction with Uncertainty Quantification using Conformal Prediction},
 url = {http://arxiv.org/abs/2503.14663v1},
 year = {2025}
}

@article{2503.14973v2,
 abstract = {Building trust in reinforcement learning (RL) agents requires understanding
why they make certain decisions, especially in high-stakes applications like
robotics, healthcare, and finance. Existing explainability methods often focus
on single states or entire trajectories, either providing only local, step-wise
insights or attributing decisions to coarse, episodelevel summaries. Both
approaches miss the recurring strategies and temporally extended patterns that
actually drive agent behavior across multiple decisions. We address this gap by
proposing a fully offline, reward-free framework for behavior discovery and
segmentation, enabling the attribution of actions to meaningful and
interpretable behavior segments that capture recurring patterns appearing
across multiple trajectories. Our method identifies coherent behavior clusters
from state-action sequences and attributes individual actions to these clusters
for fine-grained, behavior-centric explanations. Evaluations on four diverse
offline RL environments show that our approach discovers meaningful behaviors
and outperforms trajectory-level baselines in fidelity, human preference, and
cluster coherence. Our code is publicly available.},
 author = {Rishav Rishav and Somjit Nath and Vincent Michalski and Samira Ebrahimi Kahou},
 comment = {},
 doi = {},
 eprint = {2503.14973v2},
 journal = {arXiv preprint},
 title = {Behaviour Discovery and Attribution for Explainable Reinforcement Learning},
 url = {http://arxiv.org/abs/2503.14973v2},
 year = {2025}
}

@article{2503.15114v2,
 abstract = {We introduce DeCaFlow, a deconfounding causal generative model. Training once
per dataset using just observational data and the underlying causal graph,
DeCaFlow enables accurate causal inference on continuous variables under the
presence of hidden confounders. Specifically, we extend previous results on
causal estimation under hidden confounding to show that a single instance of
DeCaFlow provides correct estimates for all causal queries identifiable with
do-calculus, leveraging proxy variables to adjust for the causal effects when
do-calculus alone is insufficient. Moreover, we show that counterfactual
queries are identifiable as long as their interventional counterparts are
identifiable, and thus are also correctly estimated by DeCaFlow. Our empirical
results on diverse settings (including the Ecoli70 dataset, with 3 independent
hidden confounders, tens of observed variables and hundreds of causal queries)
show that DeCaFlow outperforms existing approaches, while demonstrating its
out-of-the-box applicability to any given causal graph. An implementation can
be found in https://github.com/aalmodovares/DeCaFlow},
 author = {Alejandro Almodóvar and Adrián Javaloy and Juan Parras and Santiago Zazo and Isabel Valera},
 comment = {46 pages, 28 figures. Under submission},
 doi = {},
 eprint = {2503.15114v2},
 journal = {arXiv preprint},
 title = {DeCaFlow: A Deconfounding Causal Generative Model},
 url = {http://arxiv.org/abs/2503.15114v2},
 year = {2025}
}

@article{2503.15168v1,
 abstract = {World Models help Artificial Intelligence (AI) predict outcomes, reason about
its environment, and guide decision-making. While widely used in reinforcement
learning, they lack the structured, adaptive representations that even young
children intuitively develop. Advancing beyond pattern recognition requires
dynamic, interpretable frameworks inspired by Piaget's cognitive development
theory. We highlight six key research areas -- physics-informed learning,
neurosymbolic learning, continual learning, causal inference, human-in-the-loop
AI, and responsible AI -- as essential for enabling true reasoning in AI. By
integrating statistical learning with advances in these areas, AI can evolve
from pattern recognition to genuine understanding, adaptation and reasoning
capabilities.},
 author = {Javier Del Ser and Jesus L. Lobo and Heimo Müller and Andreas Holzinger},
 comment = {11 pages, 1 figure},
 doi = {},
 eprint = {2503.15168v1},
 journal = {arXiv preprint},
 title = {World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child},
 url = {http://arxiv.org/abs/2503.15168v1},
 year = {2025}
}

@article{2503.16463v1,
 abstract = {Recent advances in large language models (LLMs) have shown promising results
in medical diagnosis, with some studies indicating superior performance
compared to human physicians in specific scenarios. However, the diagnostic
capabilities of LLMs are often overestimated, as their performance
significantly deteriorates in interactive diagnostic settings that require
active information gathering. This study investigates the underlying mechanisms
behind the performance degradation phenomenon and proposes a solution. We
identified that the primary deficiency of LLMs lies in the initial diagnosis
phase, particularly in information-gathering efficiency and initial diagnosis
formation, rather than in the subsequent differential diagnosis phase. To
address this limitation, we developed a plug-and-play method enhanced (PPME)
LLM agent, leveraging over 3.5 million electronic medical records from Chinese
and American healthcare facilities. Our approach integrates specialized models
for initial disease diagnosis and inquiry into the history of the present
illness, trained through supervised and reinforcement learning techniques. The
experimental results indicate that the PPME LLM achieved over 30% improvement
compared to baselines. The final diagnostic accuracy of the PPME LLM in
interactive diagnostic scenarios approached levels comparable to those achieved
using complete clinical data. These findings suggest a promising potential for
developing autonomous diagnostic systems, although further validation studies
are needed.},
 author = {Zhoujian Sun and Ziyi Liu and Cheng Luo and Jiebin Chu and Zhengxing Huang},
 comment = {30 pages},
 doi = {},
 eprint = {2503.16463v1},
 journal = {arXiv preprint},
 title = {Improving Interactive Diagnostic Ability of a Large Language Model Agent Through Clinical Experience Learning},
 url = {http://arxiv.org/abs/2503.16463v1},
 year = {2025}
}

@article{2503.16518v2,
 abstract = {Human-Machine Teaming (HMT) is revolutionizing collaboration across domains
such as defense, healthcare, and autonomous systems by integrating AI-driven
decision-making, trust calibration, and adaptive teaming. This survey presents
a comprehensive taxonomy of HMT, analyzing theoretical models, including
reinforcement learning, instance-based learning, and interdependence theory,
alongside interdisciplinary methodologies. Unlike prior reviews, we examine
team cognition, ethical AI, multi-modal interactions, and real-world evaluation
frameworks. Key challenges include explainability, role allocation, and
scalable benchmarking. We propose future research in cross-domain adaptation,
trust-aware AI, and standardized testbeds. By bridging computational and social
sciences, this work lays a foundation for resilient, ethical, and scalable HMT
systems.},
 author = {Dian Chen and Han Jun Yoon and Zelin Wan and Nithin Alluru and Sang Won Lee and Richard He and Terrence J. Moore and Frederica F. Nelson and Sunghyun Yoon and Hyuk Lim and Dan Dongseong Kim and Jin-Hee Cho},
 comment = {},
 doi = {},
 eprint = {2503.16518v2},
 journal = {arXiv preprint},
 title = {Advancing Human-Machine Teaming: Concepts, Challenges, and Applications},
 url = {http://arxiv.org/abs/2503.16518v2},
 year = {2025}
}

@article{2503.16547v1,
 abstract = {Traditional AI-based healthcare systems often rely on single-modal data,
limiting diagnostic accuracy due to incomplete information. However, recent
advancements in foundation models show promising potential for enhancing
diagnosis combining multi-modal information. While these models excel in static
tasks, they struggle with dynamic diagnosis, failing to manage multi-turn
interactions and often making premature diagnostic decisions due to
insufficient persistence in information collection.To address this, we propose
a multi-agent framework inspired by consultation flow and reinforcement
learning (RL) to simulate the entire consultation process, integrating multiple
clinical information for effective diagnosis. Our approach incorporates a
hierarchical action set, structured from clinic consultation flow and medical
textbook, to effectively guide the decision-making process. This strategy
improves agent interactions, enabling them to adapt and optimize actions based
on the dynamic state. We evaluated our framework on a public dynamic diagnosis
benchmark. The proposed framework evidentially improves the baseline methods
and achieves state-of-the-art performance compared to existing foundation
model-based methods.},
 author = {Sihan Wang and Suiyang Jiang and Yibo Gao and Boming Wang and Shangqi Gao and Xiahai Zhuang},
 comment = {},
 doi = {},
 eprint = {2503.16547v1},
 journal = {arXiv preprint},
 title = {Empowering Medical Multi-Agents with Clinical Consultation Flow for Dynamic Diagnosis},
 url = {http://arxiv.org/abs/2503.16547v1},
 year = {2025}
}

@article{2503.17290v3,
 abstract = {The partitioning of data for estimation and calibration critically impacts
the performance of propensity score based estimators like inverse probability
weighting (IPW) and double/debiased machine learning (DML) frameworks. We
extend recent advances in calibration techniques for propensity score
estimation, improving the robustness of propensity scores in challenging
settings such as limited overlap, small sample sizes, or unbalanced data. Our
contributions are twofold: First, we provide a theoretical analysis of the
properties of calibrated estimators in the context of DML. To this end, we
refine existing calibration frameworks for propensity score models, with a
particular emphasis on the role of sample-splitting schemes in ensuring valid
causal inference. Second, through extensive simulations, we show that
calibration reduces variance of inverse-based propensity score estimators while
also mitigating bias in IPW, even in small-sample regimes. Notably, calibration
improves stability for flexible learners (e.g., gradient boosting) while
preserving the doubly robust properties of DML. A key insight is that, even
when methods perform well without calibration, incorporating a calibration step
does not degrade performance, provided that an appropriate sample-splitting
approach is chosen.},
 author = {Sven Klaassen and Jan Rabenseifner and Jannis Kueck and Philipp Bach},
 comment = {},
 doi = {},
 eprint = {2503.17290v3},
 journal = {arXiv preprint},
 title = {Calibration Strategies for Robust Causal Estimation: Theoretical and Empirical Insights on Propensity Score-Based Estimators},
 url = {http://arxiv.org/abs/2503.17290v3},
 year = {2025}
}

@article{2503.18721v2,
 abstract = {Identification of joint dependence among more than two random vectors plays
an important role in many statistical applications, where the data may contain
sensitive or confidential information. In this paper, we consider the the
$d$-variable Hilbert-Schmidt independence criterion (dHSIC) in the context of
differential privacy. Given the limiting distribution of the empirical estimate
of dHSIC is complicated Gaussian chaos, constructing tests in the non-privacy
regime is typically based on permutation and bootstrap. To detect joint
dependence in privacy, we propose a dHSIC-based testing procedure by employing
a differentially private permutation methodology. Our method enjoys privacy
guarantee, valid level and pointwise consistency, while the bootstrap
counterpart suffers inconsistent power. We further investigate the uniform
power of the proposed test in dHSIC metric and $L_2$ metric, indicating that
the proposed test attains the minimax optimal power across different privacy
regimes. As a byproduct, our results also contain the pointwise and uniform
power of the non-private permutation dHSIC, addressing an unsolved question
remained in Pfister et al. (2018). Both numerical simulations and real data
analysis on causal inference suggest our proposed test performs well
empirically.},
 author = {Xingwei Liu and Yuexin Chen and Wangli Xu},
 comment = {64 pages, 6 figures},
 doi = {},
 eprint = {2503.18721v2},
 journal = {arXiv preprint},
 title = {Differentially Private Joint Independence Test},
 url = {http://arxiv.org/abs/2503.18721v2},
 year = {2025}
}

@article{2503.18912v1,
 abstract = {Air pollution poses significant health and environmental challenges,
particularly in rapidly urbanizing regions. Delhi-National Capital Region
experiences air pollution episodes due to complex interactions between
anthropogenic emissions and meteorological conditions. Understanding the causal
drivers of key pollutants such as $PM_{2.5}$ and ground $O_3$ is crucial for
developing effective mitigation strategies. This study investigates the causal
links of anthropogenic emissions on $PM_{2.5}$ and $O_3$ concentrations using
predictive modeling and causal inference techniques. Integrating
high-resolution air quality data from Jan 2018 to Aug 2023 across 32 monitoring
stations, we develop predictive regression models that incorporate
meteorological variables (temperature and relative humidity), pollutant
concentrations ($NO_2, SO_2, CO$), and seasonal harmonic components to capture
both diurnal and annual cycles. Here, we show that reductions in anthropogenic
emissions lead to significant decreases in $PM_{2.5}$ levels, whereas their
effect on $O_3$ remains marginal and statistically insignificant. To address
spatial heterogeneity, we employ Gaussian Process modeling. Further, we use
Granger causality analysis and counterfactual simulation to establish direct
causal links. Validation using real-world data from the COVID-19 lockdown
confirms that reduced emissions led to a substantial drop in $PM_{2.5}$ but
only a slight, insignificant change in $O_3$. The findings highlight the
necessity of targeted emission reduction policies while emphasizing the need
for integrated strategies addressing both particulate and ozone pollution.
These insights are crucial for policymakers designing air pollution
interventions in other megacities, and offer a scalable methodology for
tackling complex urban air pollution through data-driven decision-making.},
 author = {Sourish Das and Sudeep Shukla and Alka Yadav and Anirban Chakraborti},
 comment = {16 pages, 10 figures},
 doi = {},
 eprint = {2503.18912v1},
 journal = {arXiv preprint},
 title = {Causal Links Between Anthropogenic Emissions and Air Pollution Dynamics in Delhi},
 url = {http://arxiv.org/abs/2503.18912v1},
 year = {2025}
}

@article{2503.21629v1,
 abstract = {In causal inference with observational studies, synthetic control (SC) has
emerged as a prominent tool. SC has traditionally been applied to
aggregate-level datasets, but more recent work has extended its use to
individual-level data. As they contain a greater number of observed units, this
shift introduces the curse of dimensionality to SC. To address this, we propose
Cluster Synthetic Control (ClusterSC), based on the idea that groups of
individuals may exist where behavior aligns internally but diverges between
groups. ClusterSC incorporates a clustering step to select only the relevant
donors for the target. We provide theoretical guarantees on the improvements
induced by ClusterSC, supported by empirical demonstrations on synthetic and
real-world datasets. The results indicate that ClusterSC consistently
outperforms classical SC approaches.},
 author = {Saeyoung Rho and Andrew Tang and Noah Bergam and Rachel Cummings and Vishal Misra},
 comment = {35 pages, 11 figures, to be published in Proceedings of The 28th
  International Conference on Artificial Intelligence and Statistics (AIStats)
  2025},
 doi = {},
 eprint = {2503.21629v1},
 journal = {arXiv preprint},
 title = {ClusterSC: Advancing Synthetic Control with Donor Selection},
 url = {http://arxiv.org/abs/2503.21629v1},
 year = {2025}
}

@article{2504.01012v1,
 abstract = {Real-world networks grow over time; statistical models based on node
exchangeability are not appropriate. Instead of constraining the structure of
the \textit{distribution} of edges, we propose that the relevant symmetries
refer to the \textit{causal structure} between them. We first enumerate the 96
causal directed acyclic graph (DAG) models over pairs of nodes (dyad variables)
in a growing network with finite ancestral sets that are invariant to node
deletion. We then partition them into 21 classes with ancestral sets that are
closed under node marginalization. Several of these classes are remarkably
amenable to distributed and asynchronous evaluation. As an example, we
highlight a simple model that exhibits flexible power-law degree distributions
and emergent phase transitions in sparsity, which we characterize analytically.
With few parameters and much conditional independence, our proposed framework
provides natural baseline models for causal inference in relational data.},
 author = {Gecia Bravo-Hermsdorff and Lee M. Gunderson and Kayvan Sadeghi},
 comment = {},
 doi = {},
 eprint = {2504.01012v1},
 journal = {arXiv preprint},
 title = {Causal Models for Growing Networks},
 url = {http://arxiv.org/abs/2504.01012v1},
 year = {2025}
}

@article{2504.01702v1,
 abstract = {We propose a formal model for counterfactual estimation with unobserved
confounding in "data-rich" settings, i.e., where there are a large number of
units and a large number of measurements per unit. Our model provides a bridge
between the structural causal model view of causal inference common in the
graphical models literature with that of the latent factor model view common in
the potential outcomes literature. We show how classic models for potential
outcomes and treatment assignments fit within our framework. We provide an
identification argument for the average treatment effect, the average treatment
effect on the treated, and the average treatment effect on the untreated. For
any estimator that has a fast enough estimation error rate for a certain
nuisance parameter, we establish it is consistent for these various causal
parameters. We then show principal component regression is one such estimator
that leads to consistent estimation, and we analyze the minimal smoothness
required of the potential outcomes function for consistency.},
 author = {Alberto Abadie and Anish Agarwal and Devavrat Shah},
 comment = {},
 doi = {},
 eprint = {2504.01702v1},
 journal = {arXiv preprint},
 title = {A Causal Inference Framework for Data Rich Environments},
 url = {http://arxiv.org/abs/2504.01702v1},
 year = {2025}
}

@article{2504.03206v2,
 abstract = {Effective conversational agents like large language models (LLMs) must
personalize their interactions to adapt to user preferences, personalities, and
attributes across diverse domains like education and healthcare. Current
methods like Reinforcement Learning from Human Feedback (RLHF), often
prioritize helpfulness and safety but fall short in fostering truly empathetic,
adaptive, and personalized dialogues. Existing personalization approaches
typically rely on extensive user history, limiting their effectiveness for new
or context-limited users. To address these limitations, we propose leveraging a
user model to incorporate a curiosity-based intrinsic reward into multi-turn
RLHF. This novel reward mechanism encourages the LLM agent to actively infer
user traits by optimizing conversations to improve its user model's accuracy.
Consequently, the agent delivers more personalized interactions by learning
more about the user. We demonstrate our method's effectiveness in two distinct
domains: significantly improving personalization performance in a
conversational recommendation task, and personalizing conversations for
different learning styles in an educational setting. We show improved
generalization capabilities compared to traditional multi-turn RLHF, all while
maintaining conversation quality. Our method offers a promising solution for
creating more personalized, adaptive, and engaging conversational agents.},
 author = {Yanming Wan and Jiaxing Wu and Marwa Abdulhai and Lior Shani and Natasha Jaques},
 comment = {},
 doi = {},
 eprint = {2504.03206v2},
 journal = {arXiv preprint},
 title = {Enhancing Personalized Multi-Turn Dialogue with Curiosity Reward},
 url = {http://arxiv.org/abs/2504.03206v2},
 year = {2025}
}

@article{2504.04320v3,
 abstract = {Causal inference is often portrayed as fundamentally distinct from predictive
modeling, with its own terminology, goals, and intellectual challenges. But at
its core, causal inference is simply a structured instance of prediction under
distribution shift. In both cases, we begin with labeled data from a source
domain and seek to generalize to a target domain where outcomes are not
observed. The key difference is that in causal inference, the labels --
potential outcomes -- are selectively observed based on treatment assignment,
introducing bias that must be addressed through assumptions. This perspective
reframes causal estimation as a familiar generalization problem and highlights
how techniques from predictive modeling, such as reweighting and domain
adaptation, apply directly to causal tasks. It also clarifies that causal
assumptions are not uniquely strong -- they are simply more explicit. By
viewing causal inference through the lens of prediction, we demystify its
logic, connect it to familiar tools, and make it more accessible to
practitioners and educators alike.},
 author = {Carlos Fernández-Loría},
 comment = {},
 doi = {},
 eprint = {2504.04320v3},
 journal = {arXiv preprint},
 title = {Causal Inference Isn't Special: Why It's Just Another Prediction Problem},
 url = {http://arxiv.org/abs/2504.04320v3},
 year = {2025}
}

@article{2504.04717v4,
 abstract = {Recent advancements in large language models (LLMs) have revolutionized their
ability to handle single-turn tasks, yet real-world applications demand
sophisticated multi-turn interactions. This survey provides a comprehensive
review of recent advancements in evaluating and enhancing multi-turn
interactions in LLMs. Focusing on task-specific scenarios, from instruction
following in diverse domains such as math and coding to complex conversational
engagements in roleplay, healthcare, education, and even adversarial jailbreak
settings, we systematically examine the challenges of maintaining context,
coherence, fairness, and responsiveness over prolonged dialogues. The paper
organizes current benchmarks and datasets into coherent categories that reflect
the evolving landscape of multi-turn dialogue evaluation. In addition, we
review a range of enhancement methodologies under multi-turn settings,
including model-centric strategies (contextual learning, supervised
fine-tuning, reinforcement learning, and new architectures), external
integration approaches (memory-augmented, retrieval-based methods, and
knowledge graph), and agent-based techniques for collaborative interactions.
Finally, we discuss open challenges and propose future directions for research
to further advance the robustness and effectiveness of multi-turn interactions
in LLMs. Related resources and papers are available at
https://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.},
 author = {Yubo Li and Xiaobin Shen and Xinyu Yao and Xueying Ding and Yidi Miao and Ramayya Krishnan and Rema Padman},
 comment = {},
 doi = {},
 eprint = {2504.04717v4},
 journal = {arXiv preprint},
 title = {Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models},
 url = {http://arxiv.org/abs/2504.04717v4},
 year = {2025}
}

@article{2504.05658v2,
 abstract = {In social science researches, causal inference regarding peer effects often
faces significant challenges due to homophily bias and contextual confounding.
For example, unmeasured health conditions (e.g., influenza) and psychological
states (e.g., happiness, loneliness) can spread among closely connected
individuals, such as couples or siblings. To address these issues, we define
four effect estimands for dyadic data to characterize direct effects and
spillover effects. We employ dual instrumental variables to achieve
nonparametric identification of these causal estimands in the presence of
unobserved confounding. We then derive the efficient influence functions for
these estimands under the nonparametric model. Additionally, we develop a
triply robust and locally efficient estimator that remains consistent even
under partial misspecification of the observed data model. The proposed robust
estimators can be easily adapted to flexible approaches such as machine
learning estimation methods, provided that certain rate conditions are
satisfied. Finally, we illustrate our approach through simulations and an
empirical application evaluating the peer effects of retirement on fluid
cognitive perception among couples.},
 author = {Shanshan Luo and Kang Shuai and Yechi Zhang and Wei Li and Yangbo He},
 comment = {36 pages, 3 figures},
 doi = {},
 eprint = {2504.05658v2},
 journal = {arXiv preprint},
 title = {Identification and estimation of causal peer effects using instrumental variables},
 url = {http://arxiv.org/abs/2504.05658v2},
 year = {2025}
}

@article{2504.07257v1,
 abstract = {Reinforcement learning (RL) agents have shown remarkable performances in
various environments, where they can discover effective policies directly from
sensory inputs. However, these agents often exploit spurious correlations in
the training data, resulting in brittle behaviours that fail to generalize to
new or slightly modified environments. To address this, we introduce the Causal
Object-centric Model Extraction Tool (COMET), a novel algorithm designed to
learn the exact interpretable causal world models (CWMs). COMET first extracts
object-centric state descriptions from observations and identifies the
environment's internal states related to the depicted objects' properties.
Using symbolic regression, it models object-centric transitions and derives
causal relationships governing object dynamics. COMET further incorporates
large language models (LLMs) for semantic inference, annotating causal
variables to enhance interpretability.
  By leveraging these capabilities, COMET constructs CWMs that align with the
true causal structure of the environment, enabling agents to focus on
task-relevant features. The extracted CWMs mitigate the danger of shortcuts,
permitting the development of RL systems capable of better planning and
decision-making across dynamic scenarios. Our results, validated in Atari
environments such as Pong and Freeway, demonstrate the accuracy and robustness
of COMET, highlighting its potential to bridge the gap between object-centric
reasoning and causal inference in reinforcement learning.},
 author = {Elisabeth Dillies and Quentin Delfosse and Jannis Blüml and Raban Emunds and Florian Peter Busch and Kristian Kersting},
 comment = {5 pages including references, 2 figures},
 doi = {},
 eprint = {2504.07257v1},
 journal = {arXiv preprint},
 title = {Better Decisions through the Right Causal World Model},
 url = {http://arxiv.org/abs/2504.07257v1},
 year = {2025}
}

@article{2504.07722v6,
 abstract = {Sequential decision-making systems routinely operate with missing or
incomplete data. Classical reinforcement learning theory, which is commonly
used to solve sequential decision problems, assumes Markovian observability,
which may not hold under partial observability. Causal inference paradigms
formalise ignorability of missingness. We show these views can be unified and
generalized in order to guarantee Q-learning convergence even when the Markov
property fails. To do so, we introduce the concept of relative ignorability.
Relative ignorability is a graphical-causal criterion which refines the
requirements for accurate decision-making based on incomplete data. Theoretical
results and simulations both reveal that non-Markovian stochastic processes
whose missingness is relatively ignorable with respect to causal estimands can
still be optimized using standard Reinforcement Learning algorithms. These
results expand the theoretical foundations of safe, data-efficient AI to
real-world environments where complete information is unattainable.},
 author = {MaryLena Bleile and Minh-Nhat Phung and Minh-Binh Tran},
 comment = {},
 doi = {},
 eprint = {2504.07722v6},
 journal = {arXiv preprint},
 title = {A Relative Ignorability Framework for Decision-Relevant Observability in Control Theory and Reinforcement Learning},
 url = {http://arxiv.org/abs/2504.07722v6},
 year = {2025}
}

@article{2504.08600v4,
 abstract = {Natural Language to SQL (NL2SQL) enables intuitive interactions with
databases by transforming natural language queries into structured SQL
statements. Despite recent advancements in enhancing human-computer interaction
within database applications, significant challenges persist, particularly
regarding the inference performance in complex scenarios involving multi-table
joins and nested queries. Current methodologies primarily utilize supervised
fine-tuning (SFT) to train the NL2SQL model, which may limit adaptability and
interpretability in new environments (e.g., finance and healthcare). In order
to enhance the reasoning performance of the NL2SQL model in the above complex
situations, we introduce SQL-R1, a novel NL2SQL reasoning model trained by the
reinforcement learning (RL) algorithms. We design a specialized RL-based reward
function tailored for NL2SQL tasks and discussed the impact of cold start on
the effectiveness of intensive training. In addition, we achieve competitive
accuracy using only a tiny amount of synthetic NL2SQL data for augmented
training and further explore data engineering for RL. In existing experiments,
SQL-R1 achieves execution accuracy of 88.6% and 66.6% on the benchmark Spider
and BIRD, respectively, only using the 7B base model.},
 author = {Peixian Ma and Xialie Zhuang and Chengjin Xu and Xuhui Jiang and Ran Chen and Jian Guo},
 comment = {Accepd by NeurIPS 2025},
 doi = {},
 eprint = {2504.08600v4},
 journal = {arXiv preprint},
 title = {SQL-R1: Training Natural Language to SQL Reasoning Model By Reinforcement Learning},
 url = {http://arxiv.org/abs/2504.08600v4},
 year = {2025}
}

@article{2504.08773v2,
 abstract = {Recommender systems exemplify sequential decision-making under uncertainty,
strategically deciding what content to serve to users, to optimise a range of
potential objectives. To balance the explore-exploit trade-off successfully,
Thompson sampling provides a natural and widespread paradigm to
probabilistically select which action to take. Questions of causal and
counterfactual inference, which underpin use-cases like offline evaluation, are
not straightforward to answer in these contexts. Specifically, whilst most
existing estimators rely on action propensities, these are not readily
available under Thompson sampling procedures.
  We derive exact and efficiently computable expressions for action
propensities under a variety of parameter and outcome distributions, enabling
the use of off-policy estimators in Thompson sampling scenarios. This opens up
a range of practical use-cases where counterfactual inference is crucial,
including unbiased offline evaluation of recommender systems, as well as
general applications of causal inference in online advertising,
personalisation, and beyond.},
 author = {Olivier Jeunen},
 comment = {To appear in the Nineteenth ACM Conference on Recommender Systems
  (RecSys '25)},
 doi = {},
 eprint = {2504.08773v2},
 journal = {arXiv preprint},
 title = {Counterfactual Inference under Thompson Sampling},
 url = {http://arxiv.org/abs/2504.08773v2},
 year = {2025}
}

@article{2504.08836v1,
 abstract = {Researchers and practitioners often wish to measure treatment effects in
settings where units interact via markets and recommendation systems. In these
settings, units are affected by certain shared states, like prices, algorithmic
recommendations or social signals. We formalize this structure, calling it
shared-state interference, and argue that our formulation captures many
relevant applied settings. Our key modeling assumption is that individuals'
potential outcomes are independent conditional on the shared state. We then
prove an extension of a double machine learning (DML) theorem providing
conditions for achieving efficient inference under shared-state interference.
We also instantiate our general theorem in several models of interest where it
is possible to efficiently estimate the average direct effect (ADE) or global
average treatment effect (GATE).},
 author = {Chris Hays and Manish Raghavan},
 comment = {48 pages, 6 figures},
 doi = {},
 eprint = {2504.08836v1},
 journal = {arXiv preprint},
 title = {Double Machine Learning for Causal Inference under Shared-State Interference},
 url = {http://arxiv.org/abs/2504.08836v1},
 year = {2025}
}

@article{2504.10102v1,
 abstract = {Work-Related Musculoskeletal Disorders continue to be a major challenge in
industrial environments, leading to reduced workforce participation, increased
healthcare costs, and long-term disability. This study introduces a
human-sensitive robotic system aimed at reintegrating individuals with a
history of musculoskeletal disorders into standard job roles, while
simultaneously optimizing ergonomic conditions for the broader workforce. This
research leverages reinforcement learning to develop a human-aware control
strategy for collaborative robots, focusing on optimizing ergonomic conditions
and preventing pain during task execution. Two RL approaches, Q-Learning and
Deep Q-Network (DQN), were implemented and tested to personalize control
strategies based on individual user characteristics. Although experimental
results revealed a simulation-to-real gap, a fine-tuning phase successfully
adapted the policies to real-world conditions. DQN outperformed Q-Learning by
completing tasks faster while maintaining zero pain risk and safe ergonomic
levels. The structured testing protocol confirmed the system's adaptability to
diverse human anthropometries, underscoring the potential of RL-driven cobots
to enable safer, more inclusive workplaces.},
 author = {Vitor Martins and Sara M. Cerqueira and Mercedes Balcells and Elazer R Edelman and Cristina P. Santos},
 comment = {},
 doi = {},
 eprint = {2504.10102v1},
 journal = {arXiv preprint},
 title = {A Human-Sensitive Controller: Adapting to Human Ergonomics and Physical Constraints via Reinforcement Learning},
 url = {http://arxiv.org/abs/2504.10102v1},
 year = {2025}
}

@article{2504.11044v1,
 abstract = {The notion of relative universality with respect to a {\sigma}-field was
introduced to establish the unbiasedness and Fisher consistency of an estimator
in nonlinear sufficient dimension reduction. However, there is a gap in the
proof of this result in the existing literature. The existing definition of
relative universality seems to be too strong for the proof to be valid. In this
note we modify the definition of relative universality using the concept of
\k{o}-measurability, and rigorously establish the mentioned unbiasedness and
Fisher consistency. The significance of this result is beyond its original
context of sufficient dimension reduction, because relative universality allows
us to use the regression operator to fully characterize conditional
independence, a crucially important statistical relation that sits at the core
of many areas and methodologies in statistics and machine learning, such as
dimension reduction, graphical models, probability embedding, causal inference,
and Bayesian estimation.},
 author = {Bing Li and Ben Jones and Andreas Artemiou},
 comment = {19 pages},
 doi = {},
 eprint = {2504.11044v1},
 journal = {arXiv preprint},
 title = {On relative universality, regression operator, and conditional independence},
 url = {http://arxiv.org/abs/2504.11044v1},
 year = {2025}
}

@article{2504.11511v2,
 abstract = {The rise of reinforcement learning (RL) in critical real-world applications
demands a fundamental rethinking of privacy in AI systems. Traditional privacy
frameworks, designed to protect isolated data points, fall short for sequential
decision-making systems where sensitive information emerges from temporal
patterns, behavioral strategies, and collaborative dynamics. Modern RL
paradigms, such as federated RL (FedRL) and RL with human feedback (RLHF) in
large language models (LLMs), exacerbate these challenges by introducing
complex, interactive, and context-dependent learning environments that
traditional methods do not address. In this position paper, we argue for a new
privacy paradigm built on four core principles: multi-scale protection,
behavioral pattern protection, collaborative privacy preservation, and
context-aware adaptation. These principles expose inherent tensions between
privacy, utility, and interpretability that must be navigated as RL systems
become more pervasive in high-stakes domains like healthcare, autonomous
vehicles, and decision support systems powered by LLMs. To tackle these
challenges, we call for the development of new theoretical frameworks,
practical mechanisms, and rigorous evaluation methodologies that collectively
enable effective privacy protection in sequential decision-making systems.},
 author = {Flint Xiaofeng Fan and Cheston Tan and Roger Wattenhofer and Yew-Soon Ong},
 comment = {IJCNN 2025 Position Paper Track},
 doi = {},
 eprint = {2504.11511v2},
 journal = {arXiv preprint},
 title = {Position Paper: Rethinking Privacy in RL for Sequential Decision-making in the Age of LLMs},
 url = {http://arxiv.org/abs/2504.11511v2},
 year = {2025}
}

@article{2504.13186v1,
 abstract = {The rapid advancement of deep learning (DL) has transformed healthcare,
particularly in cancer detection and diagnosis. DL surpasses traditional
machine learning and human accuracy, making it a critical tool for identifying
diseases. Despite numerous reviews on DL in healthcare, a comprehensive
analysis of its role in cancer detection remains limited. Existing studies
focus on specific aspects, leaving gaps in understanding its broader impact.
This paper addresses these gaps by reviewing advanced DL techniques, including
transfer learning (TL), reinforcement learning (RL), federated learning (FL),
Transformers, and large language models (LLMs). These approaches enhance
accuracy, tackle data scarcity, and enable decentralized learning while
maintaining data privacy. TL adapts pre-trained models to new datasets,
improving performance with limited labeled data. RL optimizes diagnostic
pathways and treatment strategies, while FL fosters collaborative model
development without sharing sensitive data. Transformers and LLMs,
traditionally used in natural language processing, are now applied to medical
data for improved interpretability. Additionally, this review examines these
techniques' efficiency in cancer diagnosis, addresses challenges like data
imbalance, and proposes solutions. It serves as a resource for researchers and
practitioners, providing insights into current trends and guiding future
research in advanced DL for cancer detection.},
 author = {Yassine Habchi and Hamza Kheddar and Yassine Himeur and Adel Belouchrani and Erchin Serpedin and Fouad Khelifi and Muhammad E. H. Chowdhury},
 comment = {},
 doi = {10.1016/j.imavis.2025.105495},
 eprint = {2504.13186v1},
 journal = {arXiv preprint},
 title = {Advanced Deep Learning and Large Language Models: Comprehensive Insights for Cancer Detection},
 url = {http://arxiv.org/abs/2504.13186v1},
 year = {2025}
}

@article{2504.13733v1,
 abstract = {Heterogeneous treatment effect estimation in high-stakes applications demands
models that simultaneously optimize precision, interpretability, and
calibration. Many existing tree-based causal inference techniques, however,
exhibit high estimation errors when applied to observational data because they
struggle to capture complex interactions among factors and rely on static
regularization schemes. In this work, we propose Dynamic Regularized Causal
Boosted Decision Trees (CBDT), a novel framework that integrates variance
regularization and average treatment effect calibration into the loss function
of gradient boosted decision trees. Our approach dynamically updates the
regularization parameters using gradient statistics to better balance the
bias-variance tradeoff. Extensive experiments on standard benchmark datasets
and real-world clinical data demonstrate that the proposed method significantly
improves estimation accuracy while maintaining reliable coverage of true
treatment effects. In an intensive care unit patient triage study, the method
successfully identified clinically actionable rules and achieved high accuracy
in treatment effect estimation. The results validate that dynamic
regularization can effectively tighten error bounds and enhance both predictive
performance and model interpretability.},
 author = {Yichen Liu},
 comment = {Preprint version. 13 pages, 4 figures, 3 tables},
 doi = {},
 eprint = {2504.13733v1},
 journal = {arXiv preprint},
 title = {Dynamic Regularized CBDT: Variance-Calibrated Causal Boosting for Interpretable Heterogeneous Treatment Effects},
 url = {http://arxiv.org/abs/2504.13733v1},
 year = {2025}
}

@article{2504.14530v1,
 abstract = {Causal reasoning is a cornerstone of human intelligence and a critical
capability for artificial systems aiming to achieve advanced understanding and
decision-making. This thesis delves into various dimensions of causal reasoning
and understanding in large language models (LLMs). It encompasses a series of
studies that explore the causal inference skills of LLMs, the mechanisms behind
their performance, and the implications of causal and anticausal learning for
natural language processing (NLP) tasks. Additionally, it investigates the
application of causal reasoning in text-based computational social science,
specifically focusing on political decision-making and the evaluation of
scientific impact through citations. Through novel datasets, benchmark tasks,
and methodological frameworks, this work identifies key challenges and
opportunities to improve the causal capabilities of LLMs, providing a
comprehensive foundation for future research in this evolving field.},
 author = {Zhijing Jin},
 comment = {PhD Thesis 2024},
 doi = {},
 eprint = {2504.14530v1},
 journal = {arXiv preprint},
 title = {Causality for Natural Language Processing},
 url = {http://arxiv.org/abs/2504.14530v1},
 year = {2025}
}

@article{2504.14937v1,
 abstract = {Causal inference aids researchers in discovering cause-and-effect
relationships, leading to scientific insights. Accurate causal estimation
requires identifying confounding variables to avoid false discoveries. Pearl's
causal model uses causal DAGs to identify confounding variables, but incorrect
DAGs can lead to unreliable causal conclusions. However, for high dimensional
data, the causal DAGs are often complex beyond human verifiability. Graph
summarization is a logical next step, but current methods for general-purpose
graph summarization are inadequate for causal DAG summarization. This paper
addresses these challenges by proposing a causal graph summarization objective
that balances graph simplification for better understanding while retaining
essential causal information for reliable inference. We develop an efficient
greedy algorithm and show that summary causal DAGs can be directly used for
inference and are more robust to misspecification of assumptions, enhancing
robustness for causal inference. Experimenting with six real-life datasets, we
compared our algorithm to three existing solutions, showing its effectiveness
in handling high-dimensional data and its ability to generate summary DAGs that
ensure both reliable causal inference and robustness against misspecifications.},
 author = {Anna Zeng and Michael Cafarella and Batya Kenig and Markos Markakis and Brit Youngmann and Babak Salimi},
 comment = {},
 doi = {},
 eprint = {2504.14937v1},
 journal = {arXiv preprint},
 title = {Causal DAG Summarization (Full Version)},
 url = {http://arxiv.org/abs/2504.14937v1},
 year = {2025}
}

@article{2504.15854v1,
 abstract = {A treatment may be appropriate for some group (the ``sick" group) on whom it
has a positive effect, but it can also have a detrimental effect on subjects
from another group (the ``healthy" group). In a non-targeted trial both sick
and healthy subjects may be treated, producing heterogeneous effects within the
treated group. Inferring the correct treatment effect on the sick population is
then difficult, because the effects on the different groups get tangled. We
propose an efficient nonparametric approach to estimating the group effects,
called {\bf PCM} (pre-cluster and merge). We prove its asymptotic consistency
in a general setting and show, on synthetic data, more than a 10x improvement
in accuracy over existing state-of-the-art. Our approach applies more generally
to consistent estimation of functions with a finite range.},
 author = {Georgios Mavroudeas and Malik Magdon-Ismail and Kristin P. Bennett and Jason Kuruzovich},
 comment = {},
 doi = {},
 eprint = {2504.15854v1},
 journal = {arXiv preprint},
 title = {Consistent Causal Inference of Group Effects in Non-Targeted Trials with Finitely Many Effect Levels},
 url = {http://arxiv.org/abs/2504.15854v1},
 year = {2025}
}

@article{2504.16230v1,
 abstract = {Missingness in variables that define study eligibility criteria is a seldom
addressed challenge in electronic health record (EHR)-based settings. It is
typically the case that patients with incomplete eligibility information are
excluded from analysis without consideration of (implicit) assumptions that are
being made, leaving study conclusions subject to potential selection bias. In
an effort to ascertain eligibility for more patients, researchers may look back
further in time prior to study baseline, and in using outdated values of
eligibility-defining covariates may inappropriately be including individuals
who, unbeknownst to the researcher, fail to meet eligibility at baseline. To
the best of our knowledge, however, very little work has been done to mitigate
these concerns. We propose a robust and efficient estimator of the causal
average treatment effect on the treated, defined in the study eligible
population, in cohort studies where eligibility-defining covariates are missing
at random. The approach facilitates the use of flexible machine-learning
strategies for component nuisance functions while maintaining appropriate
convergence rates for valid asymptotic inference. EHR data from Kaiser
Permanente are used as motivation as well as a basis for extensive simulations
that verify robustness properties under various degrees of model
misspecification. The data are also used to demonstrate the use of the method
to analyze differences between two common bariatric surgical interventions for
long-term weight and glycemic outcomes among a cohort of severely obese
patients with type II diabetes mellitus.},
 author = {Luke Benz and Rajarshi Mukherjee and Rui Wang and David Arterburn and Heidi Fischer and Catherine Lee and Susan M. Shortreed and Sebastien Haneuse and Alexander W. Levis},
 comment = {},
 doi = {},
 eprint = {2504.16230v1},
 journal = {arXiv preprint},
 title = {Robust Causal Inference for EHR-based Studies of Point Exposures with Missingness in Eligibility Criteria},
 url = {http://arxiv.org/abs/2504.16230v1},
 year = {2025}
}

@article{2504.17166v1,
 abstract = {Heterogeneous treatment effect (HTE) estimation is critical in medical
research. It provides insights into how treatment effects vary among
individuals, which can provide statistical evidence for precision medicine.
While most existing methods focus on binary treatment situations, real-world
applications often involve multiple interventions. However, current HTE
estimation methods are primarily designed for binary comparisons and often rely
on black-box models, which limit their applicability and interpretability in
multi-arm settings. To address these challenges, we propose an interpretable
machine learning framework for HTE estimation in multi-arm trials. Our method
employs a rule-based ensemble approach consisting of rule generation, rule
ensemble, and HTE estimation, ensuring both predictive accuracy and
interpretability. Through extensive simulation studies and real data
applications, the performance of our method was evaluated against
state-of-the-art multi-arm HTE estimation approaches. The results indicate that
our approach achieved lower bias and higher estimation accuracy compared with
those of existing methods. Furthermore, the interpretability of our framework
allows clearer insights into how covariates influence treatment effects,
facilitating clinical decision making. By bridging the gap between accuracy and
interpretability, our study contributes a valuable tool for multi-arm HTE
estimation, supporting precision medicine.},
 author = {Ke Wan and Kensuke Tanioka and Toshio Shimokawa},
 comment = {},
 doi = {},
 eprint = {2504.17166v1},
 journal = {arXiv preprint},
 title = {Causal rule ensemble approach for multi-arm data},
 url = {http://arxiv.org/abs/2504.17166v1},
 year = {2025}
}

@article{2504.17703v3,
 abstract = {Federated Learning (FL) has emerged as a transformative paradigm in the field
of distributed machine learning, enabling multiple clients such as mobile
devices, edge nodes, or organizations to collaboratively train a shared global
model without the need to centralize sensitive data. This decentralized
approach addresses growing concerns around data privacy, security, and
regulatory compliance, making it particularly attractive in domains such as
healthcare, finance, and smart IoT systems. This survey provides a concise yet
comprehensive overview of Federated Learning, beginning with its core
architecture and communication protocol. We discuss the standard FL lifecycle,
including local training, model aggregation, and global updates. A particular
emphasis is placed on key technical challenges such as handling non-IID
(non-independent and identically distributed) data, mitigating system and
hardware heterogeneity, reducing communication overhead, and ensuring privacy
through mechanisms like differential privacy and secure aggregation.
Furthermore, we examine emerging trends in FL research, including personalized
FL, cross-device versus cross-silo settings, and integration with other
paradigms such as reinforcement learning and quantum computing. We also
highlight real-world applications and summarize benchmark datasets and
evaluation metrics commonly used in FL research. Finally, we outline open
research problems and future directions to guide the development of scalable,
efficient, and trustworthy FL systems.},
 author = {Ratun Rahman},
 comment = {},
 doi = {},
 eprint = {2504.17703v3},
 journal = {arXiv preprint},
 title = {Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence},
 url = {http://arxiv.org/abs/2504.17703v3},
 year = {2025}
}

@article{2504.17946v1,
 abstract = {Deep Neural Networks (DNNs) often rely on statistical correlations rather
than causal reasoning, limiting their robustness and interpretability. While
testing methods can identify failures, effective debugging and repair remain
challenging. This paper explores causal inference as an approach primarily for
DNN repair, leveraging causal debugging, counterfactual analysis, and
structural causal models (SCMs) to identify and correct failures. We discuss in
what ways these techniques support fairness, adversarial robustness, and
backdoor mitigation by providing targeted interventions. Finally, we discuss
key challenges, including scalability, generalization, and computational
efficiency, and outline future directions for integrating causality-driven
interventions to enhance DNN reliability.},
 author = {Fatemeh Vares and Brittany Johnson},
 comment = {Causality in Software Engineering (CauSE) 2025 Workshop at ESEC/FSE},
 doi = {10.1145/3696630.3731615},
 eprint = {2504.17946v1},
 journal = {arXiv preprint},
 title = {Causality-Driven Neural Network Repair: Challenges and Opportunities},
 url = {http://arxiv.org/abs/2504.17946v1},
 year = {2025}
}

@article{2504.18897v1,
 abstract = {We propose a parametric integral probability metric (IPM) to measure the
discrepancy between two probability measures. The proposed IPM leverages a
specific parametric family of discriminators, such as single-node neural
networks with ReLU activation, to effectively distinguish between
distributions, making it applicable in high-dimensional settings. By optimizing
over the parameters of the chosen discriminator class, the proposed IPM
demonstrates that its estimators have good convergence rates and can serve as a
surrogate for other IPMs that use smooth nonparametric discriminator classes.
We present an efficient algorithm for practical computation, offering a simple
implementation and requiring fewer hyperparameters. Furthermore, we explore its
applications in various tasks, such as covariate balancing for causal inference
and fair representation learning. Across such diverse applications, we
demonstrate that the proposed IPM provides strong theoretical guarantees, and
empirical experiments show that it achieves comparable or even superior
performance to other methods.},
 author = {Yuha Park and Kunwoong Kim and Insung Kong and Yongdai Kim},
 comment = {49 pages, 9 figures},
 doi = {},
 eprint = {2504.18897v1},
 journal = {arXiv preprint},
 title = {ReLU integral probability metric and its applications},
 url = {http://arxiv.org/abs/2504.18897v1},
 year = {2025}
}

@article{2504.19678v1,
 abstract = {Large language models and autonomous AI agents have evolved rapidly,
resulting in a diverse array of evaluation benchmarks, frameworks, and
collaboration protocols. However, the landscape remains fragmented and lacks a
unified taxonomy or comprehensive survey. Therefore, we present a side-by-side
comparison of benchmarks developed between 2019 and 2025 that evaluate these
models and agents across multiple domains. In addition, we propose a taxonomy
of approximately 60 benchmarks that cover general and academic knowledge
reasoning, mathematical problem-solving, code generation and software
engineering, factual grounding and retrieval, domain-specific evaluations,
multimodal and embodied tasks, task orchestration, and interactive assessments.
Furthermore, we review AI-agent frameworks introduced between 2023 and 2025
that integrate large language models with modular toolkits to enable autonomous
decision-making and multi-step reasoning. Moreover, we present real-world
applications of autonomous AI agents in materials science, biomedical research,
academic ideation, software engineering, synthetic data generation, chemical
reasoning, mathematical problem-solving, geographic information systems,
multimedia, healthcare, and finance. We then survey key agent-to-agent
collaboration protocols, namely the Agent Communication Protocol (ACP), the
Model Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,
we discuss recommendations for future research, focusing on advanced reasoning
strategies, failure modes in multi-agent LLM systems, automated scientific
discovery, dynamic tool integration via reinforcement learning, integrated
search capabilities, and security vulnerabilities in agent protocols.},
 author = {Mohamed Amine Ferrag and Norbert Tihanyi and Merouane Debbah},
 comment = {},
 doi = {},
 eprint = {2504.19678v1},
 journal = {arXiv preprint},
 title = {From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review},
 url = {http://arxiv.org/abs/2504.19678v1},
 year = {2025}
}

@article{2504.21062v1,
 abstract = {Machine learning detects patterns, block chain guarantees trust and
immutability, and modern causal inference identifies directional linkages, yet
none alone exposes the full energetic anatomy of complex systems; the
Hamiltonian Higher Order Elasticity Dynamics(2HOED) framework bridges these
gaps. Grounded in classical mechanics but extended to Economics order
elasticity terms, 2HOED represents economic, social, and physical systems as
energy-based Hamiltonians whose position, velocity, acceleration, and jerk of
elasticity jointly determine systemic power, Inertia, policy sensitivity, and
marginal responses. Because the formalism is scaling free and coordinate
agnostic, it transfers seamlessly from financial markets to climate science,
from supply chain logistics to epidemiology, thus any discipline in which
adaptation and shocks coexist. By embedding standard econometric variables
inside a Hamiltonian, 2HOED enriches conventional economic analysis with
rigorous diagnostics of resilience, tipping points, and feedback loops,
revealing failure modes invisible to linear models. Wavelet spectra, phase
space attractors, and topological persistence diagrams derived from 2HOED
expose multistage policy leverage that machine learning detects only
empirically and block chain secures only after the fact. For economists,
physicians and other scientists, the method opens a new causal energetic
channel linking biological or mechanical elasticity to macro level outcomes.
Portable, interpretable, and computationally light, 2HOED turns data streams
into dynamical energy maps, empowering decision makers to anticipate crises,
design adaptive policies, and engineer robust systems delivering the predictive
punch of AI with the explanatory clarity of physics.},
 author = {Ngueuleweu Tiwang Gildas},
 comment = {19 pages, 7 figures},
 doi = {},
 eprint = {2504.21062v1},
 journal = {arXiv preprint},
 title = {A Hamiltonian Higher-Order Elasticity Framework for Dynamic Diagnostics(2HOED)},
 url = {http://arxiv.org/abs/2504.21062v1},
 year = {2025}
}

@article{2504.21189v1,
 abstract = {Alzheimer's Disease (AD) is marked by significant inter-individual
variability in its progression, complicating accurate prognosis and
personalized care planning. This heterogeneity underscores the critical need
for predictive models capable of forecasting patient-specific disease
trajectories. Artificial Intelligence (AI) offers powerful tools to address
this challenge by analyzing complex, multi-modal, and longitudinal patient
data. This paper provides a comprehensive survey of AI methodologies applied to
personalized AD progression prediction. We review key approaches including
state-space models for capturing temporal dynamics, deep learning techniques
like Recurrent Neural Networks for sequence modeling, Graph Neural Networks
(GNNs) for leveraging network structures, and the emerging concept of AI-driven
digital twins for individualized simulation. Recognizing that data limitations
often impede progress, we examine common challenges such as high
dimensionality, missing data, and dataset imbalance. We further discuss
AI-driven mitigation strategies, with a specific focus on synthetic data
generation using Variational Autoencoders (VAEs) and Generative Adversarial
Networks (GANs) to augment and balance datasets. The survey synthesizes the
strengths and limitations of current approaches, emphasizing the trend towards
multimodal integration and the persistent need for model interpretability and
generalizability. Finally, we identify critical open challenges, including
robust external validation, clinical integration, and ethical considerations,
and outline promising future research directions such as hybrid models, causal
inference, and federated learning. This review aims to consolidate current
knowledge and guide future efforts in developing clinically relevant AI tools
for personalized AD prognostication.},
 author = {Gulsah Hancerliogullari Koksalmis and Bulent Soykan and Laura J. Brattain and Hsin-Hsiung Huang},
 comment = {25 pages, 11 figures},
 doi = {},
 eprint = {2504.21189v1},
 journal = {arXiv preprint},
 title = {Artificial Intelligence for Personalized Prediction of Alzheimer's Disease Progression: A Survey of Methods, Data Challenges, and Future Directions},
 url = {http://arxiv.org/abs/2504.21189v1},
 year = {2025}
}

@article{2505.00229v1,
 abstract = {Max-Linear Bayesian Networks (MLBNs) provide a powerful framework for causal
inference in extreme-value settings; we consider MLBNs with noise parameters
with a given topology in terms of the max-plus algebra by taking its logarithm.
Then, we show that an estimator of a parameter for each edge in a directed
acyclic graph (DAG) is distributed normally. We end this paper with
computational experiments with the expectation and maximization (EM) algorithm
and quadratic optimization.},
 author = {Mark Adams and Kamillo Ferry and Ruriko Yoshida},
 comment = {18 pages, 10 figures. Short version to appear in the proceedings of
  the 13th Workshop on Uncertainty Processing},
 doi = {},
 eprint = {2505.00229v1},
 journal = {arXiv preprint},
 title = {Inference for max-linear Bayesian networks with noise},
 url = {http://arxiv.org/abs/2505.00229v1},
 year = {2025}
}

@article{2505.00282v2,
 abstract = {This paper presents a general framework for conducting efficient inference on
parameters derived from unstructured data, which include text, images, audio,
and video. Economists have long used unstructured data by first extracting
low-dimensional structured features (e.g., the topic or sentiment of a text),
since the raw data are too high-dimensional and uninterpretable to include
directly in empirical analyses. The rise of deep neural networks has
accelerated this practice by greatly reducing the costs of extracting
structured data at scale, but neural networks do not make generically unbiased
predictions. This potentially propagates bias to the downstream estimators that
incorporate imputed structured data, and the availability of different
off-the-shelf neural networks with different biases moreover raises p-hacking
concerns. To address these challenges, we reframe inference with unstructured
data as a problem of missing structured data, where structured variables are
imputed from high-dimensional unstructured inputs. This perspective allows us
to apply classic results from semiparametric inference, leading to estimators
that are valid, efficient, and robust. We formalize this approach with MAR-S, a
framework that unifies and extends existing methods for debiased inference
using machine learning predictions, connecting them to familiar problems such
as causal inference. Within this framework, we develop robust and efficient
estimators for both descriptive and causal estimands and address challenges
like inference with aggregated and transformed missing structured data-a common
scenario that is not covered by existing work. These methods-and the
accompanying implementation package-provide economists with accessible tools
for constructing unbiased estimators using unstructured data in a wide range of
applications, as we demonstrate by re-analyzing several influential studies.},
 author = {Jacob Carlson and Melissa Dell},
 comment = {},
 doi = {},
 eprint = {2505.00282v2},
 journal = {arXiv preprint},
 title = {A Unifying Framework for Robust and Efficient Inference with Unstructured Data},
 url = {http://arxiv.org/abs/2505.00282v2},
 year = {2025}
}

@article{2505.00555v1,
 abstract = {Interpretable insights from predictive models remain critical in
bio-statistics, particularly when assessing causality, where classical
statistical and machine learning methods often provide inherent clarity. While
Neural Networks (NNs) offer powerful capabilities for modeling complex
biological data, their traditional "black-box" nature presents challenges for
validation and trust in high-stakes health applications. Recent advances in
Mechanistic Interpretability (MI) aim to decipher the internal computations
learned by these networks. This work investigates the application of MI
techniques to NNs within the context of causal inference for bio-statistics.
  We demonstrate that MI tools can be leveraged to: (1) probe and validate the
internal representations learned by NNs, such as those estimating nuisance
functions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)
discover and visualize the distinct computational pathways employed by the
network to process different types of inputs, potentially revealing how
confounders and treatments are handled; and (3) provide methodologies for
comparing the learned mechanisms and extracted insights across statistical,
machine learning, and NN models, fostering a deeper understanding of their
respective strengths and weaknesses for causal bio-statistical analysis.},
 author = {Jean-Baptiste A. Conan},
 comment = {},
 doi = {},
 eprint = {2505.00555v1},
 journal = {arXiv preprint},
 title = {On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics},
 url = {http://arxiv.org/abs/2505.00555v1},
 year = {2025}
}

@article{2505.01652v1,
 abstract = {Fair machine learning seeks to identify and mitigate biases in predictions
against unfavorable populations characterized by demographic attributes, such
as race and gender. Recently, a few works have extended fairness to graph data,
such as social networks, but most of them neglect the causal relationships
among data instances. This paper addresses the prevalent challenge in
fairness-aware ML algorithms, which typically assume Independent and
Identically Distributed (IID) data. We tackle the overlooked domain of non-IID,
graph-based settings where data instances are interconnected, influencing the
outcomes of fairness interventions. We base our research on the Network
Structural Causal Model (NSCM) framework and posit two main assumptions:
Decomposability and Graph Independence, which enable the computation of
interventional distributions in non-IID settings using the $do$-calculus. Based
on that, we develop the Message Passing Variational Autoencoder for Causal
Inference (MPVA) to compute interventional distributions and facilitate
causally fair node classification through estimated interventional
distributions. Empirical evaluations on semi-synthetic and real-world datasets
demonstrate that MPVA outperforms conventional methods by effectively
approximating interventional distributions and mitigating bias. The
implications of our findings underscore the potential of causality-based
fairness in complex ML applications, setting the stage for further research
into relaxing the initial assumptions to enhance model fairness.},
 author = {Yucong Dai and Lu Zhang and Yaowei Hu and Susan Gauch and Yongkai Wu},
 comment = {},
 doi = {},
 eprint = {2505.01652v1},
 journal = {arXiv preprint},
 title = {Causally Fair Node Classification on Non-IID Graph Data},
 url = {http://arxiv.org/abs/2505.01652v1},
 year = {2025}
}

@article{2505.01785v1,
 abstract = {Estimating the causal effect of time-varying treatments on survival outcomes
is a challenging task in many domains, particularly in medicine where treatment
protocols adapt over time. While recent advances in representation learning
have improved causal inference for static treatments, extending these methods
to dynamic treatment regimes with survival outcomes remains under-explored. In
this paper, we introduce TV-SurvCaus, a novel framework that extends
representation balancing techniques to the time-varying treatment setting for
survival analysis. We provide theoretical guarantees through (1) a generalized
bound for time-varying precision in estimation of heterogeneous effects, (2)
variance control via sequential balancing weights, (3) consistency results for
dynamic treatment regimes, (4) convergence rates for representation learning
with temporal dependencies, and (5) a formal bound on the bias due to
treatment-confounder feedback. Our neural architecture incorporates sequence
modeling to handle temporal dependencies while balancing time-dependent
representations. Through extensive experiments on both synthetic and real-world
datasets, we demonstrate that TV-SurvCaus outperforms existing methods in
estimating individualized treatment effects with time-varying covariates and
treatments. Our framework advances the field of causal inference by enabling
more accurate estimation of treatment effects in dynamic, longitudinal settings
with survival outcomes.},
 author = {Ayoub Abraich},
 comment = {},
 doi = {},
 eprint = {2505.01785v1},
 journal = {arXiv preprint},
 title = {TV-SurvCaus: Dynamic Representation Balancing for Causal Survival Analysis},
 url = {http://arxiv.org/abs/2505.01785v1},
 year = {2025}
}

@article{2505.02238v1,
 abstract = {Federated causal inference enables multi-site treatment effect estimation
without sharing individual-level data, offering a privacy-preserving solution
for real-world evidence generation. However, data heterogeneity across sites,
manifested in differences in covariate, treatment, and outcome, poses
significant challenges for unbiased and efficient estimation. In this paper, we
present a comprehensive review and theoretical analysis of federated causal
effect estimation across both binary/continuous and time-to-event outcomes. We
classify existing methods into weight-based strategies and optimization-based
frameworks and further discuss extensions including personalized models,
peer-to-peer communication, and model decomposition. For time-to-event
outcomes, we examine federated Cox and Aalen-Johansen models, deriving
asymptotic bias and variance under heterogeneity. Our analysis reveals that
FedProx-style regularization achieves near-optimal bias-variance trade-offs
compared to naive averaging and meta-analysis. We review related software tools
and conclude by outlining opportunities, challenges, and future directions for
scalable, fair, and trustworthy federated causal inference in distributed
healthcare systems.},
 author = {Haoyang Li and Jie Xu and Kyra Gan and Fei Wang and Chengxi Zang},
 comment = {},
 doi = {},
 eprint = {2505.02238v1},
 journal = {arXiv preprint},
 title = {Federated Causal Inference in Healthcare: Methods, Challenges, and Applications},
 url = {http://arxiv.org/abs/2505.02238v1},
 year = {2025}
}

@article{2505.04651v1,
 abstract = {Large Language Models (LLMs) are transforming scientific hypothesis
generation and validation by enabling information synthesis, latent
relationship discovery, and reasoning augmentation. This survey provides a
structured overview of LLM-driven approaches, including symbolic frameworks,
generative models, hybrid systems, and multi-agent architectures. We examine
techniques such as retrieval-augmented generation, knowledge-graph completion,
simulation, causal inference, and tool-assisted reasoning, highlighting
trade-offs in interpretability, novelty, and domain alignment. We contrast
early symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM
pipelines that leverage in-context learning and domain adaptation via
fine-tuning, retrieval, and symbolic grounding. For validation, we review
simulation, human-AI collaboration, causal modeling, and uncertainty
quantification, emphasizing iterative assessment in open-world contexts. The
survey maps datasets across biomedicine, materials science, environmental
science, and social science, introducing new resources like AHTech and
CSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation,
multimodal-symbolic integration, human-in-the-loop systems, and ethical
safeguards, positioning LLMs as agents for principled, scalable scientific
discovery.},
 author = {Adithya Kulkarni and Fatimah Alotaibi and Xinyue Zeng and Longfeng Wu and Tong Zeng and Barry Menglong Yao and Minqian Liu and Shuaicheng Zhang and Lifu Huang and Dawei Zhou},
 comment = {},
 doi = {},
 eprint = {2505.04651v1},
 journal = {arXiv preprint},
 title = {Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions},
 url = {http://arxiv.org/abs/2505.04651v1},
 year = {2025}
}

@article{2505.05108v2,
 abstract = {Embodied artificial intelligence (Embodied AI) plays a pivotal role in the
application of advanced technologies in the intelligent era, where AI systems
are integrated with physical bodies that enable them to perceive, reason, and
interact with their environments. Through the use of sensors for input and
actuators for action, these systems can learn and adapt based on real-world
feedback, allowing them to perform tasks effectively in dynamic and
unpredictable environments. As techniques such as deep learning (DL),
reinforcement learning (RL), and large language models (LLMs) mature, embodied
AI has become a leading field in both academia and industry, with applications
spanning robotics, healthcare, transportation, and manufacturing. However, most
research has focused on single-agent systems that often assume static, closed
environments, whereas real-world embodied AI must navigate far more complex
scenarios. In such settings, agents must not only interact with their
surroundings but also collaborate with other agents, necessitating
sophisticated mechanisms for adaptation, real-time learning, and collaborative
problem-solving. Despite increasing interest in multi-agent systems, existing
research remains narrow in scope, often relying on simplified models that fail
to capture the full complexity of dynamic, open environments for multi-agent
embodied AI. Moreover, no comprehensive survey has systematically reviewed the
advancements in this area. As embodied AI rapidly evolves, it is crucial to
deepen our understanding of multi-agent embodied AI to address the challenges
presented by real-world applications. To fill this gap and foster further
development in the field, this paper reviews the current state of research,
analyzes key contributions, and identifies challenges and future directions,
providing insights to guide innovation and progress in this field.},
 author = {Zhaohan Feng and Ruiqi Xue and Lei Yuan and Yang Yu and Ning Ding and Meiqin Liu and Bingzhao Gao and Jian Sun and Xinhu Zheng and Gang Wang},
 comment = {},
 doi = {},
 eprint = {2505.05108v2},
 journal = {arXiv preprint},
 title = {Multi-agent Embodied AI: Advances and Future Directions},
 url = {http://arxiv.org/abs/2505.05108v2},
 year = {2025}
}

@article{2505.06542v1,
 abstract = {Causal discovery is central to inferring causal relationships from
observational data. In the presence of latent confounding, algorithms such as
Fast Causal Inference (FCI) learn a Partial Ancestral Graph (PAG) representing
the true model's Markov Equivalence Class. However, their correctness
critically depends on empirical faithfulness, the assumption that observed
(in)dependencies perfectly reflect those of the underlying causal model, which
often fails in practice due to limited sample sizes. To address this, we
introduce the first nonparametric score to assess a PAG's compatibility with
observed data, even with mixed variable types. This score is both necessary and
sufficient to characterize structural uncertainty and distinguish between
distinct PAGs. We then propose data-compatible FCI (dcFCI), the first hybrid
causal discovery algorithm to jointly address latent confounding, empirical
unfaithfulness, and mixed data types. dcFCI integrates our score into an
(Anytime)FCI-guided search that systematically explores, ranks, and validates
candidate PAGs. Experiments on synthetic and real-world scenarios demonstrate
that dcFCI significantly outperforms state-of-the-art methods, often recovering
the true PAG even in small and heterogeneous datasets. Examining top-ranked
PAGs further provides valuable insights into structural uncertainty, supporting
more robust and informed causal reasoning and decision-making.},
 author = {Adèle H. Ribeiro and Dominik Heider},
 comment = {31 pages. This work has been submitted to the IEEE for possible
  publication},
 doi = {},
 eprint = {2505.06542v1},
 journal = {arXiv preprint},
 title = {dcFCI: Robust Causal Discovery Under Latent Confounding, Unfaithfulness, and Mixed Data},
 url = {http://arxiv.org/abs/2505.06542v1},
 year = {2025}
}

@article{2505.08960v2,
 abstract = {Randomized controlled trials (RCTs) often include subgroup analyses to assess
whether treatment effects vary across pre-specified patient populations.
However, these analyses frequently suffer from small sample sizes which limit
the power to detect heterogeneous effects. Power can be improved by leveraging
predictors of the outcome -- i.e., through covariate adjustment -- as well as
by borrowing external data from similar RCTs or observational studies. The
benefits of covariate adjustment may be limited when the trial sample is small.
Borrowing external data can increase the effective sample size and improve
power, but it introduces two key challenges: (i) integrating data across
sources can lead to model misspecification, and (ii) practical violations of
the positivity assumption -- where the probability of receiving the target
treatment is near-zero for some covariate profiles in the external data -- can
lead to extreme inverse-probability weights and unstable inferences, ultimately
negating potential power gains. To account for these shortcomings, we present
an approach to improving power in pre-planned subgroup analyses of small RCTs
that leverages both baseline predictors and external data. We propose debiased
estimators that accommodate parametric, machine learning, and nonparametric
Bayesian methods. To address practical positivity violations, we introduce
three estimators: a covariate-balancing approach, an automated debiased machine
learning (DML) estimator, and a calibrated DML estimator. We show improved
power in various simulations and offer practical recommendations for the
application of the proposed methods. Finally, we apply them to evaluate the
effectiveness of citalopram for negative symptoms in first-episode
schizophrenia patients across subgroups defined by duration of untreated
psychosis, using data from two small RCTs.},
 author = {Antonio D'Alessandro and Jiyu Kim and Samrachana Adhikari and Donald Goff and Falco J. Bargagli Stoffi and Michele Santacatterina},
 comment = {},
 doi = {},
 eprint = {2505.08960v2},
 journal = {arXiv preprint},
 title = {Modern causal inference approaches to improve power for subgroup analysis in randomized controlled trials},
 url = {http://arxiv.org/abs/2505.08960v2},
 year = {2025}
}

@article{2505.09706v2,
 abstract = {This paper introduces the Difference-in-Differences Bayesian Causal Forest
(DiD-BCF), a novel non-parametric model addressing key challenges in DiD
estimation, such as staggered adoption and heterogeneous treatment effects.
DiD-BCF provides a unified framework for estimating Average (ATE),
Group-Average (GATE), and Conditional Average Treatment Effects (CATE). A core
innovation, its Parallel Trends Assumption (PTA)-based reparameterization,
enhances estimation accuracy and stability in complex panel data settings.
Extensive simulations demonstrate DiD-BCF's superior performance over
established benchmarks, particularly under non-linearity, selection biases, and
effect heterogeneity. Applied to U.S. minimum wage policy, the model uncovers
significant conditional treatment effect heterogeneity related to county
population, insights obscured by traditional methods. DiD-BCF offers a robust
and versatile tool for more nuanced causal inference in modern DiD
applications.},
 author = {Hugo Gobato Souto and Francisco Louzada Neto},
 comment = {},
 doi = {},
 eprint = {2505.09706v2},
 journal = {arXiv preprint},
 title = {Forests for Differences: Robust Causal Inference Beyond Parametric DiD},
 url = {http://arxiv.org/abs/2505.09706v2},
 year = {2025}
}

@article{2505.10007v1,
 abstract = {Motivated by practical applications where stable long-term performance is
critical-such as robotics, operations research, and healthcare-we study the
problem of distributionally robust (DR) average-reward reinforcement learning.
We propose two algorithms that achieve near-optimal sample complexity. The
first reduces the problem to a DR discounted Markov decision process (MDP),
while the second, Anchored DR Average-Reward MDP, introduces an anchoring state
to stabilize the controlled transition kernels within the uncertainty set.
Assuming the nominal MDP is uniformly ergodic, we prove that both algorithms
attain a sample complexity of $\widetilde{O}\left(|\mathbf{S}||\mathbf{A}|
t_{\mathrm{mix}}^2\varepsilon^{-2}\right)$ for estimating the optimal policy as
well as the robust average reward under KL and $f_k$-divergence-based
uncertainty sets, provided the uncertainty radius is sufficiently small. Here,
$\varepsilon$ is the target accuracy, $|\mathbf{S}|$ and $|\mathbf{A}|$ denote
the sizes of the state and action spaces, and $t_{\mathrm{mix}}$ is the mixing
time of the nominal MDP. This represents the first finite-sample convergence
guarantee for DR average-reward reinforcement learning. We further validate the
convergence rates of our algorithms through numerical experiments.},
 author = {Zijun Chen and Shengbo Wang and Nian Si},
 comment = {},
 doi = {},
 eprint = {2505.10007v1},
 journal = {arXiv preprint},
 title = {Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning},
 url = {http://arxiv.org/abs/2505.10007v1},
 year = {2025}
}

@article{2505.11014v1,
 abstract = {Data integration approaches are increasingly used to enhance the efficiency
and generalizability of studies. However, a key limitation of these methods is
the assumption that outcome measures are identical across datasets -- an
assumption that often does not hold in practice. Consider the following opioid
use disorder (OUD) studies: the XBOT trial and the POAT study, both evaluating
the effect of medications for OUD on withdrawal symptom severity (not the
primary outcome of either trial). While XBOT measures withdrawal severity using
the subjective opiate withdrawal scale, POAT uses the clinical opiate
withdrawal scale. We analyze this realistic yet challenging setting where
outcome measures differ across studies and where neither study records both
types of outcomes. Our paper studies whether and when integrating studies with
disparate outcome measures leads to efficiency gains. We introduce three sets
of assumptions -- with varying degrees of strength -- linking both outcome
measures. Our theoretical and empirical results highlight a cautionary tale:
integration can improve asymptotic efficiency only under the strongest
assumption linking the outcomes. However, misspecification of this assumption
leads to bias. In contrast, a milder assumption may yield finite-sample
efficiency gains, yet these benefits diminish as sample size increases. We
illustrate these trade-offs via a case study integrating the XBOT and POAT
datasets to estimate the comparative effect of two medications for opioid use
disorder on withdrawal symptoms. By systematically varying the assumptions
linking the SOW and COW scales, we show potential efficiency gains and the
risks of bias. Our findings emphasize the need for careful assumption selection
when fusing datasets with differing outcome measures, offering guidance for
researchers navigating this common challenge in modern data integration.},
 author = {Harsh Parikh and Trang Quynh Nguyen and Elizabeth A. Stuart and Kara E. Rudolph and Caleb H. Miles},
 comment = {},
 doi = {},
 eprint = {2505.11014v1},
 journal = {arXiv preprint},
 title = {A Cautionary Tale on Integrating Studies with Disparate Outcome Measures for Causal Inference},
 url = {http://arxiv.org/abs/2505.11014v1},
 year = {2025}
}

@article{2505.11085v1,
 abstract = {Kernel-based conditional independence (KCI) testing is a powerful
nonparametric method commonly employed in causal discovery tasks. Despite its
flexibility and statistical reliability, cubic computational complexity limits
its application to large datasets. To address this computational bottleneck, we
propose \textit{FastKCI}, a scalable and parallelizable kernel-based
conditional independence test that utilizes a mixture-of-experts approach
inspired by embarrassingly parallel inference techniques for Gaussian
processes. By partitioning the dataset based on a Gaussian mixture model over
the conditioning variables, FastKCI conducts local KCI tests in parallel,
aggregating the results using an importance-weighted sampling scheme.
Experiments on synthetic datasets and benchmarks on real-world production data
validate that FastKCI maintains the statistical power of the original KCI test
while achieving substantial computational speedups. FastKCI thus represents a
practical and efficient solution for conditional independence testing in causal
inference on large-scale data.},
 author = {Oliver Schacht and Biwei Huang},
 comment = {9 pages, 5 figures},
 doi = {},
 eprint = {2505.11085v1},
 journal = {arXiv preprint},
 title = {A Fast Kernel-based Conditional Independence test with Application to Causal Discovery},
 url = {http://arxiv.org/abs/2505.11085v1},
 year = {2025}
}

@article{2505.11444v1,
 abstract = {Estimating individualized treatment effects from observational data is a
central challenge in causal inference, largely due to covariate imbalance and
confounding bias from non-randomized treatment assignment. While inverse
probability weighting (IPW) is a well-established solution to this problem, its
integration into modern deep learning frameworks remains limited. In this work,
we propose Importance-Weighted Diffusion Distillation (IWDD), a novel
generative framework that combines the pretraining of diffusion models with
importance-weighted score distillation to enable accurate and fast causal
estimation-including potential outcome prediction and treatment effect
estimation. We demonstrate how IPW can be naturally incorporated into the
distillation of pretrained diffusion models, and further introduce a
randomization-based adjustment that eliminates the need to compute IPW
explicitly-thereby simplifying computation and, more importantly, provably
reducing the variance of gradient estimates. Empirical results show that IWDD
achieves state-of-the-art out-of-sample prediction performance, with the
highest win rates compared to other baselines, significantly improving causal
estimation and supporting the development of individualized treatment
strategies. We will release our PyTorch code for reproducibility and future
research.},
 author = {Xinran Song and Tianyu Chen and Mingyuan Zhou},
 comment = {},
 doi = {},
 eprint = {2505.11444v1},
 journal = {arXiv preprint},
 title = {A Generative Framework for Causal Estimation via Importance-Weighted Diffusion Distillation},
 url = {http://arxiv.org/abs/2505.11444v1},
 year = {2025}
}

@article{2505.12094v1,
 abstract = {This paper introduces Attribution Projection Calculus (AP-Calculus), a novel
mathematical framework for determining causal relationships in structured
Bayesian networks. We investigate a specific network architecture with source
nodes connected to destination nodes through intermediate nodes, where each
input maps to a single label with maximum marginal probability. We prove that
for each label, exactly one intermediate node acts as a deconfounder while
others serve as confounders, enabling optimal attribution of features to their
corresponding labels. The framework formalizes the dual nature of intermediate
nodes as both confounders and deconfounders depending on the context, and
establishes separation functions that maximize distinctions between
intermediate representations. We demonstrate that the proposed network
architecture is optimal for causal inference compared to alternative
structures, including those based on Pearl's causal framework. AP-Calculus
provides a comprehensive mathematical foundation for analyzing feature-label
attributions, managing spurious correlations, quantifying information gain,
ensuring fairness, and evaluating uncertainty in prediction models, including
large language models. Theoretical verification shows that AP-Calculus not only
extends but can also subsume traditional do-calculus for many practical
applications, offering a more direct approach to causal inference in supervised
learning contexts.},
 author = {M Ruhul Amin},
 comment = {*AI was used to improve Text and collecting Citations},
 doi = {},
 eprint = {2505.12094v1},
 journal = {arXiv preprint},
 title = {Attribution Projection Calculus: A Novel Framework for Causal Inference in Bayesian Networks},
 url = {http://arxiv.org/abs/2505.12094v1},
 year = {2025}
}

@article{2505.12153v1,
 abstract = {The integration of Reinforcement Learning (RL) into robotic-assisted surgery
(RAS) holds significant promise for advancing surgical precision, adaptability,
and autonomous decision-making. However, the development of robust RL models in
clinical settings is hindered by key challenges, including stringent patient
data privacy regulations, limited access to diverse surgical datasets, and high
procedural variability. To address these limitations, this paper presents a
Federated Deep Reinforcement Learning (FDRL) framework that enables
decentralized training of RL models across multiple healthcare institutions
without exposing sensitive patient information. A central innovation of the
proposed framework is its dynamic policy adaptation mechanism, which allows
surgical robots to select and tailor patient-specific policies in real-time,
thereby ensuring personalized and Optimised interventions. To uphold rigorous
privacy standards while facilitating collaborative learning, the FDRL framework
incorporates secure aggregation, differential privacy, and homomorphic
encryption techniques. Experimental results demonstrate a 60\% reduction in
privacy leakage compared to conventional methods, with surgical precision
maintained within a 1.5\% margin of a centralized baseline. This work
establishes a foundational approach for adaptive, secure, and patient-centric
AI-driven surgical robotics, offering a pathway toward clinical translation and
scalable deployment across diverse healthcare environments.},
 author = {Sana Hafeez and Sundas Rafat Mulkana and Muhammad Ali Imran and Michele Sevegnani},
 comment = {11 pages, 7 figures, conference},
 doi = {},
 eprint = {2505.12153v1},
 journal = {arXiv preprint},
 title = {Federated Deep Reinforcement Learning for Privacy-Preserving Robotic-Assisted Surgery},
 url = {http://arxiv.org/abs/2505.12153v1},
 year = {2025}
}

@article{2505.12159v2,
 abstract = {Treatment strategies are critical in healthcare, particularly when outcomes
are subject to censoring. This study introduces the Counterfactual
Buckley-James Q-Learning framework, which integrates the Buckley-James method
with reinforcement learning to address challenges posed by censored survival
data. The Buckley-James method imputes censored survival times via conditional
expectations based on observed data, offering a robust mechanism for handling
incomplete outcomes. By incorporating these imputed values into a
counterfactual Q-learning framework, the proposed method enables the estimation
and comparison of potential outcomes under different treatment strategies. This
facilitates the identification of optimal dynamic treatment regimes that
maximize expected survival time. Through extensive simulation studies, the
method demonstrates robust performance across various sample sizes and
censoring scenarios, including right censoring and missing at random (MAR).
Application to real-world clinical trial data further highlights the utility of
this approach in informing personalized treatment decisions, providing an
interpretable and reliable tool for optimizing survival outcomes in complex
clinical settings.},
 author = {Jeongjin Lee and Jong-Min Kim},
 comment = {Final Version; Accepted in Journal of the Royal Statistical Society
  Series A: Statistics in Society (2025)},
 doi = {10.1093/jrsssa/qnaf123},
 eprint = {2505.12159v2},
 journal = {arXiv preprint},
 title = {Counterfactual Q Learning via the Linear Buckley James Method for Longitudinal Survival Data},
 url = {http://arxiv.org/abs/2505.12159v2},
 year = {2025}
}

@article{2505.12617v1,
 abstract = {Causal inference literature has extensively focused on binary treatments,
with relatively fewer methods developed for multi-valued treatments. In
particular, methods for multiple simultaneously assigned treatments remain
understudied despite their practical importance. This paper introduces two
settings: (1) estimating the effects of multiple treatments of different types
(binary, categorical, and continuous) and the effects of treatment
interactions, and (2) estimating the average treatment effect across categories
of multi-valued regimens. To obtain robust estimates for both settings, we
propose a class of methods based on the Double Machine Learning (DML)
framework. Our methods are well-suited for complex settings of multiple
treatments/regimens, using machine learning to model confounding relationships
while overcoming regularization and overfitting biases through Neyman
orthogonality and cross-fitting. To our knowledge, this work is the first to
apply machine learning for robust estimation of interaction effects in the
presence of multiple treatments. We further establish the asymptotic
distribution of our estimators and derive variance estimators for statistical
inference. Extensive simulations demonstrate the performance of our methods.
Finally, we apply the methods to study the effect of three treatments on
HIV-associated kidney disease in an adult HIV cohort of 2455 participants in
Nigeria.},
 author = {Qingyan Xiang and Yubai Yuan and Dongyuan Song and Usman J. Wudil and Muktar H. Aliyu and C. William Wester and Bryan E. Shepherd},
 comment = {},
 doi = {},
 eprint = {2505.12617v1},
 journal = {arXiv preprint},
 title = {Double machine learning to estimate the effects of multiple treatments and their interactions},
 url = {http://arxiv.org/abs/2505.12617v1},
 year = {2025}
}

@article{2505.12701v1,
 abstract = {Reinforcement Learning (RL) has shown great promise in domains like
healthcare and robotics but often struggles with adoption due to its lack of
interpretability. Counterfactual explanations, which address "what if"
scenarios, provide a promising avenue for understanding RL decisions but remain
underexplored for continuous action spaces. We propose a novel approach for
generating counterfactual explanations in continuous action RL by computing
alternative action sequences that improve outcomes while minimizing deviations
from the original sequence. Our approach leverages a distance metric for
continuous actions and accounts for constraints such as adhering to predefined
policies in specific states. Evaluations in two RL domains, Diabetes Control
and Lunar Lander, demonstrate the effectiveness, efficiency, and generalization
of our approach, enabling more interpretable and trustworthy RL applications.},
 author = {Shuyang Dong and Shangtong Zhang and Lu Feng},
 comment = {Accepted by International Joint Conference on Artificial Intelligence
  (IJCAI) 2025},
 doi = {},
 eprint = {2505.12701v1},
 journal = {arXiv preprint},
 title = {Counterfactual Explanations for Continuous Action Reinforcement Learning},
 url = {http://arxiv.org/abs/2505.12701v1},
 year = {2025}
}

@article{2505.12873v1,
 abstract = {Modern machine learning methods typically fail to adequately capture causal
information. Consequently, such models do not handle data distributional
shifts, are vulnerable to adversarial examples, and often learn spurious
correlations. Causal machine learning, or causal inference, aims to solve these
issues by estimating the expected outcome of counterfactual events, using
observational and/or interventional data, where causal relationships are
typically depicted as directed acyclic graphs. It is an open question as to
whether these causal algorithms provide opportunities for quantum enhancement.
In this paper we consider a recently developed family of non-parametric,
continuous causal estimators and derive quantum algorithms for these tasks.
Kernel evaluation and large matrix inversion are critical sub-routines of these
classical algorithms, which makes them particularly amenable to a quantum
treatment. Unlike other quantum machine learning algorithms, closed form
solutions for the estimators exist, negating the need for gradient evaluation
and variational learning. We describe several new hybrid quantum-classical
algorithms and show that uniform consistency of the estimators is retained.
Furthermore, if one is satisfied with a quantum state output that is
proportional to the true causal estimand, then these algorithms inherit the
exponential complexity advantages given by quantum linear system solvers.},
 author = {Rishi Goel and Casey R. Myers and Sally Shrapnel},
 comment = {6 + 13 pages},
 doi = {},
 eprint = {2505.12873v1},
 journal = {arXiv preprint},
 title = {Quantum Algorithms for Causal Estimands},
 url = {http://arxiv.org/abs/2505.12873v1},
 year = {2025}
}

@article{2505.13324v1,
 abstract = {Counterfactuals play a pivotal role in the two distinct data science fields
of causal inference (CI) and explainable artificial intelligence (XAI). While
the core idea behind counterfactuals remains the same in both fields--the
examination of what would have happened under different circumstances--there
are key differences in how they are used and interpreted. We introduce a formal
definition that encompasses the multi-faceted concept of the counterfactual in
CI and XAI. We then discuss how counterfactuals are used, evaluated, generated,
and operationalized in CI vs. XAI, highlighting conceptual and practical
differences. By comparing and contrasting the two, we hope to identify
opportunities for cross-fertilization across CI and XAI.},
 author = {Galit Shmueli and David Martens and Jaewon Yoo and Travis Greene},
 comment = {},
 doi = {},
 eprint = {2505.13324v1},
 journal = {arXiv preprint},
 title = {From What Ifs to Insights: Counterfactuals in Causal Inference vs. Explainable AI},
 url = {http://arxiv.org/abs/2505.13324v1},
 year = {2025}
}

@article{2505.13422v1,
 abstract = {Machine learning (ML) primarily evolved to solve "prediction problems." The
first stage of two-stage least squares (2SLS) is a prediction problem,
suggesting potential gains from ML first-stage assistance. However, little
guidance exists on when ML helps 2SLS$\unicode{x2014}$or when it hurts. We
investigate the implications of inserting ML into 2SLS, decomposing the bias
into three informative components. Mechanically, ML-in-2SLS procedures face
issues common to prediction and causal-inference settings$\unicode{x2014}$and
their interaction. Through simulation, we show linear ML methods (e.g.,
post-Lasso) work well, while nonlinear methods (e.g., random forests, neural
nets) generate substantial bias in second-stage
estimates$\unicode{x2014}$potentially exceeding the bias of endogenous OLS.},
 author = {Connor Lennon and Edward Rubin and Glen Waddell},
 comment = {},
 doi = {},
 eprint = {2505.13422v1},
 journal = {arXiv preprint},
 title = {Machine learning the first stage in 2SLS: Practical guidance from bias decomposition and simulation},
 url = {http://arxiv.org/abs/2505.13422v1},
 year = {2025}
}

@article{2505.13770v1,
 abstract = {Reliable causal inference is essential for making decisions in high-stakes
areas like medicine, economics, and public policy. However, it remains unclear
whether large language models (LLMs) can handle rigorous and trustworthy
statistical causal inference. Current benchmarks usually involve simplified
tasks. For example, these tasks might only ask LLMs to identify semantic causal
relationships or draw conclusions directly from raw data. As a result, models
may overlook important statistical pitfalls, such as Simpson's paradox or
selection bias. This oversight limits the applicability of LLMs in the real
world. To address these limitations, we propose CausalPitfalls, a comprehensive
benchmark designed to rigorously evaluate the capability of LLMs in overcoming
common causal inference pitfalls. Our benchmark features structured challenges
across multiple difficulty levels, each paired with grading rubrics. This
approach allows us to quantitatively measure both causal reasoning capabilities
and the reliability of LLMs' responses. We evaluate models using two protocols:
(1) direct prompting, which assesses intrinsic causal reasoning, and (2)
code-assisted prompting, where models generate executable code for explicit
statistical analysis. Additionally, we validate the effectiveness of this judge
by comparing its scoring with assessments from human experts. Our results
reveal significant limitations in current LLMs when performing statistical
causal inference. The CausalPitfalls benchmark provides essential guidance and
quantitative metrics to advance the development of trustworthy causal reasoning
systems.},
 author = {Jin Du and Li Chen and Xun Xian and An Luo and Fangqiao Tian and Ganghua Wang and Charles Doss and Xiaotong Shen and Jie Ding},
 comment = {},
 doi = {},
 eprint = {2505.13770v1},
 journal = {arXiv preprint},
 title = {Ice Cream Doesn't Cause Drowning: Benchmarking LLMs Against Statistical Pitfalls in Causal Inference},
 url = {http://arxiv.org/abs/2505.13770v1},
 year = {2025}
}

@article{2505.14396v1,
 abstract = {Causal world models are systems that can answer counterfactual questions
about an environment of interest, i.e. predict how it would have evolved if an
arbitrary subset of events had been realized differently. It requires
understanding the underlying causes behind chains of events and conducting
causal inference for arbitrary unseen distributions. So far, this task eludes
foundation models, notably large language models (LLMs), which do not have
demonstrated causal reasoning capabilities beyond the memorization of existing
causal relationships. Furthermore, evaluating counterfactuals in real-world
applications is challenging since only the factual world is observed, limiting
evaluation to synthetic datasets. We address these problems by explicitly
extracting and modeling causal relationships and propose the Causal
Cartographer framework. First, we introduce a graph retrieval-augmented
generation agent tasked to retrieve causal relationships from data. This
approach allows us to construct a large network of real-world causal
relationships that can serve as a repository of causal knowledge and build
real-world counterfactuals. In addition, we create a counterfactual reasoning
agent constrained by causal relationships to perform reliable step-by-step
causal inference. We show that our approach can extract causal knowledge and
improve the robustness of LLMs for causal reasoning tasks while reducing
inference costs and spurious correlations.},
 author = {Gaël Gendron and Jože M. Rožanec and Michael Witbrock and Gillian Dobbie},
 comment = {29 pages, 9 pages for the main paper, 20 pages for the references and
  appendix, 25 figures},
 doi = {},
 eprint = {2505.14396v1},
 journal = {arXiv preprint},
 title = {Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds},
 url = {http://arxiv.org/abs/2505.14396v1},
 year = {2025}
}

@article{2505.14748v1,
 abstract = {GraphSAGE is a widely used graph neural network. The introduction of causal
inference has improved its robust performance and named as Causal GraphSAGE.
However, Causal GraphSAGE focuses on measuring causal weighting among
individual nodes, but neglecting the cooperative relationships among sampling
nodes as a whole. To address this issue, this paper proposes Cooperative Causal
GraphSAGE (CoCa-GraphSAGE), which combines cooperative game theory with Causal
GraphSAGE. Initially, a cooperative causal structure model is constructed in
the case of cooperation based on the graph structure. Subsequently, Cooperative
Causal sampling (CoCa-sampling) algorithm is proposed, employing the Shapley
values to calculate the cooperative contribution based on causal weights of the
nodes sets. CoCa-sampling guides the selection of nodes with significant
cooperative causal effects during the neighborhood sampling process, thus
integrating the selected neighborhood features under cooperative relationships,
which takes the sampled nodes as a whole and generates more stable target node
embeddings. Experiments on publicly available datasets show that the proposed
method has comparable classification performance to the compared methods and
outperforms under perturbations, demonstrating the robustness improvement by
CoCa-sampling.},
 author = {Zaifa Xue and Tao Zhang and Tuo Xu and Huaixin Liang and Le Gao},
 comment = {},
 doi = {},
 eprint = {2505.14748v1},
 journal = {arXiv preprint},
 title = {Cooperative Causal GraphSAGE},
 url = {http://arxiv.org/abs/2505.14748v1},
 year = {2025}
}

@article{2505.14825v1,
 abstract = {Causal inference determines cause-and-effect relationships between variables
and has broad applications across disciplines. Traditional time-series methods
often reveal causal links only in a time-averaged sense, while ensemble-based
information transfer approaches detect the time evolution of short-term causal
relationships but are typically limited to low-dimensional systems. In this
paper, a new causal inference framework, called assimilative causal inference
(ACI), is developed. Fundamentally different from the state-of-the-art methods,
ACI uses a dynamical system and a single realization of a subset of the state
variables to identify instantaneous causal relationships and the dynamic
evolution of the associated causal influence range (CIR). Instead of
quantifying how causes influence effects as done traditionally, ACI solves an
inverse problem via Bayesian data assimilation, thus tracing causes backward
from observed effects with an implicit Bayesian hypothesis. Causality is
determined by assessing whether incorporating the information of the effect
variables reduces the uncertainty in recovering the potential cause variables.
ACI has several desirable features. First, it captures the dynamic interplay of
variables, where their roles as causes and effects can shift repeatedly over
time. Second, a mathematically justified objective criterion determines the CIR
without empirical thresholds. Third, ACI is scalable to high-dimensional
problems by leveraging computationally efficient Bayesian data assimilation
techniques. Finally, ACI applies to short time series and incomplete datasets.
Notably, ACI does not require observations of candidate causes, which is a key
advantage since potential drivers are often unknown or unmeasured. The
effectiveness of ACI is demonstrated by complex dynamical systems showcasing
intermittency and extreme events.},
 author = {Marios Andreou and Nan Chen and Erik Bollt},
 comment = {Includes the Main Text and Supporting Information in a single
  document. 39 pages (p. 1--2 Title, Contents and Abstract | p. 3--14 Main Text
  | p. 15--39 Supporting Information), 9 figures (3 in the Main Text and 6 in
  the Supporting Information), typeset in LaTeX. Submitted for peer-review. For
  more info see https://mariosandreou.short.gy/ACI},
 doi = {},
 eprint = {2505.14825v1},
 journal = {arXiv preprint},
 title = {Assimilative Causal Inference},
 url = {http://arxiv.org/abs/2505.14825v1},
 year = {2025}
}

@article{2505.15354v1,
 abstract = {Time series forecasting models often produce systematic, predictable errors
even in critical domains such as energy, finance, and healthcare. We introduce
a novel post training adaptive optimization framework that improves forecast
accuracy without retraining or architectural changes. Our method automatically
applies expressive transformations optimized via reinforcement learning,
contextual bandits, or genetic algorithms to correct model outputs in a
lightweight and model agnostic way. Theoretically, we prove that affine
corrections always reduce the mean squared error; practically, we extend this
idea with dynamic action based optimization. The framework also supports an
optional human in the loop component: domain experts can guide corrections
using natural language, which is parsed into actions by a language model.
Across multiple benchmarks (e.g., electricity, weather, traffic), we observe
consistent accuracy gains with minimal computational overhead. Our interactive
demo shows the framework's real time usability. By combining automated post hoc
refinement with interpretable and extensible mechanisms, our approach offers a
powerful new direction for practical forecasting systems.},
 author = {Malik Tiomoko and Hamza Cherkaoui and Giuseppe Paolo and Zhang Yili and Yu Meng and Zhang Keli and Hafiz Tiomoko Ali},
 comment = {},
 doi = {},
 eprint = {2505.15354v1},
 journal = {arXiv preprint},
 title = {Human in the Loop Adaptive Optimization for Improved Time Series Forecasting},
 url = {http://arxiv.org/abs/2505.15354v1},
 year = {2025}
}

@article{2505.16051v1,
 abstract = {We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for
causal inference that jointly models potential outcomes and counterfactuals.
Trained via flow matching, PO-Flow provides a unified framework for
individualized potential outcome prediction, counterfactual predictions, and
uncertainty-aware density learning. Among generative models, it is the first to
enable density learning of potential outcomes without requiring explicit
distributional assumptions (e.g., Gaussian mixtures), while also supporting
counterfactual prediction conditioned on factual outcomes in general
observational datasets. On benchmarks such as ACIC, IHDP, and IBM, it
consistently outperforms prior methods across a range of causal inference
tasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including
counterfactual image generation, demonstrating its broad applicability.},
 author = {Dongze Wu and David I. Inouye and Yao Xie},
 comment = {},
 doi = {},
 eprint = {2505.16051v1},
 journal = {arXiv preprint},
 title = {PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals},
 url = {http://arxiv.org/abs/2505.16051v1},
 year = {2025}
}

@article{2505.16242v1,
 abstract = {When applying offline reinforcement learning (RL) in healthcare scenarios,
the out-of-distribution (OOD) issues pose significant risks, as inappropriate
generalization beyond clinical expertise can result in potentially harmful
recommendations. While existing methods like conservative Q-learning (CQL)
attempt to address the OOD issue, their effectiveness is limited by only
constraining action selection by suppressing uncertain actions. This
action-only regularization imitates clinician actions that prioritize
short-term rewards, but it fails to regulate downstream state trajectories,
thereby limiting the discovery of improved long-term treatment strategies. To
safely improve policy beyond clinician recommendations while ensuring that
state-action trajectories remain in-distribution, we propose \textit{Offline
Guarded Safe Reinforcement Learning} ($\mathsf{OGSRL}$), a theoretically
grounded model-based offline RL framework. $\mathsf{OGSRL}$ introduces a novel
dual constraint mechanism for improving policy with reliability and safety.
First, the OOD guardian is established to specify clinically validated regions
for safe policy exploration. By constraining optimization within these regions,
it enables the reliable exploration of treatment strategies that outperform
clinician behavior by leveraging the full patient state history, without
drifting into unsupported state-action trajectories. Second, we introduce a
safety cost constraint that encodes medical knowledge about physiological
safety boundaries, providing domain-specific safeguards even in areas where
training data might contain potentially unsafe interventions. Notably, we
provide theoretical guarantees on safety and near-optimality: policies that
satisfy these constraints remain in safe and reliable regions and achieve
performance close to the best possible policy supported by the data.},
 author = {Runze Yan and Xun Shen and Akifumi Wachi and Sebastien Gros and Anni Zhao and Xiao Hu},
 comment = {},
 doi = {},
 eprint = {2505.16242v1},
 journal = {arXiv preprint},
 title = {Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies},
 url = {http://arxiv.org/abs/2505.16242v1},
 year = {2025}
}

@article{2505.16652v2,
 abstract = {Recent advancements in multimodal large language models (MLLMs) have
significantly improved performance in visual question answering. However, they
often suffer from hallucinations. In this work, hallucinations are categorized
into two main types: initial hallucinations and snowball hallucinations. We
argue that adequate contextual information can be extracted directly from the
token interaction process. Inspired by causal inference in the decoding
strategy, we propose to leverage causal masks to establish information
propagation between multimodal tokens. The hypothesis is that insufficient
interaction between those tokens may lead the model to rely on outlier tokens,
overlooking dense and rich contextual cues. Therefore, we propose to intervene
in the propagation process by tackling outlier tokens to enhance in-context
inference. With this goal, we present FarSight, a versatile plug-and-play
decoding strategy to reduce attention interference from outlier tokens merely
by optimizing the causal mask. The heart of our method is effective token
propagation. We design an attention register structure within the upper
triangular matrix of the causal mask, dynamically allocating attention to
capture attention diverted to outlier tokens. Moreover, a positional awareness
encoding method with a diminishing masking rate is proposed, allowing the model
to attend to further preceding tokens, especially for video sequence tasks.
With extensive experiments, FarSight demonstrates significant
hallucination-mitigating performance across different MLLMs on both image and
video benchmarks, proving its effectiveness.},
 author = {Feilong Tang and Chengzhi Liu and Zhongxing Xu and Ming Hu and Zelin Peng and Zhiwei Yang and Jionglong Su and Minquan Lin and Yifan Peng and Xuelian Cheng and Imran Razzak and Zongyuan Ge},
 comment = {Clarification note for the CVPR 2025 paper (FarSight). Prepared by a
  subset of the original authors; remaining co-authors are acknowledged in the
  text},
 doi = {},
 eprint = {2505.16652v2},
 journal = {arXiv preprint},
 title = {Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding},
 url = {http://arxiv.org/abs/2505.16652v2},
 year = {2025}
}

@article{2505.16675v1,
 abstract = {In this paper, we focus on the out-of-distribution (OOD) generalization of
self-supervised learning (SSL). By analyzing the mini-batch construction during
the SSL training phase, we first give one plausible explanation for SSL having
OOD generalization. Then, from the perspective of data generation and causal
inference, we analyze and conclude that SSL learns spurious correlations during
the training process, which leads to a reduction in OOD generalization. To
address this issue, we propose a post-intervention distribution (PID) grounded
in the Structural Causal Model. PID offers a scenario where the spurious
variable and label variable is mutually independent. Besides, we demonstrate
that if each mini-batch during SSL training satisfies PID, the resulting SSL
model can achieve optimal worst-case OOD performance. This motivates us to
develop a batch sampling strategy that enforces PID constraints through the
learning of a latent variable model. Through theoretical analysis, we
demonstrate the identifiability of the latent variable model and validate the
effectiveness of the proposed sampling strategy. Experiments conducted on
various downstream OOD tasks demonstrate the effectiveness of the proposed
sampling strategy.},
 author = {Wenwen Qiang and Jingyao Wang and Zeen Song and Jiangmeng Li and Changwen Zheng},
 comment = {},
 doi = {},
 eprint = {2505.16675v1},
 journal = {arXiv preprint},
 title = {On the Out-of-Distribution Generalization of Self-Supervised Learning},
 url = {http://arxiv.org/abs/2505.16675v1},
 year = {2025}
}

@article{2505.17387v2,
 abstract = {Current Large Language Models (LLMs) exhibit significant limitations, notably
in structured, interpretable, and verifiable medical reasoning, alongside
practical deployment challenges related to computational resources and data
privacy. This report focused on the development of WiNGPT-3.0, the 32-billion
parameter LLMs, engineered with the objective of enhancing its capacity for
medical reasoning and exploring its potential for effective integration within
healthcare IT infrastructures. The broader aim is to advance towards clinically
applicable models. The approach involved a multi-stage training pipeline
tailored for general, medical, and clinical reasoning. This pipeline
incorporated supervised fine-tuning (SFT) and reinforcement learning (RL),
leveraging curated Long Chain-of-Thought (CoT) datasets, auxiliary reward
models, and an evidence-based diagnostic chain simulation. WiNGPT-3.0
demonstrated strong performance: specific model variants achieved scores of
66.6 on MedCalc and 87.1 on MedQA-USMLE. Furthermore, targeted training
improved performance on a clinical reasoning task from a baseline score of 58.1
to 62.5. These findings suggest that reinforcement learning, even when applied
with a limited dataset of only a few thousand examples, can enhance medical
reasoning accuracy. Crucially, this demonstration of RL's efficacy with limited
data and computation paves the way for more trustworthy and practically
deployable LLMs within clinical workflows and health information
infrastructures.},
 author = {Boqin Zhuang and Chenxiao Song and Huitong Lu and Jiacheng Qiao and Mingqian Liu and Mingxing Yu and Ping Hong and Rui Li and Xiaoxia Song and Xiangjun Xu and Xu Chen and Yaoyao Ma and Yujie Gao},
 comment = {},
 doi = {},
 eprint = {2505.17387v2},
 journal = {arXiv preprint},
 title = {WiNGPT-3.0 Technical Report},
 url = {http://arxiv.org/abs/2505.17387v2},
 year = {2025}
}

@article{2505.17637v1,
 abstract = {Spatio-temporal prediction plays a crucial role in intelligent
transportation, weather forecasting, and urban planning. While integrating
multi-modal data has shown potential for enhancing prediction accuracy, key
challenges persist: (i) inadequate fusion of multi-modal information, (ii)
confounding factors that obscure causal relations, and (iii) high computational
complexity of prediction models. To address these challenges, we propose
E^2-CSTP, an Effective and Efficient Causal multi-modal Spatio-Temporal
Prediction framework. E^2-CSTP leverages cross-modal attention and gating
mechanisms to effectively integrate multi-modal data. Building on this, we
design a dual-branch causal inference approach: the primary branch focuses on
spatio-temporal prediction, while the auxiliary branch mitigates bias by
modeling additional modalities and applying causal interventions to uncover
true causal dependencies. To improve model efficiency, we integrate GCN with
the Mamba architecture for accelerated spatio-temporal encoding. Extensive
experiments on 4 real-world datasets show that E^2-CSTP significantly
outperforms 9 state-of-the-art methods, achieving up to 9.66% improvements in
accuracy as well as 17.37%-56.11% reductions in computational overhead.},
 author = {Yuting Huang and Ziquan Fang and Zhihao Zeng and Lu Chen and Yunjun Gao},
 comment = {},
 doi = {},
 eprint = {2505.17637v1},
 journal = {arXiv preprint},
 title = {Causal Spatio-Temporal Prediction: An Effective and Efficient Multi-Modal Approach},
 url = {http://arxiv.org/abs/2505.17637v1},
 year = {2025}
}

@article{2505.17708v2,
 abstract = {Causal reasoning and discovery, two fundamental tasks of causal analysis,
often face challenges in applications due to the complexity, noisiness, and
high-dimensionality of real-world data. Despite recent progress in identifying
latent causal structures using causal representation learning (CRL), what makes
learned representations useful for causal downstream tasks and how to evaluate
them are still not well understood. In this paper, we reinterpret CRL using a
measurement model framework, where the learned representations are viewed as
proxy measurements of the latent causal variables. Our approach clarifies the
conditions under which learned representations support downstream causal
reasoning and provides a principled basis for quantitatively assessing the
quality of representations using a new Test-based Measurement EXclusivity
(T-MEX) score. We validate T-MEX across diverse causal inference scenarios,
including numerical simulations and real-world ecological video analysis,
demonstrating that the proposed framework and corresponding score effectively
assess the identification of learned representations and their usefulness for
causal downstream tasks.},
 author = {Dingling Yao and Shimeng Huang and Riccardo Cadei and Kun Zhang and Francesco Locatello},
 comment = {22 pages, 12 figures, 2 tables},
 doi = {},
 eprint = {2505.17708v2},
 journal = {arXiv preprint},
 title = {The Third Pillar of Causal Analysis? A Measurement Perspective on Causal Representations},
 url = {http://arxiv.org/abs/2505.17708v2},
 year = {2025}
}

@article{2505.17717v1,
 abstract = {Causal inference requires evaluating models on balanced distributions between
treatment and control groups, while training data often exhibits imbalance due
to historical decision-making policies. Most conventional statistical methods
address this distribution shift through inverse probability weighting (IPW),
which requires estimating propensity scores as an intermediate step. These
methods face two key challenges: inaccurate propensity estimation and
instability from extreme weights. We decompose the generalization error to
isolate these issues--propensity ambiguity and statistical instability--and
address them through an adversarial loss function. Our approach combines
distributionally robust optimization for handling propensity uncertainty with
weight regularization based on weighted Rademacher complexity. Experiments on
synthetic and real-world datasets demonstrate consistent improvements over
existing methods.},
 author = {Akira Tanimoto},
 comment = {},
 doi = {},
 eprint = {2505.17717v1},
 journal = {arXiv preprint},
 title = {A Distributionally-Robust Framework for Nuisance in Causal Effect Estimation},
 url = {http://arxiv.org/abs/2505.17717v1},
 year = {2025}
}

@article{2505.18118v1,
 abstract = {Many interventions, such as vaccines in clinical trials or coupons in online
marketplaces, must be assigned sequentially without full knowledge of their
effects. Multi-armed bandit algorithms have proven successful in such settings.
However, standard independence assumptions fail when the treatment status of
one individual impacts the outcomes of others, a phenomenon known as
interference. We study optimal-policy learning under interference on a dynamic
network. Existing approaches to this problem require repeated observations of
the same fixed network and struggle to scale in sample size beyond as few as
fifteen connected units -- both limit applications. We show that under common
assumptions on the structure of interference, rewards become linear. This
enables us to develop a scalable Thompson sampling algorithm that maximizes
policy impact when a new $n$-node network is observed each round. We prove a
Bayesian regret bound that is sublinear in $n$ and the number of rounds.
Simulation experiments show that our algorithm learns quickly and outperforms
existing methods. The results close a key scalability gap between causal
inference methods for interference and practical bandit algorithms, enabling
policy optimization in large-scale networked systems.},
 author = {Aidan Gleich and Eric Laber and Alexander Volfovsky},
 comment = {},
 doi = {},
 eprint = {2505.18118v1},
 journal = {arXiv preprint},
 title = {Scalable Policy Maximization Under Network Interference},
 url = {http://arxiv.org/abs/2505.18118v1},
 year = {2025}
}

@article{2505.18989v1,
 abstract = {Accurate tumour segmentation is vital for various targeted diagnostic and
therapeutic procedures for cancer, e.g., planning biopsies or tumour ablations.
Manual delineation is extremely labour-intensive, requiring substantial expert
time. Fully-supervised machine learning models aim to automate such
localisation tasks, but require a large number of costly and often subjective
3D voxel-level labels for training. The high-variance and subjectivity in such
labels impacts model generalisability, even when large datasets are available.
Histopathology labels may offer more objective labels but the infeasibility of
acquiring pixel-level annotations to develop tumour localisation methods based
on histology remains challenging in-vivo. In this work, we propose a novel
weakly-supervised semantic segmentation framework called SPARS (Self-Play
Adversarial Reinforcement Learning for Segmentation), which utilises an object
presence classifier, trained on a small number of image-level binary cancer
presence labels, to localise cancerous regions on CT scans. Such binary labels
of patient-level cancer presence can be sourced more feasibly from biopsies and
histopathology reports, enabling a more objective cancer localisation on
medical images. Evaluating with real patient data, we observed that SPARS
yielded a mean dice score of $77.3 \pm 9.4$, which outperformed other
weakly-supervised methods by large margins. This performance was comparable
with recent fully-supervised methods that require voxel-level annotations. Our
results demonstrate the potential of using SPARS to reduce the need for
extensive human-annotated labels to detect cancer in real-world healthcare
settings.},
 author = {Catalina Tan and Yipeng Hu and Shaheer U. Saeed},
 comment = {Accepted at Medical Image Understanding and Analysis (MIUA) 2025},
 doi = {},
 eprint = {2505.18989v1},
 journal = {arXiv preprint},
 title = {SPARS: Self-Play Adversarial Reinforcement Learning for Segmentation of Liver Tumours},
 url = {http://arxiv.org/abs/2505.18989v1},
 year = {2025}
}

@article{2505.19589v2,
 abstract = {Estimating causal effects from observational data is essential in fields such
as medicine, economics and social sciences, where privacy concerns are
paramount. We propose a general, model-agnostic framework for differentially
private estimation of average treatment effects (ATE) that avoids strong
structural assumptions on the data-generating process or the models used to
estimate propensity scores and conditional outcomes. In contrast to prior work,
which enforces differential privacy by directly privatizing these nuisance
components and results in a privacy cost that scales with model complexity, our
approach decouples nuisance estimation from privacy protection. This separation
allows the use of flexible, state-of-the-art black-box models, while
differential privacy is achieved by perturbing only predictions and aggregation
steps within a fold-splitting scheme with ensemble techniques. We instantiate
the framework for three classical estimators -- the G-formula, inverse
propensity weighting (IPW), and augmented IPW (AIPW) -- and provide formal
utility and privacy guarantees. Empirical results show that our methods
maintain competitive performance under realistic privacy budgets. We further
extend our framework to support meta-analysis of multiple private ATE
estimates. Our results bridge a critical gap between causal inference and
privacy-preserving data analysis.},
 author = {Christian Lebeda and Mathieu Even and Aurélien Bellet and Julie Josse},
 comment = {},
 doi = {},
 eprint = {2505.19589v2},
 journal = {arXiv preprint},
 title = {Model Agnostic Differentially Private Causal Inference},
 url = {http://arxiv.org/abs/2505.19589v2},
 year = {2025}
}

@article{2505.19785v2,
 abstract = {Timely and personalized treatment decisions are essential across a wide range
of healthcare settings where patient responses can vary significantly and
evolve over time. Clinical data used to support these treatment decisions are
often irregularly sampled, where missing data frequencies may implicitly convey
information about the patient's condition. Existing Reinforcement Learning (RL)
based clinical decision support systems often ignore the missing patterns and
distort them with coarse discretization and simple imputation. They are also
predominantly model-free and largely depend on retrospective data, which could
lead to insufficient exploration and bias by historical behaviors. To address
these limitations, we propose medDreamer, a novel model-based reinforcement
learning framework for personalized treatment recommendation. medDreamer
contains a world model with an Adaptive Feature Integration module that
simulates latent patient states from irregular data and a two-phase policy
trained on a hybrid of real and imagined trajectories. This enables learning
optimal policies that go beyond the sub-optimality of historical clinical
decisions, while remaining close to real clinical data. We evaluate medDreamer
on both sepsis and mechanical ventilation treatment tasks using two large-scale
Electronic Health Records (EHRs) datasets. Comprehensive evaluations show that
medDreamer significantly outperforms model-free and model-based baselines in
both clinical outcomes and off-policy metrics.},
 author = {Qianyi Xu and Gousia Habib and Dilruk Perera and Mengling Feng},
 comment = {},
 doi = {},
 eprint = {2505.19785v2},
 journal = {arXiv preprint},
 title = {medDreamer: Model-Based Reinforcement Learning with Latent Imagination on Complex EHRs for Clinical Decision Support},
 url = {http://arxiv.org/abs/2505.19785v2},
 year = {2025}
}

@article{2505.19860v1,
 abstract = {Ensuring safe operation of safety-critical complex systems interacting with
their environment poses significant challenges, particularly when the system's
world model relies on machine learning algorithms to process the perception
input. A comprehensive safety argumentation requires knowledge of how faults or
functional insufficiencies propagate through the system and interact with
external factors, to manage their safety impact. While statistical analysis
approaches can support the safety assessment, associative reasoning alone is
neither sufficient for the safety argumentation nor for the identification and
investigation of safety measures. A causal understanding of the system and its
interaction with the environment is crucial for safeguarding safety-critical
complex systems. It allows to transfer and generalize knowledge, such as
insights gained from testing, and facilitates the identification of potential
improvements. This work explores using causal Bayesian networks to model the
system's causalities for safety analysis, and proposes measures to assess
causal influences based on Pearl's framework of causal inference. We compare
the approach of causal Bayesian networks to the well-established fault tree
analysis, outlining advantages and limitations. In particular, we examine
importance metrics typically employed in fault tree analysis as foundation to
discuss suitable causal metrics. An evaluation is performed on the example of a
perception system for automated driving. Overall, this work presents an
approach for causal reasoning in safety analysis that enables the integration
of data-driven and expert-based knowledge to account for uncertainties arising
from complex systems operating in open environments.},
 author = {Roman Gansch and Lina Putze and Tjark Koopmann and Jan Reich and Christian Neurohr},
 comment = {},
 doi = {},
 eprint = {2505.19860v1},
 journal = {arXiv preprint},
 title = {Causal Bayesian Networks for Data-driven Safety Analysis of Complex Systems},
 url = {http://arxiv.org/abs/2505.19860v1},
 year = {2025}
}

@article{2505.20321v2,
 abstract = {Biomedical researchers increasingly rely on large-scale structured databases
for complex analytical tasks. However, current text-to-SQL systems often
struggle to map qualitative scientific questions into executable SQL,
particularly when implicit domain reasoning is required. We introduce
BiomedSQL, the first benchmark explicitly designed to evaluate scientific
reasoning in text-to-SQL generation over a real-world biomedical knowledge
base. BiomedSQL comprises 68,000 question/SQL query/answer triples grounded in
a harmonized BigQuery knowledge base that integrates gene-disease associations,
causal inference from omics data, and drug approval records. Each question
requires models to infer domain-specific criteria, such as genome-wide
significance thresholds, effect directionality, or trial phase filtering,
rather than rely on syntactic translation alone. We evaluate a range of open-
and closed-source LLMs across prompting strategies and interaction paradigms.
Our results reveal a substantial performance gap: GPT-o3-mini achieves 59.0%
execution accuracy, while our custom multi-step agent, BMSQL, reaches 62.6%,
both well below the expert baseline of 90.0%. BiomedSQL provides a new
foundation for advancing text-to-SQL systems capable of supporting scientific
discovery through robust reasoning over structured biomedical knowledge bases.
Our dataset is publicly available at
https://huggingface.co/datasets/NIH-CARD/BiomedSQL, and our code is open-source
at https://github.com/NIH-CARD/biomedsql.},
 author = {Mathew J. Koretsky and Maya Willey and Adi Asija and Owen Bianchi and Chelsea X. Alvarado and Tanay Nayak and Nicole Kuznetsov and Sungwon Kim and Mike A. Nalls and Daniel Khashabi and Faraz Faghri},
 comment = {Under Review},
 doi = {},
 eprint = {2505.20321v2},
 journal = {arXiv preprint},
 title = {BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases},
 url = {http://arxiv.org/abs/2505.20321v2},
 year = {2025}
}

@article{2505.20351v1,
 abstract = {Ratio statistics--such as relative risk and odds ratios--play a central role
in hypothesis testing, model evaluation, and decision-making across many areas
of machine learning, including causal inference and fairness analysis. However,
despite privacy concerns surrounding many datasets and despite increasing
adoption of differential privacy, differentially private ratio statistics have
largely been neglected by the literature and have only recently received an
initial treatment by Lin et al. [1]. This paper attempts to fill this lacuna,
giving results that can guide practice in evaluating ratios when the results
must be protected by differential privacy. In particular, we show that even a
simple algorithm can provide excellent properties concerning privacy, sample
accuracy, and bias, not just asymptotically but also at quite small sample
sizes. Additionally, we analyze a differentially private estimator for relative
risk, prove its consistency, and develop a method for constructing valid
confidence intervals. Our approach bridges a gap in the differential privacy
literature and provides a practical solution for ratio estimation in private
machine learning pipelines.},
 author = {Tomer Shoham and Katrina Ligettt},
 comment = {32 pages, 3 figures, under review},
 doi = {},
 eprint = {2505.20351v1},
 journal = {arXiv preprint},
 title = {Differentially private ratio statistics},
 url = {http://arxiv.org/abs/2505.20351v1},
 year = {2025}
}

@article{2505.20787v1,
 abstract = {In various statistical settings, the goal is to estimate a function which is
restricted by the statistical model only through a conditional moment
restriction. Prominent examples include the nonparametric instrumental variable
framework for estimating the structural function of the outcome variable, and
the proximal causal inference framework for estimating the bridge functions. A
common strategy in the literature is to find the minimizer of the projected
mean squared error. However, this approach can be sensitive to misspecification
or slow convergence rate of the estimators of the involved nuisance components.
In this work, we propose a debiased estimation strategy based on the influence
function of a modification of the projected error and demonstrate its
finite-sample convergence rate. Our proposed estimator possesses a second-order
bias with respect to the involved nuisance functions and a desirable robustness
property with respect to the misspecification of one of the nuisance functions.
The proposed estimator involves a hyper-parameter, for which the optimal value
depends on potentially unknown features of the underlying data-generating
process. Hence, we further propose a hyper-parameter selection approach based
on cross-validation and derive an error bound for the resulting estimator. This
analysis highlights the potential rate loss due to hyper-parameter selection
and underscore the importance and advantages of incorporating debiasing in this
setting. We also study the application of our approach to the estimation of
regular parameters in a specific parameter class, which are linear functionals
of the solutions to the conditional moment restrictions and provide sufficient
conditions for achieving root-n consistency using our debiased estimator.},
 author = {AmirEmad Ghassami and James M. Robins and Andrea Rotnitzky},
 comment = {},
 doi = {},
 eprint = {2505.20787v1},
 journal = {arXiv preprint},
 title = {Debiased Ill-Posed Regression},
 url = {http://arxiv.org/abs/2505.20787v1},
 year = {2025}
}

@article{2505.21493v1,
 abstract = {The recent paradigm shift towards training large language models (LLMs) using
DeepSeek-R1-Zero-style reinforcement learning (RL) on verifiable rewards has
led to impressive advancements in code and mathematical reasoning. However,
this methodology is limited to tasks where rule-based answer verification is
possible and does not naturally extend to real-world domains such as chemistry,
healthcare, engineering, law, biology, business, and economics. Current
practical workarounds use an additional LLM as a model-based verifier; however,
this introduces issues such as reliance on a strong verifier LLM,
susceptibility to reward hacking, and the practical burden of maintaining the
verifier model in memory during training. To address this and extend
DeepSeek-R1-Zero-style training to general reasoning domains, we propose a
verifier-free method (VeriFree) that bypasses answer verification and instead
uses RL to directly maximize the probability of generating the reference
answer. We compare VeriFree with verifier-based methods and demonstrate that,
in addition to its significant practical benefits and reduced compute
requirements, VeriFree matches and even surpasses verifier-based methods on
extensive evaluations across MMLU-Pro, GPQA, SuperGPQA, and math-related
benchmarks. Moreover, we provide insights into this method from multiple
perspectives: as an elegant integration of training both the policy and
implicit verifier in a unified model, and as a variational optimization
approach. Code is available at https://github.com/sail-sg/VeriFree.},
 author = {Xiangxin Zhou and Zichen Liu and Anya Sims and Haonan Wang and Tianyu Pang and Chongxuan Li and Liang Wang and Min Lin and Chao Du},
 comment = {},
 doi = {},
 eprint = {2505.21493v1},
 journal = {arXiv preprint},
 title = {Reinforcing General Reasoning without Verifiers},
 url = {http://arxiv.org/abs/2505.21493v1},
 year = {2025}
}

@article{2505.24105v1,
 abstract = {We present EHRMIND, a practical recipe for adapting large language models
(LLMs) to complex clinical reasoning tasks using reinforcement learning with
verifiable rewards (RLVR). While RLVR has succeeded in mathematics and coding,
its application to healthcare contexts presents unique challenges due to the
specialized knowledge and reasoning required for electronic health record (EHR)
interpretation. Our pilot study on the MEDCALC benchmark reveals two key
failure modes: (1) misapplied knowledge, where models possess relevant medical
knowledge but apply it incorrectly, and (2) missing knowledge, where models
lack essential domain knowledge. To address these cases, EHRMIND applies a
two-stage solution: a lightweight supervised fine-tuning (SFT) warm-up that
injects missing domain knowledge, stabilizes subsequent training, and
encourages structured, interpretable outputs; followed by RLVR, which
reinforces outcome correctness and refines the model's decision-making. We
demonstrate the effectiveness of our method across diverse clinical
applications, including medical calculations (MEDCALC), patient-trial matching
(TREC CLINICAL TRIALS), and disease diagnosis (EHRSHOT). EHRMIND delivers
consistent gains in accuracy, interpretability, and cross-task generalization.
These findings offer practical guidance for applying RLVR to enhance LLM
capabilities in healthcare settings.},
 author = {Jiacheng Lin and Zhenbang Wu and Jimeng Sun},
 comment = {},
 doi = {},
 eprint = {2505.24105v1},
 journal = {arXiv preprint},
 title = {Training LLMs for EHR-Based Reasoning Tasks via Reinforcement Learning},
 url = {http://arxiv.org/abs/2505.24105v1},
 year = {2025}
}

@article{2505.24296v1,
 abstract = {Data fusion techniques integrate information from heterogeneous data sources
to improve learning, generalization, and decision making across data sciences.
In causal inference, these methods leverage rich observational data to improve
causal effect estimation, while maintaining the trustworthiness of randomized
controlled trials. Existing approaches often relax the strong no unobserved
confounding assumption by instead assuming exchangeability of counterfactual
outcomes across data sources. However, when both assumptions simultaneously
fail - a common scenario in practice - current methods cannot identify or
estimate causal effects. We address this limitation by proposing a novel
partial identification framework that enables researchers to answer key
questions such as: Is the causal effect positive or negative? and How severe
must assumption violations be to overturn this conclusion? Our approach
introduces interpretable sensitivity parameters that quantify assumption
violations and derives corresponding causal effect bounds. We develop doubly
robust estimators for these bounds and operationalize breakdown frontier
analysis to understand how causal conclusions change as assumption violations
increase. We apply our framework to the Project STAR study, which investigates
the effect of classroom size on students' third-grade standardized test
performance. Our analysis reveals that the Project STAR results are robust to
simultaneous violations of key assumptions, both on average and across various
subgroups of interest. This strengthens confidence in the study's conclusions
despite potential unmeasured biases in the data.},
 author = {Quinn Lanners and Cynthia Rudin and Alexander Volfovsky and Harsh Parikh},
 comment = {},
 doi = {},
 eprint = {2505.24296v1},
 journal = {arXiv preprint},
 title = {Data Fusion for Partial Identification of Causal Effects},
 url = {http://arxiv.org/abs/2505.24296v1},
 year = {2025}
}

@article{2506.00818v1,
 abstract = {The linear Markov Decision Process (MDP) framework offers a principled
foundation for reinforcement learning (RL) with strong theoretical guarantees
and sample efficiency. However, its restrictive assumption-that both transition
dynamics and reward functions are linear in the same feature space-limits its
applicability in real-world domains, where rewards often exhibit nonlinear or
discrete structures. Motivated by applications such as healthcare and
e-commerce, where data is scarce and reward signals can be binary or
count-valued, we propose the Generalized Linear MDP (GLMDP) framework-an
extension of the linear MDP framework-that models rewards using generalized
linear models (GLMs) while maintaining linear transition dynamics. We establish
the Bellman completeness of GLMDPs with respect to a new function class that
accommodates nonlinear rewards and develop two offline RL algorithms:
Generalized Pessimistic Value Iteration (GPEVI) and a semi-supervised variant
(SS-GPEVI) that utilizes both labeled and unlabeled trajectories. Our
algorithms achieve theoretical guarantees on policy suboptimality and
demonstrate improved sample efficiency in settings where reward labels are
expensive or limited.},
 author = {Sinian Zhang and Kaicheng Zhang and Ziping Xu and Tianxi Cai and Doudou Zhou},
 comment = {34 pages, 9 figures},
 doi = {},
 eprint = {2506.00818v1},
 journal = {arXiv preprint},
 title = {Generalized Linear Markov Decision Process},
 url = {http://arxiv.org/abs/2506.00818v1},
 year = {2025}
}

@article{2506.00866v1,
 abstract = {Density ratio estimation (DRE) is a paramount task in machine learning, for
its broad applications across multiple domains, such as covariate shift
adaptation, causal inference, independence tests and beyond. Parametric methods
for estimating the density ratio possibly lead to biased results if models are
misspecified, while conventional non-parametric methods suffer from the curse
of dimensionality when the dimension of data is large. To address these
challenges, in this paper, we propose a novel approach for DRE based on the
projection pursuit (PP) approximation. The proposed method leverages PP to
mitigate the impact of high dimensionality while retaining the model
flexibility needed for the accuracy of DRE. We establish the consistency and
the convergence rate for the proposed estimator. Experimental results
demonstrate that our proposed method outperforms existing alternatives in
various applications.},
 author = {Meilin Wang and Wei Huang and Mingming Gong and Zheng Zhang},
 comment = {},
 doi = {},
 eprint = {2506.00866v1},
 journal = {arXiv preprint},
 title = {Projection Pursuit Density Ratio Estimation},
 url = {http://arxiv.org/abs/2506.00866v1},
 year = {2025}
}

@article{2506.01191v1,
 abstract = {Observational studies are a key resource for causal inference but are often
affected by systematic biases. Prior work has focused mainly on detecting these
biases, via sensitivity analyses and comparisons with randomized controlled
trials, or mitigating them through debiasing techniques. However, there remains
a lack of methodology for uncovering the underlying mechanisms driving these
biases, e.g., whether due to hidden confounding or selection of participants.
In this work, we show that the relationship between bias magnitude and the
predictive performance of nuisance function estimators (in the observational
study) can help distinguish among common sources of causal bias. We validate
our methodology through extensive synthetic experiments and a real-world case
study, demonstrating its effectiveness in revealing the mechanisms behind
observed biases. Our framework offers a new lens for understanding and
characterizing bias in observational studies, with practical implications for
improving causal inference.},
 author = {Ilker Demirel and Zeshan Hussain and Piersilvio De Bartolomeis and David Sontag},
 comment = {},
 doi = {},
 eprint = {2506.01191v1},
 journal = {arXiv preprint},
 title = {Uncovering Bias Mechanisms in Observational Studies},
 url = {http://arxiv.org/abs/2506.01191v1},
 year = {2025}
}

@article{2506.01257v1,
 abstract = {DeepSeek-R1 is a cutting-edge open-source large language model (LLM)
developed by DeepSeek, showcasing advanced reasoning capabilities through a
hybrid architecture that integrates mixture of experts (MoE), chain of thought
(CoT) reasoning, and reinforcement learning. Released under the permissive MIT
license, DeepSeek-R1 offers a transparent and cost-effective alternative to
proprietary models like GPT-4o and Claude-3 Opus; it excels in structured
problem-solving domains such as mathematics, healthcare diagnostics, code
generation, and pharmaceutical research. The model demonstrates competitive
performance on benchmarks like the United States Medical Licensing Examination
(USMLE) and American Invitational Mathematics Examination (AIME), with strong
results in pediatric and ophthalmologic clinical decision support tasks. Its
architecture enables efficient inference while preserving reasoning depth,
making it suitable for deployment in resource-constrained settings. However,
DeepSeek-R1 also exhibits increased vulnerability to bias, misinformation,
adversarial manipulation, and safety failures - especially in multilingual and
ethically sensitive contexts. This survey highlights the model's strengths,
including interpretability, scalability, and adaptability, alongside its
limitations in general language fluency and safety alignment. Future research
priorities include improving bias mitigation, natural language comprehension,
domain-specific validation, and regulatory compliance. Overall, DeepSeek-R1
represents a major advance in open, scalable AI, underscoring the need for
collaborative governance to ensure responsible and equitable deployment.},
 author = {Jiancheng Ye and Sophie Bronstein and Jiarui Hai and Malak Abu Hashish},
 comment = {},
 doi = {},
 eprint = {2506.01257v1},
 journal = {arXiv preprint},
 title = {DeepSeek in Healthcare: A Survey of Capabilities, Risks, and Clinical Applications of Open-Source Large Language Models},
 url = {http://arxiv.org/abs/2506.01257v1},
 year = {2025}
}

@article{2506.01533v1,
 abstract = {In medicine, treatments often influence multiple, interdependent outcomes,
such as primary endpoints, complications, adverse events, or other secondary
endpoints. Hence, to make optimal treatment decisions, clinicians are
interested in learning the distribution of multi-dimensional treatment
outcomes. However, the vast majority of machine learning methods for predicting
treatment effects focus on single-outcome settings, despite the fact that
medical data often include multiple, interdependent outcomes. To address this
limitation, we propose a novel diffusion-based method called DIME to learn the
joint distribution of multiple outcomes of medical treatments. We addresses
three challenges relevant in medical practice: (i)it is tailored to learn the
joint interventional distribution of multiple medical outcomes, which enables
reliable decision-making with uncertainty quantification rather than relying
solely on point estimates; (ii)it explicitly captures the dependence structure
between outcomes; (iii)it can handle outcomes of mixed type, including binary,
categorical, and continuous variables. In DIME, we take into account the
fundamental problem of causal inference through causal masking. For training,
our method decomposes the joint distribution into a series of conditional
distributions with a customized conditional masking to account for the
dependence structure across outcomes. For inference, our method
auto-regressively generates predictions. This allows our method to move beyond
point estimates of causal quantities and thus learn the joint interventional
distribution. To the best of our knowledge, DIME is the first neural method
tailored to learn the joint, multi-outcome distribution of medical treatments.
Across various experiments, we demonstrate that our method effectively learns
the joint distribution and captures shared information among multiple outcomes.},
 author = {Yuchen Ma and Jonas Schweisthal and Hengrui Zhang and Stefan Feuerriegel},
 comment = {Accepted at KDD 2025},
 doi = {},
 eprint = {2506.01533v1},
 journal = {arXiv preprint},
 title = {A Diffusion-Based Method for Learning the Multi-Outcome Distribution of Medical Treatments},
 url = {http://arxiv.org/abs/2506.01533v1},
 year = {2025}
}

@article{2506.03163v1,
 abstract = {Dynamic causal discovery in wireless networks is essential due to evolving
interference, fading, and mobility, which complicate traditional static causal
models. This paper addresses causal inference challenges in dynamic fading
wireless environments by proposing a sequential regression-based algorithm with
a novel application of the NOTEARS acyclicity constraint, enabling efficient
online updates. We derive theoretical lower and upper bounds on the detection
delay required to identify structural changes, explicitly quantifying their
dependence on network size, noise variance, and fading severity. Monte Carlo
simulations validate these theoretical results, demonstrating linear increases
in detection delay with network size, quadratic growth with noise variance, and
inverse-square dependence on the magnitude of structural changes. Our findings
provide rigorous theoretical insights and practical guidelines for designing
robust online causal inference mechanisms to maintain network reliability under
nonstationary wireless conditions.},
 author = {Oluwaseyi Giwa},
 comment = {5 pages, 3 figures},
 doi = {},
 eprint = {2506.03163v1},
 journal = {arXiv preprint},
 title = {Causal Discovery in Dynamic Fading Wireless Networks},
 url = {http://arxiv.org/abs/2506.03163v1},
 year = {2025}
}

@article{2506.04166v1,
 abstract = {Nearest neighbor (NN) methods have re-emerged as competitive tools for matrix
completion, offering strong empirical performance and recent theoretical
guarantees, including entry-wise error bounds, confidence intervals, and
minimax optimality. Despite their simplicity, recent work has shown that NN
approaches are robust to a range of missingness patterns and effective across
diverse applications. This paper introduces N$^2$, a unified Python package and
testbed that consolidates a broad class of NN-based methods through a modular,
extensible interface. Built for both researchers and practitioners, N$^2$
supports rapid experimentation and benchmarking. Using this framework, we
introduce a new NN variant that achieves state-of-the-art results in several
settings. We also release a benchmark suite of real-world datasets, from
healthcare and recommender systems to causal inference and LLM evaluation,
designed to stress-test matrix completion methods beyond synthetic scenarios.
Our experiments demonstrate that while classical methods excel on idealized
data, NN-based techniques consistently outperform them in real-world settings.},
 author = {Caleb Chin and Aashish Khubchandani and Harshvardhan Maskara and Kyuseong Choi and Jacob Feitelberg and Albert Gong and Manit Paul and Tathagata Sadhukhan and Anish Agarwal and Raaz Dwivedi},
 comment = {21 pages, 6 figures},
 doi = {},
 eprint = {2506.04166v1},
 journal = {arXiv preprint},
 title = {N$^2$: A Unified Python Package and Test Bench for Nearest Neighbor-Based Matrix Completion},
 url = {http://arxiv.org/abs/2506.04166v1},
 year = {2025}
}

@article{2506.04194v2,
 abstract = {Most of the widely used estimators of the average treatment effect (ATE) in
causal inference rely on the assumptions of unconfoundedness and overlap.
Unconfoundedness requires that the observed covariates account for all
correlations between the outcome and treatment. Overlap requires the existence
of randomness in treatment decisions for all individuals. Nevertheless, many
types of studies frequently violate unconfoundedness or overlap, for instance,
observational studies with deterministic treatment decisions - popularly known
as Regression Discontinuity designs - violate overlap.
  In this paper, we initiate the study of general conditions that enable the
identification of the average treatment effect, extending beyond
unconfoundedness and overlap. In particular, following the paradigm of
statistical learning theory, we provide an interpretable condition that is
sufficient and necessary for the identification of ATE. Moreover, this
condition also characterizes the identification of the average treatment effect
on the treated (ATT) and can be used to characterize other treatment effects as
well. To illustrate the utility of our condition, we present several
well-studied scenarios where our condition is satisfied and, hence, we prove
that ATE can be identified in regimes that prior works could not capture. For
example, under mild assumptions on the data distributions, this holds for the
models proposed by Tan (2006) and Rosenbaum (2002), and the Regression
Discontinuity design model introduced by Thistlethwaite and Campbell (1960).
For each of these scenarios, we also show that, under natural additional
assumptions, ATE can be estimated from finite samples.
  We believe these findings open new avenues for bridging learning-theoretic
insights and causal inference methodologies, particularly in observational
studies with complex treatment mechanisms.},
 author = {Yang Cai and Alkis Kalavasis and Katerina Mamali and Anay Mehrotra and Manolis Zampetakis},
 comment = {Accepted for presentation at the 38th Conference on Learning Theory
  (COLT) 2025. v2 strengthens results to give a tight characterization for ATE
  identification},
 doi = {},
 eprint = {2506.04194v2},
 journal = {arXiv preprint},
 title = {What Makes Treatment Effects Identifiable? Characterizations and Estimators Beyond Unconfoundedness},
 url = {http://arxiv.org/abs/2506.04194v2},
 year = {2025}
}

@article{2506.05202v2,
 abstract = {This paper investigates causal effect identification in latent variable
Linear Non-Gaussian Acyclic Models (lvLiNGAM) using higher-order cumulants,
addressing two prominent setups that are challenging in the presence of latent
confounding: (1) a single proxy variable that may causally influence the
treatment and (2) underspecified instrumental variable cases where fewer
instruments exist than treatments. We prove that causal effects are
identifiable with a single proxy or instrument and provide corresponding
estimation methods. Experimental results demonstrate the accuracy and
robustness of our approaches compared to existing methods, advancing the
theoretical and practical understanding of causal inference in linear systems
with latent confounders.},
 author = {Daniele Tramontano and Yaroslav Kivva and Saber Salehkaleybar and Mathias Drton and Negar Kiyavash},
 comment = {Accepted at ICML 2025},
 doi = {},
 eprint = {2506.05202v2},
 journal = {arXiv preprint},
 title = {Causal Effect Identification in lvLiNGAM from Higher-Order Cumulants},
 url = {http://arxiv.org/abs/2506.05202v2},
 year = {2025}
}

@article{2506.05967v1,
 abstract = {Reward modelling from preference data is a crucial step in aligning large
language models (LLMs) with human values, requiring robust generalisation to
novel prompt-response pairs. In this work, we propose to frame this problem in
a causal paradigm, providing the rich toolbox of causality to identify the
persistent challenges, such as causal misidentification, preference
heterogeneity, and confounding due to user-specific factors. Inheriting from
the literature of causal inference, we identify key assumptions necessary for
reliable generalisation and contrast them with common data collection
practices. We illustrate failure modes of naive reward models and demonstrate
how causally-inspired approaches can improve model robustness. Finally, we
outline desiderata for future research and practices, advocating targeted
interventions to address inherent limitations of observational data.},
 author = {Katarzyna Kobalczyk and Mihaela van der Schaar},
 comment = {},
 doi = {},
 eprint = {2506.05967v1},
 journal = {arXiv preprint},
 title = {Preference Learning for AI Alignment: a Causal Perspective},
 url = {http://arxiv.org/abs/2506.05967v1},
 year = {2025}
}

@article{2506.07011v1,
 abstract = {This study advances the Variational Autoencoder (VAE) framework by addressing
challenges in Independent Component Analysis (ICA) under both determined and
underdetermined conditions, focusing on enhancing the independence and
interpretability of latent variables. Traditional VAEs map observed data to
latent variables and back via an encoder-decoder architecture, but struggle
with underdetermined ICA where the number of latent variables exceeds observed
signals. The proposed Half Adversarial VAE (Half-AVAE) builds on the
encoder-free Half-VAE framework, eliminating explicit inverse mapping to tackle
underdetermined scenarios. By integrating adversarial networks and External
Enhancement (EE) terms, Half-AVAE promotes mutual independence among latent
dimensions, achieving factorized and interpretable representations. Experiments
with synthetic signals demonstrate that Half-AVAE outperforms baseline models,
including GP-AVAE and Half-VAE, in recovering independent components under
underdetermined conditions, as evidenced by lower root mean square errors. The
study highlights the flexibility of VAEs in variational inference, showing that
encoder omission, combined with adversarial training and structured priors,
enables effective solutions for complex ICA tasks, advancing applications in
disentanglement, causal inference, and generative modeling.},
 author = {Yuan-Hao Wei and Yan-Jie Sun},
 comment = {},
 doi = {},
 eprint = {2506.07011v1},
 journal = {arXiv preprint},
 title = {Half-AVAE: Adversarial-Enhanced Factorized and Structured Encoder-Free VAE for Underdetermined Independent Component Analysis},
 url = {http://arxiv.org/abs/2506.07011v1},
 year = {2025}
}

@article{2506.07140v1,
 abstract = {We study quantile-optimal policy learning where the goal is to find a policy
whose reward distribution has the largest $\alpha$-quantile for some $\alpha
\in (0, 1)$. We focus on the offline setting whose generating process involves
unobserved confounders. Such a problem suffers from three main challenges: (i)
nonlinearity of the quantile objective as a functional of the reward
distribution, (ii) unobserved confounding issue, and (iii) insufficient
coverage of the offline dataset. To address these challenges, we propose a
suite of causal-assisted policy learning methods that provably enjoy strong
theoretical guarantees under mild conditions. In particular, to address (i) and
(ii), using causal inference tools such as instrumental variables and negative
controls, we propose to estimate the quantile objectives by solving nonlinear
functional integral equations. Then we adopt a minimax estimation approach with
nonparametric models to solve these integral equations, and propose to
construct conservative policy estimates that address (iii). The final policy is
the one that maximizes these pessimistic estimates. In addition, we propose a
novel regularized policy learning method that is more amenable to computation.
Finally, we prove that the policies learned by these methods are
$\tilde{\mathscr{O}}(n^{-1/2})$ quantile-optimal under a mild coverage
assumption on the offline dataset. Here, $\tilde{\mathscr{O}}(\cdot)$ omits
poly-logarithmic factors. To the best of our knowledge, we propose the first
sample-efficient policy learning algorithms for estimating the quantile-optimal
policy when there exist unmeasured confounding.},
 author = {Zhongren Chen and Siyu Chen and Zhengling Qi and Xiaohong Chen and Zhuoran Yang},
 comment = {},
 doi = {},
 eprint = {2506.07140v1},
 journal = {arXiv preprint},
 title = {Quantile-Optimal Policy Learning under Unmeasured Confounding},
 url = {http://arxiv.org/abs/2506.07140v1},
 year = {2025}
}

@article{2506.07275v2,
 abstract = {Machine learning approaches, such as contextual multi-armed bandit (cMAB)
algorithms, offer a promising strategy to reduce sedentary behavior by
delivering personalized interventions to encourage physical activity. However,
cMAB algorithms typically require large participant samples to learn
effectively and may overlook key psychological factors that are not explicitly
encoded in the model. In this study, we propose a hybrid approach that combines
cMAB for selecting intervention types with large language models (LLMs) to
personalize message content. We evaluate four intervention types: behavioral
self-monitoring, gain-framed, loss-framed, and social comparison, each
delivered as a motivational message aimed at increasing motivation for physical
activity and daily step count. Message content is further personalized using
dynamic contextual factors including daily fluctuations in self-efficacy,
social influence, and regulatory focus. Over a seven-day trial, participants
receive daily messages assigned by one of four models: cMAB alone, LLM alone,
combined cMAB with LLM personalization (cMABxLLM), or equal randomization
(RCT). Outcomes include daily step count and message acceptance, assessed via
ecological momentary assessments (EMAs). We apply a causal inference framework
to evaluate the effects of each model. Our findings offer new insights into the
complementary roles of LLM-based personalization and cMAB adaptation in
promoting physical activity through personalized behavioral messaging.},
 author = {Haochen Song and Dominik Hofer and Rania Islambouli and Laura Hawkins and Ananya Bhattacharjee and Meredith Franklin and Joseph Jay Williams},
 comment = {},
 doi = {},
 eprint = {2506.07275v2},
 journal = {arXiv preprint},
 title = {Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models},
 url = {http://arxiv.org/abs/2506.07275v2},
 year = {2025}
}

@article{2506.07747v1,
 abstract = {In this paper, we provide the first practical algorithms with provable
guarantees for the problem of inferring the topics assigned to each document in
an LDA topic model. This is the primary inference problem for many applications
of topic models in social science, data exploration, and causal inference
settings. We obtain this result by showing a novel non-gradient-based,
combinatorial approach to estimating topic models. This yields algorithms that
converge to near-optimal posterior probability in logarithmic parallel
computation time (adaptivity) -- exponentially faster than any known LDA
algorithm. We also show that our approach can provide interpretability
guarantees such that each learned topic is formally associated with a known
keyword. Finally, we show that unlike alternatives, our approach can maintain
the independence assumptions necessary to use the learned topic model for
downstream causal inference methods that allow researchers to study topics as
treatments. In terms of practical performance, our approach consistently
returns solutions of higher semantic quality than solutions from
state-of-the-art LDA algorithms, neural topic models, and LLM-based topic
models across a diverse range of text datasets and evaluation parameters.},
 author = {Adam Breuer},
 comment = {ICML 2025; Code available at: https://github.com/BreuerLabs/E- LDA},
 doi = {},
 eprint = {2506.07747v1},
 journal = {arXiv preprint},
 title = {E-LDA: Toward Interpretable LDA Topic Models with Strong Guarantees in Logarithmic Parallel Time},
 url = {http://arxiv.org/abs/2506.07747v1},
 year = {2025}
}

@article{2506.07918v1,
 abstract = {Causal effect estimation from observational data is fundamental across
various applications. However, selecting an appropriate estimator from dozens
of specialized methods demands substantial manual effort and domain expertise.
We present CausalPFN, a single transformer that amortizes this workflow:
trained once on a large library of simulated data-generating processes that
satisfy ignorability, it infers causal effects for new observational datasets
out-of-the-box. CausalPFN combines ideas from Bayesian causal inference with
the large-scale training protocol of prior-fitted networks (PFNs), learning to
map raw observations directly to causal effects without any task-specific
adjustment. Our approach achieves superior average performance on heterogeneous
and average treatment effect estimation benchmarks (IHDP, Lalonde, ACIC).
Moreover, it shows competitive performance for real-world policy making on
uplift modeling tasks. CausalPFN provides calibrated uncertainty estimates to
support reliable decision-making based on Bayesian principles. This
ready-to-use model does not require any further training or tuning and takes a
step toward automated causal inference (https://github.com/vdblm/CausalPFN).},
 author = {Vahid Balazadeh and Hamidreza Kamkari and Valentin Thomas and Benson Li and Junwei Ma and Jesse C. Cresswell and Rahul G. Krishnan},
 comment = {},
 doi = {},
 eprint = {2506.07918v1},
 journal = {arXiv preprint},
 title = {CausalPFN: Amortized Causal Effect Estimation via In-Context Learning},
 url = {http://arxiv.org/abs/2506.07918v1},
 year = {2025}
}

@article{2506.08771v1,
 abstract = {Inferring causal relationships between variable pairs is crucial for
understanding multivariate interactions in complex systems. Knowledge-based
causal discovery -- which involves inferring causal relationships by reasoning
over the metadata of variables (e.g., names or textual context) -- offers a
compelling alternative to traditional methods that rely on observational data.
However, existing methods using Large Language Models (LLMs) often produce
unstable and inconsistent results, compromising their reliability for causal
inference. To address this, we introduce a novel approach that integrates
Knowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery.
Our approach identifies informative metapath-based subgraphs within KGs and
further refines the selection of these subgraphs using Learning-to-Rank-based
models. The top-ranked subgraphs are then incorporated into zero-shot prompts,
improving the effectiveness of LLMs in inferring the causal relationship.
Extensive experiments on biomedical and open-domain datasets demonstrate that
our method outperforms most baselines by up to 44.4 points in F1 scores,
evaluated across diverse LLMs and KGs. Our code and datasets are available on
GitHub: https://github.com/susantiyuni/path-to-causality},
 author = {Yuni Susanti and Michael Färber},
 comment = {Accepted at KDD 2025 (full research paper)},
 doi = {},
 eprint = {2506.08771v1},
 journal = {arXiv preprint},
 title = {Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery},
 url = {http://arxiv.org/abs/2506.08771v1},
 year = {2025}
}

@article{2506.09433v1,
 abstract = {While large language models (LLMs) have demonstrated remarkable capabilities
in language modeling, recent studies reveal that they often fail on
out-of-distribution (OOD) samples due to spurious correlations acquired during
pre-training. Here, we aim to mitigate such spurious correlations through
causality-aware post-training (CAPT). By decomposing a biased prediction into
two unbiased steps, known as \textit{event estimation} and \textit{event
intervention}, we reduce LLMs' pre-training biases without incurring additional
fine-tuning biases, thus enhancing the model's generalization ability.
Experiments on the formal causal inference benchmark CLadder and the logical
reasoning dataset PrOntoQA show that 3B-scale language models fine-tuned with
CAPT can outperform both traditional SFT and larger LLMs on in-distribution
(ID) and OOD tasks using only 100 ID fine-tuning samples, demonstrating the
effectiveness and sample efficiency of CAPT.},
 author = {Shurui Gui and Shuiwang Ji},
 comment = {},
 doi = {},
 eprint = {2506.09433v1},
 journal = {arXiv preprint},
 title = {Mitigating Spurious Correlations in LLMs via Causality-Aware Post-Training},
 url = {http://arxiv.org/abs/2506.09433v1},
 year = {2025}
}

@article{2506.09544v2,
 abstract = {Spatial-temporal causal time series (STC-TS) involve region-specific temporal
observations driven by causally relevant covariates and interconnected across
geographic or network-based spaces. Existing methods often model spatial and
temporal dynamics independently and overlook causality-driven probabilistic
forecasting, limiting their predictive power. To address this, we propose STOAT
(Spatial-Temporal Probabilistic Causal Inference Network), a novel framework
for probabilistic forecasting in STC-TS. The proposed method extends a causal
inference approach by incorporating a spatial relation matrix that encodes
interregional dependencies (e.g. proximity or connectivity), enabling spatially
informed causal effect estimation. The resulting latent series are processed by
deep probabilistic models to estimate the parameters of the distributions,
enabling calibrated uncertainty modeling. We further explore multiple output
distributions (e.g., Gaussian, Student's-$t$, Laplace) to capture
region-specific variability. Experiments on COVID-19 data across six countries
demonstrate that STOAT outperforms state-of-the-art probabilistic forecasting
models (DeepAR, DeepVAR, Deep State Space Model, etc.) in key metrics,
particularly in regions with strong spatial dependencies. By bridging causal
inference and geospatial probabilistic forecasting, STOAT offers a
generalizable framework for complex spatial-temporal tasks, such as epidemic
management.},
 author = {Yang Yang and Du Yin and Hao Xue and Flora Salim},
 comment = {},
 doi = {},
 eprint = {2506.09544v2},
 journal = {arXiv preprint},
 title = {STOAT: Spatial-Temporal Probabilistic Causal Inference Network},
 url = {http://arxiv.org/abs/2506.09544v2},
 year = {2025}
}

@article{2506.09562v2,
 abstract = {Deep reinforcement learning (DRL) has achieved remarkable success in a wide
range of sequential decision-making domains, including robotics, healthcare,
smart grids, and finance. Recent research demonstrates that attackers can
efficiently exploit system vulnerabilities during the training phase to execute
backdoor attacks, producing malicious actions when specific trigger patterns
are present in the state observations. However, most existing backdoor attacks
rely primarily on simplistic and heuristic trigger configurations, overlooking
the potential efficacy of trigger optimization. To address this gap, we
introduce TooBadRL (Trigger Optimization to Boost Effectiveness of Backdoor
Attacks on DRL), the first framework to systematically optimize DRL backdoor
triggers along three critical axes, i.e., temporal, spatial, and magnitude.
Specifically, we first introduce a performance-aware adaptive freezing
mechanism for injection timing. Then, we formulate dimension selection as a
cooperative game, utilizing Shapley value analysis to identify the most
influential state variable for the injection dimension. Furthermore, we propose
a gradient-based adversarial procedure to optimize the injection magnitude
under environment constraints. Evaluations on three mainstream DRL algorithms
and nine benchmark tasks show that TooBadRL significantly improves attack
success rates, while ensuring minimal degradation of normal task performance.
These results highlight the previously underappreciated importance of
principled trigger optimization in DRL backdoor attacks. The source code of
TooBadRL can be found at https://github.com/S3IC-Lab/TooBadRL.},
 author = {Songze Li and Mingxuan Zhang and Kang Wei and Shouling Ji},
 comment = {},
 doi = {},
 eprint = {2506.09562v2},
 journal = {arXiv preprint},
 title = {TooBadRL: Trigger Optimization to Boost Effectiveness of Backdoor Attacks on Deep Reinforcement Learning},
 url = {http://arxiv.org/abs/2506.09562v2},
 year = {2025}
}

@article{2506.10073v2,
 abstract = {Anatomical changes during intensity-modulated proton therapy (IMPT) for
head-and-neck cancer (HNC) can shift Bragg peaks, risking tumor underdosing and
organ-at-risk overdosing. Treatment replanning is often required to maintain
clinically acceptable treatment quality. However, current manual replanning
processes are resource-intensive and time-consuming. We propose a
patient-specific deep reinforcement learning (DRL) framework for automated IMPT
replanning, with a reward-shaping mechanism based on a $150$-point plan quality
score addressing competing clinical objectives. We formulate the planning
process as a reinforcement learning problem where agents learn control policies
to adjust optimization priorities, maximizing plan quality. Unlike
population-based approaches, our framework trains agents for each patient using
their planning Computed Tomography (CT) and augmented anatomies simulating
anatomical changes (tumor progression and regression). This patient-specific
approach leverages anatomical similarities along the treatment course, enabling
effective plan adaptation. We implemented two DRL algorithms, Deep Q-Network
and Proximal Policy Optimization, using dose-volume histograms (DVHs) as state
representations and a $22$-dimensional action space of priority adjustments.
Evaluation on eight HNC patients using actual replanning CT data showed that
both agents improved initial plan scores from $120.78 \pm 17.18$ to $139.59 \pm
5.50$ (DQN) and $141.50 \pm 4.69$ (PPO), surpassing the replans manually
generated by a human planner ($136.32 \pm 4.79$). Clinical validation confirms
that improvements translate to better tumor coverage and OAR sparing across
diverse anatomical changes. This work highlights DRL's potential in addressing
geometric and dosimetric complexities of adaptive proton therapy, offering
efficient offline adaptation solutions and advancing online adaptive proton
therapy.},
 author = {Malvern Madondo and Yuan Shao and Yingzi Liu and Jun Zhou and Xiaofeng Yang and Zhen Tian},
 comment = {Published in Proceedings of Machine Learning Research (PMLR) 298;
  accepted at Machine Learning for Healthcare Conference (MLHC) 2025},
 doi = {},
 eprint = {2506.10073v2},
 journal = {arXiv preprint},
 title = {Patient-Specific Deep Reinforcement Learning for Automatic Replanning in Head-and-Neck Cancer Proton Therapy},
 url = {http://arxiv.org/abs/2506.10073v2},
 year = {2025}
}

@article{2506.10179v1,
 abstract = {Understanding the distinction between causation and correlation is critical
in Alzheimer's disease (AD) research, as it impacts diagnosis, treatment, and
the identification of true disease drivers. This experiment investigates the
relationships among clinical, cognitive, genetic, and biomarker features using
a combination of correlation analysis, machine learning classification, and
model interpretability techniques. Employing the XGBoost algorithm, we
identified key features influencing AD classification, including cognitive
scores and genetic risk factors. Correlation matrices revealed clusters of
interrelated variables, while SHAP (SHapley Additive exPlanations) values
provided detailed insights into feature contributions across disease stages.
Our results highlight that strong correlations do not necessarily imply
causation, emphasizing the need for careful interpretation of associative data.
By integrating feature importance and interpretability with classical
statistical analysis, this work lays groundwork for future causal inference
studies aimed at uncovering true pathological mechanisms. Ultimately,
distinguishing causal factors from correlated markers can lead to improved
early diagnosis and targeted interventions for Alzheimer's disease.},
 author = {Hamzah Dabool and Raghad Mustafa},
 comment = {},
 doi = {},
 eprint = {2506.10179v1},
 journal = {arXiv preprint},
 title = {Correlation vs causation in Alzheimer's disease: an interpretability-driven study},
 url = {http://arxiv.org/abs/2506.10179v1},
 year = {2025}
}

@article{2506.10452v1,
 abstract = {Recent advancements in Multimodal Emotion Recognition (MER) face challenges
in addressing both modality missing and Out-Of-Distribution (OOD) data
simultaneously. Existing methods often rely on specific models or introduce
excessive parameters, which limits their practicality. To address these issues,
we propose a novel robust MER framework, Causal Inference Distiller (CIDer),
and introduce a new task, Random Modality Feature Missing (RMFM), to generalize
the definition of modality missing. CIDer integrates two key components: a
Model-Specific Self-Distillation (MSSD) module and a Model-Agnostic Causal
Inference (MACI) module. MSSD enhances robustness under the RMFM task through a
weight-sharing self-distillation approach applied across low-level features,
attention maps, and high-level representations. Additionally, a Word-level
Self-aligned Attention Module (WSAM) reduces computational complexity, while a
Multimodal Composite Transformer (MCT) facilitates efficient multimodal fusion.
To tackle OOD challenges, MACI employs a tailored causal graph to mitigate
label and language biases using a Multimodal Causal Module (MCM) and
fine-grained counterfactual texts. Notably, MACI can independently enhance OOD
generalization with minimal additional parameters. Furthermore, we also
introduce the new repartitioned MER OOD datasets. Experimental results
demonstrate that CIDer achieves robust performance in both RMFM and OOD
scenarios, with fewer parameters and faster training compared to
state-of-the-art methods. The implementation of this work is publicly
accessible at https://github.com/gw-zhong/CIDer.},
 author = {Guowei Zhong and Ruohong Huan and Mingzhen Wu and Ronghua Liang and Peng Chen},
 comment = {Submitted to TAC. The code is available at
  https://github.com/gw-zhong/CIDer},
 doi = {},
 eprint = {2506.10452v1},
 journal = {arXiv preprint},
 title = {Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts},
 url = {http://arxiv.org/abs/2506.10452v1},
 year = {2025}
}

@article{2506.10914v2,
 abstract = {Prior-data fitted networks (PFNs) have recently been proposed as a promising
way to train tabular foundation models. PFNs are transformers that are
pre-trained on synthetic data generated from a prespecified prior distribution
and that enable Bayesian inference through in-context learning. In this paper,
we introduce CausalFM, a comprehensive framework for training PFN-based
foundation models in various causal inference settings. First, we formalize the
construction of Bayesian priors for causal inference based on structural causal
models (SCMs) in a principled way and derive necessary criteria for the
validity of such priors. Building on this, we propose a novel family of prior
distributions using causality-inspired Bayesian neural networks that enable
CausalFM to perform Bayesian causal inference in various settings, including
for back-door, front-door, and instrumental variable adjustment. Finally, we
instantiate CausalFM and explicitly train models to perform in-context learning
in these settings. We show that CausalFM achieves competitive in-context
learning performance even when compared to baselines that are specifically
trained for the task at hand. In sum, our framework can be used as a general
recipe to train foundation models for various causal inference settings. In
contrast to the current state-of-the-art in causal inference, CausalFM offers a
novel paradigm with the potential to fundamentally change how practitioners
perform causal inference in medicine, economics, and other disciplines.},
 author = {Yuchen Ma and Dennis Frauen and Emil Javurek and Stefan Feuerriegel},
 comment = {},
 doi = {},
 eprint = {2506.10914v2},
 journal = {arXiv preprint},
 title = {Foundation Models for Causal Inference via Prior-Data Fitted Networks},
 url = {http://arxiv.org/abs/2506.10914v2},
 year = {2025}
}

@article{2506.12218v1,
 abstract = {Directed acyclic graphs (DAGs) are central to science and engineering
applications including causal inference, scheduling, and neural architecture
search. In this work, we introduce the DAG Convolutional Network (DCN), a novel
graph neural network (GNN) architecture designed specifically for convolutional
learning from signals supported on DAGs. The DCN leverages causal graph filters
to learn nodal representations that account for the partial ordering inherent
to DAGs, a strong inductive bias does not present in conventional GNNs. Unlike
prior art in machine learning over DAGs, DCN builds on formal convolutional
operations that admit spectral-domain representations. We further propose the
Parallel DCN (PDCN), a model that feeds input DAG signals to a parallel bank of
causal graph-shift operators and processes these DAG-aware features using a
shared multilayer perceptron. This way, PDCN decouples model complexity from
graph size while maintaining satisfactory predictive performance. The
architectures' permutation equivariance and expressive power properties are
also established. Comprehensive numerical tests across several tasks, datasets,
and experimental conditions demonstrate that (P)DCN compares favorably with
state-of-the-art baselines in terms of accuracy, robustness, and computational
efficiency. These results position (P)DCN as a viable framework for deep
learning from DAG-structured data that is designed from first (graph) signal
processing principles.},
 author = {Samuel Rey and Hamed Ajorlou and Gonzalo Mateos},
 comment = {},
 doi = {},
 eprint = {2506.12218v1},
 journal = {arXiv preprint},
 title = {Directed Acyclic Graph Convolutional Networks},
 url = {http://arxiv.org/abs/2506.12218v1},
 year = {2025}
}

@article{2506.12371v1,
 abstract = {Identifying and measuring biases associated with sensitive attributes is a
crucial consideration in healthcare to prevent treatment disparities. One
prominent issue is inaccurate pulse oximeter readings, which tend to
overestimate oxygen saturation for dark-skinned patients and misrepresent
supplemental oxygen needs. Most existing research has revealed statistical
disparities linking device errors to patient outcomes in intensive care units
(ICUs) without causal formalization. In contrast, this study causally
investigates how racial discrepancies in oximetry measurements affect invasive
ventilation in ICU settings. We employ a causal inference-based approach using
path-specific effects to isolate the impact of bias by race on clinical
decision-making. To estimate these effects, we leverage a doubly robust
estimator, propose its self-normalized variant for improved sample efficiency,
and provide novel finite-sample guarantees. Our methodology is validated on
semi-synthetic data and applied to two large real-world health datasets:
MIMIC-IV and eICU. Contrary to prior work, our analysis reveals minimal impact
of racial discrepancies on invasive ventilation rates. However, path-specific
effects mediated by oxygen saturation disparity are more pronounced on
ventilation duration, and the severity differs by dataset. Our work provides a
novel and practical pipeline for investigating potential disparities in the ICU
and, more crucially, highlights the necessity of causal methods to robustly
assess fairness in decision-making.},
 author = {Kevin Zhang and Yonghan Jung and Divyat Mahajan and Karthikeyan Shanmugam and Shalmali Joshi},
 comment = {},
 doi = {},
 eprint = {2506.12371v1},
 journal = {arXiv preprint},
 title = {Path-specific effects for pulse-oximetry guided decisions in critical care},
 url = {http://arxiv.org/abs/2506.12371v1},
 year = {2025}
}

@article{2506.12765v2,
 abstract = {The double/debiased machine learning (DML) framework has become a cornerstone
of modern causal inference, allowing researchers to utilise flexible machine
learning models for the estimation of nuisance functions without introducing
first-order bias into the final parameter estimate. However, the choice of
machine learning model for the nuisance functions is often treated as a minor
implementation detail. In this paper, we argue that this choice can have a
profound impact on the substantive conclusions of the analysis. We demonstrate
this by presenting and comparing two distinct Distributional Instrumental
Variable Local Average Treatment Effect (D-IV-LATE) estimators. The first
estimator leverages standard machine learning models like Random Forests for
nuisance function estimation, while the second is a novel estimator employing
Kolmogorov-Arnold Networks (KANs). We establish the asymptotic properties of
these estimators and evaluate their performance through Monte Carlo
simulations. An empirical application analysing the distributional effects of
401(k) participation on net financial assets reveals that the choice of machine
learning model for nuisance functions can significantly alter substantive
conclusions, with the KAN-based estimator suggesting more complex treatment
effect heterogeneity. These findings underscore a critical "caveat emptor". The
selection of nuisance function estimators is not a mere implementation detail.
Instead, it is a pivotal choice that can profoundly impact research outcomes in
causal inference.},
 author = {Charles Shaw},
 comment = {},
 doi = {},
 eprint = {2506.12765v2},
 journal = {arXiv preprint},
 title = {Rethinking Distributional IVs: KAN-Powered D-IV-LATE & Model Choice},
 url = {http://arxiv.org/abs/2506.12765v2},
 year = {2025}
}

@article{2506.12771v1,
 abstract = {The linear instrumental variable (IV) model is widely applied in
observational studies. The corresponding assumptions are critical for valid
causal inference, and hence, it is important to have tools to assess the
model's well-specification. The classical Sargan-Hansen J-test is limited to
the overidentified setting, where the number of instruments is larger than the
number of endogenous variables. Here, we propose a novel and simple test for
the well-specification of the linear IV model under the assumption that the
structural error is mean independent of the instruments. Importantly, assuming
mean independence allows the construction of such a test even in the
just-identified setting. We use the idea of residual prediction tests: if the
residuals from two-stage least squares can be predicted from the instruments
better than randomly, this signals misspecification. We construct a test
statistic based on sample splitting and a user-chosen machine learning method.
We show asymptotic type I error control. Furthermore, by relying on machine
learning tools, our test has good power for detecting alternatives from a broad
class of scenarios. We also address heteroskedasticity- and cluster-robust
inference. The test is implemented in the R package RPIV and in the ivmodels
software package for Python.},
 author = {Cyrill Scheidegger and Malte Londschien and Peter Bühlmann},
 comment = {},
 doi = {},
 eprint = {2506.12771v1},
 journal = {arXiv preprint},
 title = {A Residual Prediction Test for the Well-Specification of Linear Instrumental Variable Models},
 url = {http://arxiv.org/abs/2506.12771v1},
 year = {2025}
}

@article{2506.12808v1,
 abstract = {The Medical Information Mart for Intensive Care (MIMIC) datasets have become
the Kernel of Digital Health Research by providing freely accessible,
deidentified records from tens of thousands of critical care admissions,
enabling a broad spectrum of applications in clinical decision support, outcome
prediction, and healthcare analytics. Although numerous studies and surveys
have explored the predictive power and clinical utility of MIMIC based models,
critical challenges in data integration, representation, and interoperability
remain underexplored. This paper presents a comprehensive survey that focuses
uniquely on open problems. We identify persistent issues such as data
granularity, cardinality limitations, heterogeneous coding schemes, and ethical
constraints that hinder the generalizability and real-time implementation of
machine learning models. We highlight key progress in dimensionality reduction,
temporal modelling, causal inference, and privacy preserving analytics, while
also outlining promising directions including hybrid modelling, federated
learning, and standardized preprocessing pipelines. By critically examining
these structural limitations and their implications, this survey offers
actionable insights to guide the next generation of MIMIC powered digital
health innovations.},
 author = {Afifa Khaled and Mohammed Sabir and Rizwan Qureshi and Camillo Maria Caruso and Valerio Guarrasi and Suncheng Xiang and S Kevin Zhou},
 comment = {},
 doi = {},
 eprint = {2506.12808v1},
 journal = {arXiv preprint},
 title = {Leveraging MIMIC Datasets for Better Digital Health: A Review on Open Problems, Progress Highlights, and Future Promises},
 url = {http://arxiv.org/abs/2506.12808v1},
 year = {2025}
}

@article{2506.14051v1,
 abstract = {Causal effect estimation seeks to determine the impact of an intervention
from observational data. However, the existing causal inference literature
primarily addresses treatment effects on frequently occurring events. But what
if we are interested in estimating the effects of a policy intervention whose
benefits, while potentially important, can only be observed and measured in
rare yet impactful events, such as extreme climate events? The standard causal
inference methodology is not designed for this type of inference since the
events of interest may be scarce in the observed data and some degree of
extrapolation is necessary. Extreme Value Theory (EVT) provides methodologies
for analyzing statistical phenomena in such extreme regimes. We introduce a
novel framework for assessing treatment effects in extreme data to capture the
causal effect at the occurrence of rare events of interest. In particular, we
employ the theory of multivariate regular variation to model extremities. We
develop a consistent estimator for extreme treatment effects and present a
rigorous non-asymptotic analysis of its performance. We illustrate the
performance of our estimator using both synthetic and semi-synthetic data.},
 author = {Jiyuan Tan and Jose Blanchet and Vasilis Syrgkanis},
 comment = {},
 doi = {},
 eprint = {2506.14051v1},
 journal = {arXiv preprint},
 title = {Estimation of Treatment Effects in Extreme and Unobserved Data},
 url = {http://arxiv.org/abs/2506.14051v1},
 year = {2025}
}

@article{2506.14805v2,
 abstract = {As Multimodal Large Language Models (MLLMs) continue to evolve, their
cognitive and reasoning capabilities have seen remarkable progress. However,
challenges in visual fine-grained perception and commonsense causal inference
persist. This paper introduces Argus Inspection, a multimodal benchmark with
two levels of difficulty, emphasizing detailed visual recognition while
incorporating real-world commonsense understanding to evaluate causal reasoning
abilities. Expanding on it, we present the Eye of Panoptes framework, which
integrates a binary parametric Sigmoid metric with an indicator function,
enabling a more holistic evaluation of MLLMs' responses in opinion-based
reasoning tasks. Experiments conducted on 26 mainstream MLLMs reveal that the
highest performance in visual fine-grained reasoning reaches only 0.46,
highlighting considerable potential for enhancement. Our research offers
valuable perspectives for the continued refinement of MLLMs.},
 author = {Yang Yao and Lingyu Li and Jiaxin Song and Chiyu Chen and Zhenqi He and Yixu Wang and Xin Wang and Tianle Gu and Jie Li and Yan Teng and Yingchun Wang},
 comment = {},
 doi = {},
 eprint = {2506.14805v2},
 journal = {arXiv preprint},
 title = {Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?},
 url = {http://arxiv.org/abs/2506.14805v2},
 year = {2025}
}

@article{2506.14950v2,
 abstract = {Solving conditional moment restrictions (CMRs) is a key problem considered in
statistics, causal inference, and econometrics, where the aim is to solve for a
function of interest that satisfies some conditional moment equalities.
Specifically, many techniques for causal inference, such as instrumental
variable (IV) regression and proximal causal learning (PCL), are CMR problems.
Most CMR estimators use a two-stage approach, where the first-stage estimation
is directly plugged into the second stage to estimate the function of interest.
However, naively plugging in the first-stage estimator can cause heavy bias in
the second stage. This is particularly the case for recently proposed CMR
estimators that use deep neural network (DNN) estimators for both stages, where
regularisation and overfitting bias is present. We propose DML-CMR, a two-stage
CMR estimator that provides an unbiased estimate with fast convergence rate
guarantees. We derive a novel learning objective to reduce bias and develop the
DML-CMR algorithm following the double/debiased machine learning (DML)
framework. We show that our DML-CMR estimator can achieve the minimax optimal
convergence rate of $O(N^{-1/2})$ under parameterisation and mild regularity
conditions, where $N$ is the sample size. We apply DML-CMR to a range of
problems using DNN estimators, including IV regression and proximal causal
learning on real-world datasets, demonstrating state-of-the-art performance
against existing CMR estimators and algorithms tailored to those problems.},
 author = {Daqian Shao and Ashkan Soleymani and Francesco Quinzan and Marta Kwiatkowska},
 comment = {},
 doi = {},
 eprint = {2506.14950v2},
 journal = {arXiv preprint},
 title = {Double Machine Learning for Conditional Moment Restrictions: IV Regression, Proximal Causal Learning and Beyond},
 url = {http://arxiv.org/abs/2506.14950v2},
 year = {2025}
}

@article{2506.15758v1,
 abstract = {We introduce CIfly, a framework for efficient algorithmic primitives in
graphical causal inference that isolates reachability as a reusable core
operation. It builds on the insight that many causal reasoning tasks can be
reduced to reachability in purpose-built state-space graphs that can be
constructed on the fly during traversal. We formalize a rule table schema for
specifying such algorithms and prove they run in linear time. We establish
CIfly as a more efficient alternative to the common primitives moralization and
latent projection, which we show are computationally equivalent to Boolean
matrix multiplication. Our open-source Rust implementation parses rule table
text files and runs the specified CIfly algorithms providing high-performance
execution accessible from Python and R. We demonstrate CIfly's utility by
re-implementing a range of established causal inference tasks within the
framework and by developing new algorithms for instrumental variables. These
contributions position CIfly as a flexible and scalable backbone for graphical
causal inference, guiding algorithm development and enabling easy and efficient
deployment.},
 author = {Marcel Wienöbst and Sebastian Weichwald and Leonard Henckel},
 comment = {},
 doi = {},
 eprint = {2506.15758v1},
 journal = {arXiv preprint},
 title = {Linear-Time Primitives for Algorithm Development in Graphical Causal Inference},
 url = {http://arxiv.org/abs/2506.15758v1},
 year = {2025}
}

@article{2506.16044v1,
 abstract = {With recent advancements in AI and computational tools, intelligent paradigms
have emerged to enhance fields like shared autonomy and human-machine teaming
in healthcare. Advanced AI algorithms (e.g., reinforcement learning) can
autonomously make decisions to achieve planning and motion goals. However, in
healthcare, where human intent is crucial, fully independent machine decisions
may not be ideal. This chapter presents a comprehensive review of
human-centered shared autonomy AI frameworks, focusing on upper limb
biosignal-based machine interfaces and associated motor control systems,
including computer cursors, robotic arms, and planar platforms. We examine
motor planning, learning (rehabilitation), and control, covering conceptual
foundations of human-machine teaming in reach-and-grasp tasks and analyzing
both theoretical and practical implementations. Each section explores how human
and machine inputs can be blended for shared autonomy in healthcare
applications. Topics include human factors, biosignal processing for intent
detection, shared autonomy in brain-computer interfaces (BCI), rehabilitation,
assistive robotics, and Large Language Models (LLMs) as the next frontier. We
propose adaptive shared autonomy AI as a high-performance paradigm for
collaborative human-AI systems, identify key implementation challenges, and
outline future directions, particularly regarding AI reasoning agents. This
analysis aims to bridge neuroscientific insights with robotics to create more
intuitive, effective, and ethical human-machine teaming frameworks.},
 author = {MH Farhadi and Ali Rabiee and Sima Ghafoori and Anna Cetera and Wei Xu and Reza Abiri},
 comment = {},
 doi = {},
 eprint = {2506.16044v1},
 journal = {arXiv preprint},
 title = {Human-Centered Shared Autonomy for Motor Planning, Learning, and Control Applications},
 url = {http://arxiv.org/abs/2506.16044v1},
 year = {2025}
}

@article{2506.16629v4,
 abstract = {Causal inference in longitudinal biomedical data remains a central challenge,
especially in psychiatry, where symptom heterogeneity and latent confounding
frequently undermine classical estimators. Most existing methods for treatment
effect estimation presuppose a fixed outcome variable and address confounding
through observed covariate adjustment. However, the assumption of
unconfoundedness may not hold for a fixed outcome in practice. To address this
foundational limitation, we directly optimize the outcome definition to
maximize causal identifiability. Our DEBIAS (Durable Effects with
Backdoor-Invariant Aggregated Symptoms) algorithm learns non-negative,
clinically interpretable weights for outcome aggregation, maximizing durable
treatment effects and empirically minimizing both observed and latent
confounding by leveraging the time-limited direct effects of prior treatments
in psychiatric longitudinal data. The algorithm also furnishes an empirically
verifiable test for outcome unconfoundedness. DEBIAS consistently outperforms
state-of-the-art methods in recovering causal effects for clinically
interpretable composite outcomes across comprehensive experiments in depression
and schizophrenia.},
 author = {Eric V. Strobl},
 comment = {R code is available at github.com/ericstrobl/DEBIAS},
 doi = {},
 eprint = {2506.16629v4},
 journal = {arXiv preprint},
 title = {Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data},
 url = {http://arxiv.org/abs/2506.16629v4},
 year = {2025}
}

@article{2506.17300v2,
 abstract = {Individual causal inference (ICI) uses causal inference methods to understand
and predict the effects of interventions on individuals, considering their
specific characteristics / facts. It aims to estimate individual causal effect
(ICE), which varies across individuals. Estimating ICE can be challenging due
to the limited data available for individuals, and the fact that most causal
inference methods are population-based. Structural Causal Model (SCM) is
fundamentally population-based. Therefore, causal discovery (structural
learning and parameter learning), association queries and intervention queries
are all naturally population-based. However, exogenous variables (U) in SCM can
encode individual variations and thus provide the mechanism for individualized
population per specific individual characteristics / facts. Based on this, we
propose ICI with SCM as a "rung 3" causal inference, because it involves
"imagining" what would be the causal effect of a hypothetical intervention on
an individual, given the individual's observed characteristics / facts.
Specifically, we propose the indiv-operator, indiv(W), to formalize/represent
the population individualization process, and the individual causal query, P(Y
| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI
with SCM is inference on individual alternatives (possible), not individual
counterfactuals (non-actual).},
 author = {Daniel T. Chang},
 comment = {},
 doi = {},
 eprint = {2506.17300v2},
 journal = {arXiv preprint},
 title = {Individual Causal Inference with Structural Causal Model},
 url = {http://arxiv.org/abs/2506.17300v2},
 year = {2025}
}

@article{2506.18147v1,
 abstract = {The digitalization of financial markets has shifted trading from voice to
electronic channels, with Multi-Dealer-to-Client (MD2C) platforms now enabling
clients to request quotes (RfQs) for financial instruments like bonds from
multiple dealers simultaneously. In this competitive landscape, dealers cannot
see each other's prices, making a rigorous analysis of the negotiation process
crucial to ensure their profitability. This article introduces a novel general
framework for analyzing the RfQ process using probabilistic graphical models
and causal inference. Within this framework, we explore different inferential
questions that are relevant for dealers participating in MD2C platforms, such
as the computation of optimal prices, estimating potential revenues and the
identification of clients that might be interested in trading the dealer's
axes. We then move into analyzing two different approaches for model
specification: a generative model built on the work of (Fermanian, Gu\'eant &
Pu, 2017); and discriminative models utilizing machine learning techniques. We
evaluate these methodologies using predictive metrics designed to assess their
effectiveness in the context of optimal pricing, highlighting the relative
benefits of using models that take into account the internal mechanisms of the
negotiation process.},
 author = {Paloma Marín and Sergio Ardanza-Trevijano and Javier Sabio},
 comment = {},
 doi = {},
 eprint = {2506.18147v1},
 journal = {arXiv preprint},
 title = {Causal Interventions in Bond Multi-Dealer-to-Client Platforms},
 url = {http://arxiv.org/abs/2506.18147v1},
 year = {2025}
}

@article{2506.18187v1,
 abstract = {This study quantifies the association between non-adherence to antipsychotic
medications and adverse outcomes in individuals with schizophrenia. We frame
the problem using survival analysis, focusing on the time to the earliest of
several adverse events (early death, involuntary hospitalization, jail
booking). We extend standard causal inference methods (T-learner, S-learner,
nearest neighbor matching) to utilize various survival models to estimate
individual and average treatment effects, where treatment corresponds to
medication non-adherence. Analyses are repeated using different amounts of
longitudinal information (3, 6, 9, and 12 months). Using data from Allegheny
County in western Pennsylvania, we find strong evidence that non-adherence
advances adverse outcomes by approximately 1 to 4 months. Ablation studies
confirm that county-provided risk scores adjust for key confounders, as their
removal amplifies the estimated effects. Subgroup analyses by medication
formulation (injectable vs. oral) and medication type consistently show that
non-adherence is associated with earlier adverse events. These findings
highlight the clinical importance of adherence in delaying psychiatric crises
and show that integrating survival analysis with causal inference tools can
yield policy-relevant insights. We caution that although we apply causal
inference, we only make associative claims and discuss assumptions needed for
causal interpretation.},
 author = {Shahriar Noroozizadeh and Pim Welle and Jeremy C. Weiss and George H. Chen},
 comment = {Conference on Health, Inference, and Learning (CHIL 2025)},
 doi = {},
 eprint = {2506.18187v1},
 journal = {arXiv preprint},
 title = {The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis},
 url = {http://arxiv.org/abs/2506.18187v1},
 year = {2025}
}

@article{2506.19890v1,
 abstract = {The optimization of quality of experience (QoE) in multi-user virtual reality
(VR) interactions demands a delicate balance between ultra-low latency,
high-fidelity motion synchronization, and equitable resource allocation. While
adaptive keyframe extraction mitigates transmission overhead, existing
approaches often overlook the causal relationships among allocated bandwidth,
CPU frequency, and user perception, limiting QoE gains. This paper proposes an
intelligent framework to maximize QoE by integrating adaptive keyframe
extraction with causal-aware reinforcement learning (RL). First, a novel QoE
metric is formulated using the Weber-Fechner Law, combining perceptual
sensitivity, attention-driven priorities, and motion reconstruction accuracy.
The QoE optimization problem is then modeled as a mixed integer programming
(MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational
resources under horizon-fairness constraints. We propose Partial State Causal
Deep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep
Deterministic Policy Gradient (DDPG) method with causal influence detection. By
leveraging causal information regarding how QoE is influenced and determined by
various actions, we explore actions guided by weights calculated from causal
inference (CI), which in turn improves training efficiency. Experiments
conducted with the CMU Motion Capture Database demonstrate that our framework
significantly reduces interactive latency, enhances QoE, and maintains
fairness, achieving superior performance compared to benchmark methods.},
 author = {Ziru Zhang and Jiadong Yu and Danny H. K. Tsang},
 comment = {},
 doi = {},
 eprint = {2506.19890v1},
 journal = {arXiv preprint},
 title = {Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction},
 url = {http://arxiv.org/abs/2506.19890v1},
 year = {2025}
}

@article{2506.19973v1,
 abstract = {This study investigates the application of quantum neural networks (QNNs) for
propensity score estimation to address selection bias in comparing survival
outcomes between laparoscopic and open surgical techniques in a cohort of 1177
colorectal carcinoma patients treated at University Hospital Ostrava
(2001-2009). Using a dataset with 77 variables, including patient demographics
and tumor characteristics, we developed QNN-based propensity score models
focusing on four key covariates (Age, Sex, Stage, BMI). The QNN architecture
employed a linear ZFeatureMap for data encoding, a SummedPaulis operator for
predictions, and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES)
for robust, gradient-free optimization in noisy quantum environments. Variance
regularization was integrated to mitigate quantum measurement noise, with
simulations conducted under exact, sampling (1024 shots), and noisy hardware
(FakeManhattanV2) conditions. QNNs, particularly with simulated hardware noise,
outperformed classical logistic regression and gradient boosted machines in
small samples (AUC up to 0.750 for n=100), with noise modeling enhancing
predictive stability. Propensity score matching and weighting, optimized via
genetic matching and matching weights, achieved covariate balance with
standardized mean differences of 0.0849 and 0.0869, respectively. Survival
analyses using Kaplan-Meier estimation, Cox proportional hazards, and Aalen
additive regression revealed no significant survival differences
post-adjustment (p-values 0.287-0.851), indicating confounding bias in
unadjusted outcomes. These results highlight QNNs' potential, enhanced by
CMA-ES and noise-aware strategies, to improve causal inference in biomedical
research, particularly for small-sample, high-dimensional datasets.},
 author = {Vojtěch Novák and Ivan Zelinka and Lenka Přibylová and Lubomír Martínek},
 comment = {},
 doi = {},
 eprint = {2506.19973v1},
 journal = {arXiv preprint},
 title = {Quantum Neural Networks for Propensity Score Estimation and Survival Analysis in Observational Biomedical Studies},
 url = {http://arxiv.org/abs/2506.19973v1},
 year = {2025}
}

@article{2506.20406v1,
 abstract = {Dynamic treatment regimes (DTRs) provide a principled framework for
optimizing sequential decision-making in domains where decisions must adapt
over time in response to individual trajectories, such as healthcare,
education, and digital interventions. However, existing statistical methods
often rely on strong positivity assumptions and lack robustness under partial
data coverage, while offline reinforcement learning approaches typically focus
on average training performance, lack statistical guarantees, and require
solving complex optimization problems. To address these challenges, we propose
POLAR, a novel pessimistic model-based policy learning algorithm for offline
DTR optimization. POLAR estimates the transition dynamics from offline data and
quantifies uncertainty for each history-action pair. A pessimistic penalty is
then incorporated into the reward function to discourage actions with high
uncertainty. Unlike many existing methods that focus on average training
performance, POLAR directly targets the suboptimality of the final learned
policy and offers theoretical guarantees, without relying on computationally
intensive minimax or constrained optimization procedures. To the best of our
knowledge, POLAR is the first model-based DTR method to provide both
statistical and computational guarantees, including finite-sample bounds on
policy suboptimality. Empirical results on both synthetic data and the
MIMIC-III dataset demonstrate that POLAR outperforms state-of-the-art methods
and yields near-optimal, history-aware treatment strategies.},
 author = {Ruijia Zhang and Zhengling Qi and Yue Wu and Xiangyu Zhang and Yanxun Xu},
 comment = {},
 doi = {},
 eprint = {2506.20406v1},
 journal = {arXiv preprint},
 title = {POLAR: A Pessimistic Model-based Policy Learning Algorithm for Dynamic Treatment Regimes},
 url = {http://arxiv.org/abs/2506.20406v1},
 year = {2025}
}

@article{2506.22754v1,
 abstract = {Causal inference is central to statistics and scientific discovery, enabling
researchers to identify cause-and-effect relationships beyond associations.
While traditionally studied within Euclidean spaces, contemporary applications
increasingly involve complex, non-Euclidean data structures that reside in
abstract metric spaces, known as random objects, such as images, shapes,
networks, and distributions. This paper introduces a novel framework for causal
inference with continuous treatments applied to non-Euclidean data. To address
the challenges posed by the lack of linear structures, we leverage Hilbert
space embeddings of the metric spaces to facilitate Fr\'echet mean estimation
and causal effect mapping. Motivated by a study on the impact of exposure to
fine particulate matter on age-at-death distributions across U.S. counties, we
propose a nonparametric, doubly-debiased causal inference approach for outcomes
as random objects with continuous treatments. Our framework can accommodate
moderately high-dimensional vector-valued confounders and derive efficient
influence functions for estimation to ensure both robustness and
interpretability. We establish rigorous asymptotic properties of the
cross-fitted estimators and employ conformal inference techniques for
counterfactual outcome prediction. Validated through numerical experiments and
applied to real-world environmental data, our framework extends causal
inference methodologies to complex data structures, broadening its
applicability across scientific disciplines.},
 author = {Satarupa Bhattacharjee and Bing Li and Xiao Wu and Lingzhou Xue},
 comment = {30 pages, 5 figures},
 doi = {},
 eprint = {2506.22754v1},
 journal = {arXiv preprint},
 title = {Doubly robust estimation of causal effects for random object outcomes with continuous treatments},
 url = {http://arxiv.org/abs/2506.22754v1},
 year = {2025}
}

@article{2506.23270v1,
 abstract = {Multimodal large language models (MLLMs) are broadly empowering various
fields. Despite their advancements, the explainability of MLLMs remains less
explored, hindering deeper understanding, model credibility, and effective
visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that
produce a single output, MLLMs generate sequences of tokens progressively,
where each generated token depends on the previous context. Therefore, earlier
context tokens can introduce redundant activations that interfere with the
explanation of later tokens beyond their original information. Existing studies
often overlook this issue, but our observations reveal that these redundant
correlations can significantly hurt the reliability of explanations. To address
this, we propose an estimated causal inference method to mitigate the
interference of context to achieve high-quality MLLM explanation, with a novel
rank Gaussian filter to further reduce activation noises. We term this method
Token Activation Map (TAM) to highlight the consideration of interactions
between tokens. TAM also indicates that it excels at explaining multiple tokens
of MLLM, which is different from the Class Activation Map (CAM) for a single
prediction. Our TAM method significantly outperforms existing SoTA methods,
showcasing high-quality visualization results that can be utilized for various
scenarios, such as object localization, failure case analysis, video
visualization, MLLMs visual comparison, and model understanding (e.g., color,
shape, action, location, visual reasoning, multi-turn conversation, etc). The
code is available atgithub.com/xmed-lab/TAM.},
 author = {Yi Li and Hualiang Wang and Xinpeng Ding and Haonan Wang and Xiaomeng Li},
 comment = {ICCV2025 Accepted},
 doi = {},
 eprint = {2506.23270v1},
 journal = {arXiv preprint},
 title = {Token Activation Map to Visually Explain Multimodal LLMs},
 url = {http://arxiv.org/abs/2506.23270v1},
 year = {2025}
}

@article{2506.23297v1,
 abstract = {This paper introduces a novel Proxy-Enhanced Correlated Random Effects Double
Machine Learning (P-CRE-DML) framework to estimate causal effects in panel data
with non-linearities and unobserved heterogeneity. Combining Double Machine
Learning (DML, Chernozhukov et al., 2018), Correlated Random Effects (CRE,
Mundlak, 1978), and lagged variables (Arellano & Bond, 1991) and innovating
within the CRE-DML framework (Chernozhukov et al., 2022; Clarke & Polselli,
2025; Fuhr & Papies, 2024), we apply P-CRE-DML to investigate the effect of
social trust on GDP growth across 89 countries (2010-2020). We find positive
and statistically significant relationship between social trust and economic
growth. This aligns with prior findings on trust-growth relationship (e.g.,
Knack & Keefer, 1997). Furthermore, a Monte Carlo simulation demonstrates
P-CRE-DML's advantage in terms of lower bias over CRE-DML and System GMM.
P-CRE-DML offers a robust and flexible alternative for panel data causal
inference, with applications beyond economic growth.},
 author = {Amarendra Sharma},
 comment = {20 pages, 2 tables, 1 figure},
 doi = {},
 eprint = {2506.23297v1},
 journal = {arXiv preprint},
 title = {P-CRE-DML: A Novel Approach for Causal Inference in Non-Linear Panel Data},
 url = {http://arxiv.org/abs/2506.23297v1},
 year = {2025}
}

@article{2507.01700v1,
 abstract = {Estimating causal effects from real-world relational data can be challenging
when the underlying causal model and potential confounders are unknown. While
several causal discovery algorithms exist for learning causal models with
latent confounders from data, they assume that the data is independent and
identically distributed (i.i.d.) and are not well-suited for learning from
relational data. Similarly, existing relational causal discovery algorithms
assume causal sufficiency, which is unrealistic for many real-world datasets.
To address this gap, we propose RelFCI, a sound and complete causal discovery
algorithm for relational data with latent confounders. Our work builds upon the
Fast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms
and it defines new graphical models, necessary to support causal discovery in
relational domains. We also establish soundness and completeness guarantees for
relational d-separation with latent confounders. We present experimental
results demonstrating the effectiveness of RelFCI in identifying the correct
causal structure in relational causal models with latent confounders.},
 author = {Andrea Piras and Matteo Negro and Ragib Ahsan and David Arbour and Elena Zheleva},
 comment = {30 pages, 19 figures. Accepted for publication at the 41st Conference
  on Uncertainty in Artificial Intelligence (UAI 2025). Andrea Piras and Matteo
  Negro contributed equally to this work},
 doi = {},
 eprint = {2507.01700v1},
 journal = {arXiv preprint},
 title = {Relational Causal Discovery with Latent Confounders},
 url = {http://arxiv.org/abs/2507.01700v1},
 year = {2025}
}

@article{2507.02275v2,
 abstract = {Structure-agnostic causal inference studies how well one can estimate a
treatment effect given black-box machine learning estimates of nuisance
functions (like the impact of confounders on treatment and outcomes). Here, we
find that the answer depends in a surprising way on the distribution of the
treatment noise. Focusing on the partially linear model of
\citet{robinson1988root}, we first show that the widely adopted double machine
learning (DML) estimator is minimax rate-optimal for Gaussian treatment noise,
resolving an open problem of \citet{mackey2018orthogonal}. Meanwhile, for
independent non-Gaussian treatment noise, we show that DML is always suboptimal
by constructing new practical procedures with higher-order robustness to
nuisance errors. These \emph{ACE} procedures use structure-agnostic cumulant
estimators to achieve $r$-th order insensitivity to nuisance errors whenever
the $(r+1)$-st treatment cumulant is non-zero. We complement these core results
with novel minimax guarantees for binary treatments in the partially linear
model. Finally, using synthetic demand estimation experiments, we demonstrate
the practical benefits of our higher-order robust estimators.},
 author = {Jikai Jin and Lester Mackey and Vasilis Syrgkanis},
 comment = {},
 doi = {},
 eprint = {2507.02275v2},
 journal = {arXiv preprint},
 title = {It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation},
 url = {http://arxiv.org/abs/2507.02275v2},
 year = {2025}
}

@article{2507.02912v2,
 abstract = {Industrial carbon emissions are a major driver of climate change, yet
modeling these emissions is challenging due to multicollinearity among factors
and complex interdependencies across sectors and time. We propose a novel
graph-based deep learning framework DGL to analyze and forecast industrial CO_2
emissions, addressing high feature correlation and capturing
industrial-temporal interdependencies. Unlike traditional regression or
clustering methods, our approach leverages a Graph Neural Network (GNN) with
attention mechanisms to model relationships between industries (or regions) and
a temporal transformer to learn long-range patterns. We evaluate our framework
on public global industry emissions dataset derived from EDGAR v8.0, spanning
multiple countries and sectors. The proposed model achieves superior predictive
performance - reducing error by over 15% compared to baseline deep models -
while maintaining interpretability via attention weights and causal analysis.
We believe that we are the first Graph-Temporal architecture that resolves
multicollinearity by structurally encoding feature relationships, along with
integration of causal inference to identify true drivers of emissions,
improving transparency and fairness. We also stand a demonstration of policy
relevance, showing how model insights can guide sector-specific decarbonization
strategies aligned with sustainable development goals. Based on the above, we
show high-emission "hotspots" and suggest equitable intervention plans,
illustrating the potential of state-of-the-art AI graph learning to advance
climate action, offering a powerful tool for policymakers and industry
stakeholders to achieve carbon reduction targets.},
 author = {Xuanming Zhang},
 comment = {NeurIPS 2025 AI for Science Workshop},
 doi = {},
 eprint = {2507.02912v2},
 journal = {arXiv preprint},
 title = {Deep Graph Learning for Industrial Carbon Emission Analysis and Policy Impact},
 url = {http://arxiv.org/abs/2507.02912v2},
 year = {2025}
}

@article{2507.03271v1,
 abstract = {Causal forest methods are powerful tools in causal inference. Similar to
traditional random forest in machine learning, causal forest independently
considers each causal tree. However, this independence consideration increases
the likelihood that classification errors in one tree are repeated in others,
potentially leading to significant bias in causal e ect estimation. In this
paper, we propose a novel approach that establishes connections between causal
trees through the Limit Inferior Leaf Interval (LILI) clustering algorithm.
LILIs are constructed based on the leaves of all causal trees, emphasizing the
similarity of dataset confounders. When two instances with di erent treatments
are grouped into the same leaf across a su cient number of causal trees, they
are treated as counterfactual outcomes of each other. Through this clustering
mechanism, LILI clustering reduces bias present in traditional causal tree
methods and enhances the prediction accuracy for the average treatment e ect
(ATE). By integrating LILIs into a causal forest, we develop an e cient causal
inference method. Moreover, we explore several key properties of LILI by
relating it to the concepts of limit inferior and limit superior in the set
theory. Theoretical analysis rigorously proves the convergence of the estimated
ATE using LILI clustering. Empirically, extensive comparative experiments
demonstrate the superior performance of LILI clustering.},
 author = {Yiran Dong and Di Fan and Chuanhou Gao},
 comment = {},
 doi = {},
 eprint = {2507.03271v1},
 journal = {arXiv preprint},
 title = {LILI clustering algorithm: Limit Inferior Leaf Interval Integrated into Causal Forest for Causal Interference},
 url = {http://arxiv.org/abs/2507.03271v1},
 year = {2025}
}

@article{2507.03310v1,
 abstract = {This paper studies causal discovery in irregularly sampled time series-a
pivotal challenge in high-stakes domains like finance, healthcare, and climate
science, where missing data and inconsistent sampling frequencies distort
causal mechanisms. Traditional methods (e.g., Granger causality, PCMCI) fail to
reconcile multi-scale interactions (e.g., hourly storms vs. decadal climate
shifts), while neural approaches (e.g., CUTS+) lack interpretability, stemming
from a critical gap: existing frameworks either rigidly assume temporal
regularity or aggregate dynamics into opaque representations, neglecting
real-world granularity and auditable logic. To bridge this gap, we propose
ReTimeCausal, a novel integration of Additive Noise Models (ANM) and
Expectation-Maximization (EM) that unifies physics-guided data imputation with
sparse causal inference. Through kernelized sparse regression and structural
constraints, ReTimeCausal iteratively refines missing values (E-step) and
causal graphs (M-step), resolving cross-frequency dependencies and missing data
issues. Extensive experiments on synthetic and real-world datasets demonstrate
that ReTimeCausal outperforms existing state-of-the-art methods under
challenging irregular sampling and missing data conditions.},
 author = {Weihong Li and Anpeng Wu and Kun Kuang and Keting Yin},
 comment = {12 pages, 2 figures},
 doi = {},
 eprint = {2507.03310v1},
 journal = {arXiv preprint},
 title = {ReTimeCausal: EM-Augmented Additive Noise Models for Interpretable Causal Discovery in Irregular Time Series},
 url = {http://arxiv.org/abs/2507.03310v1},
 year = {2025}
}

@article{2507.03871v1,
 abstract = {The use of reinforcement learning (RL) methods to support health behavior
change via personalized and just-in-time adaptive interventions is of
significant interest to health and behavioral science researchers focused on
problems such as smoking cessation support and physical activity promotion.
However, RL methods are often applied to these domains using a small collection
of context variables to mitigate the significant data scarcity issues that
arise from practical limitations on the design of adaptive intervention trials.
In this paper, we explore an approach to significantly expanding the state
space of an adaptive intervention without impacting data efficiency. The
proposed approach enables intervention participants to provide natural language
descriptions of aspects of their current state. It then leverages inference
with pre-trained large language models (LLMs) to better align the policy of a
base RL method with these state descriptions. To evaluate our method, we
develop a novel physical activity intervention simulation environment that
generates text-based state descriptions conditioned on latent state variables
using an auxiliary LLM. We show that this approach has the potential to
significantly improve the performance of online policy learning methods.},
 author = {Karine Karine and Benjamin M. Marlin},
 comment = {Accepted at Machine Learning for Healthcare (MLHC) 2025},
 doi = {},
 eprint = {2507.03871v1},
 journal = {arXiv preprint},
 title = {Enhancing Adaptive Behavioral Interventions with LLM Inference from Participant-Described States},
 url = {http://arxiv.org/abs/2507.03871v1},
 year = {2025}
}

@article{2507.04317v1,
 abstract = {Understanding surgical scenes can provide better healthcare quality for
patients, especially with the vast amount of video data that is generated
during MIS. Processing these videos generates valuable assets for training
sophisticated models. In this paper, we introduce CLIP-RL, a novel contrastive
language-image pre-training model tailored for semantic segmentation for
surgical scenes. CLIP-RL presents a new segmentation approach which involves
reinforcement learning and curriculum learning, enabling continuous refinement
of the segmentation masks during the full training pipeline. Our model has
shown robust performance in different optical settings, such as occlusions,
texture variations, and dynamic lighting, presenting significant challenges.
CLIP model serves as a powerful feature extractor, capturing rich semantic
context that enhances the distinction between instruments and tissues. The RL
module plays a pivotal role in dynamically refining predictions through
iterative action-space adjustments. We evaluated CLIP-RL on the EndoVis 2018
and EndoVis 2017 datasets. CLIP-RL achieved a mean IoU of 81%, outperforming
state-of-the-art models, and a mean IoU of 74.12% on EndoVis 2017. This
superior performance was achieved due to the combination of contrastive
learning with reinforcement learning and curriculum learning.},
 author = {Fatmaelzahraa Ali Ahmed and Muhammad Arsalan and Abdulaziz Al-Ali and Khalid Al-Jalham and Shidin Balakrishnan},
 comment = {},
 doi = {10.1109/CBMS65348.2025.00175},
 eprint = {2507.04317v1},
 journal = {arXiv preprint},
 title = {CLIP-RL: Surgical Scene Segmentation Using Contrastive Language-Vision Pretraining & Reinforcement Learning},
 url = {http://arxiv.org/abs/2507.04317v1},
 year = {2025}
}

@article{2507.04881v2,
 abstract = {Brain tumor resection is a highly complex procedure with profound
implications for survival and quality of life. Predicting patient outcomes is
crucial to guide clinicians in balancing oncological control with preservation
of neurological function. However, building reliable prediction models is
severely limited by the rarity of curated datasets that include both pre- and
post-surgery imaging, given the clinical, logistical and ethical challenges of
collecting such data. In this study, we develop a novel framework that
integrates explainable artificial intelligence (XAI) with neuroimaging-based
feature engineering for survival assessment in brain tumor patients. We curated
structural MRI data from 49 patients scanned pre- and post-surgery, providing a
rare resource for identifying survival-related biomarkers. A key methodological
contribution is the development of a global explanation optimizer, which
refines survival-related feature attribution in deep learning models, thereby
improving both the interpretability and reliability of predictions. From a
clinical perspective, our findings provide important evidence that survival
after oncological surgery is influenced by alterations in regions related to
cognitive and sensory functions. These results highlight the importance of
preserving areas involved in decision-making and emotional regulation to
improve long-term outcomes. From a technical perspective, the proposed
optimizer advances beyond state-of-the-art XAI methods by enhancing both the
fidelity and comprehensibility of model explanations, thus reinforcing trust in
the recognition patterns driving survival prediction. This work demonstrates
the utility of XAI-driven neuroimaging analysis in identifying survival-related
variability and underscores its potential to inform precision medicine
strategies in brain tumor treatment.},
 author = {Carmen Jimenez-Mesa and Yizhou Wan and Guilio Sansone and Francisco J. Martinez-Murcia and Javier Ramirez and Pietro Lio and Juan M. Gorriz and Stephen J. Price and John Suckling and Michail Mamalakis},
 comment = {18 pages, 6 figures},
 doi = {},
 eprint = {2507.04881v2},
 journal = {arXiv preprint},
 title = {Uncovering Neuroimaging Biomarkers of Brain Tumor Surgery with AI-Driven Methods},
 url = {http://arxiv.org/abs/2507.04881v2},
 year = {2025}
}

@article{2507.05526v1,
 abstract = {In scientific domains -- from biology to the social sciences -- many
questions boil down to \textit{What effect will we observe if we intervene on a
particular variable?} If the causal relationships (e.g.~a causal graph) are
known, it is possible to estimate the intervention distributions. In the
absence of this domain knowledge, the causal structure must be discovered from
the available observational data. However, observational data are often
compatible with multiple causal graphs, making methods that commit to a single
structure prone to overconfidence. A principled way to manage this structural
uncertainty is via Bayesian inference, which averages over a posterior
distribution on possible causal structures and functional mechanisms.
Unfortunately, the number of causal structures grows super-exponentially with
the number of nodes in the graph, making computations intractable. We propose
to circumvent these challenges by using meta-learning to create an end-to-end
model: the Model-Averaged Causal Estimation Transformer Neural Process
(MACE-TNP). The model is trained to predict the Bayesian model-averaged
interventional posterior distribution, and its end-to-end nature bypasses the
need for expensive calculations. Empirically, we demonstrate that MACE-TNP
outperforms strong Bayesian baselines. Our work establishes meta-learning as a
flexible and scalable paradigm for approximating complex Bayesian causal
inference, that can be scaled to increasingly challenging settings in the
future.},
 author = {Anish Dhir and Cristiana Diaconu and Valentinian Mihai Lungu and James Requeima and Richard E. Turner and Mark van der Wilk},
 comment = {},
 doi = {},
 eprint = {2507.05526v1},
 journal = {arXiv preprint},
 title = {Estimating Interventional Distributions with Uncertain Causal Graphs through Meta-Learning},
 url = {http://arxiv.org/abs/2507.05526v1},
 year = {2025}
}

@article{2507.06077v1,
 abstract = {This paper tackles the urgent need for efficient energy management in
healthcare facilities, where fluctuating demands challenge operational
efficiency and sustainability. Traditional methods often prove inadequate,
causing inefficiencies and higher costs. To address this, the study presents an
AI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm
(GA), and SHAP (Shapley Additive Explanations), specifically designed for
healthcare energy management. Although LSTM is widely used for time-series
forecasting, its application in healthcare energy prediction remains
underexplored. The results reveal that LSTM significantly outperforms ARIMA and
Prophet models in forecasting complex, non-linear demand patterns. LSTM
achieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE)
of 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE:
87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm
is applied to optimize model parameters and improve load balancing strategies,
enabling adaptive responses to real-time energy fluctuations. SHAP analysis
further enhances model transparency by explaining the influence of different
features on predictions, fostering trust in decision-making processes. This
integrated LSTM-GA-SHAP approach offers a robust solution for improving
forecasting accuracy, boosting energy efficiency, and advancing sustainability
in healthcare facilities. Future research may explore real-time deployment and
hybridization with reinforcement learning for continuous optimization. Overall,
the study establishes a solid foundation for using AI in healthcare energy
management, highlighting its scalability, efficiency, and resilience potential.},
 author = {Iman Rahimi and Isha Patel},
 comment = {},
 doi = {},
 eprint = {2507.06077v1},
 journal = {arXiv preprint},
 title = {AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study},
 url = {http://arxiv.org/abs/2507.06077v1},
 year = {2025}
}

@article{2507.06650v1,
 abstract = {Estimating individual-level treatment effect from observational data is a
fundamental problem in causal inference and has attracted increasing attention
in the fields of education, healthcare, and public policy.In this work, we
concentrate on the study of disentangled representation methods that have shown
promising outcomes by decomposing observed covariates into instrumental,
confounding, and adjustment factors. However, most of the previous work has
primarily revolved around generative models or hard decomposition methods for
covariates, which often struggle to guarantee the attainment of precisely
disentangled factors. In order to effectively model different causal
relationships, we propose a novel treatment effect estimation algorithm that
incorporates a mixture of experts with multi-head attention and a linear
orthogonal regularizer to softly decompose the pre-treatment variables, and
simultaneously eliminates selection bias via importance sampling re-weighting
techniques. We conduct extensive experiments on both public semi-synthetic and
real-world production datasets. The experimental results clearly demonstrate
that our algorithm outperforms the state-of-the-art methods focused on
individual treatment effects.},
 author = {Hui Meng and Keping Yang and Xuyu Peng and Bo Zheng},
 comment = {Under Review},
 doi = {},
 eprint = {2507.06650v1},
 journal = {arXiv preprint},
 title = {Deep Disentangled Representation Network for Treatment Effect Estimation},
 url = {http://arxiv.org/abs/2507.06650v1},
 year = {2025}
}

@article{2507.07271v2,
 abstract = {The Average Treatment Effect (ATE) is a foundational metric in causal
inference, widely used to assess intervention efficacy in randomized controlled
trials (RCTs). However, in many applications -- particularly in healthcare --
this static summary fails to capture the nuanced dynamics of treatment effects
that vary with both dose and time. We propose a framework for modelling
treatment effect trajectories as smooth surfaces over dose and time, enabling
the extraction of clinically actionable insights such as onset time, peak
effect, and duration of benefit. To ensure interpretability, robustness, and
verifiability -- key requirements in high-stakes domains -- we adapt
SemanticODE, a recent framework for interpretable trajectory modelling, to the
causal setting where treatment effects are never directly observed. Our
approach decouples the estimation of trajectory shape from the specification of
clinically relevant properties (e.g., maxima, inflection points), supporting
domain-informed priors, post-hoc editing, and transparent analysis. We show
that our method yields accurate, interpretable, and editable models of
treatment dynamics, facilitating both rigorous causal analysis and practical
decision-making.},
 author = {Julianna Piskorz and Krzysztof Kacprzyk and Harry Amad and Mihaela van der Schaar},
 comment = {Presented at the Actionable Interpretability Workshop at ICML 2025},
 doi = {},
 eprint = {2507.07271v2},
 journal = {arXiv preprint},
 title = {Beyond the ATE: Interpretable Modelling of Treatment Effects over Dose and Time},
 url = {http://arxiv.org/abs/2507.07271v2},
 year = {2025}
}

@article{2507.07738v1,
 abstract = {We propose a novel multi-task neural network approach for estimating
distributional treatment effects (DTE) in randomized experiments. While DTE
provides more granular insights into the experiment outcomes over conventional
methods focusing on the Average Treatment Effect (ATE), estimating it with
regression adjustment methods presents significant challenges. Specifically,
precision in the distribution tails suffers due to data imbalance, and
computational inefficiencies arise from the need to solve numerous regression
problems, particularly in large-scale datasets commonly encountered in
industry. To address these limitations, our method leverages multi-task neural
networks to estimate conditional outcome distributions while incorporating
monotonic shape constraints and multi-threshold label learning to enhance
accuracy. To demonstrate the practical effectiveness of our proposed method, we
apply our method to both simulated and real-world datasets, including a
randomized field experiment aimed at reducing water consumption in the US and a
large-scale A/B test from a leading streaming platform in Japan. The
experimental results consistently demonstrate superior performance across
various datasets, establishing our method as a robust and practical solution
for modern causal inference applications requiring a detailed understanding of
treatment effect heterogeneity.},
 author = {Tomu Hirata and Undral Byambadalai and Tatsushi Oka and Shota Yasui and Shingo Uto},
 comment = {},
 doi = {},
 eprint = {2507.07738v1},
 journal = {arXiv preprint},
 title = {Efficient and Scalable Estimation of Distributional Treatment Effects with Multi-Task Neural Networks},
 url = {http://arxiv.org/abs/2507.07738v1},
 year = {2025}
}

@article{2507.07898v1,
 abstract = {In this study, we present a novel constraint-based algorithm for causal
structure learning specifically designed for nonlinear autoregressive time
series. Our algorithm significantly reduces computational complexity compared
to existing methods, making it more efficient and scalable to larger problems.
We rigorously evaluate its performance on synthetic datasets, demonstrating
that our algorithm not only outperforms current techniques, but also excels in
scenarios with limited data availability. These results highlight its potential
for practical applications in fields requiring efficient and accurate causal
inference from nonlinear time series data.},
 author = {Mohammad Fesanghary and Achintya Gopal},
 comment = {10 pages, 8 figures},
 doi = {},
 eprint = {2507.07898v1},
 journal = {arXiv preprint},
 title = {Efficient Causal Discovery for Autoregressive Time Series},
 url = {http://arxiv.org/abs/2507.07898v1},
 year = {2025}
}

@article{2507.08235v1,
 abstract = {Smart buildings generate vast streams of sensor and control data, but
facility managers often lack clear explanations for anomalous energy usage. We
propose InsightBuild, a two-stage framework that integrates causality analysis
with a fine-tuned large language model (LLM) to provide human-readable, causal
explanations of energy consumption patterns. First, a lightweight causal
inference module applies Granger causality tests and structural causal
discovery on building telemetry (e.g., temperature, HVAC settings, occupancy)
drawn from Google Smart Buildings and Berkeley Office datasets. Next, an LLM,
fine-tuned on aligned pairs of sensor-level causes and textual explanations,
receives as input the detected causal relations and generates concise,
actionable explanations. We evaluate InsightBuild on two real-world datasets
(Google: 2017-2022; Berkeley: 2018-2020), using expert-annotated ground-truth
causes for a held-out set of anomalies. Our results demonstrate that combining
explicit causal discovery with LLM-based natural language generation yields
clear, precise explanations that assist facility managers in diagnosing and
mitigating energy inefficiencies.},
 author = {Pinaki Prasad Guha Neogi and Ahmad Mohammadshirazi and Rajiv Ramnath},
 comment = {},
 doi = {},
 eprint = {2507.08235v1},
 journal = {arXiv preprint},
 title = {InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems},
 url = {http://arxiv.org/abs/2507.08235v1},
 year = {2025}
}

@article{2507.08896v1,
 abstract = {This study introduces an integrated framework for predictive causal inference
designed to overcome limitations inherent in conventional single model
approaches. Specifically, we combine a Hidden Markov Model (HMM) for spatial
health state estimation with a Multi Task and Multi Graph Convolutional Network
(MTGCN) for capturing temporal outcome trajectories. The framework
asymmetrically treats temporal and spatial information regarding them as
endogenous variables in the outcome regression, and exogenous variables in the
propensity score model, thereby expanding the standard doubly robust treatment
effect estimation to jointly enhance bias correction and predictive accuracy.
To demonstrate its utility, we focus on clinical domains such as cancer,
dementia, and Parkinson disease, where treatment effects are challenging to
observe directly. Simulation studies are conducted to emulate latent disease
dynamics and evaluate the model performance under varying conditions. Overall,
the proposed framework advances predictive causal inference by structurally
adapting to spatiotemporal complexities common in biomedical data.},
 author = {Byunghee Lee and Hye Yeon Sin and Joonsung Kang},
 comment = {},
 doi = {},
 eprint = {2507.08896v1},
 journal = {arXiv preprint},
 title = {Predictive Causal Inference via Spatio-Temporal Modeling and Penalized Empirical Likelihood},
 url = {http://arxiv.org/abs/2507.08896v1},
 year = {2025}
}

@article{2507.09279v3,
 abstract = {Multimodal large language models (MLLMs) hold considerable promise for
applications in healthcare. However, their deployment in safety-critical
settings is hindered by two key limitations: (i) sensitivity to prompt design,
and (ii) a tendency to generate incorrect responses with high confidence. As
clinicians may rely on a model's stated confidence to gauge the reliability of
its predictions, it is especially important that when a model expresses high
confidence, it is also highly accurate. We introduce Prompt4Trust, the first
reinforcement learning (RL) framework for prompt augmentation targeting
confidence calibration in MLLMs. A lightweight LLM is trained to produce
context-aware auxiliary prompts that guide a downstream task MLLM to generate
responses in which the expressed confidence more accurately reflects predictive
accuracy. Unlike conventional calibration techniques, Prompt4Trust specifically
prioritizes aspects of calibration most critical for safe and trustworthy
clinical decision-making. Beyond improvements driven by this clinically
motivated calibration objective, our proposed method also improves task
accuracy, achieving state-of-the-art medical visual question answering (VQA)
performance on the PMC-VQA benchmark, which is composed of multiple-choice
questions spanning diverse medical imaging modalities. Moreover, our framework
trained with a small downstream task MLLM showed promising zero-shot
generalization to larger MLLMs in our experiments, suggesting the potential for
scalable calibration without the associated computational costs. This work
demonstrates the potential of automated yet human-aligned prompt engineering
for improving the the trustworthiness of MLLMs in safety critical settings. Our
codebase can be found at https://github.com/xingbpshen/prompt4trust.},
 author = {Anita Kriz and Elizabeth Laura Janes and Xing Shen and Tal Arbel},
 comment = {Accepted to ICCV 2025 Workshop CVAMD},
 doi = {},
 eprint = {2507.09279v3},
 journal = {arXiv preprint},
 title = {Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models},
 url = {http://arxiv.org/abs/2507.09279v3},
 year = {2025}
}

@article{2507.09347v1,
 abstract = {Purpose: This study introduces a novel framework for identifying and
exploiting predictive lead-lag relationships in financial markets. We propose
an integrated approach that combines advanced statistical methodologies with
machine learning models to enhance the identification and exploitation of
predictive relationships between equities. Methods: We employed a Gaussian
Mixture Model (GMM) to cluster nine prominent stocks based on their mid-range
historical volatility profiles over a three-year period. From the resulting
clusters, we constructed a multi-stage causal inference pipeline, incorporating
the Granger Causality Test (GCT), a customised Peter-Clark Momentary
Conditional Independence (PCMCI) test, and Effective Transfer Entropy (ETE) to
identify robust, predictive linkages. Subsequently, Dynamic Time Warping (DTW)
and a K-Nearest Neighbours (KNN) classifier were utilised to determine the
optimal time lag for trade execution. The resulting strategy was rigorously
backtested. Results: The proposed volatility-based trading strategy, tested
from 8 June 2023 to 12 August 2023, demonstrated substantial efficacy. The
portfolio yielded a total return of 15.38%, significantly outperforming the
10.39% return of a comparative Buy-and-Hold strategy. Key performance metrics,
including a Sharpe Ratio up to 2.17 and a win rate up to 100% for certain
pairs, confirmed the strategy's viability. Conclusion: This research
contributes a systematic and robust methodology for identifying profitable
trading opportunities derived from volatility-based causal relationships. The
findings have significant implications for both academic research in financial
modelling and the practical application of algorithmic trading, offering a
structured approach to developing resilient, data-driven strategies.},
 author = {Ivan Letteri},
 comment = {},
 doi = {},
 eprint = {2507.09347v1},
 journal = {arXiv preprint},
 title = {A Framework for Predictive Directional Trading Based on Volatility and Causal Inference},
 url = {http://arxiv.org/abs/2507.09347v1},
 year = {2025}
}

@article{2507.09439v1,
 abstract = {Understanding causal relationships in multivariate time series (MTS) is
essential for effective decision-making in fields such as finance and
marketing, where complex dependencies and lagged effects challenge conventional
analytical approaches. We introduce Dynamic Sparse Causal-Attention Temporal
Networks for Interpretable Causality Discovery in MTS (DyCAST-Net), a novel
architecture designed to enhance causal discovery by integrating dilated
temporal convolutions and dynamic sparse attention mechanisms. DyCAST-Net
effectively captures multiscale temporal dependencies through dilated
convolutions while leveraging an adaptive thresholding strategy in its
attention mechanism to eliminate spurious connections, ensuring both accuracy
and interpretability. A statistical shuffle test validation further strengthens
robustness by filtering false positives and improving causal inference
reliability. Extensive evaluations on financial and marketing datasets
demonstrate that DyCAST-Net consistently outperforms existing models such as
TCDF, GCFormer, and CausalFormer. The model provides a more precise estimation
of causal delays and significantly reduces false discoveries, particularly in
noisy environments. Moreover, attention heatmaps offer interpretable insights,
uncovering hidden causal patterns such as the mediated effects of advertising
on consumer behavior and the influence of macroeconomic indicators on financial
markets. Case studies illustrate DyCAST-Net's ability to detect latent
mediators and lagged causal factors, making it particularly effective in
high-dimensional, dynamic settings. The model's architecture enhanced by
RMSNorm stabilization and causal masking ensures scalability and adaptability
across diverse application domains},
 author = {Meriem Zerkouk and Miloud Mihoubi and Belkacem Chikhaoui},
 comment = {},
 doi = {},
 eprint = {2507.09439v1},
 journal = {arXiv preprint},
 title = {Dynamic Sparse Causal-Attention Temporal Networks for Interpretable Causality Discovery in Multivariate Time Series},
 url = {http://arxiv.org/abs/2507.09439v1},
 year = {2025}
}

@article{2507.09718v1,
 abstract = {In response to the increasing complexity of policy environments and the
proliferation of high-dimensional data, this paper introduces the S-DIDML
estimator a framework grounded in structure and semiparametrically flexible for
causal inference. By embedding Difference-in-Differences (DID) logic within a
Double Machine Learning (DML) architecture, the S-DIDML approach combines the
strengths of temporal identification, machine learning-based nuisance
adjustment, and orthogonalized estimation. We begin by identifying critical
limitations in existing methods, including the lack of structural
interpretability in ML models, instability of classical DID under
high-dimensional confounding, and the temporal rigidity of standard DML
frameworks. Building on recent advances in staggered adoption designs and
Neyman orthogonalization, S-DIDML offers a five-step estimation pipeline that
enables robust estimation of heterogeneous treatment effects (HTEs) while
maintaining interpretability and scalability. Demonstrative applications are
discussed across labor economics, education, taxation, and environmental
policy. The proposed framework contributes to the methodological frontier by
offering a blueprint for policy-relevant, structurally interpretable, and
statistically valid causal analysis in complex data settings.},
 author = {Yile Yu and Anzhi Xu},
 comment = {22 pages, 9 figures},
 doi = {},
 eprint = {2507.09718v1},
 journal = {arXiv preprint},
 title = {Bridging Structural Causal Inference and Machine Learning The S-DIDML Estimator for Heterogeneous Treatment Effects},
 url = {http://arxiv.org/abs/2507.09718v1},
 year = {2025}
}

@article{2507.09961v1,
 abstract = {Deep learning often struggles when training and test data distributions
differ. Traditional domain generalization (DG) tackles this by including data
from multiple source domains, which is impractical due to expensive data
collection and annotation. Recent vision-language models like CLIP enable
source-free domain generalization (SFDG) by using text prompts to simulate
visual representations, reducing data demands. However, existing SFDG methods
struggle with domain-specific confounders, limiting their generalization
capabilities. To address this issue, we propose TDCRL
(\textbf{T}ext-\textbf{D}riven \textbf{C}ausal \textbf{R}epresentation
\textbf{L}earning), the first method to integrate causal inference into the
SFDG setting. TDCRL operates in two steps: first, it employs data augmentation
to generate style word vectors, combining them with class information to
generate text embeddings to simulate visual representations; second, it trains
a causal intervention network with a confounder dictionary to extract
domain-invariant features. Grounded in causal learning, our approach offers a
clear and effective mechanism to achieve robust, domain-invariant features,
ensuring robust generalization. Extensive experiments on PACS, VLCS,
OfficeHome, and DomainNet show state-of-the-art performance, proving TDCRL
effectiveness in SFDG.},
 author = {Lihua Zhou and Mao Ye and Nianxin Li and Shuaifeng Li and Jinlin Wu and Xiatian Zhu and Lei Deng and Hongbin Liu and Jiebo Luo and Zhen Lei},
 comment = {Under Review},
 doi = {},
 eprint = {2507.09961v1},
 journal = {arXiv preprint},
 title = {Text-Driven Causal Representation Learning for Source-Free Domain Generalization},
 url = {http://arxiv.org/abs/2507.09961v1},
 year = {2025}
}

@article{2507.10774v2,
 abstract = {When examining a contrast between two interventions, longitudinal causal
inference studies frequently encounter positivity violations when one or both
regimes are impossible to observe for some subjects. Existing weighting methods
either assume positivity holds or produce effects that conflate interventions'
impacts on ultimate outcomes with their effects on intermediate treatments and
covariates. We propose a novel class of estimands -- cumulative cross-world
weighted effects -- that weights potential outcome differences using propensity
scores adapting to positivity violations cumulatively across timepoints and
simultaneously across both counterfactual treatment histories. This new
estimand isolates mechanistic differences between treatment regimes, is
identifiable without positivity assumptions, and circumvents the limitations of
existing longitudinal methods. Further, our analysis reveals two fundamental
insights about longitudinal causal inference under positivity violations.
First, while mechanistically meaningful, these effects correspond to
non-implementable interventions, exposing a core
interpretability-implementability tradeoff. Second, the identified effects
faithfully capture mechanistic differences only under a partial common support
assumption; violations cause the identified functional to collapse to zero,
even when the causal effect is non-zero. We develop doubly robust-style
estimators that achieve asymptotic normality and parametric convergence under
nonparametric assumptions on the nuisance estimators. To this end, we
reformulate challenging density ratio estimation as regression function
estimation, which is achievable with standard machine learning methods. We
illustrate our methods through analysis of union membership's effect on
earnings.},
 author = {Alec McClean and Iván Díaz},
 comment = {arXiv admin note: text overlap with arXiv:2506.09188},
 doi = {},
 eprint = {2507.10774v2},
 journal = {arXiv preprint},
 title = {Propensity score weighting across counterfactual worlds: longitudinal effects under positivity violations},
 url = {http://arxiv.org/abs/2507.10774v2},
 year = {2025}
}

@article{2507.10809v1,
 abstract = {Inferring causal relationships between event pairs in a temporal sequence is
applicable in many domains such as healthcare, manufacturing, and
transportation. Most existing work on causal inference primarily focuses on
event types within the designated domain, without considering the impact of
exogenous out-of-domain interventions. In real-world settings, these
out-of-domain interventions can significantly alter causal dynamics. To address
this gap, we propose a new causal framework to define average treatment effect
(ATE), beyond independent and identically distributed (i.i.d.) data in classic
Rubin's causal framework, to capture the causal relation shift between events
of temporal process under out-of-domain intervention. We design an unbiased ATE
estimator, and devise a Transformer-based neural network model to handle both
long-range temporal dependencies and local patterns while integrating
out-of-domain intervention information into process modeling. Extensive
experiments on both simulated and real-world datasets demonstrate that our
method outperforms baselines in ATE estimation and goodness-of-fit under
out-of-domain-augmented point processes.},
 author = {Kazi Tasnim Zinat and Yun Zhou and Xiang Lyu and Yawei Wang and Zhicheng Liu and Panpan Xu},
 comment = {Accepted at ICANN 2025},
 doi = {},
 eprint = {2507.10809v1},
 journal = {arXiv preprint},
 title = {Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions},
 url = {http://arxiv.org/abs/2507.10809v1},
 year = {2025}
}

@article{2507.11680v1,
 abstract = {Use of machine learning to estimate nuisance functions (e.g. outcomes models,
propensity score models) in estimators used in causal inference is increasingly
common, as it can mitigate bias due to model misspecification. However, it can
be challenging to achieve valid inference (e.g., estimate valid confidence
intervals). The efficient influence function (EIF) provides a recipe to go from
a statistical estimand relevant to our causal question, to an estimator that
can validly incorporate machine learning. Our companion paper, Renson et al.
2025 (arXiv:2502.05363), provides a thorough but approachable description of
the EIF, along with a guide through the steps to go from a unique statistical
estimand to development of one type of EIF-based estimator, the so-called
one-step estimator. Another commonly used estimator based on the EIF is the
targeted maximum likelihood/minimum loss estimator (TMLE). Construction of
TMLEs is well-discussed in the statistical literature, but there remains a gap
in translation to a more applied audience. In this letter, which supplements
Renson et al., we provide a more accessible illustration of how to construct a
TMLE.},
 author = {Rachael K. Ross and Lina M. Montoya and Dana E. Goin and Ivan Diaz and Audrey Renson},
 comment = {},
 doi = {},
 eprint = {2507.11680v1},
 journal = {arXiv preprint},
 title = {Constructing targeted minimum loss/maximum likelihood estimators: a simple illustration to build intuition},
 url = {http://arxiv.org/abs/2507.11680v1},
 year = {2025}
}

@article{2507.11780v1,
 abstract = {Constructing confidence intervals for the value of an optimal treatment
policy is an important problem in causal inference. Insight into the optimal
policy value can guide the development of reward-maximizing, individualized
treatment regimes. However, because the functional that defines the optimal
value is non-differentiable, standard semi-parametric approaches for performing
inference fail to be directly applicable. Existing approaches for handling this
non-differentiability fall roughly into two camps. In one camp are estimators
based on constructing smooth approximations of the optimal value. These
approaches are computationally lightweight, but typically place unrealistic
parametric assumptions on outcome regressions. In another camp are approaches
that directly de-bias the non-smooth objective. These approaches don't place
parametric assumptions on nuisance functions, but they either require the
computation of intractably-many nuisance estimates, assume unrealistic
$L^\infty$ nuisance convergence rates, or make strong margin assumptions that
prohibit non-response to a treatment. In this paper, we revisit the problem of
constructing smooth approximations of non-differentiable functionals. By
carefully controlling first-order bias and second-order remainders, we show
that a softmax smoothing-based estimator can be used to estimate parameters
that are specified as a maximum of scores involving nuisance components. In
particular, this includes the value of the optimal treatment policy as a
special case. Our estimator obtains $\sqrt{n}$ convergence rates, avoids
parametric restrictions/unrealistic margin assumptions, and is often
statistically efficient.},
 author = {Justin Whitehouse and Morgane Austern and Vasilis Syrgkanis},
 comment = {40 pages, 2 figures},
 doi = {},
 eprint = {2507.11780v1},
 journal = {arXiv preprint},
 title = {Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing},
 url = {http://arxiv.org/abs/2507.11780v1},
 year = {2025}
}

@article{2507.12257v1,
 abstract = {Exploring causal relationships in stochastic time series is a challenging yet
crucial task with a vast range of applications, including finance, economics,
neuroscience, and climate science. Many algorithms for Causal Discovery (CD)
have been proposed, but they often exhibit a high sensitivity to noise,
resulting in misleading causal inferences when applied to real data. In this
paper, we observe that the frequency spectra of typical real-world time series
follow a power-law distribution, notably due to an inherent self-organizing
behavior. Leveraging this insight, we build a robust CD method based on the
extraction of power -law spectral features that amplify genuine causal signals.
Our method consistently outperforms state-of-the-art alternatives on both
synthetic benchmarks and real-world datasets with known causal structures,
demonstrating its robustness and practical relevance.},
 author = {Matteo Tusoni and Giuseppe Masi and Andrea Coletta and Aldo Glielmo and Viviana Arrigoni and Novella Bartolini},
 comment = {},
 doi = {},
 eprint = {2507.12257v1},
 journal = {arXiv preprint},
 title = {Robust Causal Discovery in Real-World Time Series with Power-Laws},
 url = {http://arxiv.org/abs/2507.12257v1},
 year = {2025}
}

@article{2507.12435v1,
 abstract = {Modern deep neural networks are powerful predictive tools yet often lack
valid inference for causal parameters, such as treatment effects or entire
survival curves. While frameworks like Double Machine Learning (DML) and
Targeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,
existing neural implementations either rely on "targeted losses" that do not
guarantee solving the efficient influence function equation or computationally
expensive post-hoc "fluctuations" for multi-parameter settings. We propose
Targeted Deep Architectures (TDA), a new framework that embeds TMLE directly
into the network's parameter space with no restrictions on the backbone
architecture. Specifically, TDA partitions model parameters - freezing all but
a small "targeting" subset - and iteratively updates them along a targeting
gradient, derived from projecting the influence functions onto the span of the
gradients of the loss with respect to weights. This procedure yields plug-in
estimates that remove first-order bias and produce asymptotically valid
confidence intervals. Crucially, TDA easily extends to multi-dimensional causal
estimands (e.g., entire survival curves) by merging separate targeting
gradients into a single universal targeting update. Theoretically, TDA inherits
classical TMLE properties, including double robustness and semiparametric
efficiency. Empirically, on the benchmark IHDP dataset (average treatment
effects) and simulated survival data with informative censoring, TDA reduces
bias and improves coverage relative to both standard neural-network estimators
and prior post-hoc approaches. In doing so, TDA establishes a direct, scalable
pathway toward rigorous causal inference within modern deep architectures for
complex multi-parameter targets.},
 author = {Yi Li and David Mccoy and Nolan Gunter and Kaitlyn Lee and Alejandro Schuler and Mark van der Laan},
 comment = {},
 doi = {},
 eprint = {2507.12435v1},
 journal = {arXiv preprint},
 title = {Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks},
 url = {http://arxiv.org/abs/2507.12435v1},
 year = {2025}
}

@article{2507.13277v1,
 abstract = {Robots are increasingly integrated across industries, particularly in
healthcare. However, many valuable applications for quadrupedal robots remain
overlooked. This research explores the effectiveness of three reinforcement
learning algorithms in training a simulated quadruped robot for autonomous
navigation and obstacle avoidance. The goal is to develop a robotic guide dog
simulation capable of path following and obstacle avoidance, with long-term
potential for real-world assistance to guide dogs and visually impaired
individuals. It also seeks to expand research into medical 'pets', including
robotic guide and alert dogs.
  A comparative analysis of thirteen related research papers shaped key
evaluation criteria, including collision detection, pathfinding algorithms,
sensor usage, robot type, and simulation platforms. The study focuses on sensor
inputs, collision frequency, reward signals, and learning progression to
determine which algorithm best supports robotic navigation in complex
environments.
  Custom-made environments were used to ensure fair evaluation of all three
algorithms under controlled conditions, allowing consistent data collection.
Results show that Proximal Policy Optimization (PPO) outperformed Deep
Q-Network (DQN) and Q-learning across all metrics, particularly in average and
median steps to goal per episode.
  By analysing these results, this study contributes to robotic navigation, AI
and medical robotics, offering insights into the feasibility of AI-driven
quadruped mobility and its role in assistive robotics.},
 author = {Emma M. A. Harrison},
 comment = {},
 doi = {},
 eprint = {2507.13277v1},
 journal = {arXiv preprint},
 title = {Evaluating Reinforcement Learning Algorithms for Navigation in Simulated Robotic Quadrupeds: A Comparative Study Inspired by Guide Dog Behaviour},
 url = {http://arxiv.org/abs/2507.13277v1},
 year = {2025}
}

@article{2507.13920v1,
 abstract = {Formal frameworks of causality have operated largely parallel to modern
trends in deep reinforcement learning (RL). However, there has been a revival
of interest in formally grounding the representations learned by neural
networks in causal concepts. Yet, most attempts at neural models of causality
assume static causal graphs and ignore the dynamic nature of causal
interactions. In this work, we introduce Causal Process framework as a novel
theory for representing dynamic hypotheses about causal structure. Furthermore,
we present Causal Process Model as an implementation of this framework. This
allows us to reformulate the attention mechanism popularized by Transformer
networks within an RL setting with the goal to infer interpretable causal
processes from visual observations. Here, causal inference corresponds to
constructing a causal graph hypothesis which itself becomes an RL task nested
within the original RL problem. To create an instance of such hypothesis, we
employ RL agents. These agents establish links between units similar to the
original Transformer attention mechanism. We demonstrate the effectiveness of
our approach in an RL environment where we outperform current alternatives in
causal representation learning and agent performance, and uniquely recover
graphs of dynamic causal processes.},
 author = {Turan Orujlu and Christian Gumbsch and Martin V. Butz and Charley M Wu},
 comment = {},
 doi = {},
 eprint = {2507.13920v1},
 journal = {arXiv preprint},
 title = {Reframing attention as a reinforcement learning problem for causal discovery},
 url = {http://arxiv.org/abs/2507.13920v1},
 year = {2025}
}

@article{2507.14161v1,
 abstract = {This study integrates causal inference, graph analysis, temporal complexity
measures, and machine learning to examine whether individual symptom
trajectories can reveal meaningful diagnostic patterns. Testing on a
longitudinal dataset of N=45 individuals affected by General Anxiety Disorder
(GAD) and/or Major Depressive Disorder (MDD) derived from Fisher et al. 2017,
we propose a novel pipeline for the analysis of the temporal dynamics of
psychopathological symptoms. First, we employ the PCMCI+ algorithm with
nonparametric independence test to determine the causal network of nonlinear
dependencies between symptoms in individuals with different mental disorders.
We found that the PCMCI+ effectively highlights the individual peculiarities of
each symptom network, which could be leveraged towards personalized therapies.
At the same time, aggregating the networks by diagnosis sheds light to
disorder-specific causal mechanisms, in agreement with previous
psychopathological literature. Then, we enrich the dataset by computing
complexity-based measures (e.g. entropy, fractal dimension, recurrence) from
the symptom time series, and feed it to a suitably selected machine learning
algorithm to aid the diagnosis of each individual. The new dataset yields 91%
accuracy in the classification of the symptom dynamics, proving to be an
effective diagnostic support tool. Overall, these findings highlight how
integrating causal modeling and temporal complexity can enhance diagnostic
differentiation, offering a principled, data-driven foundation for both
personalized assessment in clinical psychology and structural advances in
psychological research.},
 author = {Eleonora Vitanza and Pietro DeLellis and Chiara Mocenni and Manuel Ruiz Marin},
 comment = {},
 doi = {},
 eprint = {2507.14161v1},
 journal = {arXiv preprint},
 title = {Complex Dynamics in Psychological Data: Mapping Individual Symptom Trajectories to Group-Level Patterns},
 url = {http://arxiv.org/abs/2507.14161v1},
 year = {2025}
}

@article{2507.14528v1,
 abstract = {In causal inference, whether through randomized controlled trials or
observational studies, access to both treated and control units is essential
for estimating the effect of a treatment on an outcome of interest. When
treatment assignment is random, the average treatment effect (ATE) can be
estimated directly by comparing outcomes between groups. In non-randomized
settings, various techniques are employed to adjust for confounding and
approximate the counterfactual scenario to recover an unbiased ATE. A common
challenge, especially in observational studies, is the absence of units clearly
labeled as controls-that is, units known not to have received the treatment. To
address this, we propose positive-unlabeled (PU) learning as a framework for
identifying, with high confidence, control units from a pool of unlabeled ones,
using only the available treated (positive) units. We evaluate this approach
using both simulated and real-world data. We construct a causal graph with
diverse relationships and use it to generate synthetic data under various
scenarios, assessing how reliably the method recovers control groups that allow
estimates of true ATE. We also apply our approach to real-world data on optimal
sowing and fertilizer treatments in sustainable agriculture. Our findings show
that PU learning can successfully identify control (negative) units from
unlabeled data based only on treated units and, through the resulting control
group, estimate an ATE that closely approximates the true value. This work has
important implications for observational causal inference, especially in fields
where randomized experiments are difficult or costly. In domains such as earth,
environmental, and agricultural sciences, it enables a plethora of
quasi-experiments by leveraging available earth observation and climate data,
particularly when treated units are available but control units are lacking.},
 author = {Ilias Tsoumas and Dimitrios Bormpoudakis and Vasileios Sitokonstantinou and Athanasios Askitopoulos and Andreas Kalogeras and Charalampos Kontoes and Ioannis Athanasiadis},
 comment = {Accepted at KDD 2025 Workshop on Causal Inference and Machine
  Learning in Practice},
 doi = {},
 eprint = {2507.14528v1},
 journal = {arXiv preprint},
 title = {Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference},
 url = {http://arxiv.org/abs/2507.14528v1},
 year = {2025}
}

@article{2507.15899v1,
 abstract = {Causal inference in observational panel data has become a central concern in
economics,policy analysis,and the broader social sciences.To address the core
contradiction where traditional difference-in-differences (DID) struggles with
high-dimensional confounding variables in observational panel data,while
machine learning (ML) lacks causal structure interpretability,this paper
proposes an innovative framework called S-DIDML that integrates structural
identification with high-dimensional estimation.Building upon the structure of
traditional DID methods,S-DIDML employs structured residual orthogonalization
techniques (Neyman orthogonality+cross-fitting) to retain the group-time
treatment effect (ATT) identification structure while resolving
high-dimensional covariate interference issues.It designs a dynamic
heterogeneity estimation module combining causal forests and semi-parametric
models to capture spatiotemporal heterogeneity effects.The framework
establishes a complete modular application process with standardized Stata
implementation paths.The introduction of S-DIDML enriches methodological
research on DID and DDML innovations, shifting causal inference from method
stacking to architecture integration.This advancement enables social sciences
to precisely identify policy-sensitive groups and optimize resource
allocation.The framework provides replicable evaluation tools, decision
optimization references,and methodological paradigms for complex intervention
scenarios such as digital transformation policies and environmental
regulations.},
 author = {Yile Yu and Anzhi Xu and Yi Wang},
 comment = {45 pages, 29 figures},
 doi = {},
 eprint = {2507.15899v1},
 journal = {arXiv preprint},
 title = {Structural DID with ML: Theory, Simulation, and a Roadmap for Applied Research},
 url = {http://arxiv.org/abs/2507.15899v1},
 year = {2025}
}

@article{2507.16467v1,
 abstract = {The field of causal inference has developed a variety of methods to
accurately estimate treatment effects in the presence of nuisance. Meanwhile,
the field of identifiability theory has developed methods like Independent
Component Analysis (ICA) to identify latent sources and mixing weights from
data. While these two research communities have developed largely
independently, they aim to achieve similar goals: the accurate and
sample-efficient estimation of model parameters. In the partially linear
regression (PLR) setting, Mackey et al. (2018) recently found that estimation
consistency can be improved with non-Gaussian treatment noise. Non-Gaussianity
is also a crucial assumption for identifying latent factors in ICA. We provide
the first theoretical and empirical insights into this connection, showing that
ICA can be used for causal effect estimation in the PLR model. Surprisingly, we
find that linear ICA can accurately estimate multiple treatment effects even in
the presence of Gaussian confounders or nonlinear nuisance.},
 author = {Patrik Reizinger and Lester Mackey and Wieland Brendel and Rahul Krishnan},
 comment = {},
 doi = {},
 eprint = {2507.16467v1},
 journal = {arXiv preprint},
 title = {Estimating Treatment Effects with Independent Component Analysis},
 url = {http://arxiv.org/abs/2507.16467v1},
 year = {2025}
}

@article{2507.16722v1,
 abstract = {We use causal inference to study how designing ballots with and without party
designations impacts electoral outcomes when partisan voters rely on
party-order cues to infer candidate affiliation in races without designations.
If the party orders of candidates in races with and without party designations
differ, these voters might cast their votes incorrectly. We identify a
quasi-randomized natural experiment with contest-level treatment assignment
pertaining to North Carolina judicial elections and use double machine learning
to accurately capture the magnitude of such incorrectly cast votes. Using
precinct-level election and demographic data, we estimate that 11.8% (95%
confidence interval: [4.0%, 19.6%]) of democratic partisan voters and 15.4%
(95% confidence interval: [7.8%, 23.1%]) of republican partisan voters cast
their votes incorrectly due to the difference in party orders. Our results
indicate that ballots mixing contests with and without party designations
mislead many voters, leading to outcomes that do not reflect true voter
preferences. To accurately capture voter intent, such ballot designs should be
avoided.},
 author = {Alessandro Arlotto and Alexandre Belloni and Fei Fang and Saša Pekeč},
 comment = {27 pages, 4 figures},
 doi = {},
 eprint = {2507.16722v1},
 journal = {arXiv preprint},
 title = {Ballot Design and Electoral Outcomes: The Role of Candidate Order and Party Affiliation},
 url = {http://arxiv.org/abs/2507.16722v1},
 year = {2025}
}

@article{2507.17070v1,
 abstract = {Recent advancements in Deep Reinforcement Learning (DRL) have demonstrated
its applicability across various domains, including robotics, healthcare,
energy optimization, and autonomous driving. However, a critical question
remains: How robust are DRL models when exposed to adversarial attacks? While
existing defense mechanisms such as adversarial training and distillation
enhance the resilience of DRL models, there remains a significant research gap
regarding the integration of multiple defenses in autonomous driving scenarios
specifically. This paper addresses this gap by proposing a novel ensemble-based
defense architecture to mitigate adversarial attacks in autonomous driving. Our
evaluation demonstrates that the proposed architecture significantly enhances
the robustness of DRL models. Compared to the baseline under FGSM attacks, our
ensemble method improves the mean reward from 5.87 to 18.38 (over 213%
increase) and reduces the mean collision rate from 0.50 to 0.09 (an 82%
decrease) in the highway scenario and merge scenario, outperforming all
standalone defense strategies.},
 author = {Adithya Mohan and Dominik Rößle and Daniel Cremers and Torsten Schön},
 comment = {6 pages, 4 figures, 2 tables},
 doi = {},
 eprint = {2507.17070v1},
 journal = {arXiv preprint},
 title = {Advancing Robustness in Deep Reinforcement Learning with an Ensemble Defense Approach},
 url = {http://arxiv.org/abs/2507.17070v1},
 year = {2025}
}

@article{2507.17686v3,
 abstract = {Previous studies have shown that hazard ratios between treatment groups
estimated with the Cox model are uninterpretable because the unspecified
baseline hazard of the model fails to identify temporal change in the risk set
composition due to treatment assignment and unobserved factors among multiple,
contradictory scenarios. To alleviate this problem, especially in studies based
on observational data with uncontrolled dynamic treatment and real-time
measurement of many covariates, we propose abandoning the baseline hazard and
using kernel-based machine learning to explicitly model the change in the risk
set with or without latent variables. For this framework, we clarify the
context in which hazard ratios can be causally interpreted, and then develop a
method based on Neyman orthogonality to compute debiased maximum-likelihood
estimators of hazard ratios, proving necessary convergence results. Numerical
simulations confirm that the proposed method identifies the true hazard ratios
with minimal bias. These results lay the foundation for developing a useful,
alternative method for causal inference with uncontrolled, observational data
in modern epidemiology.},
 author = {Takashi Hayakawa and Satoshi Asai},
 comment = {Proposition 3 of the first version was wrong. This was fixed by
  introducing new theoretical results in the second version so that all of the
  claims of the first version are valid For some reason, in the uploading of
  the second version, a duplicate of the first version was wrongly publicized,
  which we think is not our mistake. We therefore upload the updated version as
  version 3},
 doi = {},
 eprint = {2507.17686v3},
 journal = {arXiv preprint},
 title = {Debiased maximum-likelihood estimators for hazard ratios under kernel-based machine-learning adjustment},
 url = {http://arxiv.org/abs/2507.17686v3},
 year = {2025}
}

@article{2507.18118v1,
 abstract = {A/B testing is widely used in modern technology companies for policy
evaluation and product deployment, with the goal of comparing the outcomes
under a newly-developed policy against a standard control. Various causal
inference and reinforcement learning methods developed in the literature are
applicable to A/B testing. This paper introduces a two-armed bandit framework
designed to improve the power of existing approaches. The proposed procedure
consists of three main steps: (i) employing doubly robust estimation to
generate pseudo-outcomes, (ii) utilizing a two-armed bandit framework to
construct the test statistic, and (iii) applying a permutation-based method to
compute the $p$-value. We demonstrate the efficacy of the proposed method
through asymptotic theories, numerical experiments and real-world data from a
ridesharing company, showing its superior performance in comparison to existing
methods.},
 author = {Jinjuan Wang and Qianglin Wen and Yu Zhang and Xiaodong Yan and Chengchun Shi},
 comment = {},
 doi = {},
 eprint = {2507.18118v1},
 journal = {arXiv preprint},
 title = {A Two-armed Bandit Framework for A/B Testing},
 url = {http://arxiv.org/abs/2507.18118v1},
 year = {2025}
}

@article{2507.18557v2,
 abstract = {Predicting whether a molecule can cross the blood-brain barrier (BBB) is a
key step in early-stage neuropharmaceutical development, directly influencing
both research efficiency and success rates in drug discovery. Traditional
empirical methods based on physicochemical properties are prone to systematic
misjudgements due to their reliance on static rules. Early machine learning
models, although data-driven, often suffer from limited capacity, poor
generalization, and insufficient interpretability. In recent years, artificial
intelligence (AI) methods have become essential tools for predicting BBB
permeability and guiding related drug design, owing to their ability to model
molecular structures and capture complex biological mechanisms. This article
systematically reviews the evolution of this field-from deep neural networks to
graph-based structural modeling-highlighting the advantages of multi-task and
multimodal learning strategies in identifying mechanism-relevant variables. We
further explore the emerging potential of generative models and causal
inference methods for integrating permeability prediction with mechanism-aware
drug design. BBB modeling is in the transition from static classification
toward mechanistic perception and structure-function modeling. This paradigm
shift provides a methodological foundation and future roadmap for the
integration of AI into neuropharmacological development.},
 author = {Zihan Yang},
 comment = {Author list updated to reflect current contribution},
 doi = {},
 eprint = {2507.18557v2},
 journal = {arXiv preprint},
 title = {Deep Learning for Blood-Brain Barrier Permeability Prediction},
 url = {http://arxiv.org/abs/2507.18557v2},
 year = {2025}
}

@article{2507.19413v2,
 abstract = {The application of semiparametric efficient estimators, particularly those
that leverage machine learning, is rapidly expanding within epidemiology and
causal inference. This literature is increasingly invoking the Riesz
representation theorem and Riesz regression. This paper aims to introduce the
Riesz representation theorem to an epidemiologic audience, explaining what it
is and why it's useful, using step-by-step worked examples.},
 author = {Nicholas T. Williams and Oliver J. Hines and Kara E. Rudolph},
 comment = {},
 doi = {},
 eprint = {2507.19413v2},
 journal = {arXiv preprint},
 title = {Riesz representers for the rest of us},
 url = {http://arxiv.org/abs/2507.19413v2},
 year = {2025}
}

@article{2507.19657v1,
 abstract = {The development of next-generation networking systems has inherently shifted
from throughput-based paradigms towards intelligent, information-aware designs
that emphasize the quality, relevance, and utility of transmitted information,
rather than sheer data volume. While classical network metrics, such as latency
and packet loss, remain significant, they are insufficient to quantify the
nuanced information quality requirements of modern intelligent applications,
including autonomous vehicles, digital twins, and metaverse environments. In
this survey, we present the first comprehensive study of the ``X of
Information'' continuum by introducing a systematic four-dimensional taxonomic
framework that structures information metrics along temporal, quality/utility,
reliability/robustness, and network/communication dimensions. We uncover the
increasing interdependencies among these dimensions, whereby temporal freshness
triggers quality evaluation, which in turn helps with reliability appraisal,
ultimately enabling effective network delivery. Our analysis reveals that
artificial intelligence technologies, such as deep reinforcement learning,
multi-agent systems, and neural optimization models, enable adaptive,
context-aware optimization of competing information quality objectives. In our
extensive study of six critical application domains, covering autonomous
transportation, industrial IoT, healthcare digital twins, UAV communications,
LLM ecosystems, and metaverse settings, we illustrate the revolutionary promise
of multi-dimensional information metrics for meeting diverse operational needs.
Our survey identifies prominent implementation challenges, including ...},
 author = {Beining Wu and Jun Huang and Shui Yu},
 comment = {48 pages, 14 figures, submitted to IEEE},
 doi = {},
 eprint = {2507.19657v1},
 journal = {arXiv preprint},
 title = {"X of Information'' Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems},
 url = {http://arxiv.org/abs/2507.19657v1},
 year = {2025}
}

@article{2507.20068v1,
 abstract = {Off-policy evaluation (OPE) methods aim to estimate the value of a new
reinforcement learning (RL) policy prior to deployment. Recent advances have
shown that leveraging auxiliary datasets, such as those synthesized by
generative models, can improve the accuracy of these value estimates.
Unfortunately, such auxiliary datasets may also be biased, and existing methods
for using data augmentation for OPE in RL lack principled uncertainty
quantification. In high stakes settings like healthcare, reliable uncertainty
estimates are important for comparing policy value estimates. In this work, we
propose two approaches to construct valid confidence intervals for OPE when
using data augmentation. The first provides a confidence interval over the
policy performance conditioned on a particular initial state $V^{\pi}(s_0)$--
such intervals are particularly important for human-centered applications. To
do so we introduce a new conformal prediction method for high dimensional state
MDPs. Second, we consider the more common task of estimating the average policy
performance over many initial states; to do so we draw on ideas from doubly
robust estimation and prediction powered inference. Across simulators spanning
robotics, healthcare and inventory management, and a real healthcare dataset
from MIMIC-IV, we find that our methods can use augmented data and still
consistently produce intervals that cover the ground truth values, unlike
previously proposed methods.},
 author = {Aishwarya Mandyam and Jason Meng and Ge Gao and Jiankai Sun and Mac Schwager and Barbara E. Engelhardt and Emma Brunskill},
 comment = {},
 doi = {},
 eprint = {2507.20068v1},
 journal = {arXiv preprint},
 title = {PERRY: Policy Evaluation with Confidence Intervals using Auxiliary Data},
 url = {http://arxiv.org/abs/2507.20068v1},
 year = {2025}
}

@article{2507.20993v1,
 abstract = {Existing methods for estimating personalized treatment effects typically rely
on structured covariates, limiting their applicability to unstructured data.
Yet, leveraging unstructured data for causal inference has considerable
application potential, for instance in healthcare, where clinical notes or
medical images are abundant. To this end, we first introduce an approximate
'plug-in' method trained directly on the neural representations of unstructured
data. However, when these fail to capture all confounding information, the
method may be subject to confounding bias. We therefore introduce two
theoretically grounded estimators that leverage structured measurements of the
confounders during training, but allow estimating personalized treatment
effects purely from unstructured inputs, while avoiding confounding bias. When
these structured measurements are only available for a non-representative
subset of the data, these estimators may suffer from sampling bias. To address
this, we further introduce a regression-based correction that accounts for the
non-uniform sampling, assuming the sampling mechanism is known or can be
well-estimated. Our experiments on two benchmark datasets show that the plug-in
method, directly trainable on large unstructured datasets, achieves strong
empirical performance across all settings, despite its simplicity.},
 author = {Henri Arno and Thomas Demeester},
 comment = {},
 doi = {},
 eprint = {2507.20993v1},
 journal = {arXiv preprint},
 title = {Personalized Treatment Effect Estimation from Unstructured Data},
 url = {http://arxiv.org/abs/2507.20993v1},
 year = {2025}
}

@article{2507.22565v1,
 abstract = {The tension between data privacy and model utility has become the defining
bottleneck for the practical deployment of large language models (LLMs) trained
on sensitive corpora including healthcare. Differentially private stochastic
gradient descent (DP-SGD) guarantees formal privacy, yet it does so at a
pronounced cost: gradients are forcibly clipped and perturbed with noise,
degrading sample efficiency and final accuracy. Numerous variants have been
proposed to soften this trade-off, but they all share a handicap: their control
knobs are hard-coded, global, and oblivious to the evolving optimization
landscape. Consequently, practitioners are forced either to over-spend privacy
budget in pursuit of utility, or to accept mediocre models in order to stay
within privacy constraints. We present RLDP, the first framework to cast DP
optimization itself as a closed-loop control problem amenable to modern deep
reinforcement learning (RL). RLDP continuously senses rich statistics of the
learning dynamics and acts by selecting fine-grained per parameter
gradient-clipping thresholds as well as the magnitude of injected Gaussian
noise. A soft actor-critic (SAC) hyper-policy is trained online during language
model fine-tuning; it learns, from scratch, how to allocate the privacy budget
where it matters and when it matters. Across more than 1,600 ablation
experiments on GPT2-small, Llama-1B, Llama-3B, and Mistral-7B, RLDP delivers
perplexity reductions of 1.3-30.5% (mean 5.4%) and an average 5.6% downstream
utility gain. RLDP reaches each baseline's final utility after only 13-43% of
the gradient-update budget (mean speed-up 71%), all while honoring the same
($\epsilon$, $\delta$)-DP contract and exhibiting equal or lower susceptibility
to membership-inference and canary-extraction attacks.},
 author = {Afshin Khadangi and Amir Sartipi and Igor Tchappi and Ramin Bahmani and Gilbert Fridgen},
 comment = {},
 doi = {},
 eprint = {2507.22565v1},
 journal = {arXiv preprint},
 title = {Efficient Differentially Private Fine-Tuning of LLMs via Reinforcement Learning},
 url = {http://arxiv.org/abs/2507.22565v1},
 year = {2025}
}

@article{2507.22940v2,
 abstract = {We present a novel framework addressing a critical vulnerability in Large
Language Models (LLMs): the prevalence of factual inaccuracies within
intermediate reasoning steps despite correct final answers. This phenomenon
poses substantial risks in high-stakes domains including healthcare, legal
analysis, and scientific research, where erroneous yet confidently presented
reasoning can mislead users into dangerous decisions. Our framework integrates
three core components: (1) a specialized fact-checking classifier trained on
counterfactually augmented data to detect subtle factual inconsistencies within
reasoning chains; (2) an enhanced Group Relative Policy Optimization (GRPO)
reinforcement learning approach that balances factuality, coherence, and
structural correctness through multi-dimensional rewards; and (3) a mechanistic
interpretability method examining how factuality improvements manifest in model
activations during reasoning processes. Extensive evaluation across multi
state-of-the-art models reveals concerning patterns: even leading models like
Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of only 81.93% and
82.57% respectively. Our approach significantly enhances factual robustness (up
to 49.90% improvement) while maintaining or improving performance on
challenging benchmarks including Math-500, AIME-2024, and GPQA. Furthermore,
our neural activation-level analysis provides actionable insights into how
factual enhancements reshape reasoning trajectories within model architectures,
establishing foundations for future training methodologies that explicitly
target factual robustness through activation-guided optimization.},
 author = {Rui Jiao and Yue Zhang and Jinku Li},
 comment = {},
 doi = {},
 eprint = {2507.22940v2},
 journal = {arXiv preprint},
 title = {Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes},
 url = {http://arxiv.org/abs/2507.22940v2},
 year = {2025}
}

@article{2507.23495v1,
 abstract = {Practitioners making decisions based on causal effects typically ignore
structural uncertainty. We analyze when this uncertainty is consequential
enough to warrant methodological solutions (Bayesian model averaging over
competing causal structures). Focusing on bivariate relationships ($X
\rightarrow Y$ vs. $X \leftarrow Y$), we establish that model averaging is
beneficial when: (1) structural uncertainty is moderate to high, (2) causal
effects differ substantially between structures, and (3) loss functions are
sufficiently sensitive to the size of the causal effect. We prove optimality
results of our suggested methodological solution under regularity conditions
and demonstrate through simulations that modern causal discovery methods can
provide, within limits, the necessary quantification. Our framework complements
existing robust causal inference approaches by addressing a distinct source of
uncertainty typically overlooked in practice.},
 author = {Maurits Kaptein},
 comment = {This work is under review at the Journal of Causal Inference},
 doi = {},
 eprint = {2507.23495v1},
 journal = {arXiv preprint},
 title = {Incorporating structural uncertainty in causal decision making},
 url = {http://arxiv.org/abs/2507.23495v1},
 year = {2025}
}

@article{2507.23644v1,
 abstract = {Agent-based simulations have an enormous potential as tools to evaluate
social policies in a non-invasive way, before these are implemented to
real-world populations. However, the recommendations that these computational
approaches may offer to tackle urgent human development challenges can vary
substantially depending on how we model agents' (people) behaviour and the
criteria that we use to measure inequity. In this paper, we integrate the
conceptual framework of the capability approach (CA), which is explicitly
designed to promote and assess human well-being, to guide the simulation and
evaluate the effectiveness of policies. We define a reinforcement learning
environment where agents behave to restore their capabilities under the
constraints of a specific policy. Working in collaboration with local
stakeholders, non-profits and domain experts, we apply our model in a case
study to mitigate health inequity among the population experiencing
homelessness (PEH) in Barcelona. By doing so, we present the first proof of
concept simulation, aligned with the CA for human development, to assess the
impact of policies under parliamentary discussion.},
 author = {Alba Aguilera and Georgina Curto and Nardine Osman},
 comment = {},
 doi = {},
 eprint = {2507.23644v1},
 journal = {arXiv preprint},
 title = {Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity},
 url = {http://arxiv.org/abs/2507.23644v1},
 year = {2025}
}

@article{2508.00270v1,
 abstract = {We present an online tutoring system that learns to provide effective
feedback to students after they answer questions incorrectly. Using data from
one million students, the system learns which assistance action (e.g., one of
multiple hints) to provide for each question to optimize student learning.
Employing the multi-armed bandit (MAB) framework and offline policy evaluation,
we assess 43,000 assistance actions, and identify trade-offs between assistance
policies optimized for different student outcomes (e.g., response correctness,
session completion). We design an algorithm that for each question decides on a
suitable policy training objective to enhance students' immediate second
attempt success and overall practice session performance. We evaluate the
resulting MAB policies in 166,000 practice sessions, verifying significant
improvements in student outcomes. While MAB policies optimize feedback for the
overall student population, we further investigate whether contextual bandit
(CB) policies can enhance outcomes by personalizing feedback based on
individual student features (e.g., ability estimates, response times). Using
causal inference, we examine (i) how effects of assistance actions vary across
students and (ii) whether CB policies, which leverage such effect
heterogeneity, outperform MAB policies. While our analysis reveals that some
actions for some questions exhibit effect heterogeneity, effect sizes may often
be too small for CB policies to provide significant improvements beyond what
well-optimized MAB policies that deliver the same action to all students
already achieve. We discuss insights gained from deploying data-driven systems
at scale and implications for future refinements. Today, the teaching policies
optimized by our system support thousands of students daily.},
 author = {Robin Schmucker and Nimish Pachapurkar and Shanmuga Bala and Miral Shah and Tom Mitchell},
 comment = {},
 doi = {},
 eprint = {2508.00270v1},
 journal = {arXiv preprint},
 title = {Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring},
 url = {http://arxiv.org/abs/2508.00270v1},
 year = {2025}
}

@article{2508.01018v1,
 abstract = {Machine learning has revitalized causal inference by combining flexible
models and principled estimators, yet robust benchmarking and evaluation remain
challenging with real-world data. In this work, we introduce frengression, a
deep generative realization of the frugal parameterization that models the
joint distribution of covariates, treatments and outcomes around the causal
margin of interest. Frengression provides accurate estimation and flexible,
faithful simulation of multivariate, time-varying data; it also enables direct
sampling from user-specified interventional distributions. Model consistency
and extrapolation guarantees are established, with validation on real-world
clinical trial data demonstrating frengression's practical utility. We envision
this framework sparking new research into generative approaches for causal
margin modelling.},
 author = {Linying Yang and Robin J. Evans and Xinwei Shen},
 comment = {},
 doi = {},
 eprint = {2508.01018v1},
 journal = {arXiv preprint},
 title = {Frugal, Flexible, Faithful: Causal Data Simulation via Frengression},
 url = {http://arxiv.org/abs/2508.01018v1},
 year = {2025}
}

@article{2508.01341v1,
 abstract = {Machine learning models trained on Earth observation data, such as satellite
imagery, have demonstrated significant promise in predicting household-level
wealth indices, enabling the creation of high-resolution wealth maps that can
be leveraged across multiple causal trials. However, because standard training
objectives prioritize overall predictive accuracy, these predictions inherently
suffer from shrinkage toward the mean, leading to attenuated estimates of
causal treatment effects and limiting their utility in policy. Existing
debiasing methods, such as Prediction-Powered Inference, can handle this
attenuation bias but require additional fresh ground-truth data at the
downstream stage of causal inference, which restricts their applicability in
data-scarce environments. Here, we introduce and evaluate two correction
methods -- linear calibration correction and Tweedie's correction -- that
substantially reduce prediction bias without relying on newly collected labeled
data. Linear calibration corrects bias through a straightforward linear
transformation derived from held-out calibration data, whereas Tweedie's
correction leverages empirical Bayes principles to directly address
shrinkage-induced biases by exploiting score functions derived from the model's
learning patterns. Through analytical exercises and experiments using
Demographic and Health Survey data, we demonstrate that the proposed methods
meet or outperform existing approaches that either require (a) adjustments to
training pipelines or (b) additional labeled data. These approaches may
represent a promising avenue for improving the reliability of causal inference
when direct outcome measures are limited or unavailable, enabling a "one map,
many trials" paradigm where a single upstream data creation team produces
predictions usable by many downstream teams across diverse ML pipelines.},
 author = {Markus Pettersson and Connor T. Jerzak and Adel Daoud},
 comment = {31 pages},
 doi = {},
 eprint = {2508.01341v1},
 journal = {arXiv preprint},
 title = {Debiasing Machine Learning Predictions for Causal Inference Without Additional Ground Truth Data: "One Map, Many Trials" in Satellite-Driven Poverty Analysis},
 url = {http://arxiv.org/abs/2508.01341v1},
 year = {2025}
}

@article{2508.01865v1,
 abstract = {Recent developments in causal inference have greatly shifted the interest
from estimating the average treatment effect to the individual treatment
effect. In this article, we improve the predictive accuracy of representation
learning and adversarial networks in estimating individual treatment effects by
introducing a structure keeper which maintains the correlation between the
baseline covariates and their corresponding representations in the high
dimensional space. We train a discriminator at the end of representation layers
to trade off representation balance and information loss. We show that the
proposed discriminator minimizes an upper bound of the treatment estimation
error. We can address the tradeoff between distribution balance and information
loss by considering the correlations between the learned representation space
and the original covariate feature space. We conduct extensive experiments with
simulated and real-world observational data to show that our proposed Structure
Maintained Representation Learning (SMRL) algorithm outperforms
state-of-the-art methods. We also demonstrate the algorithms on real electronic
health record data from the MIMIC-III database.},
 author = {Yang Sun and Wenbin Lu and Yi-Hui Zhou},
 comment = {},
 doi = {},
 eprint = {2508.01865v1},
 journal = {arXiv preprint},
 title = {Structure Maintained Representation Learning Neural Network for Causal Inference},
 url = {http://arxiv.org/abs/2508.01865v1},
 year = {2025}
}

@article{2508.02524v1,
 abstract = {Causal analysis helps us understand variables that are responsible for system
failures. This improves fault detection and makes system more reliable. In this
work, we present a new method that combines causal inference with machine
learning to classify faults in electrical distribution systems (EDS) using
graph-based models. We first build causal graphs using transfer entropy (TE).
Each fault case is represented as a graph, where the nodes are features such as
voltage and current, and the edges demonstrate how these features influence
each other. Then, the graphs are classified using machine learning and
GraphSAGE where the model learns from both the node values and the structure of
the graph to predict the type of fault. To make the predictions understandable,
we further developed an integrated approach using GNNExplainer and Captums
Integrated Gradients to highlight the nodes (features) that influences the most
on the final prediction. This gives us clear insights into the possible causes
of the fault. Our experiments show high accuracy: 99.44% on the EDS fault
dataset, which is better than state of art models. By combining causal graphs
with machine learning, our method not only predicts faults accurately but also
helps understand their root causes. This makes it a strong and practical tool
for improving system reliability.},
 author = {Karthik Peddi and Sai Ram Aditya Parisineni and Hemanth Macharla and Mayukha Pal},
 comment = {},
 doi = {},
 eprint = {2508.02524v1},
 journal = {arXiv preprint},
 title = {Causality and Interpretability for Electrical Distribution System faults},
 url = {http://arxiv.org/abs/2508.02524v1},
 year = {2025}
}

@article{2508.03875v1,
 abstract = {Managing physiological variables within clinically safe target zones is a
central challenge in healthcare, particularly for chronic conditions such as
Type 1 Diabetes Mellitus (T1DM). Reinforcement learning (RL) offers promise for
personalising treatment, but struggles with the delayed and heterogeneous
effects of interventions. We propose a novel RL framework to study and support
decision-making in T1DM technologies, such as automated insulin delivery. Our
approach captures the complex temporal dynamics of treatment by unifying two
control modalities: \textit{impulse control} for discrete, fast-acting
interventions (e.g., insulin boluses), and \textit{switching control} for
longer-acting treatments and regime shifts. The core of our method is a
constrained Markov decision process augmented with physiological state
features, enabling safe policy learning under clinical and resource
constraints. The framework incorporates biologically realistic factors,
including insulin decay, leading to policies that better reflect real-world
therapeutic behaviour. While not intended for clinical deployment, this work
establishes a foundation for future safe and temporally-aware RL in healthcare.
We provide theoretical guarantees of convergence and demonstrate empirical
improvements in a stylised T1DM control task, reducing blood glucose level
violations from 22.4\% (state-of-the-art) to as low as 10.8\%.},
 author = {David H. Mguni and Jing Dong and Wanrong Yang and Ziquan Liu and Muhammad Salman Haleem and Baoxiang Wang},
 comment = {},
 doi = {},
 eprint = {2508.03875v1},
 journal = {arXiv preprint},
 title = {Reinforcement Learning for Target Zone Blood Glucose Control},
 url = {http://arxiv.org/abs/2508.03875v1},
 year = {2025}
}

@article{2508.04216v1,
 abstract = {External reasoning systems combine language models with process reward models
(PRMs) to select high-quality reasoning paths for complex tasks such as
mathematical problem solving. However, these systems are prone to reward
hacking, where high-scoring but logically incorrect paths are assigned high
scores by the PRMs, leading to incorrect answers. From a causal inference
perspective, we attribute this phenomenon primarily to the presence of
confounding semantic features. To address it, we propose Causal Reward
Adjustment (CRA), a method that mitigates reward hacking by estimating the true
reward of a reasoning path. CRA trains sparse autoencoders on the PRM's
internal activations to recover interpretable features, then corrects
confounding by using backdoor adjustment. Experiments on math solving datasets
demonstrate that CRA mitigates reward hacking and improves final accuracy,
without modifying the policy model or retraining PRM.},
 author = {Ruike Song and Zeen Song and Huijie Guo and Wenwen Qiang},
 comment = {},
 doi = {},
 eprint = {2508.04216v1},
 journal = {arXiv preprint},
 title = {Causal Reward Adjustment: Mitigating Reward Hacking in External Reasoning via Backdoor Correction},
 url = {http://arxiv.org/abs/2508.04216v1},
 year = {2025}
}

@article{2508.06337v1,
 abstract = {Feature importance (FI) statistics provide a prominent and valuable method of
insight into the decision process of machine learning (ML) models, but their
effectiveness has well-known limitations when correlation is present among the
features in the training data. In this case, the FI often tends to be
distributed among all features which are in correlation with the
response-generating signal features. Even worse, if multiple signal features
are in strong correlation with a noise feature, while being only modestly
correlated with one another, this can result in a noise feature having a
distinctly larger FI score than any signal feature. Here we propose local
sample weighting (losaw) which can flexibly be integrated into many ML
algorithms to improve FI scores in the presence of feature correlation in the
training data. Our approach is motivated from inverse probability weighting in
causal inference and locally, within the ML model, uses a sample weighting
scheme to decorrelate a target feature from the remaining features. This
reduces model bias locally, whenever the effect of a potential signal feature
is evaluated and compared to others. Moreover, losaw comes with a natural
tuning parameter, the minimum effective sample size of the weighted population,
which corresponds to an interpretation-prediction-tradeoff, analog to a
bias-variance-tradeoff as for classical ML tuning parameters. We demonstrate
how losaw can be integrated within decision tree-based ML methods and within
mini-batch training of neural networks. We investigate losaw for random forest
and convolutional neural networks in a simulation study on settings showing
diverse correlation patterns. We found that losaw improves FI consistently.
Moreover, it often improves prediction accuracy for out-of-distribution, while
maintaining a similar accuracy for in-distribution test data.},
 author = {Benedikt Fröhlich and Alison Durst and Merle Behr},
 comment = {},
 doi = {},
 eprint = {2508.06337v1},
 journal = {arXiv preprint},
 title = {Decorrelated feature importance from local sample weighting},
 url = {http://arxiv.org/abs/2508.06337v1},
 year = {2025}
}

@article{2508.07221v1,
 abstract = {Estimating individualized treatment effects from observational data presents
a persistent challenge due to unmeasured confounding and structural bias.
Causal Machine Learning (causal ML) methods, such as causal trees and doubly
robust estimators, provide tools for estimating conditional average treatment
effects. These methods have limited effectiveness in complex real-world
environments due to the presence of latent confounders or those described in
unstructured formats. Moreover, reliance on domain experts for confounder
identification and rule interpretation introduces high annotation cost and
scalability concerns. In this work, we proposed Large Language Model-based
agents for automated confounder discovery and subgroup analysis that integrate
agents into the causal ML pipeline to simulate domain expertise. Our framework
systematically performs subgroup identification and confounding structure
discovery by leveraging the reasoning capabilities of LLM-based agents, which
reduces human dependency while preserving interpretability. Experiments on
real-world medical datasets show that our proposed approach enhances treatment
effect estimation robustness by narrowing confidence intervals and uncovering
unrecognized confounding biases. Our findings suggest that LLM-based agents
offer a promising path toward scalable, trustworthy, and semantically aware
causal inference.},
 author = {Po-Han Lee and Yu-Cheng Lin and Chan-Tung Ku and Chan Hsu and Pei-Cing Huang and Ping-Hsun Wu and Yihuang Kang},
 comment = {},
 doi = {},
 eprint = {2508.07221v1},
 journal = {arXiv preprint},
 title = {LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference},
 url = {http://arxiv.org/abs/2508.07221v1},
 year = {2025}
}

@article{2508.08752v1,
 abstract = {We propose a novel method for sensitivity analysis to unobserved confounding
in causal inference. The method builds on a copula-based causal graphical
normalizing flow that we term $\rho$-GNF, where $\rho \in [-1,+1]$ is the
sensitivity parameter. The parameter represents the non-causal association
between exposure and outcome due to unobserved confounding, which is modeled as
a Gaussian copula. In other words, the $\rho$-GNF enables scholars to estimate
the average causal effect (ACE) as a function of $\rho$, accounting for various
confounding strengths. The output of the $\rho$-GNF is what we term the
$\rho_{curve}$, which provides the bounds for the ACE given an interval of
assumed $\rho$ values. The $\rho_{curve}$ also enables scholars to identify the
confounding strength required to nullify the ACE. We also propose a Bayesian
version of our sensitivity analysis method. Assuming a prior over the
sensitivity parameter $\rho$ enables us to derive the posterior distribution
over the ACE, which enables us to derive credible intervals. Finally,
leveraging on experiments from simulated and real-world data, we show the
benefits of our sensitivity analysis method.},
 author = {Sourabh Balgi and Marc Braun and Jose M. Peña and Adel Daoud},
 comment = {},
 doi = {},
 eprint = {2508.08752v1},
 journal = {arXiv preprint},
 title = {Sensitivity Analysis to Unobserved Confounding with Copula-based Normalizing Flows},
 url = {http://arxiv.org/abs/2508.08752v1},
 year = {2025}
}

@article{2508.08883v1,
 abstract = {Causal machine learning has the potential to revolutionize decision-making by
combining the predictive power of machine learning algorithms with the theory
of causal inference. However, these methods remain underutilized by the broader
machine learning community, in part because current empirical evaluations do
not permit assessment of their reliability and robustness, undermining their
practical utility. Specifically, one of the principal criticisms made by the
community is the extensive use of synthetic experiments. We argue, on the
contrary, that synthetic experiments are essential and necessary to precisely
assess and understand the capabilities of causal machine learning methods. To
substantiate our position, we critically review the current evaluation
practices, spotlight their shortcomings, and propose a set of principles for
conducting rigorous empirical analyses with synthetic data. Adopting the
proposed principles will enable comprehensive evaluations that build trust in
causal machine learning methods, driving their broader adoption and impactful
real-world use.},
 author = {Audrey Poinsot and Panayiotis Panayiotou and Alessandro Leite and Nicolas Chesneau and Özgür Şimşek and Marc Schoenauer},
 comment = {Accepted at ICML 2025},
 doi = {},
 eprint = {2508.08883v1},
 journal = {arXiv preprint},
 title = {Position: Causal Machine Learning Requires Rigorous Synthetic Experiments for Broader Adoption},
 url = {http://arxiv.org/abs/2508.08883v1},
 year = {2025}
}

@article{2508.09096v1,
 abstract = {Knowledge management (KM) is vital in the process industry for optimizing
operations, ensuring safety, and enabling continuous improvement through
effective use of operational data and past insights. A key challenge in this
domain is the fragmented nature of event logs in shift books, where related
records, e.g., entries documenting issues related to equipment or processes and
the corresponding solutions, may remain disconnected. This fragmentation
hinders the recommendation of previous solutions to the users. To address this
problem, we investigate record linking (RL) as link prediction, commonly
studied in graph-based machine learning, by framing it as a cross-document
coreference resolution (CDCR) task enhanced with natural language inference
(NLI) and semantic text similarity (STS) by shifting it into the causal
inference (CI). We adapt CDCR, traditionally applied in the news domain, into
an RL model to operate at the passage level, similar to NLI and STS, while
accommodating the process industry's specific text formats, which contain
unstructured text and structured record attributes. Our RL model outperformed
the best versions of NLI- and STS-driven baselines by 28% (11.43 points) and
27% (11.21 points), respectively. Our work demonstrates how domain adaptation
of the state-of-the-art CDCR models, enhanced with reasoning capabilities, can
be effectively tailored to the process industry, improving data quality and
connectivity in shift logs.},
 author = {Anastasia Zhukova and Thomas Walton and Christian E. Matt and Bela Gipp},
 comment = {},
 doi = {},
 eprint = {2508.09096v1},
 journal = {arXiv preprint},
 title = {Link Prediction for Event Logs in the Process Industry},
 url = {http://arxiv.org/abs/2508.09096v1},
 year = {2025}
}

@article{2508.09265v1,
 abstract = {Graph neural networks (GNNs) have exhibited state-of-the-art performance
across wide-range of domains such as recommender systems, material design, and
drug repurposing. Yet message-passing GNNs suffer from over-squashing --
exponential compression of long-range information from distant nodes -- which
limits expressivity. Rewiring techniques can ease this bottleneck; but their
practical impacts are unclear due to the lack of a direct empirical
over-squashing metric. We propose a rigorous, topology-focused method for
assessing over-squashing between node pairs using the decay rate of their
mutual sensitivity. We then extend these pairwise assessments to four
graph-level statistics (prevalence, intensity, variability, extremity).
Coupling these metrics with a within-graph causal design, we quantify how
rewiring strategies affect over-squashing on diverse graph- and
node-classification benchmarks. Our extensive empirical analyses show that most
graph classification datasets suffer from over-squashing (but to various
extents), and rewiring effectively mitigates it -- though the degree of
mitigation, and its translation into performance gains, varies by dataset and
method. We also found that over-squashing is less notable in node
classification datasets, where rewiring often increases over-squashing, and
performance variations are uncorrelated with over-squashing changes. These
findings suggest that rewiring is most beneficial when over-squashing is both
substantial and corrected with restraint -- while overly aggressive rewiring,
or rewiring applied to minimally over-squashed graphs, is unlikely to help and
may even harm performance. Our plug-and-play diagnostic tool lets practitioners
decide -- before any training -- whether rewiring is likely to pay off.},
 author = {Danial Saber and Amirali Salehi-Abari},
 comment = {14 pages, 2 figures},
 doi = {},
 eprint = {2508.09265v1},
 journal = {arXiv preprint},
 title = {Over-Squashing in GNNs and Causal Inference of Rewiring Strategies},
 url = {http://arxiv.org/abs/2508.09265v1},
 year = {2025}
}

@article{2508.09624v1,
 abstract = {Causal inference is crucial for humans to explore the world, which can be
modeled to enable an agent to efficiently explore the environment in
reinforcement learning. Existing research indicates that establishing the
causality between action and state transition will enhance an agent to reason
how a policy affects its future trajectory, thereby promoting directed
exploration. However, it is challenging to measure the causality due to its
intractability in the vast state-action space of complex scenarios. In this
paper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework
for efficient environment exploration. Specifically, we first derive a
measurement of causality in state space, \emph{i.e.,} causal capacity, which
represents the highest influence of an agent's behavior on future trajectories.
After that, we present a Monte Carlo based method to identify critical points
in discrete state space and further optimize this method for continuous
high-dimensional environments. Those critical points are used to uncover where
the agent makes important decisions in the environment, which are then regarded
as our subgoals to guide the agent to make exploration more purposefully and
efficiently. Empirical results from multi-objective tasks demonstrate that
states with high causal capacity align with our expected subgoals, and our GDCC
achieves significant success rate improvements compared to baselines.},
 author = {Yan Yu and Yaodong Yang and Zhengbo Lu and Chengdong Ma and Wengang Zhou and Houqiang Li},
 comment = {},
 doi = {},
 eprint = {2508.09624v1},
 journal = {arXiv preprint},
 title = {Goal Discovery with Causal Capacity for Efficient Reinforcement Learning},
 url = {http://arxiv.org/abs/2508.09624v1},
 year = {2025}
}

@article{2508.09721v1,
 abstract = {The interpretability of generative models is considered a key factor in
demonstrating their effectiveness and controllability. The generated data are
believed to be determined by latent variables that are not directly observable.
Therefore, disentangling, decoupling, decomposing, causal inference, or
performing Independent Component Analysis (ICA) in the latent variable space
helps uncover the independent factors that influence the attributes or features
affecting the generated outputs, thereby enhancing the interpretability of
generative models. As a generative model, Variational Autoencoders (VAEs)
combine with variational Bayesian inference algorithms. Using VAEs, the inverse
process of ICA can be equivalently framed as a variational inference process.
In some studies, Gaussian processes (GPs) have been introduced as priors for
each dimension of latent variables in VAEs, structuring and separating each
dimension from temporal or spatial perspectives, and encouraging different
dimensions to control various attributes of the generated data. However, GPs
impose a significant computational burden, resulting in substantial resource
consumption when handling large datasets. Essentially, GPs model different
temporal or spatial structures through various kernel functions. Structuring
the priors of latent variables via kernel functions-so that different kernel
functions model the correlations among sequence points within different latent
dimensions-is at the core of achieving disentanglement in VAEs. The proposed
Structured Kernel Regression VAE (SKR-VAE) leverages this core idea in a more
efficient way, avoiding the costly kernel matrix inversion required in GPs.
This research demonstrates that, while maintaining ICA performance, SKR-VAE
achieves greater computational efficiency and significantly reduced
computational burden compared to GP-VAE.},
 author = {Yuan-Hao Wei and Fu-Hao Deng and Lin-Yong Cui and Yan-Jie Sun},
 comment = {},
 doi = {},
 eprint = {2508.09721v1},
 journal = {arXiv preprint},
 title = {Structured Kernel Regression VAE: A Computationally Efficient Surrogate for GP-VAEs in ICA},
 url = {http://arxiv.org/abs/2508.09721v1},
 year = {2025}
}

@article{2508.10130v1,
 abstract = {Background: Glial fibrillary acidic protein (GFAP) is a biomarker for
intracerebral hemorrhage and traumatic brain injury, but its link to acute
speech disruption is untested. Speech anomalies often emerge early after
injury, enabling rapid triage.
  Methods: We simulated a cohort of 200 virtual patients stratified by lesion
location, onset time, and severity. GFAP kinetics followed published
trajectories; speech anomalies were generated from lesion-specific
neurophysiological mappings. Ensemble machine-learning models used GFAP,
speech, and lesion features; robustness was tested under noise, delays, and
label dropout. Causal inference (inverse probability of treatment weighting and
targeted maximum likelihood estimation) estimated directional associations
between GFAP elevation and speech severity.
  Findings: GFAP correlated with simulated speech anomaly severity (Spearman
rho = 0.48), strongest for cortical lesions (rho = 0.55). Voice anomalies
preceded detectable GFAP rise by a median of 42 minutes in cortical injury.
Classifier area under the curve values were 0.74 (GFAP only), 0.78 (voice
only), and 0.86 for the fused multimodal model, which showed higher sensitivity
in mild or ambiguous cases. Causal estimates indicated higher GFAP increased
the modeled probability of moderate-to-severe speech anomalies by 32 to 35
percent, independent of lesion site and onset time.
  Conclusion: These results support a link between GFAP elevation and speech
anomalies in acute brain injury and suggest integrated biochemical-voice
diagnostics could improve early triage, especially for cortical injury.
Findings are simulation-based and require validation in prospective clinical
studies with synchronized GFAP assays and speech recordings.},
 author = {Shamaley Aravinthan and Bin Hu},
 comment = {6 figures, 4 tables},
 doi = {},
 eprint = {2508.10130v1},
 journal = {arXiv preprint},
 title = {Linking GFAP Levels to Speech Anomalies in Acute Brain Injury: A Simulation Based Study},
 url = {http://arxiv.org/abs/2508.10130v1},
 year = {2025}
}

@article{2508.10501v2,
 abstract = {Existing tool-augmented agentic systems are limited in the real world by (i)
black-box reasoning steps that undermine trust of decision-making and pose
safety risks, (ii) poor multimodal integration, which is inherently critical
for healthcare tasks, and (iii) rigid and computationally inefficient agentic
pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the
first multimodal framework to address these challenges in the context of Chest
X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a
multi-tool graph, yielding decision paths annotated with interpretable
probabilities. Given the complex CXR reasoning task with multimodal medical
data, PASS leverages its learned task-conditioned distribution over the agentic
supernet. Thus, it adaptively selects the most suitable tool at each supernet
layer, offering probability-annotated trajectories for post-hoc audits and
directly enhancing medical AI safety. PASS also continuously compresses salient
findings into an evolving personalized memory, while dynamically deciding
whether to deepen its reasoning path or invoke an early exit for efficiency. To
optimize a Pareto frontier balancing performance and cost, we design a novel
three-stage training procedure, including expert knowledge warm-up, contrastive
path-ranking, and cost-aware reinforcement learning. To facilitate rigorous
evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step,
safety-critical, free-form CXR reasoning. Experiments across various benchmarks
validate that PASS significantly outperforms strong baselines in multiple
metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs,
pushing a new paradigm shift towards interpretable, adaptive, and multimodal
medical agentic systems.},
 author = {Yushi Feng and Junye Du and Yingying Hong and Qifan Wang and Lequan Yu},
 comment = {},
 doi = {},
 eprint = {2508.10501v2},
 journal = {arXiv preprint},
 title = {PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning},
 url = {http://arxiv.org/abs/2508.10501v2},
 year = {2025}
}

@article{2508.10581v1,
 abstract = {Estimating treatment effects (TE) from observational data is a critical yet
complex task in many fields, from healthcare and economics to public policy.
While recent advances in machine learning and causal inference have produced
powerful estimation techniques, their adoption remains limited due to the need
for deep expertise in causal assumptions, adjustment strategies, and model
selection. In this paper, we introduce CATE-B, an open-source co-pilot system
that uses large language models (LLMs) within an agentic framework to guide
users through the end-to-end process of treatment effect estimation. CATE-B
assists in (i) constructing a structural causal model via causal discovery and
LLM-based edge orientation, (ii) identifying robust adjustment sets through a
novel Minimal Uncertainty Adjustment Set criterion, and (iii) selecting
appropriate regression methods tailored to the causal structure and dataset
characteristics. To encourage reproducibility and evaluation, we release a
suite of benchmark tasks spanning diverse domains and causal complexities. By
combining causal inference with intelligent, interactive assistance, CATE-B
lowers the barrier to rigorous causal analysis and lays the foundation for a
new class of benchmarks in automated treatment effect estimation.},
 author = {Jeroen Berrevoets and Julianna Piskorz and Robert Davis and Harry Amad and Jim Weatherall and Mihaela van der Schaar},
 comment = {},
 doi = {},
 eprint = {2508.10581v1},
 journal = {arXiv preprint},
 title = {Technical Report: Facilitating the Adoption of Causal Inference Methods Through LLM-Empowered Co-Pilot},
 url = {http://arxiv.org/abs/2508.10581v1},
 year = {2025}
}

@article{2508.10804v1,
 abstract = {Online restless multi-armed bandits (RMABs) typically assume that each arm
follows a stationary Markov Decision Process (MDP) with fixed state transitions
and rewards. However, in real-world applications like healthcare and
recommendation systems, these assumptions often break due to non-stationary
dynamics, posing significant challenges for traditional RMAB algorithms. In
this work, we specifically consider $N$-armd RMAB with non-stationary
transition constrained by bounded variation budgets $B$. Our proposed \rmab\;
algorithm integrates sliding window reinforcement learning (RL) with an upper
confidence bound (UCB) mechanism to simultaneously learn transition dynamics
and their variations. We further establish that \rmab\; achieves
$\widetilde{\mathcal{O}}(N^2 B^{\frac{1}{4}} T^{\frac{3}{4}})$ regret bound by
leveraging a relaxed definition of regret, providing a foundational theoretical
framework for non-stationary RMAB problems for the first time.},
 author = {Yu-Heng Hung and Ping-Chun Hsieh and Kai Wang},
 comment = {},
 doi = {},
 eprint = {2508.10804v1},
 journal = {arXiv preprint},
 title = {Non-Stationary Restless Multi-Armed Bandits with Provable Guarantee},
 url = {http://arxiv.org/abs/2508.10804v1},
 year = {2025}
}

@article{2508.11894v1,
 abstract = {Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.},
 author = {Ao Li and Bin Yan and Bingfeng Cai and Chenxi Li and Cunzhong Zhao and Fugen Yao and Gaoqiang Liu and Guanjun Jiang and Jian Xu and Liang Dong and Liansheng Sun and Rongshen Zhang and Xiaolei Gui and Xin Liu and Xin Shang and Yao Wu and Yu Cao and Zhenxin Ma and Zhuang Jia},
 comment = {20 pages},
 doi = {},
 eprint = {2508.11894v1},
 journal = {arXiv preprint},
 title = {QuarkMed Medical Foundation Model Technical Report},
 url = {http://arxiv.org/abs/2508.11894v1},
 year = {2025}
}

@article{2508.12688v1,
 abstract = {This paper proposes a simple, novel, and fully-Bayesian approach for causal
inference in partially linear models with high-dimensional control variables.
Off-the-shelf machine learning methods can introduce biases in the causal
parameter known as regularization-induced confounding. To address this, we
propose a Bayesian Double Machine Learning (BDML) method, which modifies a
standard Bayesian multivariate regression model and recovers the causal effect
of interest from the reduced-form covariance matrix. Our BDML is related to the
burgeoning frequentist literature on DML while addressing its limitations in
finite-sample inference. Moreover, the BDML is based on a fully generative
probability model in the DML context, adhering to the likelihood principle. We
show that in high dimensional setups the naive estimator implicitly assumes no
selection on observables--unlike our BDML. The BDML exhibits lower asymptotic
bias and achieves asymptotic normality and semiparametric efficiency as
established by a Bernstein-von Mises theorem, thereby ensuring robustness to
misspecification. In simulations, our BDML achieves lower RMSE, better
frequentist coverage, and shorter confidence interval width than alternatives
from the literature, both Bayesian and frequentist.},
 author = {Francis J. DiTraglia and Laura Liu},
 comment = {},
 doi = {},
 eprint = {2508.12688v1},
 journal = {arXiv preprint},
 title = {Bayesian Double Machine Learning for Causal Inference},
 url = {http://arxiv.org/abs/2508.12688v1},
 year = {2025}
}

@article{2508.13355v2,
 abstract = {Predicting counterfactual distributions in complex dynamical systems is
essential for scientific modeling and decision-making in domains such as public
health and medicine. However, existing methods often rely on point estimates or
purely data-driven models, which tend to falter under data scarcity. We propose
a time series diffusion-based framework that incorporates guidance from
imperfect expert models by extracting high-level signals to serve as structured
priors for generative modeling. Our method, ODE-Diff, bridges mechanistic and
data-driven approaches, enabling more reliable and interpretable causal
inference. We evaluate ODE-Diff across semi-synthetic COVID-19 simulations,
synthetic pharmacological dynamics, and real-world case studies, demonstrating
that it consistently outperforms strong baselines in both point prediction and
distributional accuracy.},
 author = {Wenhao Mu and Zhi Cao and Mehmed Uludag and Alexander Rodríguez},
 comment = {},
 doi = {},
 eprint = {2508.13355v2},
 journal = {arXiv preprint},
 title = {Counterfactual Probabilistic Diffusion with Expert Models},
 url = {http://arxiv.org/abs/2508.13355v2},
 year = {2025}
}

@article{2508.13607v1,
 abstract = {Causal inference often hinges on strong assumptions - such as no unmeasured
confounding or perfect compliance - that are rarely satisfied in practice.
Partial identification offers a principled alternative: instead of relying on
unverifiable assumptions to estimate causal effects precisely, it derives
bounds that reflect the uncertainty inherent in the data. Despite its
theoretical appeal, partial identification remains underutilized in applied
work, in part due to the fragmented nature of existing methods and the lack of
practical guidance. This thesis addresses these challenges by systematically
comparing a diverse set of bounding algorithms across multiple causal
scenarios. We implement, extend, and unify state-of-the-art methods - including
symbolic, optimization-based, and information-theoretic approaches - within a
common evaluation framework. In particular, we propose an extension of a
recently introduced entropy-bounded method, making it applicable to
counterfactual queries such as the Probability of Necessity and Sufficiency
(PNS). Our empirical study spans thousands of randomized simulations involving
both discrete and continuous data-generating processes. We assess each method
in terms of bound tightness, computational efficiency, and robustness to
assumption violations. To support practitioners, we distill our findings into a
practical decision tree for algorithm selection and train a machine learning
model to predict the best-performing method based on observable data
characteristics.
  All implementations are released as part of an open-source Python package,
CausalBoundingEngine, which enables users to apply and compare bounding methods
through a unified interface.},
 author = {Tobias Maringgele},
 comment = {Bachelor's thesis, Technical University of Munich, 2025. 102 pages,
  20 figures},
 doi = {},
 eprint = {2508.13607v1},
 journal = {arXiv preprint},
 title = {Bounding Causal Effects and Counterfactuals},
 url = {http://arxiv.org/abs/2508.13607v1},
 year = {2025}
}

@article{2508.16942v1,
 abstract = {Evaluating human actions with clear and detailed feedback is important in
areas such as sports, healthcare, and robotics, where decisions rely not only
on final outcomes but also on interpretable reasoning. However, most existing
methods provide only a final score without explanation or detailed analysis,
limiting their practical applicability. To address this, we introduce
HieroAction, a vision-language model that delivers accurate and structured
assessments of human actions. HieroAction builds on two key ideas: (1) Stepwise
Action Reasoning, a tailored chain of thought process designed specifically for
action assessment, which guides the model to evaluate actions step by step,
from overall recognition through sub action analysis to final scoring, thus
enhancing interpretability and structured understanding; and (2) Hierarchical
Policy Learning, a reinforcement learning strategy that enables the model to
learn fine grained sub action dynamics and align them with high level action
quality, thereby improving scoring precision. The reasoning pathway structures
the evaluation process, while policy learning refines each stage through reward
based optimization. Their integration ensures accurate and interpretable
assessments, as demonstrated by superior performance across multiple benchmark
datasets. Code will be released upon acceptance.},
 author = {Junhao Wu and Xiuer Gu and Zhiying Li and Yeying Jin and Yunfeng Diao and Zhiyu Li and Zhenbo Song and Xiaomei Zhang and Zhaoxin Fan},
 comment = {},
 doi = {},
 eprint = {2508.16942v1},
 journal = {arXiv preprint},
 title = {HieroAction: Hierarchically Guided VLM for Fine-Grained Action Analysis},
 url = {http://arxiv.org/abs/2508.16942v1},
 year = {2025}
}

@article{2508.17262v1,
 abstract = {Extended reality technologies are transforming fields such as healthcare,
entertainment, and education, with Smart Eye-Wears (SEWs) and Artificial
Intelligence (AI) playing a crucial role. However, SEWs face inherent
limitations in computational power, memory, and battery life, while offloading
computations to external servers is constrained by network conditions and
server workload variability. To address these challenges, we propose a
Federated Reinforcement Learning (FRL) framework, enabling multiple agents to
train collaboratively while preserving data privacy. We implemented synchronous
and asynchronous federation strategies, where models are aggregated either at
fixed intervals or dynamically based on agent progress. Experimental results
show that federated agents exhibit significantly lower performance variability,
ensuring greater stability and reliability. These findings underscore the
potential of FRL for applications requiring robust real-time AI processing,
such as real-time object detection in SEWs.},
 author = {Hamta Sedghani and Abednego Wamuhindo Kambale and Federica Filippini and Francesca Palermo and Diana Trojaniello and Danilo Ardagna},
 comment = {},
 doi = {},
 eprint = {2508.17262v1},
 journal = {arXiv preprint},
 title = {Federated Reinforcement Learning for Runtime Optimization of AI Applications in Smart Eyewears},
 url = {http://arxiv.org/abs/2508.17262v1},
 year = {2025}
}

@article{2508.17576v2,
 abstract = {Despite the overwhelming performance improvements offered by recent natural
language processing (NLP) models, the decisions made by these models are
largely a black box. Towards closing this gap, the field of causal NLP combines
causal inference literature with modern NLP models to elucidate causal effects
of text features. We replicate and extend Bansal et al's work on regularizing
text classifiers to adhere to estimated effects, focusing instead on model
interpretability. Specifically, we focus on developing a two-headed
RieszNet-based neural network architecture which achieves better treatment
effect estimation accuracy. Our framework, CausalSent, accurately predicts
treatment effects in semi-synthetic IMDB movie reviews, reducing MAE of effect
estimates by 2-3x compared to Bansal et al's MAE on synthetic Civil Comments
data. With an ensemble of validated models, we perform an observational case
study on the causal effect of the word "love" in IMDB movie reviews, finding
that the presence of the word "love" causes a +2.9% increase in the probability
of a positive sentiment.},
 author = {Daniel Frees and Martin Pollack},
 comment = {},
 doi = {},
 eprint = {2508.17576v2},
 journal = {arXiv preprint},
 title = {CausalSent: Interpretable Sentiment Classification with RieszNet},
 url = {http://arxiv.org/abs/2508.17576v2},
 year = {2025}
}

@article{2508.17703v1,
 abstract = {Prompt engineering significantly influences the reliability and clinical
utility of Large Language Models (LLMs) in medical applications. Current
optimization approaches inadequately address domain-specific medical knowledge
and safety requirements. This paper introduces EMPOWER, a novel evolutionary
framework that enhances medical prompt quality through specialized
representation learning, multi-dimensional evaluation, and structure-preserving
algorithms. Our methodology incorporates: (1) a medical terminology attention
mechanism, (2) a comprehensive assessment architecture evaluating clarity,
specificity, clinical relevance, and factual accuracy, (3) a component-level
evolutionary algorithm preserving clinical reasoning integrity, and (4) a
semantic verification module ensuring adherence to medical knowledge.
Evaluation across diagnostic, therapeutic, and educational tasks demonstrates
significant improvements: 24.7% reduction in factually incorrect content, 19.6%
enhancement in domain specificity, and 15.3% higher clinician preference in
blinded evaluations. The framework addresses critical challenges in developing
clinically appropriate prompts, facilitating more responsible integration of
LLMs into healthcare settings.},
 author = {Yinda Chen and Yangfan He and Jing Yang and Dapeng Zhang and Zhenlong Yuan and Muhammad Attique Khan and Jamel Baili and Por Lip Yee},
 comment = {},
 doi = {},
 eprint = {2508.17703v1},
 journal = {arXiv preprint},
 title = {EMPOWER: Evolutionary Medical Prompt Optimization With Reinforcement Learning},
 url = {http://arxiv.org/abs/2508.17703v1},
 year = {2025}
}

@article{2508.18474v1,
 abstract = {Anomaly detection in time series data is important for applications in
finance, healthcare, sensor networks, and industrial monitoring. Traditional
methods usually struggle with limited labeled data, high false-positive rates,
and difficulty generalizing to novel anomaly types. To overcome these
challenges, we propose a reinforcement learning-based framework that integrates
dynamic reward shaping, Variational Autoencoder (VAE), and active learning,
called DRTA. Our method uses an adaptive reward mechanism that balances
exploration and exploitation by dynamically scaling the effect of VAE-based
reconstruction error and classification rewards. This approach enables the
agent to detect anomalies effectively in low-label systems while maintaining
high precision and recall. Our experimental results on the Yahoo A1 and Yahoo
A2 benchmark datasets demonstrate that the proposed method consistently
outperforms state-of-the-art unsupervised and semi-supervised approaches. These
findings show that our framework is a scalable and efficient solution for
real-world anomaly detection tasks.},
 author = {Bahareh Golchin and Banafsheh Rekabdar and Kunpeng Liu},
 comment = {},
 doi = {},
 eprint = {2508.18474v1},
 journal = {arXiv preprint},
 title = {DRTA: Dynamic Reward Scaling for Reinforcement Learning in Time Series Anomaly Detection},
 url = {http://arxiv.org/abs/2508.18474v1},
 year = {2025}
}

@article{2508.18708v2,
 abstract = {Fairness in multi-agent reinforcement learning (MARL) is often framed as a
workload balance problem, overlooking agent expertise and the structured
coordination required in real-world domains. In healthcare, equitable task
allocation requires workload balance or expertise alignment to prevent burnout
and overuse of highly skilled agents. Workload balance refers to distributing
an approximately equal number of subtasks or equalised effort across healthcare
workers, regardless of their expertise. We make two contributions to address
this problem. First, we propose FairSkillMARL, a framework that defines
fairness as the dual objective of workload balance and skill-task alignment.
Second, we introduce MARLHospital, a customizable healthcare-inspired
environment for modeling team compositions and energy-constrained scheduling
impacts on fairness, as no existing simulators are well-suited for this
problem. We conducted experiments to compare FairSkillMARL in conjunction with
four standard MARL methods, and against two state-of-the-art fairness metrics.
Our results suggest that fairness based solely on equal workload might lead to
task-skill mismatches and highlight the need for more robust metrics that
capture skill-task misalignment. Our work provides tools and a foundation for
studying fairness in heterogeneous multi-agent systems where aligning effort
with expertise is critical.},
 author = {Promise Osaine Ekpo and Brian La and Thomas Wiener and Saesha Agarwal and Arshia Agrawal and Gonzalo Gonzalez-Pumariega and Lekan P. Molu and Angelique Taylor},
 comment = {},
 doi = {},
 eprint = {2508.18708v2},
 journal = {arXiv preprint},
 title = {Skill-Aligned Fairness in Multi-Agent Learning for Collaboration in Healthcare},
 url = {http://arxiv.org/abs/2508.18708v2},
 year = {2025}
}

@article{2508.18803v1,
 abstract = {The proliferation of Internet of things (IoT) devices in smart cities,
transportation, healthcare, and industrial applications, coupled with the
explosive growth of AI-driven services, has increased demands for efficient
distributed computing architectures and networks, driving cloud-edge-terminal
collaborative intelligence (CETCI) as a fundamental paradigm within the
artificial intelligence of things (AIoT) community. With advancements in deep
learning, large language models (LLMs), and edge computing, CETCI has made
significant progress with emerging AIoT applications, moving beyond isolated
layer optimization to deployable collaborative intelligence systems for AIoT
(CISAIOT), a practical research focus in AI, distributed computing, and
communications. This survey describes foundational architectures, enabling
technologies, and scenarios of CETCI paradigms, offering a tutorial-style
review for CISAIOT beginners. We systematically analyze architectural
components spanning cloud, edge, and terminal layers, examining core
technologies including network virtualization, container orchestration, and
software-defined networking, while presenting categorizations of collaboration
paradigms that cover task offloading, resource allocation, and optimization
across heterogeneous infrastructures. Furthermore, we explain intelligent
collaboration learning frameworks by reviewing advances in federated learning,
distributed deep learning, edge-cloud model evolution, and reinforcement
learning-based methods. Finally, we discuss challenges (e.g., scalability,
heterogeneity, interoperability) and future trends (e.g., 6G+, agents, quantum
computing, digital twin), highlighting how integration of distributed computing
and communication can address open issues and guide development of robust,
efficient, and secure collaborative AIoT systems.},
 author = {Jiaqi Wu and Jing Liu and Yang Liu and Lixu Wang and Zehua Wang and Wei Chen and Zijian Tian and Richard Yu and Victor C. M. Leung},
 comment = {},
 doi = {},
 eprint = {2508.18803v1},
 journal = {arXiv preprint},
 title = {A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks},
 url = {http://arxiv.org/abs/2508.18803v1},
 year = {2025}
}

@article{2508.19097v1,
 abstract = {The emergence of advanced reasoning capabilities in Large Language Models
(LLMs) marks a transformative development in healthcare applications. Beyond
merely expanding functional capabilities, these reasoning mechanisms enhance
decision transparency and explainability-critical requirements in medical
contexts. This survey examines the transformation of medical LLMs from basic
information retrieval tools to sophisticated clinical reasoning systems capable
of supporting complex healthcare decisions. We provide a thorough analysis of
the enabling technological foundations, with a particular focus on specialized
prompting techniques like Chain-of-Thought and recent breakthroughs in
Reinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates
purpose-built medical frameworks while also examining emerging paradigms such
as multi-agent collaborative systems and innovative prompting architectures.
The survey critically assesses current evaluation methodologies for medical
validation and addresses persistent challenges in field interpretation
limitations, bias mitigation strategies, patient safety frameworks, and
integration of multimodal clinical data. Through this survey, we seek to
establish a roadmap for developing reliable LLMs that can serve as effective
partners in clinical practice and medical research.},
 author = {Armin Berger and Sarthak Khanna and David Berghaus and Rafet Sifa},
 comment = {},
 doi = {},
 eprint = {2508.19097v1},
 journal = {arXiv preprint},
 title = {Reasoning LLMs in the Medical Domain: A Literature Survey},
 url = {http://arxiv.org/abs/2508.19097v1},
 year = {2025}
}

@article{2508.19327v1,
 abstract = {Bell's theorem reveals a profound conflict between quantum mechanics and
local realism, a conflict we reinterpret through the modern lens of causal
inference. We propose and computationally validate a framework where quantum
entanglement acts as a "super-confounding" resource, generating correlations
that violate the classical causal bounds set by Bell's inequalities. This work
makes three key contributions: First, we establish a physical hierarchy of
confounding (Quantum > Classical) and introduce Confounding Strength (CS) to
quantify this effect. Second, we provide a circuit-based implementation of the
quantum $\mathcal{DO}$-calculus to distinguish causality from spurious
correlation. Finally, we apply this calculus to a quantum machine learning
problem, where causal feature selection yields a statistically significant
11.3% average absolute improvement in model robustness. Our framework bridges
quantum foundations and causal AI, offering a new, practical perspective on
quantum correlations.},
 author = {Pilsung Kang},
 comment = {},
 doi = {},
 eprint = {2508.19327v1},
 journal = {arXiv preprint},
 title = {Quantum Entanglement as Super-Confounding: From Bell's Theorem to Robust Machine Learning},
 url = {http://arxiv.org/abs/2508.19327v1},
 year = {2025}
}

@article{2508.19567v1,
 abstract = {In reinforcement learning with human feedback (RLHF), reward models can
efficiently learn and amplify latent biases within multimodal datasets, which
can lead to imperfect policy optimization through flawed reward signals and
decreased fairness. Bias mitigation studies have often applied passive
constraints, which can fail under causal confounding. Here, we present a
counterfactual reward model that introduces causal inference with multimodal
representation learning to provide an unsupervised, bias-resilient reward
signal. The heart of our contribution is the Counterfactual Trust Score, an
aggregated score consisting of four components: (1) counterfactual shifts that
decompose political framing bias from topical bias; (2) reconstruction
uncertainty during counterfactual perturbations; (3) demonstrable violations of
fairness rules for each protected attribute; and (4) temporal reward shifts
aligned with dynamic trust measures. We evaluated the framework on a multimodal
fake versus true news dataset, which exhibits framing bias, class imbalance,
and distributional drift. Following methodologies similar to unsupervised drift
detection from representation-based distances [1] and temporal robustness
benchmarking in language models [2], we also inject synthetic bias across
sequential batches to test robustness. The resulting system achieved an
accuracy of 89.12% in fake news detection, outperforming the baseline reward
models. More importantly, it reduced spurious correlations and unfair
reinforcement signals. This pipeline outlines a robust and interpretable
approach to fairness-aware RLHF, offering tunable bias reduction thresholds and
increasing reliability in dynamic real-time policy making.},
 author = {Sheryl Mathew and N Harshit},
 comment = {},
 doi = {},
 eprint = {2508.19567v1},
 journal = {arXiv preprint},
 title = {Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning},
 url = {http://arxiv.org/abs/2508.19567v1},
 year = {2025}
}

@article{2508.20259v1,
 abstract = {Latent variable models provide a powerful framework for incorporating and
inferring unobserved factors in observational data. In causal inference, they
help account for hidden factors influencing treatment or outcome, thereby
addressing challenges posed by missing or unmeasured covariates. This paper
proposes a new framework that integrates latent variable modeling into the
double machine learning (DML) paradigm to enable robust causal effect
estimation in the presence of such hidden factors. We consider two scenarios:
one where a latent variable affects only the outcome, and another where it may
influence both treatment and outcome. To ensure tractability, we incorporate
latent variables only in the second stage of DML, separating representation
learning from latent inference. We demonstrate the robustness and effectiveness
of our method through extensive experiments on both synthetic and real-world
datasets.},
 author = {Tetsuro Morimura and Tatsushi Oka and Yugo Suzuki and Daisuke Moriwaki},
 comment = {Accepted to CIKM 2025. This is the full version including extended
  appendix},
 doi = {},
 eprint = {2508.20259v1},
 journal = {arXiv preprint},
 title = {Latent Variable Modeling for Robust Causal Effect Estimation},
 url = {http://arxiv.org/abs/2508.20259v1},
 year = {2025}
}

@article{2508.20326v1,
 abstract = {Stochastic gradient optimization is the dominant learning paradigm for a
variety of scenarios, from classical supervised learning to modern
self-supervised learning. We consider stochastic gradient algorithms for
learning problems whose objectives rely on unknown nuisance parameters, and
establish non-asymptotic convergence guarantees. Our results show that, while
the presence of a nuisance can alter the optimum and upset the optimization
trajectory, the classical stochastic gradient algorithm may still converge
under appropriate conditions, such as Neyman orthogonality. Moreover, even when
Neyman orthogonality is not satisfied, we show that an algorithm variant with
approximately orthogonalized updates (with an approximately orthogonalized
gradient oracle) may achieve similar convergence rates. Examples from
orthogonal statistical learning/double machine learning and causal inference
are discussed.},
 author = {Facheng Yu and Ronak Mehta and Alex Luedtke and Zaid Harchaoui},
 comment = {},
 doi = {},
 eprint = {2508.20326v1},
 journal = {arXiv preprint},
 title = {Stochastic Gradients under Nuisances},
 url = {http://arxiv.org/abs/2508.20326v1},
 year = {2025}
}

@article{2508.20335v1,
 abstract = {Accurately quantifying geo-level marketing lift in two-sided marketplaces is
challenging: the Synthetic Control Method (SCM) often exhibits high power yet
systematically under-estimates effect size, while panel-style Double Machine
Learning (DML) is seldom benchmarked against SCM. We build an open, fully
documented simulator that mimics a typical large-scale geo roll-out: N_unit
regional markets are tracked for T_pre weeks before launch and for a further
T_post-week campaign window, allowing all key parameters to be varied by the
user and probe both families under five stylized stress tests: 1) curved
baseline trends, 2) heterogeneous response lags, 3) treated-biased shocks, 4) a
non-linear outcome link, and 5) a drifting control group trend.
  Seven estimators are evaluated: three standard Augmented SCM (ASC) variants
and four panel-DML flavors (TWFE, CRE/Mundlak, first-difference, and
within-group). Across 100 replications per scenario, ASC models consistently
demonstrate severe bias and near-zero coverage in challenging scenarios
involving nonlinearities or external shocks. By contrast, panel-DML variants
dramatically reduce this bias and restore nominal 95%-CI coverage, proving far
more robust.
  The results indicate that while ASC provides a simple baseline, it is
unreliable in common, complex situations. We therefore propose a
'diagnose-first' framework where practitioners first identify the primary
business challenge (e.g., nonlinear trends, response lags) and then select the
specific DML model best suited for that scenario, providing a more robust and
reliable blueprint for analyzing geo-experiments.},
 author = {Sang Su Lee and Vineeth Loganathan and Vijay Raghavan},
 comment = {Presented at the KDD 2025 Workshop on Causal Inference and Machine
  Learning in Practice},
 doi = {},
 eprint = {2508.20335v1},
 journal = {arXiv preprint},
 title = {Dynamic Synthetic Controls vs. Panel-Aware Double Machine Learning for Geo-Level Marketing Impact Estimation},
 url = {http://arxiv.org/abs/2508.20335v1},
 year = {2025}
}

@article{2508.21010v1,
 abstract = {Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/},
 author = {Paritosh Parmar and Eric Peh and Basura Fernando},
 comment = {Project page: https://paritoshparmar.github.io/chainreaction/},
 doi = {},
 eprint = {2508.21010v1},
 journal = {arXiv preprint},
 title = {ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering},
 url = {http://arxiv.org/abs/2508.21010v1},
 year = {2025}
}

@article{2508.21101v1,
 abstract = {Reinforcement learning (RL) marks a fundamental shift in how artificial
intelligence is applied in healthcare. Instead of merely predicting outcomes,
RL actively decides interventions with long term goals. Unlike traditional
models that operate on fixed associations, RL systems learn through trial,
feedback, and long-term reward optimization, introducing transformative
possibilities and new risks. From an information fusion lens, healthcare RL
typically integrates multi-source signals such as vitals, labs clinical notes,
imaging and device telemetry using temporal and decision-level mechanisms.
These systems can operate within centralized, federated, or edge architectures
to meet real-time clinical constraints, and naturally span data, features and
decision fusion levels. This survey explore RL's rise in healthcare as more
than a set of tools, rather a shift toward agentive intelligence in clinical
environments. We first structure the landscape of RL techniques including
model-based and model-free methods, offline and batch-constrained approaches,
and emerging strategies for reward specification and uncertainty calibration
through the lens of healthcare constraints. We then comprehensively analyze RL
applications spanning critical care, chronic disease, mental health,
diagnostics, and robotic assistance, identifying their trends, gaps, and
translational bottlenecks. In contrast to prior reviews, we critically analyze
RL's ethical, deployment, and reward design challenges, and synthesize lessons
for safe, human-aligned policy learning. This paper serves as both a a
technical roadmap and a critical reflection of RL's emerging transformative
role in healthcare AI not as prediction machinery, but as agentive clinical
intelligence.},
 author = {Dilruk Perera and Gousia Habib and Qianyi Xu and Daniel J. Tan and Kai He and Erik Cambria and Mengling Feng},
 comment = {40 pages in total (including appendix)},
 doi = {},
 eprint = {2508.21101v1},
 journal = {arXiv preprint},
 title = {Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI},
 url = {http://arxiv.org/abs/2508.21101v1},
 year = {2025}
}

@article{2509.00472v2,
 abstract = {Causal inference in settings involving complex spatio-temporal dependencies,
such as environmental epidemiology, is challenging due to the presence of
unmeasured confounding. However, a significant gap persists in existing
methods: current diffusion-based causal models rely on restrictive assumptions
of causal sufficiency or static confounding. To address this limitation, we
introduce the Partially Functional Dynamic Backdoor Diffusion-based Causal
Model (PFD-BDCM), a generative framework designed to bridge this gap. Our
approach uniquely incorporates valid backdoor adjustments into the diffusion
sampling mechanism to mitigate bias from unmeasured confounders. Specifically,
it captures their intricate dynamics through region-specific structural
equations and conditional autoregressive processes, and accommodates
multi-resolution variables via functional data techniques. Furthermore, we
provide theoretical guarantees by establishing error bounds for counterfactual
estimates. Extensive experiments on synthetic data and a real-world air
pollution case study confirm that PFD-BDCM outperforms current state-of-the-art
methods.},
 author = {Xinwen Liu and Lei Qian and Song Xi Chen and Niansheng Tang},
 comment = {10 pages, 2 figures},
 doi = {},
 eprint = {2509.00472v2},
 journal = {arXiv preprint},
 title = {Partially Functional Dynamic Backdoor Diffusion-based Causal Model},
 url = {http://arxiv.org/abs/2509.00472v2},
 year = {2025}
}

@article{2509.00744v1,
 abstract = {Distinguishing correlation from causation is a fundamental challenge in
machine intelligence, often representing a critical barrier to building robust
and trustworthy systems. While Pearl's $\mathcal{DO}$-calculus provides a
rigorous framework for causal inference, a parallel challenge lies in its
physical implementation. Here, we apply and experimentally validate a quantum
algorithmic framework for performing causal interventions. Our approach maps
causal networks onto quantum circuits where probabilistic links are encoded by
controlled-rotation gates, and interventions are realized by a structural
remodeling of the circuit -- a physical analogue to Pearl's ``graph surgery''.
We demonstrate the method's efficacy by resolving Simpson's Paradox in a
3-qubit model, and show its scalability by quantifying confounding bias in a
10-qubit healthcare simulation. Critically, we provide a proof-of-principle
experimental validation on an IonQ Aria quantum computer, successfully
reproducing the paradox and its resolution in the presence of real-world noise.
This work establishes a practical pathway for quantum causal inference,
offering a new computational tool to address deep-rooted challenges in
algorithmic fairness and explainable AI (XAI).},
 author = {Pilsung Kang},
 comment = {},
 doi = {},
 eprint = {2509.00744v1},
 journal = {arXiv preprint},
 title = {Quantum Causality: Resolving Simpson's Paradox with $\mathcal{DO}$-Calculus},
 url = {http://arxiv.org/abs/2509.00744v1},
 year = {2025}
}

@article{2509.00797v1,
 abstract = {Prescriptive Process Monitoring (PresPM) is the subfield of Process Mining
that focuses on optimizing processes through real-time interventions based on
event log data. Evaluating PresPM methods is challenging due to the lack of
ground-truth outcomes for all intervention actions in datasets. A generative
deep learning approach from the field of Causal Inference (CI), RealCause, has
been commonly used to estimate the outcomes for proposed intervention actions
to evaluate a new policy. However, RealCause overlooks the temporal
dependencies in process data, and relies on a single CI model architecture,
TARNet, limiting its effectiveness. To address both shortcomings, we introduce
ProCause, a generative approach that supports both sequential (e.g., LSTMs) and
non-sequential models while integrating multiple CI architectures (S-Learner,
T-Learner, TARNet, and an ensemble). Our research using a simulator with known
ground truths reveals that TARNet is not always the best choice; instead, an
ensemble of models offers more consistent reliability, and leveraging LSTMs
shows potential for improved evaluations when temporal dependencies are
present. We further validate ProCause's practical effectiveness through a
real-world data analysis, ensuring a more reliable evaluation of PresPM
methods.},
 author = {Jakob De Moor and Hans Weytjens and Johannes De Smedt},
 comment = {},
 doi = {},
 eprint = {2509.00797v1},
 journal = {arXiv preprint},
 title = {ProCause: Generating Counterfactual Outcomes to Evaluate Prescriptive Process Monitoring Methods},
 url = {http://arxiv.org/abs/2509.00797v1},
 year = {2025}
}

@article{2509.01031v1,
 abstract = {Human Activity Recognition (HAR) using wearable sensors is crucial for
healthcare, fitness tracking, and smart environments, yet cross-user
variability -- stemming from diverse motion patterns, sensor placements, and
physiological traits -- hampers generalization in real-world settings.
Conventional supervised learning methods often overfit to user-specific
patterns, leading to poor performance on unseen users. Existing domain
generalization approaches, while promising, frequently overlook temporal
dependencies or depend on impractical domain-specific labels. We propose
Temporal-Preserving Reinforcement Learning Domain Generalization (TPRL-DG), a
novel framework that redefines feature extraction as a sequential
decision-making process driven by reinforcement learning. TPRL-DG leverages a
Transformer-based autoregressive generator to produce temporal tokens that
capture user-invariant activity dynamics, optimized via a multi-objective
reward function balancing class discrimination and cross-user invariance. Key
innovations include: (1) an RL-driven approach for domain generalization, (2)
autoregressive tokenization to preserve temporal coherence, and (3) a
label-free reward design eliminating the need for target user annotations.
Evaluations on the DSADS and PAMAP2 datasets show that TPRL-DG surpasses
state-of-the-art methods in cross-user generalization, achieving superior
accuracy without per-user calibration. By learning robust, user-invariant
temporal patterns, TPRL-DG enables scalable HAR systems, facilitating
advancements in personalized healthcare, adaptive fitness tracking, and
context-aware environments.},
 author = {Xiaozhou Ye and Kevin I-Kai Wang},
 comment = {},
 doi = {},
 eprint = {2509.01031v1},
 journal = {arXiv preprint},
 title = {Reinforcement Learning Driven Generalizable Feature Representation for Cross-User Activity Recognition},
 url = {http://arxiv.org/abs/2509.01031v1},
 year = {2025}
}

@article{2509.02208v1,
 abstract = {As large language models (LLMs) advance in conversational and reasoning
capabilities, their practical application in healthcare has become a critical
research focus. However, there is a notable gap between the performance of
medical LLMs on static benchmarks such as USMLE and their utility in real-world
clinical decision-making. This discrepancy arises because traditional exams
fail to capture the dynamic, interactive nature of medical consultations. To
address this challenge, we introduce a novel dynamic verification framework
that moves beyond static answer verifier, establishing a large-scale,
high-fidelity interactive reinforcement learning system. Our framework
comprises two key components: a Patient Simulator that creates realistic
clinical environments using de-identified medical records, and a Clinical
Rubrics Generator that dynamically produces multi-dimensional evaluation
metrics. Building on this foundation, we develop Baichuan-M2, a 32B-parameter
medical augmented reasoning model trained through a multi-stage reinforcement
learning strategy with an improved Group Relative Policy Optimization (GRPO)
algorithm. Evaluated on HealthBench, Baichuan-M2 outperforms all other
open-source models and most advanced closed-source counterparts, achieving a
score above 32 on the challenging HealthBench Hard benchmark-previously
exceeded only by GPT-5. Our work demonstrates that robust dynamic verifier
system is essential for aligning LLM capabilities with practical clinical
applications, establishing a new Pareto front in the performance-parameter
trade-off for medical AI deployment.},
 author = {Baichuan-M2 Team and : and Chengfeng Dou and Chong Liu and Fan Yang and Fei Li and Jiyuan Jia and Mingyang Chen and Qiang Ju and Shuai Wang and Shunya Dang and Tianpeng Li and Xiangrong Zeng and Yijie Zhou and Chenzheng Zhu and Da Pan and Fei Deng and Guangwei Ai and Guosheng Dong and Hongda Zhang and Jinyang Tai and Jixiang Hong and Kai Lu and Linzhuang Sun and Peidong Guo and Qian Ma and Rihui Xin and Shihui Yang and Shusen Zhang and Yichuan Mo and Zheng Liang and Zhishou Zhang and Hengfu Cui and Zuyi Zhu and Xiaochuan Wang},
 comment = {Baichuan-M2 Technical Report},
 doi = {},
 eprint = {2509.02208v1},
 journal = {arXiv preprint},
 title = {Baichuan-M2: Scaling Medical Capability with Large Verifier System},
 url = {http://arxiv.org/abs/2509.02208v1},
 year = {2025}
}

@article{2509.03063v1,
 abstract = {Fintech lending has become a central mechanism through which digital
platforms stimulate consumption, offering dynamic, personalized credit limits
that directly shape the purchasing power of consumers. Although prior research
shows that higher limits increase average spending, scalar-based outcomes
obscure the heterogeneous distributional nature of consumer responses. This
paper addresses this gap by proposing a new causal inference framework that
estimates how continuous changes in the credit limit affect the entire
distribution of consumer spending. We formalize distributional causal effects
within the Wasserstein space and introduce a robust Distributional Double
Machine Learning estimator, supported by asymptotic theory to ensure
consistency and validity. To implement this estimator, we design a deep
learning architecture comprising two components: a Neural Functional Regression
Net to capture complex, nonlinear relationships between treatments, covariates,
and distributional outcomes, and a Conditional Normalizing Flow Net to estimate
generalized propensity scores under continuous treatment. Numerical experiments
demonstrate that the proposed estimator accurately recovers distributional
effects in a range of data-generating scenarios. Applying our framework to
transaction-level data from a major BigTech platform, we find that increased
credit limits primarily shift consumers towards higher-value purchases rather
than uniformly increasing spending, offering new insights for personalized
marketing strategies and digital consumer finance.},
 author = {Cheuk Hang Leung and Yijun Li and Qi Wu},
 comment = {},
 doi = {},
 eprint = {2509.03063v1},
 journal = {arXiv preprint},
 title = {Distribution-valued Causal Machine Learning: Implications of Credit on Spending Patterns},
 url = {http://arxiv.org/abs/2509.03063v1},
 year = {2025}
}

@article{2509.03194v1,
 abstract = {This paper focuses on the Bayesian Network Propensity Score (BNPS), a novel
approach for estimating treatment effects in observational studies
characterized by unknown (and likely unbalanced) designs and complex dependency
structures among covariates. Traditional methods, such as logistic regression,
often impose rigid parametric assumptions that may lead to misspecification
errors, compromising causal inference. Recent classical and machine learning
alternatives, such as boosted CART, random forests, and Stable Balancing
Weights, seem to be attractive in a predictive perspective, but they typically
lack asymptotic properties, such as consistency, efficiency, and valid variance
estimation. In contrast, the recently proposed BNPS to estimate propensity
scores uses Bayesian Networks to flexibly model conditional dependencies while
preserving essential statistical properties such as consistency, asymptotic
normality and asymptotic efficiency. Combined with the H\'ajek estimator, BNPS
enables robust estimation of the Average Treatment Effect (ATE) in scenarios
with strong covariate interactions and unknown data-generating mechanisms.
Through extensive simulations across fifteen realistic scenarios and varying
sample sizes, BNPS consistently outperforms benchmark methods in both empirical
rejection rates and coverage accuracy. Finally, an application to a real-world
dataset of 7,162 prostate cancer patients from San Raffaele Hospital (Milan,
Italy) demonstrates BNPS's practical value in assessing the impact of pelvic
lymph node dissection on hospitalization duration and biochemical recurrence.
The findings support BNPS as a statistically robust, interpretable and
transparent alternative for causal inference in complex observational settings,
enhancing the reliability of evidence from real-world biomedical data.},
 author = {Clelia Di Serio and Federica Cugnata and Pier Luigi Conti and Alberto Briganti and Fulvia Mecatti and Paola Vicard and Paola Maria Vittoria Rancoita},
 comment = {},
 doi = {},
 eprint = {2509.03194v1},
 journal = {arXiv preprint},
 title = {Bayesian Network Propensity Score to Evaluate Treatment Effects in Observational Studies},
 url = {http://arxiv.org/abs/2509.03194v1},
 year = {2025}
}

@article{2509.03315v1,
 abstract = {Estimating risks or survival probabilities conditional on individual
characteristics based on censored time-to-event data is a commonly faced task.
This may be for the purpose of developing a prediction model or may be part of
a wider estimation procedure, such as in causal inference. A challenge is that
it is impossible to know at the outset which of a set of candidate models will
provide the best predictions. The super learner is a powerful approach for
finding the best model or combination of models ('ensemble') among a
pre-specified set of candidate models or 'learners', which can include
parametric and machine learning models. Super learners for time-to-event
outcomes have been developed, but the literature is technical and a reader may
find it challenging to gather together the full details of how these methods
work and can be implemented. In this paper we provide a practical tutorial on
super learner methods for time-to-event outcomes. An overview of the general
steps involved in the super learner is given, followed by details of three
specific implementations for time-to-event outcomes. We cover discrete-time and
continuous-time versions of the super learner, as described by Polley and van
der Laan (2011), Westling et al. (2023) and Munch and Gerds (2024). We compare
the properties of the methods and provide information on how they can be
implemented in R. The methods are illustrated using an open access data set and
R code is provided.},
 author = {Ruth H. Keogh and Karla Diaz-Ordaz and Nan van Geloven and Jon Michael Gran and Kamaryn T. Tanner},
 comment = {},
 doi = {},
 eprint = {2509.03315v1},
 journal = {arXiv preprint},
 title = {The super learner for time-to-event outcomes: A tutorial},
 url = {http://arxiv.org/abs/2509.03315v1},
 year = {2025}
}

@article{2509.03393v1,
 abstract = {Sepsis is a serious, life-threatening condition. When treating sepsis, it is
challenging to determine the correct amount of intravenous fluids and
vasopressors for a given patient. While automated reinforcement learning
(RL)-based methods have been used to support these decisions with promising
results, previous studies have relied on relational data. Given the complexity
of modern healthcare data, representing data as a graph may provide a more
natural and effective approach. This study models patient data from the
well-known MIMIC-III dataset as a heterogeneous graph that evolves over time.
Subsequently, we explore two Graph Neural Network architectures - GraphSAGE and
GATv2 - for learning patient state representations, adopting the approach of
decoupling representation learning from policy learning. The encoders are
trained to produce latent state representations, jointly with decoders that
predict the next patient state. These representations are then used for policy
learning with the dBCQ algorithm. The results of our experimental evaluation
confirm the potential of a graph-based approach, while highlighting the
complexity of representation learning in this domain.},
 author = {Taisiya Khakharova and Lucas Sakizloglou and Leen Lambers},
 comment = {18th European Workshop on Reinforcement Learning (EWRL 2025)},
 doi = {},
 eprint = {2509.03393v1},
 journal = {arXiv preprint},
 title = {Exploring a Graph-based Approach to Offline Reinforcement Learning for Sepsis Treatment},
 url = {http://arxiv.org/abs/2509.03393v1},
 year = {2025}
}

@article{2509.05716v1,
 abstract = {Conversational Question Answering (ConvQA) systems have emerged as a pivotal
area within Natural Language Processing (NLP) by driving advancements that
enable machines to engage in dynamic and context-aware conversations. These
capabilities are increasingly being applied across various domains, i.e.,
customer support, education, legal, and healthcare where maintaining a coherent
and relevant conversation is essential. Building on recent advancements, this
survey provides a comprehensive analysis of the state-of-the-art in ConvQA.
This survey begins by examining the core components of ConvQA systems, i.e.,
history selection, question understanding, and answer prediction, highlighting
their interplay in ensuring coherence and relevance in multi-turn
conversations. It further investigates the use of advanced machine learning
techniques, including but not limited to, reinforcement learning, contrastive
learning, and transfer learning to improve ConvQA accuracy and efficiency. The
pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash,
Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact
through data scalability and architectural advancements. Additionally, this
survey presents a comprehensive analysis of key ConvQA datasets and concludes
by outlining open research directions. Overall, this work offers a
comprehensive overview of the ConvQA landscape and provides valuable insights
to guide future advancements in the field.},
 author = {Manoj Madushanka Perera and Adnan Mahmood and Kasun Eranda Wijethilake and Fahmida Islam and Maryam Tahermazandarani and Quan Z. Sheng},
 comment = {42 pages, 12 figures, 4 tables},
 doi = {},
 eprint = {2509.05716v1},
 journal = {arXiv preprint},
 title = {A Survey of the State-of-the-Art in Conversational Question Answering Systems},
 url = {http://arxiv.org/abs/2509.05716v1},
 year = {2025}
}

@article{2509.05775v2,
 abstract = {Estimating heterogeneous treatment effects is critical in domains such as
personalized medicine, resource allocation, and policy evaluation. A central
challenge lies in identifying subpopulations that respond differently to
interventions, thereby enabling more targeted and effective decision-making.
While clustering methods are well-studied in unsupervised learning, their
integration with causal inference remains limited. We propose a novel framework
that clusters individuals based on estimated treatment effects using a learned
kernel derived from causal forests, revealing latent subgroup structures. Our
approach consists of two main steps. First, we estimate debiased Conditional
Average Treatment Effects (CATEs) using orthogonalized learners via the
Robinson decomposition, yielding a kernel matrix that encodes sample-level
similarities in treatment responsiveness. Second, we apply kernelized
clustering to this matrix to uncover distinct, treatment-sensitive
subpopulations and compute cluster-level average CATEs. We present this
kernelized clustering step as a form of regularization within the
residual-on-residual regression framework. Through extensive experiments on
semi-synthetic and real-world datasets, supported by ablation studies and
exploratory analyses, we demonstrate the effectiveness of our method in
capturing meaningful treatment effect heterogeneity.},
 author = {Zilong Wang and Turgay Ayer and Shihao Yang},
 comment = {Pre-print for camera ready version for IEEE EMBS BHI 2025. This work
  has been submitted to the IEEE for possible publication},
 doi = {},
 eprint = {2509.05775v2},
 journal = {arXiv preprint},
 title = {Causal Clustering for Conditional Average Treatment Effects Estimation and Subgroup Discovery},
 url = {http://arxiv.org/abs/2509.05775v2},
 year = {2025}
}

@article{2509.05818v1,
 abstract = {Patients must possess the knowledge necessary to actively participate in
their care. We present NoteAid-Chatbot, a conversational AI that promotes
patient understanding via a novel 'learning as conversation' framework, built
on a multi-agent large language model (LLM) and reinforcement learning (RL)
setup without human-labeled data. NoteAid-Chatbot was built on a lightweight
LLaMA 3.2 3B model trained in two stages: initial supervised fine-tuning on
conversational data synthetically generated using medical conversation
strategies, followed by RL with rewards derived from patient understanding
assessments in simulated hospital discharge scenarios. Our evaluation, which
includes comprehensive human-aligned assessments and case studies, demonstrates
that NoteAid-Chatbot exhibits key emergent behaviors critical for patient
education, such as clarity, relevance, and structured dialogue, even though it
received no explicit supervision for these attributes. Our results show that
even simple Proximal Policy Optimization (PPO)-based reward modeling can
successfully train lightweight, domain-specific chatbots to handle multi-turn
interactions, incorporate diverse educational strategies, and meet nuanced
communication objectives. Our Turing test demonstrates that NoteAid-Chatbot
surpasses non-expert human. Although our current focus is on healthcare, the
framework we present illustrates the feasibility and promise of applying
low-cost, PPO-based RL to realistic, open-ended conversational domains,
broadening the applicability of RL-based alignment methods.},
 author = {Won Seok Jang and Hieu Tran and Manav Mistry and SaiKiran Gandluri and Yifan Zhang and Sharmin Sultana and Sunjae Kown and Yuan Zhang and Zonghai Yao and Hong Yu},
 comment = {Accepted in EMNLP 2025 Findings},
 doi = {},
 eprint = {2509.05818v1},
 journal = {arXiv preprint},
 title = {Chatbot To Help Patients Understand Their Health},
 url = {http://arxiv.org/abs/2509.05818v1},
 year = {2025}
}

@article{2509.05922v1,
 abstract = {This paper provides robust, new evidence on the causal drivers of market
troughs. We demonstrate that conclusions about these triggers are critically
sensitive to model specification, moving beyond restrictive linear models with
a flexible DML average partial effect causal machine learning framework. Our
robust estimates identify the volatility of options-implied risk appetite and
market liquidity as key causal drivers, relationships misrepresented or
obscured by simpler models. These findings provide high-frequency empirical
support for intermediary asset pricing theories. This causal analysis is
enabled by a high-performance nowcasting model that accurately identifies
capitulation events in real-time.},
 author = {Peilin Rao and Randall R. Rojas},
 comment = {Working Paper. 68 pages, 10 figures, 16 tables. Keywords: Causal
  Inference, Machine Learning, Financial Econometrics, Market Microstructure,
  Asset Pricing},
 doi = {},
 eprint = {2509.05922v1},
 journal = {arXiv preprint},
 title = {Predicting Market Troughs: A Machine Learning Approach with Causal Interpretation},
 url = {http://arxiv.org/abs/2509.05922v1},
 year = {2025}
}

@article{2509.08756v1,
 abstract = {Mass casualty incidents (MCIs) overwhelm healthcare systems and demand rapid,
accurate patient-hospital allocation decisions under extreme pressure. Here, we
developed and validated a deep reinforcement learning-based decision-support AI
agent to optimize patient transfer decisions during simulated MCIs by balancing
patient acuity levels, specialized care requirements, hospital capacities, and
transport logistics. To integrate this AI agent, we developed MasTER, a
web-accessible command dashboard for MCI management simulations. Through a
controlled user study with 30 participants (6 trauma experts and 24
non-experts), we evaluated three interaction approaches with the AI agent
(human-only, human-AI collaboration, and AI-only) across 20- and 60-patient MCI
scenarios in the Greater Toronto Area. Results demonstrate that increasing AI
involvement significantly improves decision quality and consistency. The AI
agent outperforms trauma surgeons (p < 0.001) and enables non-experts to
achieve expert-level performance when assisted, contrasting sharply with their
significantly inferior unassisted performance (p < 0.001). These findings
establish the potential for our AI-driven decision support to enhance both MCI
preparedness training and real-world emergency response management.},
 author = {Zhaoxun "Lorenz" Liu and Wagner H. Souza and Jay Han and Amin Madani},
 comment = {},
 doi = {},
 eprint = {2509.08756v1},
 journal = {arXiv preprint},
 title = {Using AI to Optimize Patient Transfer and Resource Utilization During Mass-Casualty Incidents: A Simulation Platform},
 url = {http://arxiv.org/abs/2509.08756v1},
 year = {2025}
}

@article{2509.08788v1,
 abstract = {Considering censored outcomes in survival analysis can lead to quite complex
results in the model setting of causal inference. Causal inference has
attracted a lot of attention over the past few years, but little research has
been done on survival analysis. Even for the only research conducted, the
machine learning method was considered assuming a large sample, which is not
suitable in that the actual data are high dimensional low sample size (HDLSS)
method. Therefore, penalty is considered for numerous covariates, and the
relationship between these covariates and treatment variables is reflected as a
covariate balancing property score (CBPS). It also considers censored results.
To this end, we will try to solve the above-mentioned problems by using
penalized empirical likelihood, which considers both estimating equation and
penalty. The proposed average treatment effect (ATE) estimator possesses the
oracle property, exhibiting key characteristics such as double robustness for
unbiasedness, sparsity in model selection, and asymptotic normality.},
 author = {Byeonghee Lee and Joonsung Kang},
 comment = {18 pages},
 doi = {},
 eprint = {2509.08788v1},
 journal = {arXiv preprint},
 title = {Doubly robust average treatment effect estimation for survival data},
 url = {http://arxiv.org/abs/2509.08788v1},
 year = {2025}
}

@article{2509.09585v1,
 abstract = {Classical portfolio models collapse under structural breaks, while modern
machine-learning allocators adapt flexibly but often at the cost of
transparency and interpretability. This paper introduces Causal PDE-Control
Models (CPCMs), a unifying framework that integrates causal inference,
nonlinear filtering, and forward-backward partial differential equations for
dynamic portfolio optimization. The framework delivers three theoretical
advances: (i) the existence of conditional risk-neutral measures under evolving
information sets; (ii) a projection-divergence duality that quantifies the
stability cost of departing from the causal driver manifold; and (iii) causal
completeness, establishing that a finite driver span can capture all systematic
premia. Classical methods such as Markowitz, CAPM, and Black-Litterman appear
as degenerate cases, while reinforcement learning and deep-hedging policies
emerge as unconstrained, symmetry-breaking approximations. Empirically, CPCM
solvers implemented with physics-informed neural networks achieve higher Sharpe
ratios, lower turnover, and more persistent premia than both econometric and
machine-learning benchmarks, using a global equity panel with more than 300
candidate drivers. By reframing portfolio optimization around structural
causality and PDE control, CPCMs provide a rigorous, interpretable, and
computationally tractable foundation for robust asset allocation under
nonstationary conditions.},
 author = {Alejandro Rodriguez Dominguez},
 comment = {54 pages, 14 pages, 14 figures. Code and data available from authors
  upon request},
 doi = {},
 eprint = {2509.09585v1},
 journal = {arXiv preprint},
 title = {Causal PDE-Control Models: A Structural Framework for Dynamic Portfolio Optimization},
 url = {http://arxiv.org/abs/2509.09585v1},
 year = {2025}
}

@article{2509.09737v1,
 abstract = {We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.},
 author = {Klemen Kotar and Wanhee Lee and Rahul Venkatesh and Honglin Chen and Daniel Bear and Jared Watrous and Simon Kim and Khai Loong Aw and Lilian Naing Chen and Stefan Stojanov and Kevin Feigelis and Imran Thobani and Alex Durango and Khaled Jedoui and Atlas Kazemian and Dan Yamins},
 comment = {},
 doi = {},
 eprint = {2509.09737v1},
 journal = {arXiv preprint},
 title = {World Modeling with Probabilistic Structure Integration},
 url = {http://arxiv.org/abs/2509.09737v1},
 year = {2025}
}

@article{2509.11297v1,
 abstract = {Social robots offer a promising solution for autonomously guiding patients
through physiotherapy exercise sessions, but effective deployment requires
advanced decision-making to adapt to patient needs. A key challenge is the
scarcity of patient behavior data for developing robust policies. To address
this, we engaged 33 expert healthcare practitioners as patient proxies, using
their interactions with our robot to inform a patient behavior model capable of
generating exercise performance metrics and subjective scores on perceived
exertion. We trained a reinforcement learning-based policy in simulation,
demonstrating that it can adapt exercise instructions to individual exertion
tolerances and fluctuating performance, while also being applicable to patients
at different recovery stages with varying exercise plans.},
 author = {Carl Bettosi and Lynne Ballie and Susan Shenkin and Marta Romeo},
 comment = {},
 doi = {},
 eprint = {2509.11297v1},
 journal = {arXiv preprint},
 title = {Policy Learning for Social Robot-Led Physiotherapy},
 url = {http://arxiv.org/abs/2509.11297v1},
 year = {2025}
}

@article{2509.11367v1,
 abstract = {Reinforcement learning (RL) agents typically assume stationary environment
dynamics. Yet in real-world applications such as healthcare, robotics, and
finance, transition probabilities or reward functions may evolve, leading to
model drift. This paper proposes a novel framework to detect such drifts by
analyzing the distributional changes in sequences of agent behavior.
Specifically, we introduce a suite of edit operation-based measures to quantify
deviations between state-action trajectories generated under stationary and
perturbed conditions. Our experiments demonstrate that these measures can
effectively distinguish drifted from non-drifted scenarios, even under varying
levels of noise, providing a practical tool for drift detection in
non-stationary RL environments.},
 author = {Chang-Hwan Lee and Alexander Shim},
 comment = {28 pages, 3 figures, 17 tables},
 doi = {},
 eprint = {2509.11367v1},
 journal = {arXiv preprint},
 title = {Detecting Model Drifts in Non-Stationary Environment Using Edit Operation Measures},
 url = {http://arxiv.org/abs/2509.11367v1},
 year = {2025}
}

@article{2509.12387v1,
 abstract = {Modern deep learning models excel at pattern recognition but remain
fundamentally limited by their reliance on spurious correlations, leading to
poor generalization and a demand for massive datasets. We argue that a key
ingredient for human-like intelligence-robust, sample-efficient learning-stems
from an understanding of causal mechanisms. In this work, we introduce
Causal-Symbolic Meta-Learning (CSML), a novel framework that learns to infer
the latent causal structure of a task distribution. CSML comprises three key
modules: a perception module that maps raw inputs to disentangled symbolic
representations; a differentiable causal induction module that discovers the
underlying causal graph governing these symbols and a graph-based reasoning
module that leverages this graph to make predictions. By meta-learning a shared
causal world model across a distribution of tasks, CSML can rapidly adapt to
novel tasks, including those requiring reasoning about interventions and
counterfactuals, from only a handful of examples. We introduce CausalWorld, a
new physics-based benchmark designed to test these capabilities. Our
experiments show that CSML dramatically outperforms state-of-the-art
meta-learning and neuro-symbolic baselines, particularly on tasks demanding
true causal inference.},
 author = {Mohamed Zayaan S},
 comment = {10 pages, 4 figures},
 doi = {},
 eprint = {2509.12387v1},
 journal = {arXiv preprint},
 title = {Causal-Symbolic Meta-Learning (CSML): Inducing Causal World Models for Few-Shot Generalization},
 url = {http://arxiv.org/abs/2509.12387v1},
 year = {2025}
}

@article{2509.15594v1,
 abstract = {We study the estimation of distributional treatment effects in randomized
experiments with imperfect compliance. When participants do not adhere to their
assigned treatments, we leverage treatment assignment as an instrumental
variable to identify the local distributional treatment effect-the difference
in outcome distributions between treatment and control groups for the
subpopulation of compliers. We propose a regression-adjusted estimator based on
a distribution regression framework with Neyman-orthogonal moment conditions,
enabling robustness and flexibility with high-dimensional covariates. Our
approach accommodates continuous, discrete, and mixed discrete-continuous
outcomes, and applies under a broad class of covariate-adaptive randomization
schemes, including stratified block designs and simple random sampling. We
derive the estimator's asymptotic distribution and show that it achieves the
semiparametric efficiency bound. Simulation results demonstrate favorable
finite-sample performance, and we demonstrate the method's practical relevance
in an application to the Oregon Health Insurance Experiment.},
 author = {Undral Byambadalai and Tomu Hirata and Tatsushi Oka and Shota Yasui},
 comment = {arXiv admin note: text overlap with arXiv:2506.05945},
 doi = {},
 eprint = {2509.15594v1},
 journal = {arXiv preprint},
 title = {Beyond the Average: Distributional Causal Inference under Imperfect Compliance},
 url = {http://arxiv.org/abs/2509.15594v1},
 year = {2025}
}

@article{2509.16027v1,
 abstract = {Coupling probability measures lies at the core of many problems in statistics
and machine learning, from domain adaptation to transfer learning and causal
inference. Yet, even when restricted to deterministic transports, such
couplings are not identifiable: two atomless marginals admit infinitely many
transport maps. The common recourse to optimal transport, motivated by cost
minimization and cyclical monotonicity, obscures the fact that several distinct
notions of multivariate monotone matchings coexist. In this work, we first
carry a comparative analysis of three constructions of transport maps:
cyclically monotone, quantile-preserving and triangular monotone maps. We
establish necessary and sufficient conditions for their equivalence, thereby
clarifying their respective structural properties. In parallel, we formulate
counterfactual reasoning within the framework of structural causal models as a
problem of selecting transport maps between fixed marginals, which makes
explicit the role of untestable assumptions in counterfactual reasoning. Then,
we are able to connect these two perspectives by identifying conditions on
causal graphs and structural equations under which counterfactual maps coincide
with classical statistical transports. In this way, we delineate the
circumstances in which causal assumptions support the use of a specific
structure of transport map. Taken together, our results aim to enrich the
theoretical understanding of families of transport maps and to clarify their
possible causal interpretations. We hope this work contributes to establishing
new bridges between statistical transport and causal inference.},
 author = {Lucas De Lara and Luca Ganassali},
 comment = {37 pages; comments most welcome},
 doi = {},
 eprint = {2509.16027v1},
 journal = {arXiv preprint},
 title = {What is a good matching of probability measures? A counterfactual lens on transport maps},
 url = {http://arxiv.org/abs/2509.16027v1},
 year = {2025}
}

@article{2509.16463v1,
 abstract = {Entropic causal inference is a recent framework for learning the causal graph
between two variables from observational data by finding the
information-theoretically simplest structural explanation of the data, i.e.,
the model with smallest entropy. In our work, we first extend the causal graph
identifiability result in the two-variable setting under relaxed assumptions.
We then show the first identifiability result using the entropic approach for
learning causal graphs with more than two nodes. Our approach utilizes the
property that ancestrality between a source node and its descendants can be
determined using the bivariate entropic tests. We provide a sound sequential
peeling algorithm for general graphs that relies on this property. We also
propose a heuristic algorithm for small graphs that shows strong empirical
performance. We rigorously evaluate the performance of our algorithms on
synthetic data generated from a variety of models, observing improvement over
prior work. Finally we test our algorithms on real-world datasets.},
 author = {Spencer Compton and Kristjan Greenewald and Dmitriy Katz and Murat Kocaoglu},
 comment = {Presented at ICML 2022. This version corrects a bug in semi-synthetic
  experiments},
 doi = {},
 eprint = {2509.16463v1},
 journal = {arXiv preprint},
 title = {Entropic Causal Inference: Graph Identifiability},
 url = {http://arxiv.org/abs/2509.16463v1},
 year = {2025}
}

@article{2509.17180v1,
 abstract = {Many common estimators in machine learning and causal inference are linear
smoothers, where the prediction is a weighted average of the training outcomes.
Some estimators, such as ordinary least squares and kernel ridge regression,
allow for arbitrarily negative weights, which improve feature imbalance but
often at the cost of increased dependence on parametric modeling assumptions
and higher variance. By contrast, estimators like importance weighting and
random forests (sometimes implicitly) restrict weights to be non-negative,
reducing dependence on parametric modeling and variance at the cost of worse
imbalance. In this paper, we propose a unified framework that directly
penalizes the level of extrapolation, replacing the current practice of a hard
non-negativity constraint with a soft constraint and corresponding
hyperparameter. We derive a worst-case extrapolation error bound and introduce
a novel "bias-bias-variance" tradeoff, encompassing biases due to feature
imbalance, model misspecification, and estimator variance; this tradeoff is
especially pronounced in high dimensions, particularly when positivity is poor.
We then develop an optimization procedure that regularizes this bound while
minimizing imbalance and outline how to use this approach as a sensitivity
analysis for dependence on parametric modeling assumptions. We demonstrate the
effectiveness of our approach through synthetic experiments and a real-world
application, involving the generalization of randomized controlled trial
estimates to a target population of interest.},
 author = {David Arbour and Harsh Parikh and Bijan Niknam and Elizabeth Stuart and Kara Rudolph and Avi Feller},
 comment = {},
 doi = {},
 eprint = {2509.17180v1},
 journal = {arXiv preprint},
 title = {Regularizing Extrapolation in Causal Inference},
 url = {http://arxiv.org/abs/2509.17180v1},
 year = {2025}
}

@article{2509.17960v1,
 abstract = {Many research questions -- particularly those in environmental health -- do
not involve binary exposures. In environmental epidemiology, this includes
multivariate exposure mixtures with nondiscrete components. Causal inference
estimands and estimators to quantify the relationship between an exposure
mixture and an outcome are relatively few. We propose an approach to quantify a
relationship between a shift in the exposure mixture and the outcome -- either
in the single timepoint or longitudinal setting. The shift in the exposure
mixture can be defined flexibly in terms of shifting one or more components,
including examining interaction between mixture components, and in terms of
shifting the same or different amounts across components. The estimand we
discuss has a similar interpretation as a main effect regression coefficient.
First, we focus on choosing a shift in the exposure mixture supported by
observed data. We demonstrate how to assess extrapolation and modify the shift
to minimize reliance on extrapolation. Second, we propose estimating the
relationship between the exposure mixture shift and outcome completely
nonparametrically, using machine learning in model-fitting. This is in contrast
to other current approaches, which employ parametric modeling for at least some
relationships, which we would like to avoid because parametric modeling
assumptions in complex, nonrandomized settings are tenuous at best. We are
motivated by longitudinal data on pesticide exposures among participants in the
CHAMACOS Maternal Cognition cohort. We examine the relationship between
longitudinal exposure to agricultural pesticides and risk of hypertension. We
provide step-by-step code to facilitate the easy replication and adaptation of
the approaches we use.},
 author = {Kara E. Rudolph and Shodai Inose and Nicholas Williams and Ivan Diaz and Lucia Calderon and Jacqueline M. Torres and Marianthi-Anna Kioumourtzoglou},
 comment = {},
 doi = {},
 eprint = {2509.17960v1},
 journal = {arXiv preprint},
 title = {Everything all at once: On choosing an estimand for multi-component environmental exposures},
 url = {http://arxiv.org/abs/2509.17960v1},
 year = {2025}
}

@article{2509.18125v1,
 abstract = {Healthcare systems face increasing pressure to allocate limited nursing
resources efficiently while accounting for skill heterogeneity, patient acuity,
staff fatigue, and continuity of care. Traditional optimization and heuristic
scheduling methods struggle to capture these dynamic, multi-constraint
environments. I propose NurseSchedRL, a reinforcement learning framework for
nurse-patient assignment that integrates structured state encoding, constrained
action masking, and attention-based representations of skills, fatigue, and
geographical context. NurseSchedRL uses Proximal Policy Optimization (PPO) with
feasibility masks to ensure assignments respect real-world constraints, while
dynamically adapting to patient arrivals and varying nurse availability. In
simulation with realistic nurse and patient data, NurseSchedRL achieves
improved scheduling efficiency, better alignment of skills to patient needs,
and reduced fatigue compared to baseline heuristic and unconstrained RL
approaches. These results highlight the potential of reinforcement learning for
decision support in complex, high-stakes healthcare workforce management.},
 author = {Harsha Koduri},
 comment = {},
 doi = {},
 eprint = {2509.18125v1},
 journal = {arXiv preprint},
 title = {NurseSchedRL: Attention-Guided Reinforcement Learning for Nurse-Patient Assignment},
 url = {http://arxiv.org/abs/2509.18125v1},
 year = {2025}
}

@article{2509.18433v1,
 abstract = {Utilizing offline reinforcement learning (RL) with real-world clinical data
is getting increasing attention in AI for healthcare. However, implementation
poses significant challenges. Defining direct rewards is difficult, and inverse
RL (IRL) struggles to infer accurate reward functions from expert behavior in
complex environments. Offline RL also encounters challenges in aligning learned
policies with observed human behavior in healthcare applications. To address
challenges in applying offline RL to physical activity promotion for older
adults at high risk of falls, based on wearable sensor activity monitoring, we
introduce Kolmogorov-Arnold Networks and Diffusion Policies for Offline Inverse
Reinforcement Learning (KANDI). By leveraging the flexible function
approximation in Kolmogorov-Arnold Networks, we estimate reward functions by
learning free-living environment behavior from low-fall-risk older adults
(experts), while diffusion-based policies within an Actor-Critic framework
provide a generative approach for action refinement and efficiency in offline
RL. We evaluate KANDI using wearable activity monitoring data in a two-arm
clinical trial from our Physio-feedback Exercise Program (PEER) study,
emphasizing its practical application in a fall-risk intervention program to
promote physical activity among older adults. Additionally, KANDI outperforms
state-of-the-art methods on the D4RL benchmark. These results underscore
KANDI's potential to address key challenges in offline RL for healthcare
applications, offering an effective solution for activity promotion
intervention strategies in healthcare.},
 author = {Chang Liu and Ladda Thiamwong and Yanjie Fu and Rui Xie},
 comment = {Accepted at ICMLA 2025. 8 pages, 6 figures},
 doi = {},
 eprint = {2509.18433v1},
 journal = {arXiv preprint},
 title = {Diffusion Policies with Offline and Inverse Reinforcement Learning for Promoting Physical Activity in Older Adults Using Wearable Sensors},
 url = {http://arxiv.org/abs/2509.18433v1},
 year = {2025}
}

@article{2509.18484v1,
 abstract = {Estimating causal effects on networks is important for both scientific
research and practical applications. Unlike traditional settings that assume
the Stable Unit Treatment Value Assumption (SUTVA), interference allows an
intervention/treatment on one unit to affect the outcomes of others.
Understanding both direct and spillover effects is critical in fields such as
epidemiology, political science, and economics. Causal inference on networks
faces two main challenges. First, causal effects are typically heterogeneous,
varying with unit features and local network structure. Second, connected units
often exhibit dependence due to network homophily, creating confounding between
structural correlations and causal effects. In this paper, we propose a
two-stage method to estimate heterogeneous direct and spillover effects on
networks. The first stage uses graph neural networks to estimate nuisance
components that depend on the complex network topology. In the second stage, we
adjust for network confounding using these estimates and infer causal effects
through a novel attention-based interference model. Our approach balances
expressiveness and interpretability, enabling downstream tasks such as
identifying influential neighborhoods and recovering the sign of spillover
effects. We integrate the two stages using Neyman orthogonalization and
cross-fitting, which ensures that errors from nuisance estimation contribute
only at higher order. As a result, our causal effect estimates are robust to
bias and misspecification in modeling causal effects under network
dependencies.},
 author = {Yuanchen Wu and Yubai Yuan},
 comment = {},
 doi = {},
 eprint = {2509.18484v1},
 journal = {arXiv preprint},
 title = {Estimating Heterogeneous Causal Effect on Networks via Orthogonal Learning},
 url = {http://arxiv.org/abs/2509.18484v1},
 year = {2025}
}

@article{2509.19490v2,
 abstract = {In regression and causal inference, controlled subgroup selection aims to
identify, with inferential guarantees, a subgroup (defined as a subset of the
covariate space) on which the average response or treatment effect is above a
given threshold. E.g., in a clinical trial, it may be of interest to find a
subgroup with a positive average treatment effect. However, existing methods
either lack inferential guarantees, heavily restrict the search for the
subgroup, or sacrifice efficiency by naive data splitting. We propose a novel
framework called chiseling that allows the analyst to interactively refine and
test a candidate subgroup by iteratively shrinking it. The sole restriction is
that the shrinkage direction only depends on the points outside the current
subgroup, but otherwise the analyst may leverage any prior information or
machine learning algorithm. Despite this flexibility, chiseling controls the
probability that the discovered subgroup is null (e.g., has a non-positive
average treatment effect) under minimal assumptions: for example, in randomized
experiments, this inferential validity guarantee holds under only bounded
moment conditions. When applied to a variety of simulated datasets and a real
survey experiment, chiseling identifies substantially better subgroups than
existing methods with inferential guarantees.},
 author = {Nathan Cheng and Asher Spector and Lucas Janson},
 comment = {26+7+97 pages (main text, references, appendix), 6+15 figures (main
  text, appendix); fixed some references},
 doi = {},
 eprint = {2509.19490v2},
 journal = {arXiv preprint},
 title = {Chiseling: Powerful and Valid Subgroup Selection via Interactive Machine Learning},
 url = {http://arxiv.org/abs/2509.19490v2},
 year = {2025}
}

@article{2509.20211v1,
 abstract = {Among explainability techniques, SHAP stands out as one of the most popular,
but often overlooks the causal structure of the problem. In response, do-SHAP
employs interventional queries, but its reliance on estimands hinders its
practical application. To address this problem, we propose the use of
estimand-agnostic approaches, which allow for the estimation of any
identifiable query from a single model, making do-SHAP feasible on complex
graphs. We also develop a novel algorithm to significantly accelerate its
computation at a negligible cost, as well as a method to explain inaccessible
Data Generating Processes. We demonstrate the estimation and computational
performance of our approach, and validate it on two real-world datasets,
highlighting its potential in obtaining reliable explanations.},
 author = {Álvaro Parafita and Tomas Garriga and Axel Brando and Francisco J. Cazorla},
 comment = {Accepted for publication at NeurIPS 2025},
 doi = {},
 eprint = {2509.20211v1},
 journal = {arXiv preprint},
 title = {Practical do-Shapley Explanations with Estimand-Agnostic Causal Inference},
 url = {http://arxiv.org/abs/2509.20211v1},
 year = {2025}
}

@article{2509.20586v1,
 abstract = {Randomized controlled trials (RCTs) are widely regarded as the gold standard
for causal inference in biomedical research. For instance, when estimating the
average treatment effect on the treated (ATT), a doubly robust estimation
procedure can be applied, requiring either the propensity score model or the
control outcome model to be correctly specified. In this paper, we address
scenarios where external control data, often with a much larger sample size,
are available. Such data are typically easier to obtain from historical records
or third-party sources. However, we find that incorporating external controls
into the standard doubly robust estimator for ATT may paradoxically result in
reduced efficiency compared to using the estimator without external controls.
This counterintuitive outcome suggests that the naive incorporation of external
controls could be detrimental to estimation efficiency. To resolve this issue,
we propose a novel doubly robust estimator that guarantees higher efficiency
than the standard approach without external controls, even under model
misspecification. When all models are correctly specified, this estimator
aligns with the standard doubly robust estimator that incorporates external
controls and achieves semiparametric efficiency. The asymptotic theory
developed in this work applies to high-dimensional confounder settings, which
are increasingly common with the growing prevalence of electronic health record
data. We demonstrate the effectiveness of our methodology through extensive
simulation studies and a real-world data application.},
 author = {Chi-Shian Dai and Chao Ying and Yang Ning and Jiwei Zhao},
 comment = {},
 doi = {},
 eprint = {2509.20586v1},
 journal = {arXiv preprint},
 title = {Incorporating External Controls for Estimating the Average Treatment Effect on the Treated with High-Dimensional Data: Retaining Double Robustness and Ensuring Double Safety},
 url = {http://arxiv.org/abs/2509.20586v1},
 year = {2025}
}

@article{2509.21791v1,
 abstract = {Structured output from large language models (LLMs) has enhanced efficiency
in processing generated information and is increasingly adopted in industrial
applications. Prior studies have investigated the impact of structured output
on LLMs' generation quality, often presenting one-way findings. Some suggest
that structured format enhances completeness and factual accuracy, while others
argue that it restricts the reasoning capacity of LLMs and leads to reductions
in standard evaluation metrics. Potential limitations of these assessments
include restricted testing scenarios, weakly controlled comparative settings,
and reliance on coarse metrics. In this work, we present a refined analysis
using causal inference. Based on one assumed and two guaranteed constraints, we
derive five potential causal structures characterizing the influence of
structured output on LLMs' generation: (1) collider without m-bias, (2)
collider with m-bias, (3) single cause from instruction, (4) single cause from
output format, and (5) independence. Across seven public and one developed
reasoning tasks, we find that coarse metrics report positive, negative, or
neutral effects of structured output on GPT-4o's generation. However, causal
inference reveals no causal impact in 43 out of 48 scenarios. In the remaining
5, 3 involve multifaceted causal structures influenced by concrete
instructions.},
 author = {Han Yuan and Yue Zhao and Li Zhang and Wuqiong Luo and Zheng Ma},
 comment = {},
 doi = {},
 eprint = {2509.21791v1},
 journal = {arXiv preprint},
 title = {Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference},
 url = {http://arxiv.org/abs/2509.21791v1},
 year = {2025}
}

@article{2509.22343v1,
 abstract = {Reasoning capability is essential to ensure the factual correctness of the
responses of transformer-based Large Language Models (LLMs), and robust
reasoning about transitive relations is instrumental in many settings, such as
causal inference. Hence, it is essential to investigate the capability of
transformers in the task of inferring transitive relations (e.g., knowing A
causes B and B causes C, then A causes C). The task of inferring transitive
relations is equivalent to the task of connectivity in directed graphs (e.g.,
knowing there is a path from A to B, and there is a path from B to C, then
there is a path from A to C). Past research focused on whether transformers can
learn to infer transitivity from in-context examples provided in the input
prompt. However, transformers' capability to infer transitive relations from
training examples and how scaling affects the ability is unexplored. In this
study, we seek to answer this question by generating directed graphs to train
transformer models of varying sizes and evaluate their ability to infer
transitive relations for various graph sizes. Our findings suggest that
transformers are capable of learning connectivity on "grid-like'' directed
graphs where each node can be embedded in a low-dimensional subspace, and
connectivity is easily inferable from the embeddings of the nodes. We find that
the dimensionality of the underlying grid graph is a strong predictor of
transformers' ability to learn the connectivity task, where higher-dimensional
grid graphs pose a greater challenge than low-dimensional grid graphs. In
addition, we observe that increasing the model scale leads to increasingly
better generalization to infer connectivity over grid graphs. However, if the
graph is not a grid graph and contains many disconnected components,
transformers struggle to learn the connectivity task, especially when the
number of components is large.},
 author = {Amit Roy and Abulhair Saparov},
 comment = {Under Review},
 doi = {},
 eprint = {2509.22343v1},
 journal = {arXiv preprint},
 title = {Transformers Can Learn Connectivity in Some Graphs but Not Others},
 url = {http://arxiv.org/abs/2509.22343v1},
 year = {2025}
}

@article{2509.22531v1,
 abstract = {In observational settings where treatment and outcome share unmeasured
confounders but an observed mediator remains unconfounded, the front-door (FD)
adjustment identifies causal effects through the mediator. We study the
heterogeneous treatment effect (HTE) under FD identification and introduce two
debiased learners: FD-DR-Learner and FD-R-Learner. Both attain fast,
quasi-oracle rates (i.e., performance comparable to an oracle that knows the
nuisances) even when nuisance functions converge as slowly as n^-1/4. We
provide error analyses establishing debiasedness and demonstrate robust
empirical performance in synthetic studies and a real-world case study of
primary seat-belt laws using Fatality Analysis Reporting System (FARS) dataset.
Together, these results indicate that the proposed learners deliver reliable
and sample-efficient HTE estimates in FD scenarios. The implementation is
available at https://github.com/yonghanjung/FD-CATE.
  Keywords: Front-door adjustment; Heterogeneous treatment effects; Debiased
learning; Quasi-oracle rates; Causal inference.},
 author = {Yonghan Jung},
 comment = {27 pages, 3 figures. Preprint. Code available at
  https://github.com/yonghanjung/FD-CATE},
 doi = {},
 eprint = {2509.22531v1},
 journal = {arXiv preprint},
 title = {Debiased Front-Door Learners for Heterogeneous Effects},
 url = {http://arxiv.org/abs/2509.22531v1},
 year = {2025}
}

@article{2509.22553v1,
 abstract = {Causal representation learning (CRL) has garnered increasing interests from
the causal inference and artificial intelligence community, due to its
capability of disentangling potentially complex data-generating mechanism into
causally interpretable latent features, by leveraging the heterogeneity of
modern datasets. In this paper, we further contribute to the CRL literature, by
focusing on the stylized linear structural causal model over the latent
features and assuming a linear mixing function that maps latent features to the
observed data or measurements. Existing linear CRL methods often rely on
stringent assumptions, such as accessibility to single-node interventional data
or restrictive distributional constraints on latent features and exogenous
measurement noise. However, these prerequisites can be challenging to satisfy
in certain scenarios. In this work, we propose a novel linear CRL algorithm
that, unlike most existing linear CRL methods, operates under weaker
assumptions about environment heterogeneity and data-generating distributions
while still recovering latent causal features up to an equivalence class. We
further validate our new algorithm via synthetic experiments and an
interpretability analysis of large language models (LLMs), demonstrating both
its superiority over competing methods in finite samples and its potential in
integrating causality into AI.},
 author = {Hao Chen and Lin Liu and Yu Guang Wang},
 comment = {},
 doi = {},
 eprint = {2509.22553v1},
 journal = {arXiv preprint},
 title = {Linear Causal Representation Learning by Topological Ordering, Pruning, and Disentanglement},
 url = {http://arxiv.org/abs/2509.22553v1},
 year = {2025}
}

@article{2509.25155v1,
 abstract = {The proliferation of large language models (LLMs) has driven demand for long
context inference on resource constrained edge devices. However, deploying
these models on Neural Processing Units (NPUs) presents significant challenges
due to the architectural mismatch: quadratic complexity of standard attention
mechanisms conflicts with memory and compute patterns of edge accelerators.
This paper presents a comprehensive performance analysis of various causal
inference operators on a modern NPU. We benchmark standard quadratic attention
against several sub-quadratic alternatives, including structured state-space
and linear attention models. Our analysis reveals that while sub-quadratic
methods offer superior scalability, they introduce distinct computational
bottlenecks on the NPU's specialized execution units. We identify that
quadratic attention becomes severely memory-bound, suffering from cache
inefficiency and pipeline stalls exceeding 95% at long contexts. In contrast,
sub-quadratic models can become compute-bound on programmable vector cores.
These findings provide critical insights for the co-design of hardware-aware
models and optimization strategies to enable on-device AI inference with
long-contexts.},
 author = {Neelesh Gupta and Rakshith Jayanth and Dhruv Parikh and Viktor Prasanna},
 comment = {IEEE HiPC 2025},
 doi = {},
 eprint = {2509.25155v1},
 journal = {arXiv preprint},
 title = {Context-Driven Performance Modeling for Causal Inference Operators on Neural Processing Units},
 url = {http://arxiv.org/abs/2509.25155v1},
 year = {2025}
}

@article{2509.25535v1,
 abstract = {In language tasks that require extensive human--model interaction, deploying
a single "best" model for every query can be expensive. To reduce inference
cost while preserving the quality of the responses, a large language model
(LLM) router selects the most appropriate model from a pool of candidates for
each query. A central challenge to training a high-quality router is the
scarcity of reliable supervision. Gold-standard data (e.g., expert-verified
labels or rubric-based scores) provide accurate quality evaluations of LLM
responses but are costly and difficult to scale. In contrast, preference-based
data, collected via crowdsourcing or LLM-as-a-judge systems, are cheaper and
more scalable, yet often biased in reflecting the true quality of responses. We
cast the problem of LLM router training with combined gold-standard and
preference-based data into a causal inference framework by viewing the response
evaluation mechanism as the treatment assignment. This perspective further
reveals that the bias in preference-based data corresponds to the well-known
causal estimand: the conditional average treatment effect. Based on this new
perspective, we develop an integrative causal router training framework that
corrects preference-data bias, address imbalances between two data sources, and
improve routing robustness and efficiency. Numerical experiments demonstrate
that our approach delivers more accurate routing and improves the trade-off
between cost and quality.},
 author = {Yichi Zhang and Fangzheng Xie and Shu Yang and Chong Wu},
 comment = {},
 doi = {},
 eprint = {2509.25535v1},
 journal = {arXiv preprint},
 title = {Meta-Router: Bridging Gold-standard and Preference-based Evaluations in Large Language Model Routing},
 url = {http://arxiv.org/abs/2509.25535v1},
 year = {2025}
}

@article{2509.25536v1,
 abstract = {In this paper, we explore the asymptotically optimal tuning parameter choice
in ridge regression for estimating nuisance functions of a statistical
functional that has recently gained prominence in conditional independence
testing and causal inference. Given a sample of size $n$, we study estimators
of the Expected Conditional Covariance (ECC) between variables $Y$ and $A$
given a high-dimensional covariate $X \in \mathbb{R}^p$. Under linear
regression models for $Y$ and $A$ on $X$ and the proportional asymptotic regime
$p/n \to c \in (0, \infty)$, we evaluate three existing ECC estimators and two
sample splitting strategies for estimating the required nuisance functions.
Since no consistent estimator of the nuisance functions exists in the
proportional asymptotic regime without imposing further structure on the
problem, we first derive debiased versions of the ECC estimators that utilize
the ridge regression nuisance function estimators. We show that our bias
correction strategy yields $\sqrt{n}$-consistent estimators of the ECC across
different sample splitting strategies and estimator choices. We then derive the
asymptotic variances of these debiased estimators to illustrate the nuanced
interplay between the sample splitting strategy, estimator choice, and tuning
parameters of the nuisance function estimators for optimally estimating the
ECC. Our analysis reveals that prediction-optimal tuning parameters (i.e.,
those that optimally estimate the nuisance functions) may not lead to the
lowest asymptotic variance of the ECC estimator -- thereby demonstrating the
need to be careful in selecting tuning parameters based on the final goal of
inference. Finally, we verify our theoretical results through extensive
numerical experiments.},
 author = {Sean McGrath and Debarghya Mukherjee and Rajarshi Mukherjee and Zixiao Jolene Wang},
 comment = {},
 doi = {},
 eprint = {2509.25536v1},
 journal = {arXiv preprint},
 title = {Optimal Nuisance Function Tuning for Estimating a Doubly Robust Functional under Proportional Asymptotics},
 url = {http://arxiv.org/abs/2509.25536v1},
 year = {2025}
}

@article{2509.26265v1,
 abstract = {Average and conditional treatment effects are fundamental causal quantities
used to evaluate the effectiveness of treatments in various critical
applications, including clinical settings and policy-making. Beyond the
gold-standard estimators from randomized trials, numerous methods have been
proposed to estimate treatment effects using observational data. In this paper,
we provide a novel characterization of widely used causal inference techniques
within the framework of staged event trees, demonstrating their capacity to
enhance treatment effect estimation. These models offer a distinct advantage
due to their interpretability, making them particularly valuable for practical
applications. We implement classical estimators within the framework of staged
event trees and illustrate their capabilities through both simulation studies
and real-world applications. Furthermore, we showcase how staged event trees
explicitly and visually describe when standard causal assumptions, such as
positivity, hold, further enhancing their practical utility.},
 author = {Gherardo Varando and Manuele Leonelli and Jordi Cerdà-Bautista and Vasileios Sitokonstantinou and Gustau Camps-Valls},
 comment = {},
 doi = {},
 eprint = {2509.26265v1},
 journal = {arXiv preprint},
 title = {Staged Event Trees for Transparent Treatment Effect Estimation},
 url = {http://arxiv.org/abs/2509.26265v1},
 year = {2025}
}

@article{2509.26429v1,
 abstract = {Predicting individualized potential outcomes in sequential decision-making is
central for optimizing therapeutic decisions in personalized medicine (e.g.,
which dosing sequence to give to a cancer patient). However, predicting
potential outcomes over long horizons is notoriously difficult. Existing
methods that break the curse of the horizon typically lack strong theoretical
guarantees such as orthogonality and quasi-oracle efficiency. In this paper, we
revisit the problem of predicting individualized potential outcomes in
sequential decision-making (i.e., estimating Q-functions in Markov decision
processes with observational data) through a causal inference lens. In
particular, we develop a comprehensive theoretical foundation for meta-learners
in this setting with a focus on beneficial theoretical properties. As a result,
we yield a novel meta-learner called DRQ-learner and establish that it is: (1)
doubly robust (i.e., valid inference under the misspecification of one of the
nuisances), (2) Neyman-orthogonal (i.e., insensitive to first-order estimation
errors in the nuisance functions), and (3) achieves quasi-oracle efficiency
(i.e., behaves asymptotically as if the ground-truth nuisance functions were
known). Our DRQ-learner is applicable to settings with both discrete and
continuous state spaces. Further, our DRQ-learner is flexible and can be used
together with arbitrary machine learning models (e.g., neural networks). We
validate our theoretical results through numerical experiments, thereby showing
that our meta-learner outperforms state-of-the-art baselines.},
 author = {Emil Javurek and Valentyn Melnychuk and Jonas Schweisthal and Konstantin Hess and Dennis Frauen and Stefan Feuerriegel},
 comment = {Preprint},
 doi = {},
 eprint = {2509.26429v1},
 journal = {arXiv preprint},
 title = {An Orthogonal Learner for Individualized Outcomes in Markov Decision Processes},
 url = {http://arxiv.org/abs/2509.26429v1},
 year = {2025}
}
