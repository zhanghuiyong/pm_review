TY  - CONF
TI  - SiftIQ: Unraveling the Ethical Dilemma of AI in Healthcare
T2  - 2025 IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)
SP  - 494
EP  - 495
AU  - S. Dhar
AU  - N. Razdan
AU  - S. Razdan
PY  - 2025
KW  - Measurement
KW  - Ethics
KW  - Systematics
KW  - Explainable AI
KW  - Computational modeling
KW  - Medical services
KW  - Rendering (computer graphics)
KW  - Reliability
KW  - Artificial intelligence
KW  - Connected health
KW  - artificial intelligence
KW  - ethical AI
KW  - explainable AI (XAI)
KW  - biases in AI
KW  - AI evaluation
DO  - 
JO  - 2025 IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)
IS  - 
SN  - 2832-2975
VO  - 
VL  - 
JA  - 2025 IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)
Y1  - 24-26 June 2025
AB  - Artificial Intelligence (AI) is revolutionizing medicine, yet whether it is trustworthy remains an open question. Hidden beneath its complex algorithms are biases, unexplained decisions, and unpredictable risks that can mean the difference between life-saving treatments and harmful misdiagnoses. This paper outlines a systematic evaluation framework that puts healthcare AI in the dock—trialing bias, explainability, and reliability through targeted prompts and a risk matrix. By uncovering vulnerabilities and offering a clear path forward for improvement, our approach exceeds blind trust in AI, rendering these systems not only powerful but also fair, transparent, and truly safe for the patients who rely on them.CCS Concepts· Computing methodologies → Artificial intelligence.
ER  - 

TY  - JOUR
TI  - Automated Ensemble Multimodal Machine Learning for Healthcare
T2  - IEEE Journal of Biomedical and Health Informatics
SP  - 4213
EP  - 4226
AU  - F. Imrie
AU  - S. Denner
AU  - L. S. Brunschwig
AU  - K. Maier-Hein
AU  - M. van der Schaar
PY  - 2025
KW  - Predictive models
KW  - Feature extraction
KW  - Data models
KW  - Biological system modeling
KW  - Machine learning
KW  - Data mining
KW  - Automated machine learning
KW  - Medical services
KW  - Transformers
KW  - Pipelines
KW  - Automated machine learning
KW  - biomedicine
KW  - cancer
KW  - deep learning
KW  - healthcare informatics
KW  - machine learning
KW  - medical imaging
KW  - multimodal machine learning
DO  - 10.1109/JBHI.2025.3530156
JO  - IEEE Journal of Biomedical and Health Informatics
IS  - 6
SN  - 2168-2208
VO  - 29
VL  - 29
JA  - IEEE Journal of Biomedical and Health Informatics
Y1  - June 2025
AB  - The application of machine learning in medicine and healthcare has led to the creation of numerous diagnostic and prognostic models. However, despite their success, current approaches generally issue predictions using data from a single modality. This stands in stark contrast with clinician decision-making which employs diverse information from multiple sources. While several multimodal machine learning approaches exist, significant challenges in developing multimodal systems remain that are hindering clinical adoption. In this paper, we introduce a multimodal framework, AutoPrognosis-M, that enables the integration of structured clinical (tabular) data and medical imaging using automated machine learning. AutoPrognosis-M incorporates 17 imaging models, including convolutional neural networks and vision transformers, and three distinct multimodal fusion strategies. In an illustrative application using a multimodal skin lesion dataset, we highlight the importance of multimodal machine learning and the power of combining multiple fusion strategies using ensemble learning. We have open-sourced our framework as a tool for the community and hope it will accelerate the uptake of multimodal machine learning in healthcare and spur further innovation.
ER  - 

TY  - CONF
TI  - Explainable Artificial Intelligence for Breast Cancer Classification Using SHAP: A Comprehensive Analysis
T2  - 2025 International Conference on Emerging Systems and Intelligent Computing (ESIC)
SP  - 566
EP  - 571
AU  - R. K. Nayak
AU  - S. K. Nayak
AU  - K. P. Swain
PY  - 2025
KW  - Accuracy
KW  - Incremental learning
KW  - Explainable AI
KW  - Malignant tumors
KW  - Force
KW  - Medical services
KW  - Predictive models
KW  - Logic gates
KW  - Breast cancer
KW  - Reliability
KW  - Breast Cancer Classification
KW  - Explainable AI
KW  - SHAP
KW  - Machine Learning
KW  - Healthcare Diagnostics
DO  - 10.1109/ESIC64052.2025.10962570
JO  - 2025 International Conference on Emerging Systems and Intelligent Computing (ESIC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Emerging Systems and Intelligent Computing (ESIC)
Y1  - 8-9 Feb. 2025
AB  - Breast cancer is one of the top life-threatening cancers in women around the world which itself suggests there should be an imperative need for accurate and reliable diagnostic tools. Related to the above fact, although machine learning models show excellent performance in classifying instances of breast cancer, often their "black-box" nature limits their acceptance in clinical practice. Explainable AI (XAI) therefore gives a gateway to improving this challenge by making the model predictions more transparent and interpretable, helping the clinicians to further understand and trust the results. This work introduces an interpretable machine learning framework for classifying breast cancer using (SHAP) SHapley Additive exPlanations for explaining model predictions. At first, a breast cancer dataset is analyzed using multiple models where the ExtraTreesClassifier performs with 97% accuracy. Next, the SHAP method is employed to determine the important features in the model for making it globally and locally interpretable in more understandable ways using various types of visualizations such as summary and force plots. This insight contributed much to understanding how the model makes such decisions and hence matching these conclusions with clinical reasoning. The proposed framework provides a high predictive accuracy value with improved interpretability.
ER  - 

TY  - JOUR
TI  - A Comparative Analysis of LIME and SHAP Interpreters With Explainable ML-Based Diabetes Predictions
T2  - IEEE Access
SP  - 37370
EP  - 37388
AU  - S. Ahmed
AU  - M. S. Kaiser
AU  - M. Shahadat Hossain
AU  - K. Andersson
PY  - 2025
KW  - Diabetes
KW  - Machine learning
KW  - Predictive models
KW  - Artificial intelligence
KW  - Medical diagnostic imaging
KW  - Explainable AI
KW  - Data models
KW  - Artificial intelligence
KW  - diabetes prediction
KW  - healthcare
KW  - interpretability
KW  - LIME
KW  - machine learning
KW  - medicine
KW  - SHAP
KW  - XAI
DO  - 10.1109/ACCESS.2024.3422319
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 13
VL  - 13
JA  - IEEE Access
Y1  - 2025
AB  - Explainable artificial intelligence is beneficial in converting opaque machine learning models into transparent ones and outlining how each one makes decisions in the healthcare industry. To comprehend the variables that affect decision-making regarding diabetes prediction that can be accounted for by model-agnostic techniques. In this project, we investigate how to generate local and global explanations for a machine-learning model built on a logistic regression architecture. We trained on 253,680 survey responses from diabetes patients using the explainable AI techniques LIME and SHAP. LIME and SHAP were then used to explain the predictions produced by the logistic regression and Random forest-based model on the validation and test sets. With a discussion of future work, the comparative analysis and discussion of various experimental findings between LIME and SHAP are provided, along with their strengths and weaknesses in terms of interpretation. With a high accuracy of 86% on the test set, we used LR architecture with a spatial attention mechanism, demonstrating the possibility of merging machine learning and explainable AI to improve diabetes prediction, diagnosis, and treatment. We also focus on various applications, difficulties, and probable future directions of machine learning models for LIME and SHAP interpreters.
ER  - 

TY  - CONF
TI  - AI-Driven Clinical Decision Support Systems: Revolutionizing Healthcare With Predictive Models
T2  - 2025 International Conference on Computational, Communication and Information Technology (ICCCIT)
SP  - 560
EP  - 565
AU  - S. Kukreti
AU  - A. Shrivastava
AU  - R. Chandrashekar
AU  - K. P. Rani
AU  - A. Badhoutiya
AU  - S. Lakhanpal
PY  - 2025
KW  - Decision support systems
KW  - Human computer interaction
KW  - Scalability
KW  - Medical services
KW  - Predictive models
KW  - Data models
KW  - Real-time systems
KW  - Internet of Things
KW  - Faces
KW  - Diseases
KW  - AI-Driven CDSS
KW  - Predictive Models
KW  - Healthcare
KW  - Clinical Decision Support
KW  - Machine Learning
DO  - 10.1109/ICCCIT62592.2025.10927929
JO  - 2025 International Conference on Computational, Communication and Information Technology (ICCCIT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Computational, Communication and Information Technology (ICCCIT)
Y1  - 7-8 Feb. 2025
AB  - The integration of artificial intelligence (AI) into Clinical Decision Support Systems (CDSS) is changing the face of healthcare by allowing AI powered predictive, data driven insights, enabling medical practitioners to prolong their diagnosis and treatment planning. To make better and faster clinical judgements, CDSS based on AI using machine learning techniques such as ensemble methods and deep learning is discussed in this paper. He said most of the focus is on models that can predict future events, diagnose plagues and deliver tailored treatment programs sifting through mountains of health care data, such as genetics, medical imaging and EHRs. Some of the main problems we work with as we implement AI driven CDSS is its data privacy, model interpretability and integration to current healthcare processes. In addition this study summarizes recent advances in artificial intelligence (AI), enabling real time analysis and making real time decisions to improve patient outcomes and reduce workloads of healthcare personnel. Case examples that employ AI-CDSS to identify diseases, optimize treatments and predict risk are provided to show how they can change the face of clinical practice. Finally, we explore where AI healthcare may be going from here with a focus on the importance of deploying these systems with patient well being in mind and with full compliance to the relevant regulations.
ER  - 

TY  - CONF
TI  - The Digital Therapist: How Artificial Intelligence is Transforming and Reshaping Mental Healthcare?
T2  - 2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)
SP  - 1
EP  - 6
AU  - R. R. Maaliw
AU  - M. C. Esperal
PY  - 2025
KW  - Ethics
KW  - Reviews
KW  - Digital transformation
KW  - Medical treatment
KW  - Mental health
KW  - Machine learning
KW  - Market research
KW  - Knowledge management
KW  - Artificial intelligence
KW  - Faces
KW  - ethical AI
KW  - digital transformation
KW  - machine learning
KW  - mental health
KW  - psychology
KW  - therapy
DO  - 10.1109/RMKMATE64874.2025.11042299
JO  - 2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 2nd International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)
Y1  - 7-8 May 2025
AB  - Artificial intelligence (AI) is emerging as a "digital therapist", fundamentally transforming healthcare delivery by providing innovative tools for diagnosis. This topic is critical as the world faces mental health crisis with insufficient resources. AI offers scalable solutions to expand access, personalized treatment, and improve outcomes with various services. However, there is a research gap in understanding the extent of its impact and the challenges of integrating these technologies into traditional frameworks. To address the problem, our study examines how AI applications are reshaping mental healthcare, patient engagement, and overall service delivery. Using a narrative review methodology, we synthesized findings from 49 peer-reviewed studies published between 2020 and 2025 by identifying key trends and ethical considerations. We found evidence that AI-driven tools can reduce barriers and improve individualized treatment, but also noted persistent issues related to data privacy and algorithmic bias. In fact, human empathy remains irreplaceable in therapy. These findings reveal that AI’s transformative potential in mental health is substantial yet intricate. Our work contributes to the field by providing a comprehensive overview that informs clinicians, researchers, and policy-makers on leveraging AI effectively and responsibly.
ER  - 

TY  - CONF
TI  - A Systematic Analysis of Machine and Deep Learning Frameworks for Human Resource Attrition Dataset
T2  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
SP  - 1
EP  - 7
AU  - G. Ramani
AU  - L. P. V
PY  - 2025
KW  - Deep learning
KW  - Ethics
KW  - Analytical models
KW  - Accuracy
KW  - Reviews
KW  - Neural networks
KW  - Predictive models
KW  - Data models
KW  - Planning
KW  - Human resource management
KW  - Employee Attrition
KW  - Human Resource Analytics
KW  - Deep Learning
KW  - Turnover Prediction
KW  - Workforce Management
KW  - Neural Networks
KW  - Feature Engineering
KW  - Model Interpretability
KW  - Ethical AI
KW  - Retention Strategies
DO  - 10.1109/AIMLA63829.2025.11041047
JO  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
Y1  - 29-30 April 2025
AB  - Employee attrition poses significant challenges for organizations, affecting productivity, workforce stability, and operational costs. The ability to predict turnover with high accuracy can assist businesses to craft meaningful retention strategies and improve human resource management strategies. This paper, systematically review the literature on using deep learning methods for employee attrition prediction and the capabilities of uncovering complex patterns and relationships from HR data. The study opens with a consideration of common attrition predictors, including job satisfaction and workload, as well as the effect of data preprocessing and feature engineering on model performance. Different deep learning architectures are discussed with respect to applicability and effectiveness in this field. The traditional models are evaluated based on the datasets used and metrics compared, and some discuss common challenges, such as imbalanced data, model interpretability, and ethics. It also looks at practical applications like proactive retention efforts and workforce planning, showcasing the transformative impact of deep learning on human resource analytics. Lastly, the review suggests ways forward for future research in areas such as explainable AI, different architectures, and the need for a more ethical approach to the context in which AI operates to ensure fairness and transparency. The present study aims to provide guidance on using deep learning techniques to solve employee attrition problems for practitioners.
ER  - 

TY  - CHAP
TI  - Chapter 12 Challenges and ethical considerations
T2  - Digital Blockchain: Big Data, Artificial Intelligence, and Virtual Reality in Healthcare Ecosystem
SP  - 219
EP  - 236
AU  - Rishabha Malviya
AU  - Shristy Verma
AU  - Sonali Sundram
AU  - Harshil Shah
PY  - 2025
DO  - 
PB  - De Gruyter
SN  - 9783111574851
UR  - http://ieeexplore.ieee.org/document/11052347
AB  - In the healthcare industry, artificial intelligence (AI) is crucial because it helps with disease diagnosis, treatment planning, and operational efficiency. However, there are issues with biases, data breaches, and ethical consequences. The chapter aims to provide some knowledge on the challenges faced by the researchers of AI in healthcare along with some ethical considerations. Collaboration between AI clinicians can succeed if appropriate governance frameworks are in place. An overview of the challenges and ethical quandaries surrounding AI in healthcare is given in the chapter. Explainable AI techniques address issues with bias and transparency. Data privacy, algorithmic transparency, and ethical issues are among the difficulties. Up skilling medical staff, addressing biases, and obtaining patient consent are all necessary before implementing AI in healthcare. Furthermore, healthcare professionals need to believe in AI for it to be adopted. Research suggests that AI holds promise for enhancing patient outcomes and healthcare delivery. More research is necessary to fully grasp how AI will affect healthcare professionals’ roles and responsibilities.
ER  - 

TY  - JOUR
TI  - Enhancing AI Explainability Through the EXACT Framework: A User-Centric Approach
T2  - IEEE Access
SP  - 98208
EP  - 98228
AU  - S. S. Alhasan
AU  - R. A. Alnanih
PY  - 2025
KW  - Artificial intelligence
KW  - Explainable AI
KW  - Decision making
KW  - User experience
KW  - Stakeholders
KW  - Medical diagnostic imaging
KW  - Faces
KW  - Cognitive science
KW  - Usability
KW  - Psychology
KW  - Cognitive functions
KW  - cognitive theories
KW  - explainable artificial intelligence (XAI)
KW  - human-centered XAI
KW  - human-computer interaction (HCI)
KW  - medical diagnosis tool
DO  - 10.1109/ACCESS.2025.3576234
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 13
VL  - 13
JA  - IEEE Access
Y1  - 2025
AB  - The increasing adoption of Artificial Intelligence (AI) in several industries has created a demand for user-centered explanations that align with how users think and understand concepts. This paper presents EXACT (EXplainable AI with Cognitive Theories), a novel framework that combines cognitive theories that explain how people think and understand with cognitive functions, focusing on perception, memory and language abilities, to improve users’ comprehension of and engagement with artificial intelligence technologies. By aligning cognitive functions with the design principles of Human-Computer Interaction (HCI), which promote user-centered intuitive systems. the framework addresses challenges related to making AI understandable to users with various levels of cognitive abilities. As a proof-of-concept, a self-diagnosis tool was created to demonstrate the framework’s effectiveness. Then, 60 participants were divided into a control group and an experimental group. Participants completed six tasks designed to evaluate their perception, memory, and language-related cognitive functions. The experimental group outperformed the control group across all tasks, demonstrating significantly improved performance. Subjective metrics also supported these findings: the experimental group reported higher levels of understanding (4.60 vs. 2.87), confidence (4.67 vs. 3.07), and clarity (4.87 vs. 2.80) compared to the control group. These findings suggest that EXACT framework significantly enhances user’s functions when using AI systems. However, further research is needed to explore its broader applicability in other contexts and utilize other cognitive functions.
ER  - 

TY  - CONF
TI  - Blockchain-Enabled Federated Learning Systems with Explainable AI: A Review
T2  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
SP  - 1650
EP  - 1656
AU  - N. Potdukhe
AU  - P. Gourshettiwar
AU  - S. Zade
AU  - A. Waghale
PY  - 2025
KW  - Training
KW  - Privacy
KW  - Data privacy
KW  - Explainable AI
KW  - Reviews
KW  - Federated learning
KW  - Data security
KW  - Data models
KW  - Blockchains
KW  - Protection
KW  - Blockchain
KW  - Federated Learning
KW  - Explainable AI
KW  - Privacy
KW  - Decentralized Systems
KW  - Transparency
KW  - Data Security
DO  - 10.1109/ICMLAS64557.2025.10968523
JO  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
Y1  - 10-12 March 2025
AB  - The convergence of Blockchain with Federated Learning (FL) technology and Explainable Artificial Intelligence (XAI) serves as a new framework to solve privacy protection problems, security issues, and interpretability needs. Model training collaborations supported by FL technology allow different entities to develop models while safeguarding raw data from exposure during training processes, thus addressing privacy needs in healthcare and finance. The combined challenges of model vulnerability to malicious attacks, data poisoning vulnerabilities, and explainability issues block broad industrial adoption. Blockchains strengthen FL security systems by providing decentralised solutions that produce unchangeable audit trails through their proof of transparency, immutability, and distributed consensus models. By enabling model interpretability, XAI methods build stakeholder trust and ensure system accountability. The study combines the technologies to analyse current systems and identify gaps that integrated systems should resolve. A detailed review examines explainable blockchain models and privacy preservation methods to tackle performance and implementation limitations within the framework. Combining these technologies builds a transformative process to create secure AI systems that maintain interpretability functions and protect data privacy during system development as researchers develop frameworks for wider application deployment.
ER  - 

TY  - JOUR
TI  - Explainability, Robustness, and Fairness in User-Centric Intelligent Systems: A Systematic Review
T2  - IEEE Transactions on Emerging Topics in Computational Intelligence
SP  - 1
EP  - 26
AU  - I. A. Zahid
AU  - S. Garfan
AU  - M. A. Chyad
AU  - A. S. Albahri
AU  - O. S. Albahri
AU  - A. H. Alamoodi
AU  - M. Deveci
AU  - R. Z. Homod
AU  - L. Alzubaidi
PY  - 2025
KW  - Artificial intelligence
KW  - Intelligent systems
KW  - Robustness
KW  - Systematic literature review
KW  - Taxonomy
KW  - Focusing
KW  - Explainable AI
KW  - Medical services
KW  - User experience
KW  - NIST
KW  - Artificial intelligence
KW  - ethical
KW  - explainability
KW  - fairness
KW  - robustness
KW  - user-centric
DO  - 10.1109/TETCI.2025.3567604
JO  - IEEE Transactions on Emerging Topics in Computational Intelligence
IS  - 
SN  - 2471-285X
VO  - 
VL  - 
JA  - IEEE Transactions on Emerging Topics in Computational Intelligence
Y1  - 
AB  - The demand for tailored user-centric systems is increasing in the evolving landscape of artificial intelligence (AI). This paper systematically explores the literature on user-centric intelligent systems, focusing on three vital dimensions: explainability, robustness, and fairness. By employing a rigorous systematic literature review and adhering to the PRISMA protocol, this study scrutinizes articles from several esteemed online scientific journals—IEEE Xplore, ScienceDirect (SD), Web of Science (WoS), and Scopus. Crafting a coherent taxonomy from insights gained through meticulous analysis, ensuring a comprehensive review. Categorizing the literature by explainability, robustness, and fairness, the resulting taxonomy aids readers in navigating this intricate domain, and each category is investigated through different approaches. Detailed discussions, enriched with insights from challenges, motivations, and recommendations in prior articles, analyse the literature through identified perspectives. This paper explores datasets, methods, and frameworks researchers employ, providing a holistic view of methodologies in user-centric intelligent systems. Going beyond a standard literature review, this work guides readers and future researchers, addressing challenges and advancing user-centric intelligent systems. This paper serves as a significant resource for understanding the current user-centric intelligent systems landscape. As the field evolves, subsequent works can build upon this foundation, exploring the nuanced dimensions of user-centric intelligent systems.
ER  - 

TY  - CONF
TI  - AI, Federated Learning, and Explainable AI for Developing Secure and Robust Healthcare 4.0 Networks
T2  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
SP  - 1
EP  - 6
AU  - K. Shrivastava
AU  - A. H. Jumaah
AU  - A. -H. Adel
AU  - K. A. Jabbar
AU  - M. Kumar Sahu
PY  - 2025
KW  - Training
KW  - Technological innovation
KW  - Accuracy
KW  - Federated learning
KW  - Computational modeling
KW  - Medical services
KW  - Data models
KW  - Safety
KW  - Computational efficiency
KW  - Artificial intelligence
KW  - Adversarial attacks
KW  - Accuracy
KW  - Artificial intelligence
KW  - Computational efficiency
KW  - Data privacy
KW  - Federated learning
KW  - Healthcare
KW  - Model training
KW  - Precision
KW  - Recall
DO  - 10.1109/OTCON65728.2025.11071020
JO  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
Y1  - 9-11 April 2025
AB  - This study presents a secure federated learning architecture to improve shared model training across multiple nodes in healthcare 4.0 networks while prioritizing data privacy and efficiency. Each node in the recommended technique may define its own starting weights based on local datasets and calculate encrypted model modifications before transmitting them to a central collector. This collector combines these modifications to create global model parameters. Nodes receive this data for repeated improvement. While training, the system protects private data via safe gradient aggregation, convergence checks, and differential privacy. A comparative test demonstrates that the recommended strategy outperforms other AI systems with 94% accuracy, 92% precision, and 90% memory. The approach predicts the future well with an F1 score of 91% and an AUC-ROC of 0.96. Its 90% computational efficiency and 10% connection overhead allow it to manage large datasets. The framework's capacity to expand and protect against threats proves its safety and reliability in healthcare. This innovative method solves the technological criteria for AI usage and fosters confidence among healthcare professionals, allowing them to collaborate and be more creative in healthcare applications.
ER  - 

TY  - JOUR
TI  - A Literature Review on Applications of Explainable Artificial Intelligence (XAI)
T2  - IEEE Access
SP  - 41111
EP  - 41140
AU  - K. Kalasampath
AU  - K. N. Spoorthi
AU  - S. Sajeev
AU  - S. S. Kuppa
AU  - K. Ajay
AU  - A. Maruthamuthu
PY  - 2025
KW  - Artificial intelligence
KW  - Explainable AI
KW  - Libraries
KW  - Decision making
KW  - Systematic literature review
KW  - Medical services
KW  - Finance
KW  - Ethics
KW  - Education
KW  - Stakeholders
KW  - XAI
KW  - deep learning
KW  - machine learning
KW  - applications
KW  - challenges
DO  - 10.1109/ACCESS.2025.3546681
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 13
VL  - 13
JA  - IEEE Access
Y1  - 2025
AB  - As AI technologies, particularly deep learning models, have advanced, their inherent “black box” nature has raised significant concerns regarding accountability, fairness, and trust, especially in critical domains such as healthcare, finance, and criminal justice. We present a detailed exploration of XAI, emphasizing its essential role in improving the interpretability and transparency of complex AI systems in various application domains. Health-related applications were notably using XAI, emphasizing diagnostics, and medical imaging. Other notable domains of use of XAI is encompassed environmental and agricultural management, industrial optimization, cybersecurity, finance, transportation, and social media. Furthermore, nascent applications in law, education, and social care underscore the growing influence of XAI. The analysis indicates a prevalent application of local explanation techniques, especially SHAP and LIME, with a preference for SHAP due to its stability and mathematical assurances. Each technique is analysed for its strengths and limitations in providing clear, actionable insights into model decision-making processes, thereby aiding stakeholders in understanding AI behaviour. Ultimately, this document underscores the critical challenges for XAI in fostering user trust, enhancing decision-making processes, and ensuring that AI technologies are utilized responsibly and ethically across various applications, paving the way for a more transparent and accountable AI landscape. We believe that by serving as a guide for future studies in the area, our systematic review contributes to the body of literature on XAI.
ER  - 

TY  - CONF
TI  - Enhanced Healthcare Through Metaverse Integration: Explainable AI and Blockchain for Trust, Security, and Immersive Experiences
T2  - 2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)
SP  - 1
EP  - 7
AU  - B. I. Sowan
AU  - H. Qattous
AU  - M. Fasha
AU  - A. Altarawneh
PY  - 2025
KW  - Training
KW  - Ethics
KW  - Technological innovation
KW  - Solid modeling
KW  - Metaverse
KW  - Medical services
KW  - Blockchains
KW  - Digital twins
KW  - Security
KW  - Medical diagnostic imaging
KW  - Metaverse
KW  - Healthcare
KW  - Virtual Reality
KW  - Artificial Intelligence
KW  - Blockchain
KW  - Digital Twins
DO  - 10.1109/ICCIAA65327.2025.11013241
JO  - 2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)
Y1  - 28-30 April 2025
AB  - The metaverse, a dynamic blend of virtual and augmented reality, holds extraordinary promise for reshaping the healthcare landscape. By integrating advanced technologies such as virtual reality (VR), artificial intelligence (AI), blockchain, and digital twins, the metaverse introduces transformative opportunities in patient care, medical education, and healthcare operations. These tools foster immersive, personalized, and data-driven environments, significantly improving diagnostic precision, therapeutic strategies, and training methodologies. This paper provides a framework to utilize this potential while navigating key concerns, including systems scale, user customization, and ethical adequacy. In that case, the framework's goal should be eliminating existing limitations and barriers within healthcare systems by utilizing state-of-the-art technologies with real-world applications. The framework involves virtual consultation sites that enable provider-patient interactions, intelligent virtual agents with specific care recommendations, blockchain integration for data integrity, and dynamic VR segments that are functional in delivering healthcare education and training. The study focuses on scenario-based modeling and the use of pilot deployment in various healthcare settings to test for practicability and feasibility. The research also emphasizes that ethical issues and inclusion during the design and implementation of the innovations should also consider society's values regarding the medical field and promote equal access to healthcare. This framework proves a comprehensive blueprint for continuous progress and places the metaverse as one cornerstone in the global healthcare system.
ER  - 

TY  - CONF
TI  - Counterfactual AI in Healthcare: Enhancing Decision-Making and Outcome Prediction
T2  - 2025 Seventh International Conference on Computational Intelligence andCommunication Technologies (CCICT)
SP  - 608
EP  - 615
AU  - H. Sharmam
AU  - R. Pradhan
AU  - H. Mogha
AU  - S. Singh
AU  - R. Kumar
PY  - 2025
KW  - Statistical analysis
KW  - Computational modeling
KW  - Autoencoders
KW  - Refining
KW  - Medical services
KW  - Machine learning
KW  - Predictive models
KW  - Generative adversarial networks
KW  - Real-time systems
KW  - Computational complexity
KW  - Counterfactual Modeling
KW  - Personalized Treatment Prediction
KW  - Generative Adversarial Networks (GANs)
KW  - Structural Causal Models (SCMs)
KW  - Healthcare AI
KW  - NLP
KW  - Machine Learning
KW  - Clinical Decision Support
KW  - Variational Autoencoders (VAEs)
KW  - Treatment Effect Estimation
DO  - 10.1109/CCICT65753.2025.00097
JO  - 2025 Seventh International Conference on Computational Intelligence andCommunication Technologies (CCICT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 Seventh International Conference on Computational Intelligence andCommunication Technologies (CCICT)
Y1  - 11-12 April 2025
AB  - Personalized treatment outcome prediction is critical for enhancing patient care and clinical decision-making. This research introduces a novel counterfactual modeling framework that leverages machine learning techniques, including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Structural Causal Models (SCMs), to estimate treatment effects accurately. By addressing confounding biases and enhancing causal inference, our approach improves the reliability of counterfactual outcome predictions. The proposed model is evaluated on real-world healthcare datasets, demonstrating superior performance compared to traditional statistical methods. Despite its advantages, challenges such as data availability, computational complexity, and generalizability remain. Future research will focus on refining causal assumptions, integrating multi-modal data, and improving model interpretability for real-time clinical applications.
ER  - 

TY  - CONF
TI  - Explainable AI for Skin Cancer Classification Unlocking Insights with Grad-Cam and Grad-Cam++
T2  - 2025 International Conference on Circuit, Systems and Communication (ICCSC)
SP  - 1
EP  - 4
AU  - A. El mrabet
AU  - M. Benaly
AU  - B. Kouach
AU  - I. Alihamidi
AU  - L. Hlou
AU  - R. El gouri
PY  - 2025
KW  - Heating systems
KW  - Deep learning
KW  - Accuracy
KW  - Explainable AI
KW  - Pipelines
KW  - Closed box
KW  - Convolutional neural networks
KW  - Lesions
KW  - Medical diagnostic imaging
KW  - Skin cancer
KW  - Skin Cancer Classification
KW  - Explainable AI (XAI)
KW  - Grad-CAM
KW  - Grad-CAM++
KW  - MobileNetV2
KW  - Deep Learning
KW  - Medical Imaging
KW  - Model Interpretability
KW  - Dermatology
KW  - Convolutional Neural Network (CNN)
DO  - 10.1109/ICCSC66714.2025.11134955
JO  - 2025 International Conference on Circuit, Systems and Communication (ICCSC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Circuit, Systems and Communication (ICCSC)
Y1  - 19-20 June 2025
AB  - Skin cancer is a long-term global public health problem with increasing incidence and high mortality, especially for malignant forms like melanoma. Although non-invasive diagnostic methods exist, early detection still relies to a large extent on clinical experience, so researchers have been investigating the use of artificial intelligence (AI) to improve diagnostic precision and efficiency. In this study, we integrate MobileNetV2, a lightweight yet powerful convolutional neural network, into a skin cancer diagnostic pipeline using the ISIC 2024 dataset. The deep learning model achieves a very good degree of diagnostic accuracy with 97.7 % accuracy and 99.2 % recall in differentiating between benign and malignant lesions, hence reducing the risk of false negatives. A novel contribution is the integration of Gradient-weighted Class Activation Mapping (Grad-CAM) and its improved variant, Grad-CAM++, to alleviate the “black-box” aspect of AI models. Both techniques produce visual heatmaps that highlight the most relevant areas in an image, enabling clinicians to have an interpretable rationale for the model's predictions. Comparative studies show that GradCAM++ yields more accurate and clinically meaningful heatmaps, thereby enhancing healthcare professionals' trust in automated diagnosis. This combination of high diagnostic capability, computational efficiency, and improved interpretability foretells widespread clinical adoption and emphasizes the significant role that explainable AI can play in advancing the future of dermatologic medicine.
ER  - 

TY  - CONF
TI  - Deep Learning for Precision Medicine: Advancing Personalized Treatment Plans in Oncology
T2  - 2025 International Conference on Computational, Communication and Information Technology (ICCCIT)
SP  - 536
EP  - 541
AU  - A. Shrivastava
AU  - A. Kotiyal
AU  - A. Jain
AU  - V. S. A. Devi
AU  - B. D. Rao
AU  - S. Bansal
PY  - 2025
KW  - Deep learning
KW  - Biological system modeling
KW  - Precision medicine
KW  - Predictive models
KW  - Oncology
KW  - Prediction algorithms
KW  - Genetics
KW  - Natural language processing
KW  - Medical diagnostic imaging
KW  - Cancer
DO  - 10.1109/ICCCIT62592.2025.10928094
JO  - 2025 International Conference on Computational, Communication and Information Technology (ICCCIT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Computational, Communication and Information Technology (ICCCIT)
Y1  - 7-8 Feb. 2025
AB  - A new approach to cancer care, precision medicine tailors treatments to each patient's specific genetic, molecular, and clinical characteristics. In order to analyze complicated, high-dimensional data and create individualized treatment plans, deep learning—a potent subfield of AI—has arisen as a game-changing tool in this area. Discover how deep learning methods are being used in precision oncology to improve cancer diagnosis, prognosis, and treatment planning in this groundbreaking article. A few examples of notable developments are the use of CNNs to medical image tumor identification and segmentation, RNNs to treatment outcome prediction, and LSTM models to patient survival. More effective and less harmful treatments are possible because too deep learning models that integrate multimodal data, such as genetic sequences, histopathological pictures, and electronic health records. These models can detect new biomarkers and forecast how different medications will affect individual patients. The clinical translation of deep learning models is hindered by a number of obstacles, despite these encouraging improvements. Problems including data scarcity, unequal distribution of classes, and unintelligibility are major roadblocks. Also, to make sure these models are accurate and reliable, they need to be standardized and validated thoroughly before they can be used in clinical processes. Fostering trust and acceptance in therapeutic contexts also requires addressing ethical problems, such as data security, possible biases in algorithmic predictions, and patient privacy. This work offers a thorough analysis of existing approaches, delves into the difficulties and moral concerns, and suggests avenues for further study to improve the use of deep learning in precision oncology. Personalized treatment regimens, made possible by deep learning, have the potential to revolutionize cancer care by vastly increasing patient outcomes.
ER  - 

TY  - JOUR
TI  - XAI-Empowered MRI Analysis for Consumer Electronic Health
T2  - IEEE Transactions on Consumer Electronics
SP  - 1423
EP  - 1431
AU  - A. Amin
AU  - K. Hasan
AU  - M. S. Hossain
PY  - 2025
KW  - Feature extraction
KW  - Magnetic resonance imaging
KW  - Brain modeling
KW  - Medical services
KW  - Deep learning
KW  - Tumors
KW  - Artificial intelligence
KW  - Explainable AI (XAI)
KW  - physics-informed deep learning (PIDL)
KW  - AIGC
KW  - feature extraction method
KW  - consumer health electronics
DO  - 10.1109/TCE.2024.3443203
JO  - IEEE Transactions on Consumer Electronics
IS  - 1
SN  - 1558-4127
VO  - 71
VL  - 71
JA  - IEEE Transactions on Consumer Electronics
Y1  - Feb. 2025
AB  - The intelligent use of artificial intelligence-generated content (AIGC) in magnetic resonance imaging (MRI) analysis is a significant step towards the rapidly advancing field of consumer electronics (CE) used in healthcare. It greatly improves the accuracy and usefulness of diagnostic processes. This paper introduces a novel MRI analysis approach through the lens of AIGC, leveraging physics-informed deep learning (PIDL) models. This integration pioneers a new paradigm in consumer healthcare diagnostics and embeds physics principles into deep learning (DL) models, thus improving interpretability and adherence to physical constraints. Additionally, this method improves the visibility of the healthcare community by integrating explainable AI (XAI) techniques, including gradient-weighted class activation mapping (Grad-CAM) and Local Interpretable Model-Agnostic Explanations (LIME). This approach demonstrates a reasonable precision rate of 96% when applied to brain tumor MRI images. Therefore, this research introduces a new para diagram of applying AIGC in medical imaging analysis within Consumer Healthcare Electronics (CHE).
ER  - 

TY  - JOUR
TI  - Artificial Intelligence (AI) in Patient–Healthcare Relationships: Psychosocial Perspective
T2  - IEEE Access
SP  - 164682
EP  - 164701
AU  - M. J. Saikia
AU  - D. Borthakur
PY  - 2025
KW  - Artificial intelligence
KW  - Medical services
KW  - Medical diagnostic imaging
KW  - Older adults
KW  - Analytical models
KW  - Stakeholders
KW  - Robots
KW  - Pediatrics
KW  - User preference
KW  - Translation
KW  - Artificial intelligence
KW  - AI
KW  - LLMs
KW  - caregivers
KW  - healthcare
KW  - patient
KW  - providers
KW  - psychosocial
KW  - relationships
DO  - 10.1109/ACCESS.2025.3611818
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 13
VL  - 13
JA  - IEEE Access
Y1  - 2025
AB  - As artificial intelligence (AI) becomes increasingly integrated into healthcare–ranging from basic health monitoring tools such as heart rate monitors and sleep tracking apps to advanced systems such as AI–powered software and companion robots, it is vital to better understand how these technologies affect the dynamics of patient–healthcare relationships. This paper aims to provide a comprehensive perspective of existing research examining both the observable and potential effects of AI–enabled technologies on existing relationships and interactions among patients, healthcare providers, and caregivers. It also explores the emerging field of patient–AI engagement. Based on existing research and challenges, this paper proposes a conceptual model, a Healthcare–AI Triadic Relational Model, to facilitate analyze, discuss, and communicate the psychosocial impacts of AI–powered healthcare technologies on these patient–healthcare relationships. The discussion concludes by highlighting key considerations and practical recommendations for the implementation of AI technologies within these relational contexts, aiming to improve healthcare outcomes and uphold a patient-centered approach to care.
ER  - 

TY  - CONF
TI  - Leveraging Cloud-Based Deep Learning for Cardiovascular Diseases Prediction: Challenges and Solutions
T2  - 2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)
SP  - 1
EP  - 6
AU  - S. Kanagaraj
PY  - 2025
KW  - Deep learning
KW  - Accuracy
KW  - Federated learning
KW  - Explainable AI
KW  - Transfer learning
KW  - Data integration
KW  - Medical services
KW  - Predictive models
KW  - Data models
KW  - Cardiovascular diseases
KW  - Cardiovascular Disease (CVD)
KW  - Cloud-Based Deep Learning
KW  - Explainable AI (XAI)
KW  - Model Interpretability
KW  - Federated Learning
KW  - Data Augmentation
KW  - Multi-Modal Data Integration
DO  - 10.1109/ICAECA63854.2025.11012184
JO  - 2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)
Y1  - 4-5 April 2025
AB  - Cardiovascular diseases CVDs are a growing threat to global mortality therefore the need for accurate early prediction of diseases is imperative to improve patient outcome. The cloud-based deep learning model provides powerful CVD prediction solutions using large volumes of multi-structured medical data. But even then there are considerable challenges regarding data privacy, model interpretability, and effectiveness which inhibit effective application in clinics. The objective of this paper is to evaluate the role of explainable AI in the prediction of cardiovascular diseases using cloud based deep learning. Important shortcomings such as lack of model interpretability and trust are also discussed along with solutions to counter them. Here, XAI methods, for example SHAP and LIME may be used to enhance model interpretability. Clarifying the basis for AI predictions can enhance clinician's trust in AI-based decision making systems. Utilizing data augmentation techniques, multi-modal data integration, transfer learning, and other approaches can overcome data challenges and improve prediction outcomes. The paper further addresses the issues of data confidentiality and time multi-structured prediction by exploring federated learning and hybrid cloud models. This paper offers a new perspective in building XAI enhanced cardiovascular disease (CVD) predictive Deep Learning models through the integration of interpretability techniques and cloud infrastructure that will ultimately lead to better results, greater access to the systems, all while allowing the use of more personalized and effective healthcare methods.
ER  - 

TY  - CONF
TI  - Explainable AI and Trust, Design Methodologies to Explore Patients' Perspective
T2  - 2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS)
SP  - 512
EP  - 513
AU  - W. Zhan
AU  - M. Motta
AU  - S. Baez-Lugo
AU  - N. Henchoz
AU  - M. B. Cuadra
AU  - D. R. Lemay
PY  - 2025
KW  - Human computer interaction
KW  - Ethics
KW  - Explainable AI
KW  - Conferences
KW  - User centered design
KW  - Medical services
KW  - Radiology
KW  - Safety
KW  - Stakeholders
KW  - Interviews
KW  - Explainable AI
KW  - Human Computer Interaction
KW  - Radiology
KW  - Patient and Public Involvement
KW  - Trust
KW  - User-Centered
KW  - Design
KW  - Workshop
DO  - 10.1109/CBMS65348.2025.00110
JO  - 2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS)
IS  - 
SN  - 2372-9198
VO  - 
VL  - 
JA  - 2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS)
Y1  - 18-20 June 2025
AB  - This study investigates patient's perspective on the use of AI in healthcare and the role of Explainable AI in this context. Through a co-creative workshop with six participants from diverse disciplines, we investigated the impact of transparency on trust. The findings highlight parallels between AI and doctors as “black boxes,” the complexity of informed consent and the importance of emotional safety. This work serves as a starting point for ongoing research that engages diverse stakeholder groups, to ensure the development of usercentered XAI solutions that can be effectively implemented in clinical practice.
ER  - 

TY  - CONF
TI  - Comparative Analysis of AI Models for Accurate Early Diabetes Detection
T2  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
SP  - 836
EP  - 843
AU  - R. Dodda
AU  - M. M. Ali
AU  - P. Munugala
AU  - R. Rajan
AU  - D. O. Keerthi
PY  - 2025
KW  - Deep learning
KW  - Accuracy
KW  - Machine learning algorithms
KW  - Gaussian processes
KW  - Prediction algorithms
KW  - Diabetes
KW  - Convolutional neural networks
KW  - Decision trees
KW  - Random forests
KW  - Medical diagnostic imaging
KW  - Diabetes Prediction
KW  - Healthcare Analytics
KW  - Random Forest Classifier
KW  - Decision Tree
KW  - GaussianNB
KW  - CNN
DO  - 10.1109/ICMLAS64557.2025.10968152
JO  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
Y1  - 10-12 March 2025
AB  - Diabetes is a common long-term disease with significant health implications, necessitating early and accurate diagnosis to manage and mitigate its impact. The use of deep learning (DL) and machine learning (ML) algorithms is investigated in this study to predict diabetes based on patient-specific factors, including medical history and lifestyle habits. By leveraging various algorithms, the research evaluates and compares their prediction accuracy to identify the most effective model. The findings aim to improve the early detection of diabetes, providing insights into the performance and feasibility of AI-driven diagnostic approaches in healthcare. In the experimental study we have compared machine learning and deep learning algorithms with the same dataset and found that convolutional neural network outperformed other algorithms.
ER  - 

TY  - CONF
TI  - Unlocking the Potential of Deep Learning in Medical Image Analysis
T2  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
SP  - 1
EP  - 7
AU  - R. Joshi
AU  - K. Pandey
AU  - S. Kumari
PY  - 2025
KW  - Deep learning
KW  - Industries
KW  - Image analysis
KW  - Medical services
KW  - Planning
KW  - Reliability
KW  - Noise measurement
KW  - Intelligent systems
KW  - Hemorrhaging
KW  - Medical diagnostic imaging
KW  - Healthcare
KW  - Artificial intelligence
KW  - deep learning
KW  - diseases
KW  - adversarial effect
KW  - medical image analysis
KW  - convolutional neural network
DO  - 10.23919/INDIACom66777.2025.11115816
JO  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
Y1  - 2-4 April 2025
AB  - Deep learning has transformed illness detection and is assisting the healthcare industry in overcoming obstacles related to correctness and reliability to develop effective as well as resilient computer-aided diagnostic tools. Deep learning approaches provide automated AI-driven utilities that need minimum human oversight to execute tasks associated with the medical detection of fractures, malignancies, internal bleeding, preoperative planning, and intra-operative guiding. Nonetheless, deep learning encounters significant challenges within the burgeoning healthcare sector. This article analyzes the primary obstacles facing the deep learning (DL) research and engineering community in the medical image diagnosis, specifically balanced annotated medical image datasets deficiency, adversarial attacks on deep neural networks (DNN) as well as architectures stemming from noisy medical images, patients' & users' lack of trust, along with ethical and privacy concerns of medical data. This research investigates potential for AI autonomy in healthcare by addressing societal trust issues about autonomous intelligent systems.
ER  - 

TY  - CONF
TI  - Brain Tumor Classification Using Explainable Artificial Intelligence
T2  - 2025 International Conference on Next Generation Information System Engineering (NGISE)
SP  - 1
EP  - 6
AU  - A. Sharma
AU  - A. K. Dwivedi
AU  - R. K. Shrivastava
PY  - 2025
KW  - Visualization
KW  - Explainable AI
KW  - Magnetic resonance imaging
KW  - Transfer learning
KW  - Brain tumors
KW  - Medical services
KW  - Convolutional neural networks
KW  - Reliability
KW  - Next generation networking
KW  - Medical diagnostic imaging
KW  - Deep Learning
KW  - CNN
KW  - SHAP
KW  - XAI
KW  - Transfer Learning
KW  - Medical Imagining
DO  - 10.1109/NGISE64126.2025.11085255
JO  - 2025 International Conference on Next Generation Information System Engineering (NGISE)
IS  - 
SN  - 
VO  - 1
VL  - 1
JA  - 2025 International Conference on Next Generation Information System Engineering (NGISE)
Y1  - 28-29 March 2025
AB  - This work discusses a methodology for brain tumor classification using a Convolutional Neural Network (CNN) integrated with explainable AI techniques to enhance model transparency. Using a Kaggle magnetic resonance (MRI) dataset with two classes, tumorous and non-tumorous, this study addresses the challenge of class imbalance through extensive data augmentation, increasing the dataset to approximately 1,000 images per class. After preprocessing, a custom CNN model was trained, achieving a classification accuracy of 90.88%, demonstrating its effectiveness in distinguishing between tumor classes. The model architecture included convolutional, pooling, dense and dropout layers optimized for robust performance on medical imaging data. SHapley Additive Explanations (SHAP) is applied to explain the result of the model, generating visual insight into the features that affect the classification results. This interpretability is critical for clinical applications, allowing healthcare providers to understand and trust AI-assisted decisions in diagnostics. Although the study shows promising results, further validation with extensive and heterogeneous datasets is suggested. The integration of CNNs and XAI techniques like SHAP offers a powerful and transparent framework for brain tumor detection, aiming to support clinicians with reliable and interpretable AIbased diagnostic tools.
ER  - 

TY  - CONF
TI  - Explainable AI for Public Health: Predictive Modelling of Non-Communicable Diseases Risk using SHAP and LIME
T2  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
SP  - 1942
EP  - 1948
AU  - M. S. Ahmad
AU  - R. A. Canessane
PY  - 2025
KW  - Radio frequency
KW  - Support vector machines
KW  - Accuracy
KW  - Explainable AI
KW  - Artificial neural networks
KW  - Predictive models
KW  - Nearest neighbor methods
KW  - Public healthcare
KW  - Random forests
KW  - Stress
KW  - Non-communicable Diseases
KW  - Healthcare AI
KW  - Interpretability
KW  - Random Forest
KW  - SHAP
KW  - LIME
KW  - Deep Neural Networks
KW  - Predictive Modeling
KW  - India
DO  - 10.1109/ICSCDS65426.2025.11166917
JO  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
Y1  - 6-8 Aug. 2025
AB  - Non-communicable diseases (NCDs) are a grave threat to public health in India, as they are a prime contributor to overall morbidity and mortality rates in the country. The economic impact of NCDs in India also poses a lot of challenges, sapping precious and limited resources the country has at its disposal. As the country finds itself in a precarious situation with ever-increasing cases of dangerous diseases like diabetes, cardiovascular problems, and cancer, the need for a data-driven approach to detect and mitigate the impact of these dreadful ailments in the very initial stages assumes an added urgency. Artificial Intelligence (AI) and Machine Learning (ML) have given cause for a lot of hope, demonstrating immense potential for scalable, population-wide predictive modeling. However, despite the promise and the ability of AI and ML, their clinical deployment falls short of expectations. The reasons cited for these include the high level of opacity surrounding many high-performing models, which often leads to a lack of trust, doubtful interpretability, and inability to adhere completely to regulatory requirements. This study deals with a vigorous and explainable predictive framework that integrates six widely used ML classifiers Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest (RF), Multi-Layer Perceptron (MLP), XGBoost, and Deep Neural Networks (DNN)—trained on comprehensive Indian health datasets including NFHS-5, National Health Profile (NHP), and ICMR reports. Feature selection was optimized through techniques such as Elastic Net, SVR-RFE, and SBFS-RF. To ensure the desired transparency, we employed state-of-the-art explainable AI (XAI) techniques SHAP and LIME for both global and local interpretability. Our experiments demonstrated that DNN and XGBoost both constantly achieved top-tier accuracy (95.01% and 94.11%, respectively). However, the higher level of complexity associated with them often inhibited transparency. On the other hand, RF seamlessly combines strong performance (90.01%) with interpretability, and that too with a lower requirement for a higher degree of computational power. This makes it a better candidate for deployment in real-world clinical environments. This work underlines the all-important role of balancing accuracy, credibility, and interpretability in the realm of AI-driven healthcare, while presenting detailed and practical insights for the realistic integration of ML solutions into India’s overburdened and stretched public health infrastructure
ER  - 

TY  - CONF
TI  - Privacy-Centric and Explainable AI Frameworks: Combining Edge Analytics, DAG-based Systems, and GANs for Pandemic Preparedness and Healthcare Innovation
T2  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
SP  - 1255
EP  - 1261
AU  - S. R. Sitaraman
AU  - K. Gattupalli
AU  - V. S. Bhavana Harish Gollavilli
AU  - H. Nagarajan
AU  - P. Alagarsundaram
AU  - R. Nagendran
PY  - 2025
KW  - Technological innovation
KW  - Pandemics
KW  - Explainable AI
KW  - Scalability
KW  - Data security
KW  - Medical services
KW  - Real-time systems
KW  - Blockchains
KW  - Low latency communication
KW  - Next generation networking
KW  - Next-generation healthcare framework
KW  - DAGs
KW  - lightweight CNNs
KW  - Capsule Networks
KW  - real-time diagnostics
KW  - data security
KW  - modular healthcare systems
DO  - 10.1109/ICSCDS65426.2025.11167691
JO  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
Y1  - 6-8 Aug. 2025
AB  - The proposed title effectively emphasizes the integration of AI techniques in healthcare innovation, but could be improved by hyphenizing "DAG-Based Systems" and simplifying the phrasing. The study explores the potential of advanced techniques like lightweight CNNs, blockchain alternatives, and capsule networks in healthcare to improve data confidentiality, diagnostic precision, and real-time processing. It aims to develop a scalable framework using DAGs, GANs, lightweight CNNs, and capsule networks for better scalability and precision. The system incorporates Capsule Networks for enhanced feature representation, lightweight CNNs for real-time illness diagnosis, and blockchain alternatives for safe data processing. The proposed solution has excellent scalability of 1200 TPS, strong data integrity of 99.9%, and great accuracy of 96.4%. Its energy economy and low latency make it suitable for real-time, resource-constrained settings. The abstract has been thoroughly revised to enhance originality and clearly reflect the unique contributions of this study, minimizing similarity with existing literature.
ER  - 

TY  - CONF
TI  - An Explainable AI-Driven Deep Learning Algorithm for Heart Disease Detection in Healthcare
T2  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
SP  - 471
EP  - 477
AU  - A. Singh
AU  - B. P. Alapatt
AU  - J. P. George
PY  - 2025
KW  - Support vector machines
KW  - Deep learning
KW  - Accuracy
KW  - Computational modeling
KW  - Cardiac arrest
KW  - Prediction algorithms
KW  - Real-time systems
KW  - Convolutional neural networks
KW  - Risk management
KW  - Random forests
KW  - Heart Attack Prediction
KW  - Machine Learning
KW  - Random Forest
KW  - XGBoost
KW  - CNN-SVM Hybrid
KW  - Medical Diagnostics
KW  - Predictive Analytics
KW  - Cardiovascular Disease
KW  - Healthcare AI
DO  - 10.1109/ICICV64824.2025.11085482
JO  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
Y1  - 17-19 June 2025
AB  - The application of preprocessed Kaggle data serves as a subject of analysis to investigate heart attack prediction capabilities through machine learning models. The research examines performance outcomes of five algorithms which consist of K-Nearest Neighbors (KNN), Random Forest, Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost) and Convolutional Neural Networks (CNN). Random Forest together with XGBoost proved as the most accurate machine learning models when used for cardiovascular risk assessment. The researchers built a hybrid structure of CNN and SVM because it improved both data classification and feature extraction processes for better prediction outcomes. The training and evaluation process of models encountered difficulties because of overfitting along with high computational expenses and problems regarding optimal hyperparameter settings. The research stresses that explainable AI (XAI) methods should integrate into systems to enhance model interpretability and achieve trust from clinical professionals. Future initiatives seek real-time patient monitoring and innovative interpretability systems for heart attack prediction to enable person-specific diagnoses and optimal clinical choices in medical fields.
ER  - 

TY  - JOUR
TI  - Developing a Transparent Anaemia Prediction Model Empowered With Explainable Artificial Intelligence
T2  - IEEE Access
SP  - 1307
EP  - 1318
AU  - M. Sajid Farooq
AU  - M. Hassan Ghulam Muhammad
AU  - O. Ali
AU  - Z. Zeeshan
AU  - M. Saleem
AU  - M. Ahmad
AU  - S. Abbas
AU  - M. A. Khan
AU  - T. M. Ghazal
PY  - 2025
KW  - Anemia
KW  - Predictive models
KW  - Artificial intelligence
KW  - Medical services
KW  - Accuracy
KW  - Explainable AI
KW  - Diseases
KW  - Closed box
KW  - Support vector machines
KW  - Glass box
KW  - Anaemia prediction
KW  - explainable artificial intelligence
KW  - SHAP
KW  - LIME
DO  - 10.1109/ACCESS.2024.3522080
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 13
VL  - 13
JA  - IEEE Access
Y1  - 2025
AB  - The worldwide health epidemic of anaemia which is a condition with low levels of red blood cells or haemoglobin requires accurate prediction models to act promptly and improve patient outcomes because it is widespread and has different causes. The effective management of anaemia is piled with obstructions, which may include the variability of diagnostic criteria, the resource limitations of healthcare, and the multifactorial nature of the disease including nutritional deficiencies, chronic disease, and genetic factors. Conventional anaemia prediction models, that predominantly rely on statistics and are trained on clinical risk scores, are frequently incapable of providing practical solutions and meaningful insights into anaemia diagnosis. There is a growing interest in focusing on Artificial Intelligence (AI) use for anaemia prediction, however, traditional AI models (black boxes) lack transparency, which causes doctors not to pick them up for practical usage. Actionable insights that are enabled by transparent AI models (white boxes) based on the explainable AI methodologies reveal the rationales of the prediction, clarify the features that are responsible for them, and help clinicians and healthcare providers. In this research work, a transparent anaemia prediction model (white box) empowered by explainable AI techniques is proposed to address the limitations of black boxes in terms of transparency. The proposed model utilizes machine learning algorithms such as Support Vector Machine (SVM), Decision Trees, K-Neighbors Classifier, and Gradient Boosting Classifier, enhanced with Explainable AI (XAI) techniques like SHAP and LIME. With the integration of explainable AI techniques like SHapley Additive exPlanations (SHAP), and Local Interpretable Model-agnostic Explanations (LIME), the proposed model offers insights into the underlying factors influencing anaemia predictions. The proposed model, significantly, represents exceptional growth in the healthcare sector and helps in bridging the gap between predictive performance and clinical interpretability, thus improving patient care and disease management strategies. The model simulation results are showing promising results in terms of the accuracy (98.13%) and the miss-rate (1.87%) which are the superior performance compared to the previous published approaches.
ER  - 

TY  - CONF
TI  - Enhancing Transparency and Trust in AI: the Role of Explainable AI and Visualization Techniques
T2  - 2025 11th International Conference on Communication and Signal Processing (ICCSP)
SP  - 19
EP  - 24
AU  - P. D
AU  - J. K
AU  - A. T. Paul
AU  - D. B. M
AU  - E. M
AU  - S. S. R
PY  - 2025
KW  - Surveys
KW  - Measurement
KW  - Visualization
KW  - Ethics
KW  - Explainable AI
KW  - Finance
KW  - Medical services
KW  - Real-time systems
KW  - Stakeholders
KW  - Artificial intelligence
KW  - Machine learning
KW  - AI
KW  - XAI
KW  - visualization
KW  - post hoc model interpretation
KW  - transparency
KW  - saliency maps
KW  - real-time
DO  - 10.1109/ICCSP64183.2025.11089097
JO  - 2025 11th International Conference on Communication and Signal Processing (ICCSP)
IS  - 
SN  - 2836-1873
VO  - 
VL  - 
JA  - 2025 11th International Conference on Communication and Signal Processing (ICCSP)
Y1  - 5-7 June 2025
AB  - The concepts of Explainable AI (XAI), and visualization methods are crucial in improving the interpretability of the ML models. With AI solutions being used in important industries including healthcare, finance, and autonomous, there is a need to explain the results produced by the models. The following survey focuses on the perspective of visualization in XAI to better illustrate the mechanisms by which models function and which are understandable to users. We present and compare several types of visualizations that might be applied for the given model: model-specific and model-agnostic ones as well as more complex approaches such as saliency maps and counterfactual visualization. The paper also considers the primary use cases for XAI and visualization across the contexts and responds to concerns, including scalability, ethicality, and the dilemma of the explainable accuracy vs. interpretability. Last, it presents future work findings in evaluation metrics, real-time system incorporation, and generative AI for visualization.
ER  - 

TY  - CONF
TI  - Advancements and Challenges in AI-Driven Breast Cancer Detection: A Comprehensive Review
T2  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
SP  - 1
EP  - 6
AU  - P. Kalsi
AU  - I. Sharma
PY  - 2025
KW  - Training
KW  - Deep learning
KW  - Machine learning algorithms
KW  - Ultrasonic imaging
KW  - Reviews
KW  - Medical services
KW  - Transforms
KW  - Breast cancer
KW  - Data models
KW  - Artificial intelligence
KW  - Breast Cancer Detection
KW  - Artificial Intelligence
KW  - Machine Learning
KW  - Deep Learning
DO  - 10.23919/INDIACom66777.2025.11115411
JO  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
Y1  - 2-4 April 2025
AB  - Breast cancer is the most common cause of death among women worldwide, which may decline with advancements in early detection methods. Healthcare has been transformed by Artificial Intelligence (AI), particularly in breast cancer detection. AI algorithms have improved early-stage cancer detection and reduced diagnostic errors by analyzing imaging data such as mammograms, MRIs, ultrasounds, and genomic information. However, evaluating the findings remains a human role. The most recent improvements regarding AI applications, Machine learning (ML), and Deep learning (DL) for breast cancer screening are reviewed in this paper/study. AI still needs developments in clinical practice to overcome challenges such as data scarcity and model explainability and reduce challenges. The training gained from this review that large, encrypted datasets are necessary for training interpretable AI models and for closer integration with conventional healthcare workflows is discussed. Finally, possible applications of AI are reviewed in precision medical techniques with a focus on improving patient care for personalized detection and treatment of breast cancer. While AI has been enhanced during the last years considering diagnosis related to breast cancer, some issues that remain are under consideration for resolution. Using AI in breast cancer diagnosis and treatment offers hope for better healthcare outcomes.
ER  - 

TY  - CONF
TI  - Foundation Models in Digital Pathology Imaging: Next-Generation AI for Healthcare Transformation
T2  - 2025 1st International Conference on Secure IoT, Assured and Trusted Computing (SATC)
SP  - 1
EP  - 5
AU  - M. A. I. Mozumder
AU  - R. I. Sumon
AU  - M. N. Kaysar
AU  - I. Ahmed
AU  - A. Sumiraj
AU  - H. C. Kim
PY  - 2025
KW  - Pathology
KW  - Frequency modulation
KW  - Foundation models
KW  - Biological system modeling
KW  - Computer architecture
KW  - Transformers
KW  - Data models
KW  - Artificial intelligence
KW  - Prognostics and health management
KW  - Tumors
KW  - Artificial Intelligence
KW  - Healthcare
KW  - Foundation models
KW  - Digital pathology
KW  - Image Processing
DO  - 10.1109/SATC65530.2025.11137229
JO  - 2025 1st International Conference on Secure IoT, Assured and Trusted Computing (SATC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 1st International Conference on Secure IoT, Assured and Trusted Computing (SATC)
Y1  - 25-27 Feb. 2025
AB  - Digital pathology has revolutionized the field of pathology by enabling the digitization of glass slides into highresolution whole slide images (WSIs), facilitating seamless storage, sharing, and analysis of histopathological data. This shift from conventional microscopy to digital platforms has opened new possibilities for computational pathology, allowing the application of artificial intelligence (AI) to assist in diagnosis, prognosis, and treatment planning. Pathology is critical in diagnosing and evaluating patient tissue samples, where accuracy and efficiency are paramount. The advent of deep learning and AI technologies has significantly advanced digital pathology by enhancing diagnostic precision, reducing pathologists’ workload, and streamlining decision-making processes. Among AI advancements, foundation models (FMs) have gained significant prominence, offering superior performance over traditional machine learning methods. These models have shown remarkable capabilities in various pathology tasks, including disease diagnosis, rare cancer detection, survival prognosis, and biomarker expression prediction. Despite their promising performance, the clinical application of FMs faces several challenges, such as data quality, interpretability, scalability, and regulatory compliance. This study explores FMs in digital pathology, including their underlying architectures, such as transformers, convolutional neural networks (CNNs), and self-supervised learning approaches. It provides an in-depth analysis of prominent models like Titan, CONCH, and qPath. The review highlights their applications in tumor classification, tissue segmentation, and biomarker detection, while addressing key challenges and opportunities for future research.
ER  - 

TY  - CHAP
TI  - Introduction to AI in Disease Detection &#x2014; An Overview of the Use of AI in Detecting Diseases, Including the Benefits and Limitations of the Technology
T2  - AI in Disease Detection: Advancements and Applications
SP  - 1
EP  - 26
AU  - Arvind Singh Rawat
AU  - Jagadheswaran Rajendran
AU  - Shailendra Singh Sikarwar
PY  - 2025
KW  - Diseases
KW  - Artificial intelligence
KW  - Medical services
KW  - Biological system modeling
KW  - Accuracy
KW  - Data models
KW  - Cancer
KW  - Biomedical imaging
KW  - Federated learning
KW  - Deep learning
DO  - 10.1002/9781394278695.ch1
PB  - IEEE
SN  - 9781394278688
UR  - http://ieeexplore.ieee.org/document/10834001
AB  - Summary <p>The convergence of artificial intelligence (AI) and disease detection signals a sea change in modern medicine. This chapter contributes to this overview by detailing the role of AI in revolutionizing disease diagnosis, focusing on innovations and imminent trends reshaping diagnostic practices. The chapter adds to the debate regarding the pros and cons of AI in disease detection through a critical review, underlining its transformative potential via deep learning algorithms that make the processing of vast amounts of medical data possible at speeds and precisions that were unimaginable before. Out of these developments, several challenges are emerging, such as the &#x201c;black box&#x201d; characteristics of AI models and data privacy and bias issues. It is in this regard that this study brings to the table cutting&#x2010;edge innovations in state&#x2010;of&#x2010;the&#x2010;art AI&#x2010;driven diagnosis techniques: multimodal fusion that assimilates a wide variety of data sources, transfer learning for efficient adaptation of models, explainable AI methods that enhance interpretability and privacy&#x2010;preserving federated learning for diagnostics. Innovation areas under investigation offer great hope for improved diagnostic accuracy, personalization of patient care, and mitigated healthcare disparities. By embracing the advancements and facilitating interdisciplinary collaboration, healthcare stakeholders can allow AI to have the full potential for disruptive change in disease detection toward improving patient outcomes and furthering the paradigm of precision medicine.</p>
ER  - 

TY  - CONF
TI  - Web of Science-based Bibliometric Analysis of AI on Healthcare
T2  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
SP  - 297
EP  - 304
AU  - H. Chauhan
AU  - K. Rawat
AU  - G. K. Kaur
AU  - P. Kumar
AU  - N. Joshi
AU  - S. Singla
PY  - 2025
KW  - Patient monitoring
KW  - Pathology
KW  - Telemedicine
KW  - Surgery
KW  - Machine learning
KW  - Mental health
KW  - Radiology
KW  - Predictive analytics
KW  - Robots
KW  - Medical diagnostic imaging
KW  - artificial intelligence
KW  - healthcare
KW  - machine learning
KW  - medical
DO  - 10.1109/ICICV64824.2025.11085565
JO  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
Y1  - 17-19 June 2025
AB  - The incorporation of Artificial Intelligence (AI) into the healthcare sector is revolutionizing various areas, including clinical practices, administrative functions, and research. AI technologies are enhancing operational effectiveness, improving diagnostic processes, and tailoring treatment plans through the use of virtual health assistants, predictive analytics, and machine learning techniques. AI is also bolstering security and enabling better interoperability, especially when combined with blockchain technology. In the fields of radiology, pathology, and imaging, AI has improved the accuracy of diagnoses, while AI-assisted robotic surgeries provide high precision and less invasive methods. AI also enhances telemedicine services, facilitating remote consultations and ongoing patient monitoring. Nonetheless, there are challenges such as cybersecurity concerns, ethical dilemmas including algorithmic bias, and the necessity for regulatory guidelines. Furthermore, the use of AI is broadening in areas such as mental health services, hospital management, and drug development.
ER  - 

TY  - CONF
TI  - Skin Cancer Detection: A Hybrid Approach Combining CNNs and Explainable AI
T2  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
SP  - 1102
EP  - 1107
AU  - M. K. Kumar
AU  - J. Vaishnavi
AU  - T. Anjibabu
AU  - V. Jayasri
PY  - 2025
KW  - Deep learning
KW  - Accuracy
KW  - Explainable AI
KW  - Medical services
KW  - Data augmentation
KW  - Real-time systems
KW  - Data models
KW  - Convolutional neural networks
KW  - Lesions
KW  - Skin cancer
KW  - Convolutional Neural Network
KW  - Data Augmentation
KW  - DenseNet121
KW  - Explainable AI
KW  - Grad-CAM and Skin Cancer Detection
DO  - 10.1109/ICMLAS64557.2025.10968907
JO  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
Y1  - 10-12 March 2025
AB  - One of the most common and potentially deadly types of cancer is skin cancer, for which prompt and precise detection is essential to successful treatment and better patient outcomes. Conventional diagnostic techniques mostly rely on dermatologists' manual examinations, which can be laborious, subjective, and prone to mistakes, particularly in environments with limited resources. Furthermore, because of their similar visual features, the variety of skin cancer types from vascular lesions to melanoma and actinic keratosis presents further difficulties. In order to overcome these constraints, this study suggests an advanced deep learning-based method for automated skin cancer detection that makes use of Explainable Artificial Intelligence (XAI) and Convolutional Neural Networks (CNN). We utilized the Synthetic Minority Oversampling Technique (SMOTE) to rectify class imbalances and guarantee a well-balanced dataset after performing significant data augmentation strategies to increase data diversity and improve model robustness. This improved dataset was used to train a CNN model using convolutional operations, which demonstrated its capacity to generalize complex patterns in the data with an amazing accuracy of 95%. The DenseNet121 model then achieved an accuracy of 78%. Furthermore, the model's approach to decision-making was made interpretable through the use of XAI techniques like Grad-CAM, which improved understanding of its predictions and promoted confidence among medical experts. This method is a viable way to help dermatologists with early diagnosis and promote AI-driven healthcare solutions because it not only showed great accuracy in identifying skin cancer b
ER  - 

TY  - CONF
TI  - The Role of AI and Machine Learning in Cancer Diagnosis and Treatment
T2  - 2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)
SP  - 1695
EP  - 1700
AU  - T. Gawande
AU  - P. Verma
PY  - 2025
KW  - Technological innovation
KW  - Accuracy
KW  - Federated learning
KW  - Magnetic resonance imaging
KW  - Oncology
KW  - Data models
KW  - Medical diagnosis
KW  - Artificial intelligence
KW  - Medical diagnostic imaging
KW  - Cancer
KW  - Artificial Intelligence (AI)
KW  - Machine Learning (ML)
KW  - Cancer Diagnosis
KW  - Medical Imaging
KW  - Personalized Cancer Treatment
DO  - 10.1109/ICSADL65848.2025.10933321
JO  - 2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)
Y1  - 18-20 Feb. 2025
AB  - AI together with ML technology now provides detailed rapid medical data evaluation to enhance cancer diagnosis and treatment methods. Advanced algorithms installed in these technologies help medical staff identify cancer indicators which human experts commonly miss leading to better diagnostic accuracy. AI-powered Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) scan analysis allows doctors to perform quicker and more efficient medical diagnosis. The usage of ML models enables medical professionals to detect prognostic trace elements thus they can enhance treatment choices by analyzing tumor cell biological classification groups. AI actively participates in protein and gene targeting together with clinical trial planning to move personal cancer treatment forward. AI applications face multiple obstacles that stop their effective adoption in the field of oncology. The majority of present-day barriers to AI implementation in oncology stem from problems with data privacy together with algorithmic biases and model validation methods while the high complexity of systems and decreasing model interpretability specifically hinder usage. The success of AI models depends on extensive and diverse datasets although the actual availability of relevant data sets combined with standardization procedures continues to be difficult. Medical diagnostic applications where AI performs its decision-making work present important transparency issues that create doubts about its effectiveness. The analysis of data privacy through federated learning and XAI for interpretability and transfer learning for efficiency and deep learning for accuracy improvement are recent solutions being researched to resolve these problems. The primary aim of this research explores how AI and ML influence cancer diagnosis together with treatment methods while studying present challenges alongside suggested methods to boost their operational performance. The combination of better data governance together with ethical AI frameworks and model validation protocols makes way for AI and ML to remodel oncology practice with highly personalized efficient trustworthy cancer care solutions.
ER  - 

TY  - CONF
TI  - Deep Learning-Driven Cybersecurity Threat Detection and Mitigation in Saudi Arabia Healthcare System
T2  - 2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)
SP  - 1
EP  - 5
AU  - M. Aljaramiz
AU  - M. Khurana
AU  - F. Aljarameez
AU  - N. Alnasiry
PY  - 2025
KW  - Adaptation models
KW  - Technological innovation
KW  - Accuracy
KW  - Prevention and mitigation
KW  - Phishing
KW  - Medical services
KW  - Threat assessment
KW  - Real-time systems
KW  - Convolutional neural networks
KW  - Ransomware
KW  - Cybersecurity
KW  - Healthcare
KW  - Threat Mitigation
KW  - Bi-LSTM
KW  - CNN
DO  - 10.1109/ITIKD63574.2025.11004975
JO  - 2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)
Y1  - 13-15 April 2025
AB  - Cybersecurity threats in the healthcare industry, particularly in Saudi Arabia, pose significant challenges. As institutions adopt digital technologies under Saudi Arabia's Vision 2030, vulnerabilities to ransomware, phishing, and data breaches escalate. This paper investigates the role of Bidirectional Long Short-Term Memory (Bi-LSTM) and Convolutional Neural Networks (CNN) models in enhancing threat detection and mitigation strategies tailored to Saudi Arabia's unique healthcare requirements. The proposed model achieves 94 % accuracy, with high precision, recall, and F1-score, confirming its reliability in identifying cyber threats. Additionally, we introduce a hybrid deep learning architecture that integrates real-time threat monitoring and adaptive mitigation strategies. Experimental results demonstrate its effectiveness in safeguarding sensitive health care data and ensuring service continuity. These findings underscore the potential of deep learning in strengthening cybersecurity defenses in critical sectors.
ER  - 

TY  - CHAP
TI  - 13 Explainable Artificial Intelligence Techniques in Deep Learning-Based Liver Tumor Analysis
T2  - Math Optimization for Artificial Intelligence: Heuristic and Metaheuristic Methods for Robotics and Machine Learning
SP  - 281
EP  - 302
AU  - R. Manjula Devi
AU  - S. Dheenathayalan
PY  - 2025
DO  - 
PB  - De Gruyter
SN  - 9783111436241
UR  - http://ieeexplore.ieee.org/document/11052446
AB  - As medical imaging technology develops, artificial intelligence (AI) can help radiologists and physicians classify liver tumors accurately and significantly. However, the inherent intricacy of AI models, primarily deep learning algorithms, commonly precludes their adoption because their decision-making processes are opaque and difficult to explain. This chapter proposes a complete architecture that achieves high classification accuracy and offers interpretable perceptions of the model’s choice, addressing the important requirement for explainable AI in liver tumor classification. The proposed system combines existing deep learning architectures with cutting-edge explainable AI (XAI) XAI methods to produce a hybrid model that syndicates predicted accuracy with understandable validations. The model may concentrate on essential areas of medical images and emphasize discriminative features that contribute to its classification conclusions because the framework implements attention mechanisms and feature visualization techniques.
ER  - 

TY  - CONF
TI  - AI-Driven Deep Learning Based Sentiment Analysis with Optimization Healthcare Recommendation System Using CNN and biLSTM
T2  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
SP  - 1
EP  - 6
AU  - S. D. Dip
AU  - M. A. Dewan
AU  - R. A. Mollik
AU  - R. Moni
AU  - J. Dua
AU  - V. K. Dwivedi
PY  - 2025
KW  - Deep learning
KW  - Support vector machines
KW  - Sentiment analysis
KW  - Analytical models
KW  - Accuracy
KW  - Bidirectional long short term memory
KW  - Medical services
KW  - Tokenization
KW  - Bayes methods
KW  - Recommender systems
KW  - Machine Learning
KW  - Healthcare Recommendation
KW  - Deep Learning
KW  - NLP
KW  - Sentiment Analysis
DO  - 10.23919/INDIACom66777.2025.11115182
JO  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 12th International Conference on Computing for Sustainable Global Development (INDIACom)
Y1  - 2-4 April 2025
AB  - Healthcare investigates sentimental analysis by analyzing patients' comments to identify their issues and recommend appropriate specialists. This datasheet contains 6000 patient comments, which were preprocessed using normalization, tokenization, label encoding, and sequence padding. Three models were applied here: Naive Bayes, Support vector machine (SVM), and CNN combined with the biLSM model, achieving an accuracy of 0.9828, 0.9552, and 0.9930, respectively. The hybrid model successfully captured low-level and high-level features by providing strong sentiment classification. This method overcomes problems like delaying diagnosis and constricted access to professionals by helping healthcare providers, which gives them insights into patients’ issues and needs for recommending accurate specialists. By simplifying the processing of patient feedback, it showcases how machine learning and deep learning approach problems and provide suitable solutions. For more trustworthiness and integrity in medical sectors, future research has the potential to improve the system by applying models and growing datasheets.
ER  - 

TY  - CONF
TI  - Unveiling the Potential of Machine Learning and Explainable AI for Enhanced Diabetes Prediction: An Extensive Exploration
T2  - 2025 International Conference on Computing Technologies (ICOCT)
SP  - 1
EP  - 6
AU  - R. R
AU  - R. J
AU  - M. K. B. N
AU  - K. H. G
AU  - R. K. B
PY  - 2025
KW  - Accuracy
KW  - Machine learning algorithms
KW  - Federated learning
KW  - Explainable AI
KW  - Decision making
KW  - Predictive models
KW  - Prediction algorithms
KW  - Diabetes
KW  - Insulin
KW  - Optimization
KW  - MLP
KW  - SHAP
KW  - Diabetes Prediction
KW  - May Fly
KW  - SMOTE
KW  - Healthcare
DO  - 10.1109/ICOCT64433.2025.11118430
JO  - 2025 International Conference on Computing Technologies (ICOCT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Computing Technologies (ICOCT)
Y1  - 13-14 June 2025
AB  - Diabetes is an irreversible metabolic illness marked by elevated blood sugar levels brought on by either insufficient creation of insulin or improper circulating insulin utilization by the organism. Numerous health issues, including as heart, kidney and nerve related damage, may result from it. Proper management through lifestyle changes and Medication is essential for managing diabetes and avoiding its consequences. This study explores the application of machine learning (ML) techniques in diabetes prediction using the Pima Indians Diabetes Dataset. Various models, including Random Forest (RF), Naïve Bayes (NB), Logistic Regression (LR), and Multi-Layer Perceptron (MLP), were evaluated, with MLP emerging as the most effective. The Mayfly Optimization Algorithm was employed to fine-tune hyperparameters, further enhancing model performance. The optimized MLP model achieved a remarkable accuracy of 99.35%. Additionally, SHAP was utilized for model interpretability, ensuring transparency in decision-making. The results demonstrate that combining ML and optimization techniques significantly improves diabetes prediction accuracy, offering a promising approach for early diagnosis and healthcare decision-making.
ER  - 

TY  - CONF
TI  - WoS Driven Bibliometric Analysis of Diabetes Mellitus Prediction Using Machine Learning and Deep Learning
T2  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
SP  - 1
EP  - 6
AU  - I. Kaur
AU  - A. Ali
PY  - 2025
KW  - Deep learning
KW  - Productivity
KW  - Technological innovation
KW  - Bibliometrics
KW  - Urban areas
KW  - Medical services
KW  - Market research
KW  - Diabetes
KW  - Spreadsheet programs
KW  - Software tools
KW  - Diabetes
KW  - Artificial Intelligence
KW  - ML Classifier
KW  - Deep Learning
DO  - 10.1109/OTCON65728.2025.11070435
JO  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
Y1  - 9-11 April 2025
AB  - Diabetes Mellitus is a chronic condition that, if not addressed, can be lethal. AI is immensely benefiting the healthcare industry. When identified early, diabetes can save countless lives. Generating decisions, identifying diabetes, and generating predictions about it have all been more popular in recent years. Diabetes prediction has been the subject of many publications, and new information and techniques are constantly being developed.The application of ML and DL techniques to diabetes research has recently received interest. Nonetheless, very few studies provide a comprehensive view of the knowledge generating ecosystem in this sector. To address this, scientific mapping was carried out utilising bibliometric methodology, which is based on procedures for estimating, quantifying, tracking, and assessing scientific publications published between 2014 and 2024 to identify worldwide research trends and networks, as well as to highlight the most notable nations, institutions, journals, articles, and major themes in this sector. The analysis comprised many scholarly papers from the Web of Science. The data was analysed with Microsoft Excel, ’R’, and Biblioshiny software tools.
ER  - 

TY  - CONF
TI  - Smart Healthcare: Skin Disease Detection With Amazon Recognition
T2  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
SP  - 1355
EP  - 1360
AU  - K. S. D. Varsha
AU  - P. Gayathri
AU  - P. S. S. Subha
AU  - B. Barmavat
AU  - K. S. P. Karey
AU  - I. T. Joseph S
PY  - 2025
KW  - Deep learning
KW  - Cloud computing
KW  - Image analysis
KW  - Accuracy
KW  - Medical services
KW  - Predictive models
KW  - Skin
KW  - Convolutional neural networks
KW  - Medical diagnostic imaging
KW  - Diseases
KW  - Skin Disease Detection
KW  - AWS Rekognition
KW  - Flask API
KW  - Machine Learning
KW  - Medical Image Analysis
KW  - AWS S3
KW  - Deep Learning
KW  - Healthcare AI
DO  - 10.1109/ICIRCA65293.2025.11089798
JO  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
Y1  - 25-27 June 2025
AB  - Skin disorders are one of the most common and visually apparent health conditions, occurring in millions of individuals globally. Diagnosis being accurate and current, nonetheless, is most often hindered by the diminishing number of dermatologists, especially in rural locations. This article examines the application of deep learning techniques in preprocessing skin disease image data, opening the door to automated diagnosis via cloud-based AI platforms. The classification model is driven by Amazon Rekognition, providing a cost-effective and scalable solution for self-diagnosis. We analyzed number of notable research studies that comes after 2016 in the same area, in terms of disease classes, datasets, preprocessing strategies, augmentation strategies, recognition and deep learning methods, metrics, and model accuracy. This paper also compares cloud based machine learning diagnostics with other state of art methods like CNN and results indicate that our proposed method significantly provides better diagnostic precision with the accuracy rate of 98 %, highlighting the scalability and efficacy of cloud-powered AI in the diagnosis of skin diseases.
ER  - 

TY  - CONF
TI  - Managing Healthcare Using Artificial Intelligence
T2  - 2025 International Conference on Computing and Communication Technologies (ICCCT)
SP  - 1
EP  - 8
AU  - A. M. G
AU  - P. R. S
AU  - S. P. R
PY  - 2025
KW  - Patient monitoring
KW  - Technological innovation
KW  - Medical services
KW  - Mental health
KW  - Aging
KW  - Older adults
KW  - Artificial intelligence
KW  - Biomedical monitoring
KW  - Wearable devices
KW  - Standards
KW  - Elderly care
KW  - Patient monitoring system
KW  - Artificial intelligence
KW  - Wearable
KW  - technology
KW  - Healthcare delivery
KW  - Chronic conditions
DO  - 10.1109/ICCCT63501.2025.11020266
JO  - 2025 International Conference on Computing and Communication Technologies (ICCCT)
IS  - 
SN  - 2995-3197
VO  - 
VL  - 
JA  - 2025 International Conference on Computing and Communication Technologies (ICCCT)
Y1  - 16-17 April 2025
AB  - As the global population ages, the demand for innovative healthcare solutions tailored to the needs of elderly individuals has become increasingly urgent. This research explores a novel elderly patient monitoring system powered by artificial intelligence and wearable technology, designed to enhance healthcare delivery for seniors with chronic conditions. Utilizing a mixed-methods approach, the study examines the system's effectiveness in improving patient satisfaction, medication adherence, emergency care utilization, and overall health outcomes. A total of 150 elderly participants were recruited and divided into an experimental group, utilizing the monitoring system, and a control group receiving standard care. Key metrics were evaluated over six months, revealing significant improvements in the experimental group, including a patient satisfaction score increase from 6.5 to 9.1, a reduction in average monthly emergency visits from 3.2 to 1.0, and a medication adherence rate rising from 70% to 92%. Additionally, the monitoring system led to a decrease in readmission rates and improved mental health outcomes. These findings underscore the potential of integrating technology in elderly care, fostering proactive health management and enhancing communication among patients, caregivers, and healthcare providers. This research highlights the need for continued innovation in healthcare delivery systems for seniors, ultimately promoting better health outcomes and quality of life for an increasingly aging population.
ER  - 

TY  - JOUR
TI  - Explainable AI for Audio and Visual Affective Computing: A Scoping Review
T2  - IEEE Transactions on Affective Computing
SP  - 518
EP  - 536
AU  - D. S. Johnson
AU  - O. Hakobyan
AU  - J. Paletschek
AU  - H. Drimalla
PY  - 2025
KW  - Computational modeling
KW  - Affective computing
KW  - Machine learning
KW  - Analytical models
KW  - Reviews
KW  - Explainable AI
KW  - Predictive models
KW  - Data models
KW  - Visualization
KW  - Feature extraction
KW  - Affective machine learning
KW  - audiovisual
KW  - interpretability
KW  - XAI
DO  - 10.1109/TAFFC.2024.3505269
JO  - IEEE Transactions on Affective Computing
IS  - 2
SN  - 1949-3045
VO  - 16
VL  - 16
JA  - IEEE Transactions on Affective Computing
Y1  - April-June 2025
AB  - Affective computing often relies on audiovisual data to identify affective states from non-verbal signals, such as facial expressions and vocal cues. Since automatic affect recognition can be used in sensitive applications, such as healthcare and education, it is crucial to understand how models arrive at their decisions. Interpretability of machine learning models is the goal of the emerging research area of Explainable AI (explainable AI (XAI)). This scoping review aims to survey the field of audiovisual affective machine learning to identify how XAI is applied in this domain. We first provide an overview of XAI concepts relevant to affective computing. Next, following the recommended PRISMA guidelines, we perform a literature search in the ACM, IEEE, Web of Science and PubMed databases. After systematically reviewing 1190 articles, a final set of 65 papers is included in our analysis. We quantitatively summarize the scope, methods and evaluation of the XAI techniques used in the identified papers. Our findings show encouraging developments for using XAI to explain models in audiovisual affective computing, yet only a limited set of methods are used in the reviewed works. Following a critical discussion, we provide recommendations for incorporating interpretability in future work for affective machine learning.
ER  - 

TY  - CONF
TI  - Advancing Clinical Decision-Making using Artificial Intelligence and Machine Learning for Accurate Disease Diagnosis
T2  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
SP  - 164
EP  - 169
AU  - R. Gupta
AU  - T. A. Kakani
AU  - J. Vedula
AU  - M. Mohammed
AU  - K. Hudani
AU  - N. Yuvaraj
PY  - 2025
KW  - Knowledge engineering
KW  - Accuracy
KW  - Image recognition
KW  - Decision making
KW  - Genomics
KW  - Data models
KW  - Natural language processing
KW  - Medical diagnosis
KW  - Electronic medical records
KW  - Diseases
KW  - Data Modalities
KW  - Disease Diagnosis
KW  - Heterogeneous
KW  - Artificial Intelligence
KW  - Machine Learning
DO  - 10.1109/ICICV64824.2025.11085548
JO  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 6th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)
Y1  - 17-19 June 2025
AB  - The paper discusses on how the fusion of AI and ML techniques can lead to more precise disease detections, ultimately revolutionizing clinical decision-making at the diagnostic level. The evolution of computational algorithms and outbursts of healthcare data catalyzed the development of AI and ML models that can improve diagnostic precision. Such models harness large volumes of data (e.g., electronic health records, imaging, genomic data) to discover complex relationships/associations that are likely difficult for human clinicians to recognize. AI systems improve diagnostic accuracy, reduce errors and incorporate predictive modeling of disease prognostics and treatment outcomes using supervised and unsupervised machine learning techniques. It relies heavily on deep learning, natural language processing techniques, and neural networks to process and extract meaning from varying data modalities. The artificial intelligence (AI)-driven decision-support systems helps physicians navigate the growing quantities of data, leading to an improved distribution of workflow and proper distribution of resources. While their potential is already displayed, there remain key barriers: model interpretability, implementation into clinical workflows and data privacy.
ER  - 

TY  - CONF
TI  - Parkinson's Disease Progression Prediction Using Transformer-based Time-Series Models and Explainable AI (XAI)
T2  - 2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220)
SP  - 1
EP  - 6
AU  - S. Perumal
AU  - K. Duraisamy
AU  - G. PV
AU  - S. Rajesh
PY  - 2025
KW  - Accuracy
KW  - Additives
KW  - Explainable AI
KW  - Parkinson's disease
KW  - Medical services
KW  - Predictive models
KW  - Transformers
KW  - Monitoring
KW  - Medical diagnostic imaging
KW  - Context modeling
KW  - Optimized Explainable AI Framework (OEAIF-PD)
KW  - Parkinson's Disease Progression Monitoring
KW  - Unified Parkinson's Disease Rating Scale (UPDRS)
KW  - SHapley Additive exPlanations (SHAP)
KW  - Predictive Accuracy and Transparency in Healthcare
DO  - 10.1109/SENNET64220.2025.11136094
JO  - 2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220)
Y1  - 24-27 July 2025
AB  - This study investigates the application of an Optimized Explainable AI Framework (OEAIF-PD) for the detection and progression monitoring of Parkinson's Disease (PD). The framework uses Machine Learning (ML) to simulate the real-world health care scenarios and forecast the clinical progression considering the Unified Parkinson's Disease Rating Scale (UPDRS) scores of patients, their medication state and synthetic observation data. Besides, feature engineering alongside sliding window helps in handling issues in time-series data that needs preprocessing. In the OEAIF-PD framework, the interpretable model is based on SHapley Additive exPlanations (SHAP) to improve the model’s outcome for confidence by clinicians. In evaluation, the current model, the OEAIF-PD is found to deliver better prediction accuracy that enhances from traditional models through demonstrating lower Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) than the current models. The framework’s stability is confirmed with the residual analysis, and SHAP results reveal major feature importance as the interpretation is improved. The findings in this work illustrate the ability of OEAIF-PD to enhance diagnosis, track PD progression, and confirming Parkinson’s disease, while overcoming the drawbacks of traditional approaches. This approach is best suited to healthcare uses and could easily be replicated in other areas of medicine, presenting a solution that is easily scalable and fully transparent.
ER  - 

TY  - CONF
TI  - An Empirical Evaluation of Machine Learning Models for Stroke Risk Assessment with Explainable AI
T2  - 2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)
SP  - 150
EP  - 157
AU  - J. V. N. Yashwanth Reddy
AU  - G. Sai Saketh Ram
AU  - V. Varshini
AU  - M. Srinivas
PY  - 2025
KW  - Adaptation models
KW  - Accuracy
KW  - Explainable AI
KW  - Medical services
KW  - Predictive models
KW  - Data models
KW  - Risk management
KW  - Reliability
KW  - Socioeconomics
KW  - Random forests
KW  - Stroke
KW  - Machine Learning
KW  - Explainable AI
DO  - 10.1109/AIDE64228.2025.10987490
JO  - 2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)
Y1  - 6-7 Feb. 2025
AB  - Stroke has significant socioeconomic effects, particularly in low- and middle-income nations, and is a major cause of mortality and disability worldwide. This study applies machine learning models to predict stroke, leveraging clinical and demographic data to highlight those who may be at risk. We applied a range of models, including Random Forest, XGBoost, Gradient Boosting, and Neural Networks, after comprehensive data preprocessing. Among these, Random Forest achieved the highest accuracy (98.87%) and ROC AUC (1.0), making it highly effective for stroke risk prediction. We improved transparency in healthcare applications by emphasizing the relevance of individual risk factors in forecasts using LIME for model interpretability.. These findings support the use of ensemble models and explainable AI for reliable, interpretable stroke prediction, paving the way for preventive healthcare.
ER  - 

TY  - CONF
TI  - Machine Learning and Artificial Intelligence for Predictive Modeling in Antimicrobial Resistance Data Sets, Challenges, and Future Directions
T2  - 2025 3rd International Conference on Smart Systems for applications in Electrical Sciences (ICSSES)
SP  - 1
EP  - 6
AU  - A. Sagar
AU  - V. Kolluru
AU  - U. Jaiswal
AU  - G. Kumavat
AU  - S. R. Hole
AU  - A. Kumar
PY  - 2025
KW  - Ethics
KW  - Phenotypes
KW  - Explainable AI
KW  - Antibiotics
KW  - Genomics
KW  - Predictive models
KW  - Data models
KW  - Bioinformatics
KW  - Public healthcare
KW  - Immune system
KW  - AMR
KW  - machine learning
KW  - artificial intelligence
KW  - predictive modeling
KW  - genomic data
KW  - phenotypic data
KW  - public health
KW  - deep learning
KW  - data integration
KW  - explainable AI
KW  - resistance prediction
DO  - 10.1109/ICSSES64899.2025.11009316
JO  - 2025 3rd International Conference on Smart Systems for applications in Electrical Sciences (ICSSES)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Smart Systems for applications in Electrical Sciences (ICSSES)
Y1  - 21-22 March 2025
AB  - The phenomenon of Antimicrobial Resistance (AMR) is emerging strategically rather quickly and efficiently on a global scale. Because of due AMR Corona-virus outbreaks, previously effective antibiotics are becoming obsolete. The situation is only becoming dire as a result of chronic infections, increased deaths and subsequent healthcare expenditures. Increasingly, Artificial Intelligence solutions and Machine Learning strategies are contributing towards optimizing large volume data sets and offer introduction of new intervention methodologies. Within the scope of the current work, we aim to focus on data set amalgamation through Open-Source genomic data along with phenotype and environmental data sets within ML frameworks. While genomic datasets explain portion of resistance around genes, phenotype datasets gather ‘recorded’ datasets of resistance patterns and Environmental datasets monitor the distribution of AMR loops. Opportunities for improving model ethics, integration of data, and addressable generalization gaps to subsequently increase prediction accuracy are studied in focus. Predictability in AMR detection through leveraging AI increases accuracy and optimizes clinical decision-making alongside public health responsiveness. With the help of exact models, it is also possible to predict alterations in the resistance evolution timeline with new resistance genes and while clinically useful to determine right treatment options, they can aid clinical decisions. AI and ML mechanisms enable streamlined AMR surveillance, effectively guiding the direction for inline policy and containment control centers for antibiotic sustainability frameworks. AI, along with ML developments and emergence, is looked upon to take the lead in delays in AMR deployment. ML would intensively work in maintaining the effectiveness of antibiotics and redefining infection healthcare management.
ER  - 

TY  - CONF
TI  - NUTRIC AI: an AI-Assisted Personalized Nutrition Recommendation System
T2  - 2025 11th International Conference on Communication and Signal Processing (ICCSP)
SP  - 891
EP  - 895
AU  - H. N
AU  - K. S
AU  - S. P. G
AU  - S. G
PY  - 2025
KW  - Employee welfare
KW  - Microorganisms
KW  - Explainable AI
KW  - Federated learning
KW  - Medical services
KW  - Chatbots
KW  - Real-time systems
KW  - Planning
KW  - Reliability
KW  - Long short term memory
KW  - Personalized Nutrition
KW  - AI Healthcare
KW  - CNN
KW  - LSTM
KW  - Generative Networks
KW  - Explainable AI
KW  - Food Recognition
KW  - Health Tracking
DO  - 10.1109/ICCSP64183.2025.11089427
JO  - 2025 11th International Conference on Communication and Signal Processing (ICCSP)
IS  - 
SN  - 2836-1873
VO  - 
VL  - 
JA  - 2025 11th International Conference on Communication and Signal Processing (ICCSP)
Y1  - 5-7 June 2025
AB  - In this paper, NUTRIC AI is explained as a cutting-edge AI-assisted personal nutrition advisory system that provides personalized dietary guidelines through the review of individual clinical histories, current medical records, and AI-assisted meal planning. Real-time food recognition is performed by the system via Convolutional Neural Networks (CNNs), and Forecasting of Dietary Patterns is achieved using Long Short-Term Memory (LSTM) networks on past records of health information. Generative Networks are utilized to design personalized meal plans as per the specified dietary needs. For transparency and user confidence induction, the system utilizes Explainable AI (XAI) techniques, i.e., SHAP, to incorporate interpretability in its recommendations. Experimental trials depict substantial gains at a 95% accurate meal planning rate and a 92% user acceptance rate, better than existing available nutrition management platforms. The real-time food scoring system, user-specific dietary advice tailored to a user's own health record, and AI-facilitated chatbot interface are the distinguishing strengths of NUTRIC AI. The convergence of these three features places NUTRIC AI at the forefront of the art of personalized nutritional management.
ER  - 

TY  - CONF
TI  - Personalized Predictive Healthcare Using Machine Learning and Generative AI
T2  - 2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)
SP  - 867
EP  - 872
AU  - S. R. Shetty
AU  - P. K. M K
PY  - 2025
KW  - Support vector machines
KW  - Logistic regression
KW  - Generative AI
KW  - Medical services
KW  - Predictive models
KW  - Nearest neighbor methods
KW  - Bayes methods
KW  - Ensemble learning
KW  - Random forests
KW  - Diseases
KW  - predictive model
KW  - machine learning
KW  - generative AI
KW  - voting ensemble
KW  - personalized healthcare
KW  - disease prediction
DO  - 10.1109/AIDE64228.2025.10987453
JO  - 2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Artificial Intelligence and Data Engineering (AIDE)
Y1  - 6-7 Feb. 2025
AB  - In the modern world, the convergence of technology and healthcare presents an opportunity to deliver individualized and reasonably priced health support at the user’s fingertips. This study offers a system that can serve as a personal health assistant by providing comprehensive health insights and early disease prediction. In order to predict possible health issues, users provide three primary symptoms and basic biographical information like age and gender. Using a voting ensemble model, the system generates a final prediction by integrating predictions from seven machine learning models: decision trees, random forests, naive bayes, logistic regression, SVM, K-nearest neighbors, and XGBoost. The system combines generative AI with predictive analytics to provide comprehensive explanations of the anticipated disease, including causes, symptoms, solutions, and available treatments. The generative AI model gives information that is tailored to each user’s needs by considering factors like age and gender. Evaluation measures that demonstrate the system’s efficacy and dependability include accuracy, precision, recall, and F1-score. By providing easily available health insights, this user-friendly platform raises awareness and makes it easier for people to make educated health decisions.
ER  - 

TY  - CONF
TI  - Explainable Machine Learning-Based Analysis for Identifying Risk Factors of Chronic Obstructive Pulmonary Disease
T2  - 2025 IEEE International Conference on Digital Health (ICDH)
SP  - 78
EP  - 84
AU  - C. Jayanath
AU  - E. Arnaud
AU  - M. Elbattah
PY  - 2025
KW  - Explainable AI
KW  - Prevention and mitigation
KW  - Mental health
KW  - Predictive models
KW  - Chronic obstructive pulmonary disease
KW  - Electronic healthcare
KW  - Public healthcare
KW  - Chronic Obstructive Pulmonary Disease
KW  - COPD
KW  - Explainable Machine Learning
KW  - XAI
DO  - 10.1109/ICDH67620.2025.00020
JO  - 2025 IEEE International Conference on Digital Health (ICDH)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 IEEE International Conference on Digital Health (ICDH)
Y1  - 7-12 July 2025
AB  - Chronic Obstructive Pulmonary Disease (COPD) is a major global health issue. Early detection and identification of risk factors are critical for effective management. This study applies explainable machine learning techniques using LIME and SHAP to analyze a large US dataset and provide interpretable insights into COPD risk factors. While established factors such as smoking and age remain central, the analysis also highlights the underappreciated influence of mental health, physical inactivity, and comorbid conditions. These insights enable a more holistic understanding of COPD risk profiles and support the development of tailored prevention strategies. While limited to US data, the findings pave the way for future studies incorporating diverse populations
ER  - 

TY  - CONF
TI  - AI-Based Cancer Risk Assessment Models: Current Trends Overview
T2  - 2025 International Conference on Cognitive Computing in Engineering, Communications, Sciences and Biomedical Health Informatics (IC3ECSBHI)
SP  - 1
EP  - 8
AU  - S. Jha
AU  - N. Singh
AU  - M. A. Ansari
PY  - 2025
KW  - Deep learning
KW  - Data privacy
KW  - Accuracy
KW  - Prevention and mitigation
KW  - Medical services
KW  - X-rays
KW  - Data models
KW  - Artificial intelligence
KW  - Bioinformatics
KW  - Cancer
KW  - AI
KW  - Deep learning
KW  - X-rays
KW  - Radiomics
DO  - 10.1109/IC3ECSBHI63591.2025.10991254
JO  - 2025 International Conference on Cognitive Computing in Engineering, Communications, Sciences and Biomedical Health Informatics (IC3ECSBHI)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Cognitive Computing in Engineering, Communications, Sciences and Biomedical Health Informatics (IC3ECSBHI)
Y1  - 16-18 Jan. 2025
AB  - Cancer risk assessment is crucial for early cancer detection and prevention, customized treatment plans, and and better results for patients. Artificial intelligence (AI) has transformed the healthcare sector in recent years by providing advanced techniques for improving cancer risk assessment. This review paper provides a thorough overview of the latest advancements in AI-based cancer risk assessment models. We examine a number of AI techniques, including deep learning and machine learning, and how they could be used to the analysis of imaging, genomics, and medical records, among other data sources. The article's primary focus is on significant advancements in AI models that improve workflow integration, interpretability, and predictive accuracy for healthcare settings. We also discuss the difficulties in implementing AI, such as data privacy issues, model biases, and the need for large annotated datasets. This study shows how artificial intelligence (AI) has the potential to transform cancer risk assessment and open the door to more accurate and customized healthcare methods by looking at recent advancements and case studies. To focus continued efforts in this quickly developing field, future research areas and approaches to overcoming present obstacles are also highlighted.
ER  - 

TY  - JOUR
TI  - Bridging the Gap: The Rise of Neurosymbolic Artificial Intelligence in Advanced Computing
T2  - IT Professional
SP  - 48
EP  - 53
AU  - P. Ganguly
AU  - I. Mukherjee
PY  - 2025
KW  - Deep learning
KW  - Neural networks
KW  - Finance
KW  - Medical services
KW  - Market research
KW  - Feature extraction
KW  - Cognition
KW  - Artificial intelligence
KW  - Robots
KW  - Neuroscience
KW  - Symbols
DO  - 10.1109/MITP.2025.3532388
JO  - IT Professional
IS  - 2
SN  - 1941-045X
VO  - 27
VL  - 27
JA  - IT Professional
Y1  - March-April 2025
AB  - Neurosymbolic artificial intelligence (AI) has emerged as a transformative approach, integrating the reasoning capabilities of symbolic AI with the data-driven nature of neural networks. This article discusses the evolution of AI, identifying the distinct advantages and limitations of symbolic and deep learning methodologies. Neurosymbolic AI aims to leverage the strengths of both approaches to enhance decision-making transparency and efficiency, which are crucial in high-stakes domains like health care and law. We explore techniques like embedding symbolic reasoning within neural architectures and utilizing neural networks for feature extraction. These strategies enable the application of neurosymbolic AI across various sectors, including health-care diagnostics, automated financial advising, and robotics. Case studies demonstrate its potential in improving diagnosis accuracy, ensuring regulatory compliance in finance, and enabling adaptive responses in robotics. The article concludes by highlighting emerging trends that are aimed at refining the interaction between neural and symbolic components, fostering more robust and versatile AI applications.
ER  - 

TY  - CONF
TI  - ECG-DPSHAP: An Approach towards Privacy-preserving SHAP-based Explainable AI for 12-lead ECG Classification Model
T2  - 2025 16th International Conference on E-Education, E-Business, E-Management and E-Learning (IC4e)
SP  - 242
EP  - 248
AU  - S. Nuannimnoi
AU  - M. W. Azhar
AU  - K. -H. Chang
AU  - A. Baskoro
AU  - J. A. D. Pratiwi
AU  - C. -Y. Huang
PY  - 2025
KW  - Privacy
KW  - Ethics
KW  - Differential privacy
KW  - Electronic learning
KW  - Additives
KW  - Noise
KW  - Electrocardiography
KW  - Data models
KW  - Medical diagnosis
KW  - Artificial intelligence
KW  - Responsible Artificial Intelligence
KW  - Explainable Artificial Intelligence
KW  - SHapley Additive exPlanations
KW  - Differential privacy
KW  - Electrocardiograms
DO  - 10.1109/IC4e65071.2025.11075395
JO  - 2025 16th International Conference on E-Education, E-Business, E-Management and E-Learning (IC4e)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 16th International Conference on E-Education, E-Business, E-Management and E-Learning (IC4e)
Y1  - 26-29 April 2025
AB  - Deep learning (DL) methods have demonstrated immense potential in healthcare applications, particularly for medical diagnostics, where they enable automated and accurate analysis of complex physiological signals. However, integrating AI into clinical settings presents two fundamental challenges— interpretability and data privacy—both of which are essential for the ethical and responsible deployment of AI-driven healthcare solutions. Ensuring that AI models provide transparent, explainable decisions is crucial for clinician trust and patient safety, while simultaneously preserving sensitive patient data is imperative for compliance with privacy regulations. In this paper, we explore the inherent tension between explainability and privacy preservation in AI-powered medical diagnostics. We then introduce a case study on 12-lead electrocardiogram (ECG) classification and propose a novel approach, ECG-DPSHAP, which integrates differential privacy (DP) mechanisms with SHAP (SHapley Additive Explanations) to safeguard patient data while maintaining the interpretability of model predictions. Through this case study, we systematically analyze the trade-offs between privacy and explainability, identify best practices for balancing these objectives, and outline potential research directions that could further enhance the development of responsible AI solutions in healthcare. Our findings contribute to the ongoing discourse on AI ethics and provide insights into designing privacy-preserving yet interpretable models for real-world clinical applications.
ER  - 

TY  - CONF
TI  - Leveraging Reinforcement Learning and AlphaGo Algorithms for Enhanced Cancer Detection: A Novel Approach in Medical AI
T2  - 2025 International Conference on Next Generation Communication & Information Processing (INCIP)
SP  - 333
EP  - 338
AU  - P. Whig
AU  - I. Batra
AU  - S. N. Jain
AU  - P. Bhattacharya
AU  - S. Redkar
AU  - S. Roy
PY  - 2025
KW  - Adaptation models
KW  - Ethics
KW  - Accuracy
KW  - Sensitivity
KW  - Decision making
KW  - Reinforcement learning
KW  - Cancer detection
KW  - Reliability
KW  - Medical diagnostic imaging
KW  - Cancer
KW  - Reinforcement learning
KW  - AlphaGo
KW  - cancer detection
KW  - artificial intelligence
KW  - medical imaging
KW  - diagnostic accuracy
KW  - machine learning
KW  - healthcare technology
DO  - 10.1109/INCIP64058.2025.11020462
JO  - 2025 International Conference on Next Generation Communication & Information Processing (INCIP)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Next Generation Communication & Information Processing (INCIP)
Y1  - 23-24 Jan. 2025
AB  - Advancements in artificial intelligence (AI) have opened new avenues for enhancing healthcare outcomes, particularly in the field of cancer detection. This research paper investigates the application of reinforcement learning (RL) and AlphaGo algorithms to improve cancer detection accuracy and efficiency. By integrating the strategic decision-making capabilities of AlphaGo with the adaptive learning approach of RL, we propose a novel AI model designed to analyze medical imaging data for the early and precise identification of malignant cells. Our experiments, conducted on a large dataset of 10,000 labeled medical images, demonstrate significant improvements in key performance metrics, including accuracy, sensitivity, specificity, precision, and the F1-score, compared to traditional machine learning models. The proposed model achieved an accuracy of 94.7%, a sensitivity of 92.3%, and a specificity of 96.8%. These findings highlight the potential of RL and AlphaGo algorithms to revolutionize cancer diagnostics, offering more reliable and timely detection methods. The study also addresses the challenges and ethical considerations of implementing AI in clinical settings, emphasizing the need for transparent and interpretable systems. This research suggests a promising future for AI-driven cancer detection, ultimately aiming to improve patient outcomes and healthcare efficiency.
ER  - 

TY  - CONF
TI  - Exploring the need of a Responsible AI Framework for Healthcare: Key Considerations for Developing Countries
T2  - 2025 International Conference on Software, Knowledge, Information Management & Applications (SKIMA)
SP  - 1
EP  - 6
AU  - H. K. Neupane
AU  - B. Kumar Mishra
AU  - D. Thakker
AU  - K. Aslansefat
AU  - W. Jones
AU  - P. Simkhada
PY  - 2025
KW  - Surveys
KW  - Ethics
KW  - Privacy
KW  - Regulators
KW  - Focusing
KW  - Developing countries
KW  - Safety
KW  - Stakeholders
KW  - Artificial intelligence
KW  - Guidelines
KW  - Responsible AI
KW  - Healthcare
KW  - Developing Countries
KW  - Bias
KW  - Transparency
KW  - Safety
KW  - Privacy
KW  - Ethics
KW  - Local Context
DO  - 10.1109/SKIMA66621.2025.11155588
JO  - 2025 International Conference on Software, Knowledge, Information Management & Applications (SKIMA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Software, Knowledge, Information Management & Applications (SKIMA)
Y1  - 9-11 June 2025
AB  - Artificial intelligence (AI) is transforming the healthcare landscape globally. However, the unregulated use of AI tools and models raises concerns about patient safety, particularly in developing countries. This study aims to explore the necessity of a Responsible AI (RAI) framework in developing nations, focusing on Nepal and Ghana. By reviewing established AI guidelines, engaging with stakeholders from Nepal and Ghana, observing their existing digital healthcare systems for AI readiness, and conducting a survey, we identify key components around opportunity and ethical concerns for AI adoption in their healthcare system. Our analysis reveals a lack of advanced medical technology infrastructure, and the risks associated with unregulated AI use, which compromise patient safety. This advocates the urgent need for an RAI framework to ensure ethical AI integration tailored to local contexts, addressing risks related to AI model transparency, data bias, privacy, and safety. The findings provide practical insights for regulators in developing countries for designing, implementing, and governing AI-driven healthcare solutions using the localised RAI Framework.
ER  - 

TY  - CONF
TI  - Federated Learning-Based Human-Robot Collaboration with Explainable AI: A Framework for Secure and Transparent Interaction
T2  - 2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE)
SP  - 1
EP  - 5
AU  - P. Marimuktu
AU  - R. R. Subramanian
PY  - 2025
KW  - Training
KW  - Federated learning
KW  - Explainable AI
KW  - Service robots
KW  - Scalability
KW  - Human-robot interaction
KW  - Collaboration
KW  - Robot sensing systems
KW  - Security
KW  - Testing
KW  - Human-Robot Collaboration
KW  - XAI
KW  - Federated Learning
KW  - FL-HRC-XAI framework
DO  - 10.1109/ICCRTEE64519.2025.11052945
JO  - 2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Computational Robotics, Testing and Engineering Evaluation (ICCRTEE)
Y1  - 28-30 May 2025
AB  - The advancement of Human-Robot Collaboration (HRC) is pivotal for achieving intelligent, autonomous, and safe cooperative systems across industries such as healthcare, manufacturing, and service robotics. However, traditional centralized learning methods pose significant risks related to data privacy, scalability, and adaptability. Moreover, opaque decision-making processes in robotic systems hinder human trust and effective collaboration. This paper introduces a novel framework, Federated Learning-Based Human-Robot Collaboration with Explainable AI (FL-HRC-XAI), aimed at enabling secure, transparent, and adaptive human-robot teaming.The proposed framework leverages Federated Learning (FL) to allow robots to learn collaboratively from decentralized data without sharing raw information, thus preserving user privacy and mitigating data exposure risks. To address the crucial need for trust and transparency, the system integrates Explainable AI (XAI) modules that generate personalized, real-time explanations for robot behaviors. The framework further incorporates robust aggregation methods and differential privacy mechanisms to defend against adversarial attacks and information leakage during the federated training process. We demonstrate that the FL-HRC-XAI framework achieves task performance comparable to centralized baselines while significantly enhancing user trust, satisfaction, and collaboration fluency. Overall, the research findings validate the practical viability of combining federated learning, explainable AI, and adaptive human-robot collaboration for secure, transparent, and effective human-robot teaming.
ER  - 

TY  - CONF
TI  - Hybrid YOLOv8-ViT Framework for Real-Time Intelligent Wildlife Monitoring System with XAI Insights
T2  - 2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220)
SP  - 1
EP  - 6
AU  - R. R. Katangure
AU  - M. G B
AU  - S. Rao
AU  - K. R. B S
AU  - V. R. Konkala
AU  - G. Veerapu
AU  - N. J S
AU  - G. Palanisamy
PY  - 2025
KW  - YOLO
KW  - Computer vision
KW  - Visualization
KW  - Accuracy
KW  - Biological system modeling
KW  - Surveillance
KW  - Wildlife
KW  - Transformers
KW  - Real-time systems
KW  - Sensor systems
KW  - Deep learning
KW  - Edge AI
KW  - Enhanced YOLO network
KW  - Eigen CAM
KW  - Vision Transformer
DO  - 10.1109/SENNET64220.2025.11135988
JO  - 2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Sensors and Related Networks (SENNET) Special Focus on Digital Healthcare(64220)
Y1  - 24-27 July 2025
AB  - Human-wildlife conflicts are increasing due to habitat encroachment, posing threats to both human safety and biodiversity. Traditional wildlife monitoring methods, such as manual surveillance and fencing, are labor-intensive, costly, and often ineffective. To address this, we propose an hybrid framework based on YOLOv8 model by incorporating a Vision Transformer (ViT) for real-time wildlife detection to achieve high accuracy (mAP of 87%). To enhance model interpretability, we integrated Eigen-CAM-based XAI techniques, enabling visualization of the key features used for detection. This approach ensures transparency, improves reliability, and aids in identifying misclassifications. The proposed system is deployed on Raspberry Pi 4B, which acts as edge device, making it cost-effective, scalable, and suitable for resource-constrained environments. This research contributes to sustainable wildlife monitoring by enabling accurate, real-time species detection with explainable AI, reducing false alerts, and enhancing conservation efforts.
ER  - 

TY  - JOUR
TI  - Precision and Personalization: How Large Language Models Redefining Diagnostic Accuracy in Personalized Medicine — A Systematic Literature Review
T2  - IEEE Journal of Biomedical and Health Informatics
SP  - 1
EP  - 21
AU  - A. K. N. L. Aththanagoda
AU  - K. A. S. H. Kulathilake
AU  - N. A. Abdullah
PY  - 2025
KW  - Precision medicine
KW  - Medical diagnostic imaging
KW  - Artificial intelligence
KW  - Accuracy
KW  - Medical services
KW  - Systematic literature review
KW  - Bioinformatics
KW  - Large language models
KW  - Training
KW  - Ethics
KW  - Personalized Medicine
KW  - Diagnostic Accuracy
KW  - Large Language Models (LLMs)
KW  - Clinical Informatics
KW  - AI in Healthcare
DO  - 10.1109/JBHI.2025.3584179
JO  - IEEE Journal of Biomedical and Health Informatics
IS  - 
SN  - 2168-2208
VO  - 
VL  - 
JA  - IEEE Journal of Biomedical and Health Informatics
Y1  - 
AB  - Personalized medicine aims to tailor medical treatments to the unique characteristics of each patient, but its effectiveness relies on achieving diagnostic accuracy to fully understand individual variability in disease response and treatment efficacy. This systematic literature review explores the role of large language models (LLMs) in enhancing diagnostic precision and supporting the advancement of personalized medicine. A comprehensive search was conducted across Web of Science, Science Direct, Scopus, and IEEE Xplore, targeting peer-reviewed articles published in English between January 2020 and March 2025 that applied LLMs within personalized medicine contexts. Following PRISMA guidelines, 39 relevant studies were selected and systematically analyzed. The findings indicate a growing integration of LLMs across key domains such as clinical informatics, medical imaging, patient-specific diagnosis, and clinical decision support. LLMs have shown potential in uncovering subtle data patterns critical for accurate diagnosis and personalized treatment planning. This review highlights the expanding role of LLMs in improving diagnostic accuracy in personalized medicine, offering insights into their performance, applications, and challenges, while also acknowledging limitations in generalizability due to variable model performance and dataset biases. The review highlights the importance of addressing challenges related to data privacy, model interpretability, and reliability across diverse clinical scenarios. For successful clinical integration, future research must focus on refining LLM technologies, ensuring ethical standards, and validating models continuously to safeguard effective and responsible use in healthcare environments.
ER  - 

TY  - CONF
TI  - Lightweight Chest X-Ray Classification for Pneumonia and Tuberculosis Using MobileNet with Explainable AI
T2  - 2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT)
SP  - 834
EP  - 840
AU  - S. H. N. B M
AU  - S. C
AU  - S. B
AU  - S. V. Gautham
AU  - K. P. L
PY  - 2025
KW  - Technological innovation
KW  - Pneumonia
KW  - Accuracy
KW  - Tuberculosis
KW  - Explainable AI
KW  - Computational modeling
KW  - Medical services
KW  - Computer architecture
KW  - X-ray imaging
KW  - Medical diagnostic imaging
KW  - Mobile Net
KW  - Chest X-Ray
KW  - Disease Classification
KW  - Pneumonia
KW  - Tuberculosis
KW  - Explainable-Ai
KW  - Early Diagnosis
DO  - 10.1109/CSNT64827.2025.10967627
JO  - 2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT)
IS  - 
SN  - 2473-5655
VO  - 
VL  - 
JA  - 2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT)
Y1  - 7-9 March 2025
AB  - Chest X-rays are a low-radiation, cost-effective alternative for the diagnosis of respiratory diseases and are particularly valuable as a first-line screening tool. Our solution uses deep learning to classify chest radiographs into three categories: pneumonia, tuberculosis, and healthy (without disease). The Mobile Net model has a lightweight architecture perfectly suited for smartphones which in turn is useful as our aim here is to make this tool accessible, easy to use and helpful for health care workers in remote areas. In order to improve trust and reliability, we have incorporated explainable AI (XAI), which provides detailed insights of how the model arrived at a particular conclusion/decision. While our model does maintain a balance between speed and accuracy, we have also tested it against other resource-intensive models such as ResNet and DenseNet. The results show that MobileNet achieves comparable accuracy while significantly reducing computational demands. This was designed as an early diagnostic aid and provides a feasible, affordable alternative to CT scans, especially for regions with minimal access to advanced medical infrastructure. Its aim is to combine innovation and accessibility in one place to bring about timely and effective healthcare delivery.
ER  - 

TY  - JOUR
TI  - Machine Learning in Ambient Assisted Living for Enhanced Elderly Healthcare: A Systematic Literature Review
T2  - IEEE Access
SP  - 110508
EP  - 110527
AU  - A. A. Mir
AU  - A. S. Khalid
AU  - S. Musa
AU  - M. Faizal Ahmad Fauzi
AU  - N. Norfiza Abdul Razak
AU  - T. Boon Tang
PY  - 2025
KW  - Older adults
KW  - Medical services
KW  - Data privacy
KW  - Sensors
KW  - Prediction algorithms
KW  - Monitoring
KW  - Ambient assisted living
KW  - Internet of Things
KW  - Ethics
KW  - Real-time systems
KW  - Ambient assisted living
KW  - elderly
KW  - explainable AI
KW  - generative AI
KW  - healthcare
KW  - Internet of Things
KW  - machine learning
KW  - predictive analytics
KW  - privacy
DO  - 10.1109/ACCESS.2025.3580961
JO  - IEEE Access
IS  - 
SN  - 2169-3536
VO  - 13
VL  - 13
JA  - IEEE Access
Y1  - 2025
AB  - As the global population ages, Ambient Assisted Living (AAL) systems have become essential in supporting the elderly to maintain independence and quality of life. Such systems integrate advanced technologies such as machine learning (ML), internet of things (IoT), and sensors to enhance safety and healthcare delivery. However, deploying such technologies raises significant challenges, especially in managing privacy, ensuring ethical compliance, and gaining user acceptance. This systematic literature review (SLR) explores the current state and advancements in AAL technologies, with a specific focus on their applications in elderly care. It synthesizes current methodologies, including predictive analytics, Explainable AI (XAI), and Generative AI (GenAI), while also evaluating the role of vision-based systems and multi-modal data fusion. It examines how such technologies are implemented to improve lives while also highlighting critical areas requiring attention, particularly privacy and ethical considerations. The review methodically analyzes articles and papers from the year 2020, selected based on their relevance to AAL technologies, their use of ML algorithms, and their focus on elderly care. The findings reveal the need for interpretability in AI-driven decisions and the role of GenAI in synthetic data generation and personalized conversational assistants. While ML and IoT significantly enhance AAL systems through predictive healthcare and personalized interventions, they also pose substantial privacy risks. The review identifies privacy as a critical concern due to the sensitive nature of the data collected and the vulnerabilities inherent in digital systems. Issues around data privacy, security breaches, and the need for robust privacy-preserving mechanisms are recurrent themes. This SLR illustrates the potential of AAL systems in elderly care and emphasizes the crucial requirement of addressing privacy and ethical issues to ensure such technologies are both beneficial and secure. The findings serve as a foundation for understanding the current state of AAL technologies and guide future advancements in elderly healthcare.
ER  - 

TY  - CONF
TI  - Machine Learning Models for Advancing Heart Disease Prediction and Diagnosis
T2  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
SP  - 2045
EP  - 2051
AU  - S. Reddy
AU  - K. K. Shetty
AU  - A. G S
PY  - 2025
KW  - Support vector machines
KW  - Adaptation models
KW  - Medical services
KW  - Predictive models
KW  - Prediction algorithms
KW  - Data models
KW  - Real-time systems
KW  - Cardiovascular diseases
KW  - Wearable devices
KW  - Random forests
KW  - Artificial Intelligence
KW  - Machine Learning
KW  - Cardiovascular Diseases (CVDs)
KW  - Heart Disease Prediction
KW  - Early Detection
KW  - Personalized Healthcare
KW  - Random Forest
KW  - Support Vector Machines (SVMs)
KW  - Neural Networks
DO  - 10.1109/IDCIOT64235.2025.10915036
JO  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
Y1  - 5-7 Feb. 2025
AB  - Cardiovascular diseases are still among the leading causes of deaths worldwide, thus calling for early detection and precise risk assessment. Traditional methods of diagnosing cardiovascular disease often rely on standardized risk factors, which might not always catch the condition in its early stages. Machine learning and AI are revolutionizing CVD prediction by examining complex data in healthcare to find previously unknown patterns. The paper discusses advances in ML techniques such as supervised and unsupervised learning, deep learning, and ensemble methods. It emphasizes hyperparameter tuning, feature engineering, and model interpretability. AI models like Random Forest, SVM, and Neural Networks have shown better accuracy in predicting cardiovascular disease risk, enabling earlier and more personalized interventions. AI's potential reaches from wearable devices to predictive cardiac event models, promising huge advances in cardiovascular care. Still, there are data privacy issues, model interpretability, and regulatory problems that will continue to pose significant challenges. Future advancements in multimodal imaging, precision medicine, and collaboration between clinicians and data scientists will be pivotal to the realization of AI's full potential in transforming the prediction and prevention of CVD.
ER  - 

TY  - CONF
TI  - An AI-Powered Chatbot for Advanced Scan Interpretation of Brain Tumors, Pneumonia, and Lung Cancer
T2  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
SP  - 1
EP  - 6
AU  - S. Gayathri
AU  - P. Synthan
AU  - K. Vishnu Karthikeyan
AU  - V. Gokulnath
PY  - 2025
KW  - Deep learning
KW  - Pneumonia
KW  - Image analysis
KW  - Accuracy
KW  - Semantics
KW  - Brain tumors
KW  - Chatbots
KW  - Information retrieval
KW  - User experience
KW  - Medical diagnostic imaging
KW  - Medical Chatbot
KW  - Image Analysis
KW  - Natural Language Processing
KW  - Cancer Detection
KW  - Machine Learning
KW  - Deep Learning
DO  - 10.1109/AIMLA63829.2025.11041546
JO  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
Y1  - 29-30 April 2025
AB  - By combining Natural Language Processing with cutting-edge Machine Learning techniques, the intelligent medical chatbot will transform healthcare by helping to diagnose brain tumors, pneumonia, and different types of cancer. It will be possible for users to upload CT and MRI scans for a wide-range analysis using TensorFlow-driven deep learning models that will be accurate in detecting abnormalities. The system will also allow interactive medical consultations. Users will be able to talk about symptoms, illnesses, and diagnoses in a natural, conversational way. It will be supported by LangChain for intelligent dialogue management, Sentence Transformers for semantic understanding, and FAISS for rapid medical information retrieval. Ngrok API will be ensuring secure and scalable web deployment to let as many people reach the chatbot. This is an innovation that combines advanced image analysis with conversational AI to enhance medical diagnostics. It provides a new simple yet extremely effective tool for health assessment and consultation to people.
ER  - 

TY  - CONF
TI  - Multimodal Emotion Recognition with Explainable AI for Cognitive Human-Computer Interaction in Smart Environments
T2  - 2025 5th International Conference on Soft Computing for Security Applications (ICSCSA)
SP  - 1091
EP  - 1096
AU  - S. Sarah
AU  - P. Valarmathie
AU  - L. R. Rose
AU  - J. Jamila
AU  - A. J
AU  - M. Sundarrajan
AU  - M. D. Choudhry
PY  - 2025
KW  - Human computer interaction
KW  - Emotion recognition
KW  - Accuracy
KW  - Explainable AI
KW  - Computer architecture
KW  - Throughput
KW  - Real-time systems
KW  - Robustness
KW  - Time factors
KW  - Security
KW  - Multimodal Emotion Recognition
KW  - Explainable AI
KW  - Human-Computer Interaction
KW  - Smart Environments
KW  - Cognitive Systems
DO  - 10.1109/ICSCSA66339.2025.11170860
JO  - 2025 5th International Conference on Soft Computing for Security Applications (ICSCSA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 5th International Conference on Soft Computing for Security Applications (ICSCSA)
Y1  - 4-6 Aug. 2025
AB  - The increasing complexity of human-computer interaction in smart environments has necessitated the development of systems that can accurately recognize and respond to human emotions. Traditional emotion recognition models relying on a single modality—whether text, audio, or image—often suffer from limited robustness, sensitivity to noise, and an inability to generalize across diverse real-world conditions. Existing multimodal approaches attempt to integrate information from different sources but are frequently hampered by inefficient feature fusion strategies, high computational overhead, delayed response times, and a critical lack of explainability in decision-making processes. To address these challenges, this research proposes a novel Multimodal Emotion Recognition framework enhanced with Explainable AI (XAI) to achieve accurate, transparent, and efficient emotion detection in cognitive human-computer interaction environments. The proposed system employs dedicated deep encoders for each modality, followed by an attention-guided feature fusion mechanism that dynamically prioritizes the most informative features. This approach enhances user trust while maintaining operational excellence. Extensive experiments conducted using benchmark datasets demonstrate that the proposed framework achieves an overall accuracy of 89%, significantly outperforming unimodal baselines and traditional multimodal fusion techniques. The system reduces real-time response latency by 70% compared to conventional methods and improves fault recovery and throughput by over 35%, while maintaining a moderate model complexity suitable for real-time deployment. Explainability evaluations further confirm that over 92% of the model's decision pathways are human- interpretable.
ER  - 

TY  - CONF
TI  - Ensuring Informed Consent and Fair Access to Artificial Intelligence Enhanced Healthcare Services
T2  - 2025 6th International Conference for Emerging Technology (INCET)
SP  - 1
EP  - 8
AU  - M. M. A. Zahra
AU  - K. Nema
AU  - R. Nair
AU  - B. B. Dash
AU  - S. Chowdhury
AU  - S. S. Patra
PY  - 2025
KW  - Measurement
KW  - Accuracy
KW  - Law
KW  - Government
KW  - Medical services
KW  - Real-time systems
KW  - Regulation
KW  - Natural language processing
KW  - Artificial intelligence
KW  - Monitoring
KW  - Accessibility
KW  - AI
KW  - Consent
KW  - Healthcare
KW  - Methodology
KW  - Patient engagement
KW  - Readability
KW  - Regulatory compliance
KW  - Transparency
KW  - User feedback
DO  - 10.1109/INCET64471.2025.11140180
JO  - 2025 6th International Conference for Emerging Technology (INCET)
IS  - 
SN  - 2996-4490
VO  - 
VL  - 
JA  - 2025 6th International Conference for Emerging Technology (INCET)
Y1  - 23-25 May 2025
AB  - This article discusses a novel strategy to make AI-based healthcare informed consent clearer, simpler to obtain, and more equitable. The recommended solution uses natural language processing and user input to process permission forms faster and make them easier to understand for patients. We verify the shorter documents for clarity, user comprehension, and fairness, ensuring the agreement process is effective for numerous individuals. Dynamic feedback allows the consent process to improve depending on user behavior and group-specific issues. The strategy uses continual growth and monitoring to eliminate bias, clarify materials, and ensure compliance. Performance measuring metrics improve reading scores, user comprehension, validation accuracy, and fairness measures compared to previous techniques. The proposed method simplifies health care and makes consumers happy. These modifications ensure that informed consent in healthcare is lawful, fair, and adaptable, enabling a patient-centered strategy that adjusts to changing healthcare requirements. This study suggests that employing modern technology in informed consent might make patients more confident and participating, creating a more inclusive healthcare system.
ER  - 

TY  - CONF
TI  - Personalized Healthcare: Utilizing Probabilistic Models for Disease-Drug Association and Treatment Prediction
T2  - 2025 8th International Conference on Data Science and Machine Learning Applications (CDMA)
SP  - 103
EP  - 108
AU  - S. A. Alsubhi
AU  - M. Al-Luhaybi
AU  - R. A. ALlihyani
AU  - R. A. Alharbi
AU  - F. S. Alharbi
AU  - B. M. Alharbi
PY  - 2025
KW  - Drugs
KW  - Adaptation models
KW  - Accuracy
KW  - Machine learning algorithms
KW  - Precision medicine
KW  - Predictive models
KW  - Prediction algorithms
KW  - Probabilistic logic
KW  - Data models
KW  - Bayes methods
KW  - Personalized Medicine
KW  - Bayesian Networks
KW  - Explainable AI
KW  - Disease-Drug Associations
DO  - 10.1109/CDMA61895.2025.00023
JO  - 2025 8th International Conference on Data Science and Machine Learning Applications (CDMA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 8th International Conference on Data Science and Machine Learning Applications (CDMA)
Y1  - 16-17 Feb. 2025
AB  - The current healthcare system faces challenges in delivering treatment recommendations personalized to individual patient needs, leading to issues such as misdiagnosis, delayed treatment plans, and harmful drug interactions. In response to these challenges, personalized medicine has emerged as a critical component in healthcare, aiming to provide patient-specific clinical treatment recommendations based on individual conditions, thereby enabling more accurate diagnoses and treatments. Machine Learning (ML) has proven to be a crucial approach in advancing personalized medicine and healthcare. Numerous ML algorithms have been implemented to generate suitable recommendations tailored to individual patient conditions. However, most of these algorithms lack explain ability and reasoning behind their decisions, often relying on advanced black-box models. In this paper, we implement the Bayesian networks algorithm, which utilizes a probabilistic learning approach that is both explainable and effective due to its ability to learn, represent relationships, and exploit correlations between variables, thereby enabling ethically informed predictions of risks and side effects. Using graphical models, healthcare providers can deliver individualized care by proposing methods and treatment plans adapted to each patient's specific needs and conditions. This approach aims to minimize side effects and provide precise treatment recommendations, thereby enhancing overall patient care. We conducted three experiments to develop explainable predictive models, exploring three predictive classes: drug class, drug activity, and the side effects of drugs associated with diseases such as Allergies, Alzheimer's, Cancer, and Stroke, etc. The predictive models achieved high accuracy rates, ranging from 82% to 99%, and obtained very reasonable validation accuracies.
ER  - 

TY  - CONF
TI  - AI-Powered Clinical Decision Support Systems (CDSS): Challenges, Benefits, Applications, and Future Directions
T2  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
SP  - 1192
EP  - 1197
AU  - P. Yesankar
AU  - C. Puri
AU  - P. M. Gote
PY  - 2025
KW  - Decision support systems
KW  - Ethics
KW  - Technological innovation
KW  - Collaboration
KW  - Medical services
KW  - Transforms
KW  - Robustness
KW  - Predictive analytics
KW  - Stress
KW  - Standards
KW  - AI-powered Clinical Decision Support Systems (CDSS)
KW  - diagnostic accuracy
KW  - personalized medicine
KW  - Electronic Health Records (EHRs)
KW  - healthcare efficiency
KW  - ethical AI
KW  - predictive analytics
KW  - multimodal data integration
KW  - preventive care
DO  - 10.1109/ICMLAS64557.2025.10969014
JO  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
Y1  - 10-12 March 2025
AB  - AI-based Clinical Decision Support Systems are a revolutionary innovation in the healthcare sector, using artificial intelligence to improve diagnostic precision, optimize treatment planning, and enhance patient outcomes. This paper discusses the challenges, benefits, applications, and future directions of AI-driven CDSS. Some of the key challenges are data quality, integration with EHRs, ethical concerns, and explainability issues. Despite these challenges, benefits such as efficiency improvements, reduced clinician workload, and the possibility of tailored medicine are substantial. In addition, the paper depicts diverse applications across oncology, cardiology, and primary care. The paper further stresses the directions: validation of robustness, user-friendly interfaces, and equitable deployment to achieve maximal utilization of AI-CDSS in global health care systems. Besides this, the integration of multimodal data and improvement in predictive analytics will help to revolutionize preventive care. Moreover, ethical practices with AI will bring forth trust and adoption. Such an all-inclusive review signifies the pivotal role AI will play in shaping clinical decision-making for the future.
ER  - 

TY  - CONF
TI  - The Explanation Necessity for Healthcare AI
T2  - 2025 IEEE Symposium on Trustworthy, Explainable and Responsible Computational Intelligence (CITREx Companion)
SP  - 1
EP  - 5
AU  - M. Mamalakis
AU  - H. de Vareilles
AU  - G. K. Murray
AU  - P. Lio
AU  - J. Suckling
PY  - 2025
KW  - Biomedical equipment
KW  - Computer vision
KW  - Protocols
KW  - Explainable AI
KW  - Medical treatment
KW  - Medical services
KW  - Robustness
KW  - Safety
KW  - Artificial intelligence
KW  - Guidelines
KW  - eXplainable AI
KW  - healthcare
KW  - clinical applications
KW  - XAI necessity
DO  - 10.1109/CITRExCompanion65208.2025.10981502
JO  - 2025 IEEE Symposium on Trustworthy, Explainable and Responsible Computational Intelligence (CITREx Companion)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 IEEE Symposium on Trustworthy, Explainable and Responsible Computational Intelligence (CITREx Companion)
Y1  - 17-20 March 2025
AB  - Explainability is a critical factor in enhancing the trustworthiness and acceptance of artificial intelligence (AI) in healthcare, where decisions directly impact patient outcomes. Despite advancements in AI interpretability, clear guidelines on when and to what extent explanations are required in medical applications remain lacking. We propose a novel categorization system comprising four classes of explanation necessity (self-explainable, semi-explainable, non-explainable, and new-patterns discovery), guiding the required level of explanation; whether local (patient or sample level), global (cohort or dataset level), or both. To support this system, we introduce a mathematical formulation that incorporates three key factors: (i) robustness of the evaluation protocol, (ii) variability of expert observations, and (iii) representation dimensionality of the application. This framework provides a practical tool for researchers to determine the appropriate depth of explainability needed, addressing the critical question: When does an AI medical application need to be explained, and at what level of detail?.
ER  - 

TY  - CONF
TI  - An Explainable IoT-based Framework for Anomaly Detection and Emergency Decision Management in Smart Healthcare
T2  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
SP  - 678
EP  - 682
AU  - S. Divyabharathi
AU  - S. Madhavan
PY  - 2025
KW  - Accuracy
KW  - Computational modeling
KW  - Sensor fusion
KW  - Emergency services
KW  - Real-time systems
KW  - Reliability
KW  - History
KW  - Anomaly detection
KW  - Intelligent sensors
KW  - Engines
KW  - DIADEM-X
KW  - Healthcare systems
KW  - IoT sensor
KW  - machine learning
KW  - SHapley Additive exPlanations
DO  - 10.1109/ICSCDS65426.2025.11167637
JO  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
Y1  - 6-8 Aug. 2025
AB  - As the usage of IoT technology in health care has grown, patient monitoring in real time has become more feasible. However, existing systems do not usually possess accurate anomaly detection, timely emergency response, and interpretable decision support. To address these limitations, this paper proposes a Decision-Integrated Anomaly Detection and Emergency Management framework with eXplainable models (DIADEM-X). DIADEM-X employs physiological data from IoT sensors to identify unusual health patterns using an XGBoost classifier augmented with SHapley Additive exPlanations (SHAP) explanations for clinical interpretability. An innovative Emergency Decision Fusion Engine combines several sensor readings and patient history to create priority-ordered alerts, reducing false alarms and alert fatigue. For deployment on the edge, the system uses low-latency in constrained resources to make it deployable in hospital wards, home care, and mobile units of health. Comparison with SVM, CNN, and Bi-LSTM models shows that DIADEM-X reports 96.1% accuracy, 94 F1-score, 370 ms alert latency, and a 3.5% false alarm rate, which is a considerable improvement over current method. The system's reliability, speed, and explainability make it a potential candidate as a next-generation intelligent health care monitoring system. In this paper, the author identifies the possibilities of using machine learning, explainable AI, and edge computing to achieve trusted, efficient, and clinically relevant IoT-based health systems.
ER  - 

TY  - CONF
TI  - A High-Precision Clinical Decision Support System for Heart Failure Prediction using HF-PGANN Model
T2  - 2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)
SP  - 352
EP  - 360
AU  - S. Parthasarathy
AU  - V. Jayaraman
AU  - P. S
AU  - A. S
PY  - 2025
KW  - Decision support systems
KW  - Support vector machines
KW  - Accuracy
KW  - Explainable AI
KW  - Artificial neural networks
KW  - Predictive models
KW  - Nearest neighbor methods
KW  - Cardiovascular diseases
KW  - Principal component analysis
KW  - Testing
KW  - Heart Failure
KW  - Machine Learning
KW  - Deep Learning
KW  - Principal Component Analysis (PCA)
KW  - XAI
KW  - Healthcare
DO  - 10.1109/ICSSAS66150.2025.11080804
JO  - 2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)
Y1  - 11-13 June 2025
AB  - Early and precise prediction is essential for the enhancement of patient outcomes, as Heart Failure (HF) is an important global cause of morbidity and mortality. Although there are conventional approaches to resolve the issue, they are time-consuming. Consequently, this research developed a novel predictive framework, HF-PGANN. It then incorporates a Grid Search-optimized Artificial Neural Network (ANN) with Principal Component Analysis (PCA) to reduce dimensionality and improve performance on complex clinical data. Initially, conventional models such as K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Naive Bayes (NB), Elastic Net and ANN were assessed, with ANN obtaining the highest baseline accuracy of 92.74%. The accuracy of ANN was enhanced to 93.35% by incorporating PCA, which eliminated redundancy and highlighted latent clinical patterns. The final HF-PGANN model achieved an exceptional accuracy of 99.77% after being optimized through grid search. Furthermore, it demonstrated strong predictive capability and reliability, achieving precision, recall, and F1-score of 99%. To guarantee model transparency, Local Interpretable Model-agnostic Explanations (LIME) was implemented for explainable AI (XAI), which provides interpretable insights into the primary contributing components. The proposed HF-PGANN model is an appealing option for real-world deployment in clinical decision support systems due to its high precision and interpretability.
ER  - 

TY  - CONF
TI  - Enhancing predictive accuracy and interpretability through Explainable Deep Ensembles learning for lung cancer classification
T2  - 2025 International Conference on Pervasive Computational Technologies (ICPCT)
SP  - 30
EP  - 34
AU  - S. S. Carmel Mary
AU  - M. D. Ananda Raj
PY  - 2025
KW  - Deep learning
KW  - Accuracy
KW  - Computational modeling
KW  - Decision making
KW  - Transfer learning
KW  - Lung cancer
KW  - Predictive models
KW  - Data models
KW  - Robustness
KW  - Resilience
KW  - Machine learning
KW  - Deep Learning
KW  - Ensembles
KW  - Explainability
KW  - Saliency Map
KW  - Model Evaluation
DO  - 10.1109/ICPCT64145.2025.10940764
JO  - 2025 International Conference on Pervasive Computational Technologies (ICPCT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Pervasive Computational Technologies (ICPCT)
Y1  - 8-9 Feb. 2025
AB  - In the era of Artificial Intelligence, applications in healthcare, banking, and autonomous vehicles have been significantly enhanced and simplified through machine learning and deep learning models, collectively known as Artificial Intelligence. The models are developed to produce efficient predictive outcomes. When a machine learning (ML) model underperforms, combining weaker and stronger models can lead to a more effective and efficient result. In deep learning, the "Black Box" nature of models presents a challenge regarding transparency, commonly referred to as "Explainability". To address these challenges, we proposed a novel approach that integrates the robustness of the average Ensemble technique with saliency maps to enhance Explainability in multiple Deep neural networks (X-DEL). This approach aims to improve accuracy while identifying the most significant features contributing to the decision-making process. The model is applied to a lung cancer dataset to classify types of pathological lung cancers. Our novel method, compared to traditional ML algorithms, achieved an accuracy of 98%. Furthermore, it identified that features 0, 20, 30, and 50 have higher saliency values, suggesting they are more influential in the decision-making framework.
ER  - 

TY  - CHAP
TI  - Applications of AI in Cancer Detection &#x2014; A Review of the Specific Ways in which AI Is Being Used to Detect and Diagnose Various Types of Cancer
T2  - AI in Disease Detection: Advancements and Applications
SP  - 147
EP  - 166
AU  - Shival Dubey
AU  - Shailendra Singh Sikarwar
PY  - 2025
KW  - Artificial intelligence
KW  - Cancer detection
KW  - Medical services
KW  - Cancer
KW  - Technological innovation
KW  - Oncology
KW  - Accuracy
KW  - Medical diagnostic imaging
KW  - Collaboration
KW  - Bioinformatics
DO  - 10.1002/9781394278695.ch7
PB  - IEEE
SN  - 9781394278688
UR  - http://ieeexplore.ieee.org/document/10834115
AB  - Summary <p>The mixing of superior deep learning strategies has profoundly impacted the sector of sickness identification, promising sizable advancements in diagnostic accuracy and performance. This paper explores the utilization of multi&#x2010;scale convolutional layers, interest mechanisms, switch learning, generative adversarial networks (GANs), and self&#x2010;supervised learning in the healthcare domain. These techniques collectively beautify the capability of convolutional neural networks (CNNs) to discover and diagnose diseases from medical pix with extraordinary precision. Multi&#x2010;scale convolutional layers allow the models to capture features at numerous scales, improving the sensitivity and specificity of disease detection, mainly in situations like most cancers. Attention mechanisms similarly refine this process by allowing models to focus on the most applicable components of an picture, mirroring the meticulous examination by healthcare professionals.</p> <p>Transfer learning, leveraging training fashions, extensively reduces the reliance on tremendous, categorized datasets, thereby expediting the development process and enhancing version accuracy. This approach has shown outstanding success throughout distinctive imaging modalities, from X&#x2010;rays to CT scans, improving the adaptability and robustness of diagnostic models. GANs contribute via producing artificial records to augment schooling datasets, addressing the challenge of limited data availability and enhancing model performance, specifically in uncommon disease scenarios. Self&#x2010;supervised learning, which trains fashions on unlabeled records via proxy duties, has demonstrated comparable performance to absolutely supervised fashions while requiring fewer categorized samples, therefore lowering the need for luxurious and time&#x2010;eating data annotation.</p> <p>Innovations in those areas have not only improved the technical performance of disease identification models but also opened new avenues for his or her application. Future research should explore multimodal learning, which mixes data from various assets, including genomic information and digital health data, imparting a more complete diagnostic perspective. The implementation of federated learning guarantees data privacy while enhancing model training via decentralized records assets. Explainable AI (XAI) techniques enhance model interpretability, fostering extra consider and popularity amongst healthcare professionals. Moreover, the integration of AI with wearable devices for continuous fitness tracking and the improvement of real&#x2010;time adaptive learning fashions hold tremendous promise for revolutionizing patient care and disease control.</p> <p>This comprehensive method to leveraging superior deep learning methodologies in disorder identification underscores the transformative potential of AI in healthcare. With the aid of addressing modern&#x2010;day demanding situations and exploring progressive answers, we can pave the way for greater accuracy, efficiency, and personalized diagnostic systems, in the end enhancing patient results and advancing current care in medical exercise.</p>
ER  - 

TY  - CONF
TI  - Leukemia Classification Using CNN and VGG19 Architecture
T2  - 2025 International Conference on Intelligent Control, Computing and Communications (IC3)
SP  - 331
EP  - 336
AU  - S. Sharma
AU  - S. Rani
AU  - R. Sujitha
PY  - 2025
KW  - Deep learning
KW  - White blood cells
KW  - Accuracy
KW  - Transfer learning
KW  - Leukemia
KW  - Computer architecture
KW  - Predictive models
KW  - Convolutional neural networks
KW  - Medical diagnostic imaging
KW  - Tuning
KW  - Convolutional Neural Network (CNN)
KW  - Deep Learning
KW  - Healthcare Informatics
KW  - Machine Learning
KW  - Neural Networks
KW  - Transfer Learning
KW  - VGG19 Architecture
DO  - 10.1109/IC363308.2025.10957277
JO  - 2025 International Conference on Intelligent Control, Computing and Communications (IC3)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Intelligent Control, Computing and Communications (IC3)
Y1  - 13-14 Feb. 2025
AB  - Leukemia, a severe kind of blood cancer marked by aberrant white blood cell proliferation, presents great difficulties for diagnosis and categorization. Effective treatment planning and enhancement of patient outcomes depend on precise identi- fication of leukemia subtypes. Based on the VGG19 architecture, this paper offers a Convolutional Neural Network (CNN) model to classify leukemia into four subtypes: Benign, Malignant Pre- B, Malignant Pro-B, and Malignant early Pre-B. High accuracy is obtained by the model using transfer learning and fine- tuning on a dataset of leukemia cell images, thereby lowering training time and improving performance. Our results show that, surpassing conventional diagnostic approaches and current Machine Learning (ML) models, the VGG19-based CNN model achieves an accuracy of 99.1%. This study underlines the need of automated systems in the diagnosis process and the possibilities of Deep Learning (DL) methods in medical image classification. Aiming for enhanced accuracy and efficiency in clinical settings, the results open the path for more research of sophisticated computational methods in the diagnosis of leukemia.
ER  - 

TY  - JOUR
TI  - FairXAI - A Taxonomy and Framework for Fairness and Explainability Synergy in Machine Learning
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 9819
EP  - 9836
AU  - R. Ramachandranpillai
AU  - R. Baeza-Yates
AU  - F. Heintz
PY  - 2025
KW  - Artificial intelligence
KW  - Taxonomy
KW  - Reviews
KW  - Predictive models
KW  - Decision making
KW  - Explainable AI
KW  - Hands
KW  - Regulation
KW  - Prediction algorithms
KW  - Machine learning algorithms
KW  - Explainability
KW  - fair machine learning (ML)
KW  - interpretability
KW  - responsible AI
DO  - 10.1109/TNNLS.2025.3528321
JO  - IEEE Transactions on Neural Networks and Learning Systems
IS  - 6
SN  - 2162-2388
VO  - 36
VL  - 36
JA  - IEEE Transactions on Neural Networks and Learning Systems
Y1  - June 2025
AB  - Explainable artificial intelligence (XAI) and fair learning have made significant strides in various application domains, including criminal recidivism predictions, healthcare settings, toxic comment detection, automatic speech detection, recommendation systems, and image segmentation. However, these two fields have largely evolved independently. Recent studies have demonstrated that incorporating explanations into decision-making processes enhances the transparency and trustworthiness of AI systems. In light of this, our objective is to conduct a systematic review of FairXAI, which explores the interplay between fairness and explainability frameworks. To commence, we propose a taxonomy of FairXAI that utilizes XAI to mitigate and evaluate bias. This taxonomy will be a base for machine learning researchers operating in diverse domains. Additionally, we will undertake an extensive review of existing articles, taking into account factors such as the purpose of the interaction, target audience, and domain and context. Moreover, we outline an interaction framework for FairXAI considering various fairness perceptions and propose a FairXAI wheel that encompasses four core properties that must be verified and evaluated. This will serve as a practical tool for researchers and practitioners, ensuring the fairness and transparency of their AI systems. Furthermore, we will identify challenges and conflicts in the interactions between fairness and explainability, which could potentially pave the way for enhancing the responsibility of AI systems. As the inaugural review of its kind, we hope that this survey will inspire scholars to address these challenges by scrutinizing current research in their respective domains.
ER  - 

TY  - CONF
TI  - Personalized Disease Risk Prediction Using Secure Multi-Cloud AI Models in Healthcare
T2  - 2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)
SP  - 792
EP  - 799
AU  - S. Kumar
AU  - R. Sivaraman
AU  - E. Pandian
AU  - V. Kolasani
AU  - V. P
AU  - B. Jegajothi
PY  - 2025
KW  - Training
KW  - Data privacy
KW  - Accuracy
KW  - Protocols
KW  - Federated learning
KW  - Predictive models
KW  - Performance metrics
KW  - Data models
KW  - Artificial intelligence
KW  - Diseases
KW  - Federated Learning
KW  - Disease Prediction
KW  - Personalized AI
KW  - Multimodal Fusion
KW  - Secure Communication
KW  - SPFH-AI
KW  - Healthcare Analytics
KW  - Deep Learning
DO  - 10.1109/ICDICI66477.2025.11135131
JO  - 2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)
Y1  - 9-11 July 2025
AB  - The increasing demand for privacy-preserving and accurate diagnostic systems in healthcare has motivated the development of intelligent hybrid architectures. This paper presents SPFH-AI - Secure Personalized Federated Hybrid AI, a novel framework designed for disease prediction across 41 medical conditions using 132 symptom parameters. The system combines Federated Learning, Multimodal Fusion, Personalized Attention, and Secure Communication Protocols to deliver robust classification while maintaining data confidentiality. Unlike traditional centralized models, SPFH-AI enables collaborative model training across distributed nodes without sharing raw patient data. Each module within the architecture plays a vital role-federated learning ensures privacy, personalized layers improve patient-specific learning, and fusion layers integrate diverse symptom data for enriched understanding. Comprehensive evaluations demonstrate that SPFH-AI achieves a classification accuracy of 96.9 %, surpassing existing models such as SVM (91.2%), MLP (92.7%), CNN (93.5%), BiLSTM (94.1%), Capsule Net (94.8 %), and Maxout Network (95.2 %). Performance metrics including precision (96.7 %), recall (96.6 %), and F1-score (96.6 %) affirm the model's effectiveness. ROC curve analysis and ablation studies further validate SPFH-AI's superiority in both performance and architecture design.
ER  - 

TY  - CONF
TI  - Enhanced Chromosome Defect Detection Using Hybrid Swin Transformer and Explainable AI
T2  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
SP  - 1
EP  - 6
AU  - Y. M
AU  - S. N
AU  - P. R
AU  - D. K. K
PY  - 2025
KW  - Image segmentation
KW  - Accuracy
KW  - Sensitivity
KW  - Explainable AI
KW  - Statistical analysis
KW  - Transformers
KW  - Feature extraction
KW  - Real-time systems
KW  - Biological cells
KW  - Defect detection
KW  - Chromosome Defect Detection
KW  - Hybrid Swin Transformer
KW  - Explainable AI
KW  - Neural Image Segmentation
KW  - Karyotype Analysis
KW  - Genetic Diagnostics
DO  - 10.1109/AIMLA63829.2025.11041444
JO  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA)
Y1  - 29-30 April 2025
AB  - This research offers a new method for detecting chromosome defects using a Hybrid Swin Transformer integrated with Explainable AI (XAI), incorporating advanced algorithms for enhanced performance. The Hybrid Swin Transformer leverages hierarchical feature learning for robust feature extraction, while XAI provides interpretability and transparency in defect classification, achieving an impressive accuracy of 97.8%, surpassing existing solutions (85%-96.5%). The architecture incorporates Neural Image Segmentation (UNet-based) for segmenting chromosomes from karyotype images, achieving a segmentation accuracy of 95.1%, significantly enhancing defect region identification. Data augmentation and preprocessing techniques, such as normalization and G-banding enhancement, ensure the model effectively generalizes across diverse datasets. The workflow is further optimized with XAI for adaptability to new classes of abnormalities and decision transparency, reducing the 2.5% for false positives and 3.4% for false negatives. rateof false negatives (3.4%) and false positives (2.5%). The architecture processes images in an average time of ~0.18 seconds per image, making it highly efficient for real-time deployment. Validation against a curated dataset of 1.3 GB, containing high-resolution karyotype images, demonstrates superior recall (96.5%) and precision (96.2%), achieving an F1-score of 96.4%, setting new benchmarks in the field.
ER  - 

TY  - CONF
TI  - Stroke Detection Using Deep Learning
T2  - 2025 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA)
SP  - 1
EP  - 6
AU  - L. S
AU  - A. Shaju
AU  - A. I. Babu
AU  - N. Viju
AU  - S. R. Shijo
PY  - 2025
KW  - Deep learning
KW  - Training
KW  - Accuracy
KW  - Hospitals
KW  - Computed tomography
KW  - Bidirectional long short term memory
KW  - Stroke (medical condition)
KW  - Feature extraction
KW  - Convolutional neural networks
KW  - Reliability
KW  - Stroke detection
KW  - Deep Learning
KW  - CNN
KW  - BiL-STM
KW  - EfficientNetB0
KW  - CT scan
KW  - Feature Extraction
KW  - Medical Diagnosis
DO  - 10.1109/ACCTHPA65749.2025.11168511
JO  - 2025 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA)
Y1  - 18-19 July 2025
AB  - Stroke is a critical medical condition that requires rapid and accurate diagnosis to improve patient recovery out-comes. This study presents a deep learning-based approach for stroke detection using Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory (BiLSTM) networks. Initially, CNN and BiLSTM models are evaluated separately before integrating them to enhance feature extraction. The optimized model leverages EfficientNetB0 as a pretrained CNN backbone, combined with additional layers such as BiLSTM, Flatten, Dense, and Dropout layers to improve classification accuracy. Achieving a training accuracy of 98 percent and a validation accuracy of 95 percent, the model demonstrates high effectiveness in stroke diagnosis. EfficientNetB0 extracts intricate features from CT scan images, while the BiLSTM network processes spatial and sequential dependencies, leading to more reliable classification. The system categorizes strokes into three types: hemorrhagic, ischemic, and silent stroke. For practical application, the model is integrated into a hospital management platform, allowing doctors and patients to upload CT scans for instant analysis, thus facilitating timely medical intervention. The findings suggest that combining EfficientNetB0 with BiLSTM provides a robust and efficient solution for automated stroke detection, making it a valuable tool in clinical settings.
ER  - 

TY  - CONF
TI  - Optimized Real-Time Mortality Prediction System based on Combining Machine Learning, Explainable AI and Big Data Platforms
T2  - 2025 15th International Conference on Electrical Engineering (ICEENG)
SP  - 1
EP  - 7
AU  - H. Saleh
AU  - N. El-Rashidy
AU  - S. El-Sappagh
AU  - S. A. Lotfy
AU  - E. A. Zanaty
AU  - N. F. Omran
PY  - 2025
KW  - Data analysis
KW  - Explainable AI
KW  - Pipelines
KW  - Mortality
KW  - Predictive models
KW  - Big Data
KW  - Feature extraction
KW  - Real-time systems
KW  - Ensemble learning
KW  - Sparks
KW  - Ensemble learning
KW  - Machine learning
KW  - Explainable Artificial Intelligence
KW  - Mortality prediction
KW  - Real-time data analytics
KW  - Big data platforms
KW  - Emergency response optimization
KW  - Health monitoring systems
DO  - 10.1109/ICEENG64546.2025.11031315
JO  - 2025 15th International Conference on Electrical Engineering (ICEENG)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 15th International Conference on Electrical Engineering (ICEENG)
Y1  - 12-15 May 2025
AB  - Mortality prediction plays a vital role in healthcare as it allows the identification of patients at risk of deterioration or death. Machine learning (ML) techniques have been increasingly adopted to handle this task by capturing complex relationships and insights in data. This study proposes a real-time framework that integrates ensemble learning techniques, feature extraction methods, explainable artificial intelligence (XAI), and big data platforms to predict mortality in real-time. The proposed framework consists of two main phases: an offline model phase and an online prediction pipeline. In the offline model phase, feature selection methods are used to identify the most significant features. Different ML models and ensemble learning are applied to both the complete feature set and the pruned feature subset to determine the best performing model for real-time mortality prediction. XAI is utilized to provide understandable explanations for the model, incorporating both global and local explainability. Local explainability aims to offer understandable explanations for individual instances, allowing insights into the decision-making process on a case-by-case basis. In contrast, global explainability tools provide comprehensive explanations that encompass all model instances. Experimental results show that XGBoost model combined with the mutual feature selection achieves the best accuracy, precision, recall, and F1-score of 97.08%, 97.09%, 97.08%, and 97.08%, respectively. In the online prediction pipeline, streaming data is generated and processed sequentially using Kafka topics. Spark streaming retrieves data from the topic and relevant health features are extracted. The optimized model is applied to predict the health status based on the extracted features. The proposed framework addresses the challenge of real-time data analysis for the prevention of mortality.
ER  - 

TY  - CONF
TI  - Advances in Deep Learning for Tuberculosis Detection in Chest X-Rays: A Review of Diagnostic Accuracy
T2  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
SP  - 1158
EP  - 1162
AU  - J. K
AU  - G. Muthupandi
AU  - D. R
AU  - S. Pavithra
PY  - 2025
KW  - Deep learning
KW  - Accuracy
KW  - Tuberculosis
KW  - Transfer learning
KW  - Medical services
KW  - Feature extraction
KW  - X-ray imaging
KW  - Optimization
KW  - Tuning
KW  - Biomedical imaging
KW  - Deep Learning
KW  - Tuberculosis Detection
KW  - Chest X-Rays
KW  - CNN
KW  - Diagnostic Accuracy
KW  - Optimization Techniques
KW  - AI in Healthcare
DO  - 10.1109/IDCIOT64235.2025.10914759
JO  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
Y1  - 5-7 Feb. 2025
AB  - Tuberculosis (TB) is one of the leading causes of deaths globally, mainly in low- and middle-income countries. Early and accurate detection is crucial for effective treatment and disease control. In this paper, models like CNNs-VGG16, ResNet, and DenseNet, to name a few, are taken into an exhaustive study. Optimization techniques, including transfer learning and ensemble methods, which can increase accuracy in the challenging diverse clinical settings, will be presented. Equitable healthcare outcome is achieved in terms of future research directions which include representative datasets and interpretability of the model.
ER  - 

TY  - CONF
TI  - Concept of Hierarchically Organized Explainable Intelligent Systems: Synthesis of Deep Neural Networks, Fuzzy Logic and Incremental Learning in Medical Diagnostics
T2  - 2025 VI International Conference on Neural Networks and Neurotechnologies (NeuroNT)
SP  - 14
EP  - 17
AU  - Y. V. Trofimov
AU  - A. V. Shevchenko
AU  - A. N. Averkin
AU  - I. P. Muravyov
AU  - E. M. Kuznetsov
PY  - 2025
KW  - Fuzzy logic
KW  - Adaptation models
KW  - Incremental learning
KW  - Adaptive systems
KW  - Accuracy
KW  - Explainable AI
KW  - Artificial neural networks
KW  - Intelligent systems
KW  - Medical diagnostic imaging
KW  - X-ray imaging
KW  - artificial intelligence
KW  - intelligent medical systems
KW  - interpretable artificial intelligence
KW  - explainable artificial intelligence
KW  - cognitive-oriented systems
KW  - fuzzy logic
KW  - incremental learning
KW  - adaptive explainability
DO  - 10.1109/NeuroNT66873.2025.11049976
JO  - 2025 VI International Conference on Neural Networks and Neurotechnologies (NeuroNT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 VI International Conference on Neural Networks and Neurotechnologies (NeuroNT)
Y1  - 20-20 June 2025
AB  - The development of explainable artificial intelligence (XAI) goes beyond traditional post-hoc methods of interpretation, forming a new generation of cognitive-oriented intelligent systems based on deep integration of neural network methods, fuzzy logic and incremental learning. The report presents the concept of hierarchically organized XAI systems that provide adaptive explainability and continuous knowledge updating in the process of their practical application. The implementation is based on the dynamic formation of explanations, including a cascade connection of local and global interpreters, production models and adaptive mechanisms for generating medical reports. The presented approach forms the XAI 2.0 paradigm, providing resistance to uncertainty of medical data, cognitive transparency of decisions and the possibility of multi-level interpretation of results. The paper discusses the theoretical and practical principles of building such systems, and substantiates the need to integrate deep neural networks and fuzzy logic to create intelligent medical systems of a new generation.
ER  - 

TY  - CONF
TI  - Federated AI Framework for Privacy-Preserving Differential Diagnosis Across Distributed Medical Networks
T2  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
SP  - 932
EP  - 940
AU  - U. G. Naidu
AU  - A. Lakkshmanan
AU  - J. S. V. G. Krishna
AU  - E. Elamathi
AU  - T. S. Reddy
AU  - V. T. R. P. Kumar M
PY  - 2025
KW  - Privacy
KW  - Data privacy
KW  - Federated learning
KW  - Explainable AI
KW  - Ontologies
KW  - Transformers
KW  - Natural language processing
KW  - Differential diagnosis
KW  - Regulation
KW  - Medical diagnostic imaging
KW  - Federated Learning
KW  - Differential Diagnosis
KW  - Explainable AI (XAI)
KW  - Natural Language Processing (NLP)
KW  - Intelligent Age
DO  - 10.1109/ICIRCA65293.2025.11089748
JO  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
Y1  - 25-27 June 2025
AB  - In the modern healthcare, accurate and timely differential diagnosis is vital, and the scope is broad, in geographically distributed hospitals and clinics. Nevertheless, centralized AI training is sometimes constrained by data privacy regulations, as well as by soloed health information systems. This work presents a new Federated AI Framework that allows the privacy preserving differential diagnosis across distributed medical networks. It is a federation of learning (Federated learning), transformer based natural language processing (NLP) and explainable AI (XAI) techniques, as well as knowledge graph based reasoning that collaboratively trains AI diagnostic models on decentralized, sensitive patient data. The system uses patients' clinical notes, symptom data, and Electronic Health Records (EHRs) that it does not collect in a central server, keeping patient confidential. Local models are trained using participating medical institutions and aggregated periodically in a secure model update into a global model. Diagnostic predictions are dynamically refined through hierarchical disease ontologies and contextual feedback within an intelligent agent layer. Additionally, XAI techniques including SHAP and counterfactual analysis are also included in this framework for transparency of the model and trust by the clinicians. Gaining favourable diagnostic precision and recall while strictly keeping data privacy is demonstrated through experimental evaluation on multiinstitutional datasets. Not only does the proposed approach make advisable the reduction of diagnostic errors, but it also provides scalable, secure, and interpretable AI-driven healthcare solutions for real world deployment to privacy sensitive environments.
ER  - 

TY  - CONF
TI  - Ethics, Privacy, and Security Challenges in AI and Blockchain-Driven Digital Health Ecosystems
T2  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
SP  - 1
EP  - 6
AU  - V. R. Krishna
AU  - A. H. Maad
AU  - A. I. Alanssari
AU  - N. R. Nimah
AU  - K. A. Jabbar
AU  - P. Thuniki
PY  - 2025
KW  - Ethics
KW  - Privacy
KW  - Differential privacy
KW  - Federated learning
KW  - Explainable AI
KW  - Ecosystems
KW  - Decision making
KW  - Blockchains
KW  - Electronic healthcare
KW  - Homomorphic encryption
KW  - AI
KW  - Algorithm fairness
KW  - Blockchain
KW  - Data protection
KW  - Differential privacy
KW  - Ethical AI
KW  - Explainable AI
KW  - Federated learning
KW  - Privacy-preserving techniques
KW  - Transparency
DO  - 10.1109/OTCON65728.2025.11070382
JO  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 4th OPJU International Technology Conference (OTCON) on Smart Computing for Innovation and Advancement in Industry 5.0
Y1  - 9-11 April 2025
AB  - This article discusses how integrating AI and blockchain technology into digital health platforms might help and hurt privacy, fairness, transparency, and compliance. This research compares AI and blockchain technologies for making honest and ethical healthcare choices. We are investigating federated learning, homomorphic encryption, differential privacy, zero-knowledge proofs, self-sovereign identity systems, explainable AI, blockchain interface protocols, and privacypreserving AI systems. We rated each technique based on data protection, ethical data collecting, computer justice, openness, and system security. While most approaches perform well in certain locations, they all have issues that may render them unsuitable for use in healthcare. The proposed solution addresses these concerns and outperforms speed standards. It evaluates ethical risks based on bias, fairness, and transparency and is continuously improving ethical decision-making. These evaluations improve healthcare AI systems' reliability, fairness, and clarity during decision-making. This implies its potential application in AI-driven healthcare systems.
ER  - 

TY  - CHAP
TI  - Integration of AI in Healthcare Systems &#x2014; A Discussion of the Challenges and Opportunities of Integrating AI in Healthcare Systems for Disease Detection and Diagnosis
T2  - AI in Disease Detection: Advancements and Applications
SP  - 239
EP  - 263
AU  - Nitin Sharma
AU  - Priyanka Kaushik
PY  - 2025
KW  - Medical services
KW  - Artificial intelligence
KW  - Ethics
KW  - Diseases
KW  - Collaboration
KW  - Technological innovation
KW  - Predictive models
KW  - Prediction algorithms
KW  - Accuracy
KW  - Streaming media
DO  - 10.1002/9781394278695.ch11
PB  - IEEE
SN  - 9781394278688
UR  - http://ieeexplore.ieee.org/document/10834099
AB  - Summary <p>AI has become a revolutionary device in disease identification and has introduced new strategies to increase accuracy, interpretability, and integrity in healthcare. This research could be an examination of follow&#x2010;on imperative approaches, causal inference methods, synthetic adversarial systems counting, review components, and considerations that improve the performance and robustness of AI infection location models. This involves significantly reducing symptomatic errors by combining GANs that synthesize different real&#x2010;world tests to reduce bias and improve program generality. Consideration components highlight potential highlights in the clinical performance or individual measurements that are affected, thereby improving interpretability and reliability. Causal inference methods illustrate promiscuous tools that promote personalized healing procedures. Unified learning truly strengthens collaborative tutoring by considering the realities of security and administrative compliance. Future thinking needs to incorporate cross&#x2010;models, ethical recommendations, adaptability, and integration with growing innovations to achieve comprehensive AI control in the evolution of healthcare transportation.</p>
ER  - 

TY  - CONF
TI  - Ethical AI Redefined: Pioneering Transparency with Hybrid Explainable Models
T2  - 2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI)
SP  - 1872
EP  - 1878
AU  - J. Gayathri
AU  - K. S. Vimal Chandran
AU  - F. D. Rathna Mala
AU  - A. M. S
AU  - K. S
AU  - A. Maheshwaran
PY  - 2025
KW  - Ethics
KW  - Privacy
KW  - Ethnicity
KW  - Explainable AI
KW  - Heuristic algorithms
KW  - Finance
KW  - Medical services
KW  - Transformers
KW  - Artificial intelligence
KW  - Homomorphic encryption
KW  - Ethical AI
KW  - Hybrid Explainable Models
KW  - SHAP
KW  - Transparency
KW  - Fairness
KW  - Bias Detection
KW  - Privacy Preservation
KW  - Deep Learning
KW  - Transformer Models
KW  - Responsible AI
DO  - 10.1109/ICMSCI62561.2025.10894436
JO  - 2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI)
Y1  - 20-22 Jan. 2025
AB  - The rapid proliferation of artificial intelligence (AI) in critical domains like healthcare, finance, and governance has necessitated the development of ethical, transparent, and responsible AI systems. This study proposes a hybrid explainable AI model to achieve ethical, transparent, and high-performance artificial intelligence solutions. Combining black-box models such as Transformers with explainable techniques like SHAP, the proposed methodology addresses key challenges in AI, including fairness, interpretability, and privacy. The model tested on a diverse and representative dataset, focusing on performance, bias detection, and explainability. Results demonstrate that the proposed model achieved a 97.71% accuracy with an F1-score of 0.96, outperforming baseline models such as CNN (87.50%) and Transformer-Causal combinations (94.10%). SHAP analysis identified key features like Age, Blood Pressure, and Cholesterol Level as the most influential predictors, ensuring transparency and trustworthiness. Fairness evaluation across sensitive attributes, including gender and ethnicity, showed Demographic Parity of 96.40% and Equal Opportunity of 94.40%, indicating minimal bias. Privacy-preserving techniques such as Differential Privacy and Homomorphic Encryption implemented, achieving robust data protection with minor trade-offs. This hybrid approach successfully balances performance, fairness, interpretability, and privacy, presenting a scalable framework for ethical AI development.
ER  - 

TY  - CONF
TI  - A Systemic Review of Healthcare Challenges Due to Ethical Implications: A PRISMA Analysis
T2  - 2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)
SP  - 1
EP  - 8
AU  - A. Ara
AU  - A. Thomas
PY  - 2025
KW  - Training
KW  - Ethics
KW  - Technological innovation
KW  - Smart cities
KW  - Reviews
KW  - Collaboration
KW  - Medical services
KW  - Stakeholders
KW  - Artificial intelligence
KW  - Guidelines
KW  - Healthcare challenges
KW  - Ethics
KW  - Artificial Intelligence
DO  - 10.1109/ICAISC64594.2025.10959586
JO  - 2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)
Y1  - 9-11 Feb. 2025
AB  - In this rapidly evolving field of healthcare, Artificial Intelligence(AI) presents significant ethical challenges. There is an urgent need to address these ethical concerns as they are directly affecting patient care, As per Healthcare Tech Outlook, 80% of healthcare data cannot be used as it is not structured, resulting in biased outcomes due to its inability to be analyzed. The integration of artificial intelligence (AI) into healthcare has the potential to revolutionize medical services, enhancing patient outcomes, operational efficiency, and overall healthcare management. However, this technological advancement also introduces significant ethical challenges that must be addressed to ensure responsible and equitable use. This research explores the systemic impacts of AI ethics in healthcare by examining five key themes: ethical challenges, influential contributors and collaboration networks, emerging themes, cooccurrence of ethical concepts, and influential publications. The study identifies critical ethical issues such as bias, privacy, transparency, and accountability, highlighting the need for robust ethical guidelines. It also maps the contributions of leading authors and institutions, revealing collaboration networks that drive research in this field. Emerging themes such as transparency, data privacy, fairness, and the environmental impact of AI are discussed, reflecting the evolving landscape of AI ethics. The cooccurrence of ethical concepts is analyzed to understand their interconnected nature, emphasizing the complexity of ethical AI implementation. Finally, influential publications are reviewed to assess their impact on the development of ethical guidelines and best practices. By addressing these research themes, the study aims to contribute to the development of comprehensive ethical frameworks for AI in healthcare, ensuring that the benefits of this technology are realized while minimizing potential risks and ethical concerns.
ER  - 

TY  - CONF
TI  - Harnessing Computational Intelligence: In-Depth Applications in Biology and Medicine
T2  - 2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)
SP  - 1
EP  - 6
AU  - A. TOUMI
AU  - H. M. Mohamed
AU  - S. M. Elsayed
PY  - 2025
KW  - Technological innovation
KW  - Ethics
KW  - Computational modeling
KW  - Precision medicine
KW  - Collaboration
KW  - Medical services
KW  - Transforms
KW  - Standardization
KW  - Planning
KW  - Medical diagnostic imaging
KW  - Computational Intelligence
KW  - Computational modeling
KW  - Biological system modeling
KW  - Decision making
KW  - Ethical and Legal issues
DO  - 10.1109/ITIKD63574.2025.11004766
JO  - 2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)
Y1  - 13-15 April 2025
AB  - Computational Intelligence (CI) has significantly impacted biology and medicine by enhancing diagnostics, treatment planning, and biological research. CI techniques like artificial neural networks, fuzzy logic, and evolutionary algorithms have revolutionized diagnostics, treatment planning, and biological research by processing high-dimensional, nonlinear, and uncertain data. This study highlights the role of CI in advancing healthcare through innovations such as explainable AI, adaptive systems, and multimodal data fusion. While CI improves accuracy and personalization, challenges remain in data quality, interpretability, and computational demands. Integrative approaches, combining various CI techniques, are key in areas like drug discovery, personalized medicine, and disease modeling. Future research should focus on interdisciplinary collaboration, standardization, and ethical governance to ensure sustainable progress.
ER  - 

TY  - CONF
TI  - Artificial Intelligence Powered Healthcare Diagnostics Based on Residual Network-50 with Federated Learning
T2  - 2025 3rd International Conference on Data Science and Information System (ICDSIS)
SP  - 1
EP  - 6
AU  - A. Padthe
AU  - S. Wbaid
AU  - R. B. N
AU  - R. Vallabhaneni
AU  - C. E. E. S
PY  - 2025
KW  - Accuracy
KW  - Sensitivity
KW  - Federated learning
KW  - Medical services
KW  - Feature extraction
KW  - Data models
KW  - Artificial intelligence
KW  - X-ray imaging
KW  - Medical diagnostic imaging
KW  - Diseases
KW  - artificial intelligence
KW  - federated learning
KW  - image normalization
KW  - recursive feature elimination
KW  - residual network-50
DO  - 10.1109/ICDSIS65355.2025.11113644
JO  - 2025 3rd International Conference on Data Science and Information System (ICDSIS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Data Science and Information System (ICDSIS)
Y1  - 16-17 May 2025
AB  - In recent years, Artificial Intelligence (AI) has developed advanced healthcare diagnostics by generating rapid growth and accurate disease detection. However, traditional approaches faced challenges like model interpretability, data security. To overcome these issues, hybrid approach Residual Network-50 with Federated Learning namely (ResNet-50-FL) is proposed for AI powered healthcare diagnostics. Initially, data is collected from ChestX-ray14 dataset which consists of over 100,000 frontal-view chest X-ray images annotated with 14 disease labels. Next, preprocessing is done by using image normalization and augmentation for medical images to improve the generalization of models. Then, feature selection is done by using Recursive Feature Elimination (RFE) were used to identify the most relevant predictors of patient outcomes. Finally, healthcare diagnostics is done by using proposed ResNet-50-FL to secure the patient raw data. From the results, the proposed ResNet-50-FL model attained better outcomes compared to existing ResNet-50 in terms of Accuracy, Sensitivity, Specificity, and Area Under the Receiver Operating Characteristic curve (AUC-ROC) by achieving 95.02%, 97.31%, 96.76% and 0.98% respectively.
ER  - 

TY  - CONF
TI  - Multiple Lung Disease Classification Using Fine Tuned Transfer Learning: An Explainable AI Approach
T2  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
SP  - 1982
EP  - 1986
AU  - J. KN
AU  - R. Parameswari
PY  - 2025
KW  - COVID-19
KW  - Pneumonia
KW  - Tuberculosis
KW  - Explainable AI
KW  - Computational modeling
KW  - Transfer learning
KW  - Medical services
KW  - Fatigue
KW  - Stakeholders
KW  - Residual neural networks
KW  - Transfer Learning
KW  - Machine Learning
KW  - LIME
KW  - InceptionV3
KW  - DenseNet 201
KW  - LeNet
DO  - 10.1109/ICIRCA65293.2025.11089917
JO  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)
Y1  - 25-27 June 2025
AB  - Multiple Lung Disease Classification is an important problem for health care stakeholders. Tuberculosis, COVID-19, and Pneumonia are found to be severe lung diseases. All these diseases commonly have many symptoms like cough, fever, fatigue, and other breathing difficulties. Hence, a healthcare practitioner finds it very challenging to identify which lung disease the patient belongs to. Hence, it is important to develop a Machine Learning (ML) for classifying an X Ray image into 3 categories namely Tuberculosis, COVID 19, and Pneumonia. So, we developed a ML model consists of transfer learning using pre-trained Residual Networks (Res Net) classifier, reported with a Balanced Classification Accuracy (BCA) of 98.2 %, precision and recall of 98.3 %, F1 Score of 0.98. We compared the proposed method with that of other transfer learning methods such as InceptionV3, DenseNet 201, and LeNet using BCA and F1 Score. Then, we applied Local Interpretable Model-Agnostic Explanations (LIME) based explainability to the developed model for gaining a better understanding of the developed model.
ER  - 

TY  - JOUR
TI  - Enhancing Pneumonia Diagnosis Through AI Interpretability: Comparative Analysis of Pixel-Level Interpretability and Grad-CAM on X-ray Imaging With VGG19
T2  - IEEE Open Journal of the Computer Society
SP  - 1155
EP  - 1165
AU  - M. Ennab
AU  - H. Mcheick
PY  - 2025
KW  - Pneumonia
KW  - X-ray imaging
KW  - Artificial intelligence
KW  - Accuracy
KW  - Heating systems
KW  - Training
KW  - Medical services
KW  - Visualization
KW  - Predictive models
KW  - Medical diagnostic imaging
KW  - AI interpretability
KW  - deep learning
KW  - grad-CAM
KW  - machine learning
KW  - medical imaging
KW  - PLI
KW  - pneumonia
KW  - VGG19
DO  - 10.1109/OJCS.2025.3582726
JO  - IEEE Open Journal of the Computer Society
IS  - 
SN  - 2644-1268
VO  - 6
VL  - 6
JA  - IEEE Open Journal of the Computer Society
Y1  - 2025
AB  - Pneumonia is a leading cause of morbidity and mortality worldwide, necessitating timely and precise diagnosis for effective treatment. Chest X-rays are the primary diagnostic tool, but their interpretation demands substantial expertise. Recent advancements in AI have shown promise in enhancing pneumonia detection from X-ray images, yet the opacity of deep learning models raises concerns about their clinical adoption. Interpretability in AI models is vital for fostering trust among healthcare professionals by providing transparency in decision-making processes. This study conducts a comparative analysis of two interpretability methods, Pixel Level Interpretability (PLI) and Gradient-weighted Class Activation Mapping (Grad-CAM), in the context of pneumonia classification using VGG19 on X-ray datasets. The research includes an experiment involving three distinct X-ray datasets. VGG19 is applied to classify a query image, and both PLI and Grad-CAM are used to interpret the classification decisions. The study evaluates these interpretability methods across multiple dimensions: computational efficiency, diagnostic performance, explanation continuity, calibration accuracy, robustness to training parameters, and feedback from medical experts. Our findings aim to determine which interpretability technique offers a more clinically meaningful explanation, balancing computational feasibility and diagnostic reliability. This study contributes to the development of explainable AI in healthcare, supporting the integration of trustworthy AI systems in clinical environments for enhanced pneumonia diagnosis.
ER  - 

TY  - CONF
TI  - Predicting Medical Costs Using Machine Learning: A Data-Driven Approach
T2  - 2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)
SP  - 1507
EP  - 1512
AU  - A. Pradhan
AU  - U. Soni
PY  - 2025
KW  - Analytical models
KW  - Costs
KW  - Accuracy
KW  - Medical services
KW  - Predictive models
KW  - Data models
KW  - Polynomials
KW  - Security
KW  - Public healthcare
KW  - Random forests
KW  - Machine Learning
KW  - Private Healthcare
KW  - Financial Transparency
DO  - 10.1109/ICCSAI64074.2025.11064656
JO  - 2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)
IS  - 
SN  - 
VO  - 3
VL  - 3
JA  - 2025 3rd International Conference on Communication, Security, and Artificial Intelligence (ICCSAI)
Y1  - 4-6 April 2025
AB  - The UK is currently seeing rapid growth in private healthcare services. This growth is complemented by increased demand for private healthcare as well, as per The Guardian, consumer expenditure on private healthcare ranges from 3,200 pounds to 15, 075 pounds [1]. Granted that this growth in private healthcare can benefit the increasing demand and supply, these private medical practitioners must maintain financial transparency between their patients. Private medical services are deemed to be significantly costlier than public healthcare, which is why to assure the patient that private institutes are not exploiting consumer expenditure on healthcare, they must provide the patient with an estimated total cost of the medical service beforehand. Subsequently, patients can decide based on the urgency of their medical situation when and where to get treated. The prediction of the total cost of a medical service can be done by analyzing the data of a patient's medical history. Given that the prediction of the total cost requires the analysis and processing of data, it can be argued that the most efficient method of prediction would be via a machine learning model. Hence, this paper will compare the performance of a ridge regression machine learning model, the polynomial regression model, and a random forest regressor. The dataset used for this comparison is constant for both models and was taken from Kaggle. To measure the accuracy of the two models for their comparison, they will be tested based on their accuracy, mean absolute error, and root mean squared error to compare the results of the two models. After analyzing the data collected, this paper concluded that the best performing model was the random forest regressor with the highest accuracy of 87.5%. These reports suggest that machine learning models could be the solution to financial transparency in private medical institutes, and the utilization of a random forest regressor for this task seems to be the best fit.
ER  - 

TY  - CONF
TI  - Early Detection of Chronic Diseases Using Machine and Deep Learning Algorithms
T2  - 2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)
SP  - 1656
EP  - 1661
AU  - B. Fulkar
AU  - T. Dhale
AU  - U. Pacharaney
AU  - S. Deshmukh
PY  - 2025
KW  - Deep learning
KW  - Accuracy
KW  - Machine learning algorithms
KW  - Medical services
KW  - Feature extraction
KW  - Classification algorithms
KW  - History
KW  - Convolutional neural networks
KW  - Diseases
KW  - Biomedical imaging
KW  - Deep Learning
KW  - Convolutional Neural Networks
KW  - Recurrent Neural Networks
KW  - Transfer Learning
KW  - Ensemble Methods
KW  - Attention Mechanisms
KW  - Explainable AI
KW  - Healthcare
KW  - Medical Imaging
DO  - 10.1109/ICSADL65848.2025.10933005
JO  - 2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)
Y1  - 18-20 Feb. 2025
AB  - Today's persons suffer from a wide variety of diseases due to various influences and choices made at the community level. Thus, to prevent the occurrence of such illnesses persistent identification and prediction are paramount. Manually determining the disorders is generally challenging for the doctors to be accurate with the exact numbers. The objective of this study is thus to use these chronic conditions and an accompanying test to select people who will be predominantly affected by these diseases. This might be done by making certain that this categorization correctly singles out people with chronic diseases employing the most advanced data learning technique. Another tough issue is a prediction concerning health conditions. It can therefore be concluded that data mining is an important component of sickness prediction. Employing automatic feature extraction and disease prediction by CNN, distance computation employing KNN for identification of the closest match or data within the data set, and the last disease prognosis of a broad disease, the proposed system enables the determination of patient's symptoms. The patient's life history, medical history of consultations, and illness symptoms were used to construct the data client set. It is on this comprehensive sickness prediction that all of these details were considered. The above said method is compared with logistic regression, Decision tree and Naive Bayes in the conclusion part of the paper.
ER  - 

TY  - CONF
TI  - Ethical Challenges and Bias in Real-World AI: A Fairness-Oriented Approach to Resume Screening Systems
T2  - 2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)
SP  - 674
EP  - 681
AU  - S. Ponmalar
AU  - K. Naveen Kumar
AU  - R. V. Balaji
AU  - T. Rohith
AU  - A. K. Naren Kaarthick
PY  - 2025
KW  - Industries
KW  - Ethics
KW  - Machine learning algorithms
KW  - Explainable AI
KW  - Law
KW  - Prevention and mitigation
KW  - Pressing
KW  - Oral communication
KW  - Medical services
KW  - Artificial intelligence
KW  - Artificial Intelligence (AI)
KW  - Machine Learning (ML)
KW  - Algorithmic Fairness
KW  - Explainable AI (XAI)
KW  - Bias Mitigation
KW  - Resume Screening Systems
KW  - Ethical AI Policies
DO  - 10.1109/ICAISS61471.2025.11042179
JO  - 2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)
Y1  - 21-23 May 2025
AB  - Artificial Intelligence (AI) is rapidly integrating into decision-making across fields like finance, healthcare, and criminal justice. However, its widespread use brings ethical challenges, especially the potential for bias in AI algorithms. This paper examines these ethical concerns, emphasizing three main types of bias: data bias, algorithmic bias, and interaction biasThrough real-world case studies, including biased facial recognition systems, hiring algorithms, and criminal justice AI tools, this paper highlights the far-reaching societal impact of these biases. These case studies demonstrate how bias in AI systems can result in unequal access to resources, unjust treatment in legal systems, and perpetuation of stereotypes in employment practices. This paper highlights the pressing need for robust strategies to address the ethical risks associated with AI. It delves into established frameworks such as Ethically Aligned AI, the EU Guidelines on Trustworthy AI, and the Toronto Declaration, offering essential principles for creating AI systems that prioritize fairness, transparency, and accountability. By evaluating current applications across different industries, this paper proposes actionable solutions to reduce bias in AI systems and also a sample model has been developed to represent how the system has to be under ethics and including enhancing data diversity and implementing robust governance mechanisms to ensure ethical oversight in resume screening processThis research seeks to advance the conversation on ethical AI by emphasizing fairness, equity, and the social good, ensuring that AI technologies are developed to benefit all communities equally.
ER  - 

TY  - CONF
TI  - A Novel AI System for Trustworthy and Accurate Diagnostics and Troubleshooting
T2  - 2025 IEEE Integrated STEM Education Conference (ISEC)
SP  - 1
EP  - 6
AU  - M. Z. Li
PY  - 2025
KW  - Flowcharts
KW  - Accuracy
KW  - Explainable AI
KW  - Computational modeling
KW  - Decision making
KW  - Maintenance
KW  - Medical diagnosis
KW  - Logic
KW  - Time factors
KW  - Engines
KW  - - Artificial intelligence
KW  - large-language models
KW  - diagnostics
KW  - troubleshooting
KW  - AI agent
DO  - 10.1109/ISEC64801.2025.11147314
JO  - 2025 IEEE Integrated STEM Education Conference (ISEC)
IS  - 
SN  - 2473-7623
VO  - 
VL  - 
JA  - 2025 IEEE Integrated STEM Education Conference (ISEC)
Y1  - 15-15 March 2025
AB  - The emergence of large-language models (LLMs) in everyday applications has highlighted their capability to provide human-like dialog and answer complex questions. However, LLMs often exhibit a tendency to "hallucinate," generating responses that appear factual but are incorrect, even when trained on ground truth data. In high-stakes applications such as medical diagnostics and mechanical troubleshooting, the need for accurate, trustworthy, and explainable AI systems is paramount. Without these qualities, such systems cannot be fully relied upon for critical decision-making. In this paper, we propose a novel AI system designed to address these challenges. The system integrates an AI agent, a logic model, an LLM, and a prompt engine to enhance accuracy and trustworthiness in a sequence of dialog. Experimental results demonstrate that the proposed system achieves an average accuracy of 86.49% across three diagnostic and troubleshooting tasks in healthcare, automotive maintenance, and digital equipment applications. In contrast, the baseline LLM only approach achieves an average accuracy of 63.42%, representing an absolute accuracy improvement of 23.07% with our approach. Additionally, the proposed system achieves a 4.26-fold speedup in response time across the experiments. These results highlight the potential of the proposed system to enhance reliability and efficiency in critical real-world applications.
ER  - 

TY  - CHAP
TI  - AI Integration in Healthcare Systems &#x2014; A Review of the Problems and Potential Associated with Integrating AI in Healthcare for Disease Detection and Diagnosis
T2  - AI in Disease Detection: Advancements and Applications
SP  - 191
EP  - 213
AU  - Praveen Kumar Malik
AU  - Hitesh Bhatt
AU  - Madhuri Sharma
PY  - 2025
KW  - Medical services
KW  - Artificial intelligence
KW  - Ethics
KW  - Collaboration
KW  - Technological innovation
KW  - Accuracy
KW  - Predictive models
KW  - Deep learning
KW  - Skin cancer
KW  - Interoperability
DO  - 10.1002/9781394278695.ch9
PB  - IEEE
SN  - 9781394278688
UR  - http://ieeexplore.ieee.org/document/10834102
AB  - Summary <p>Artificial intelligence has emerged as a groundbreaking tool in clutter location, offering up&#x2010;to&#x2010;date strategies to enhance demonstrative accuracy, interpretability, and fairness in healthcare. This chapter explores new approaches that include generative adversarial networks, attention tools, causal induction techniques, and integrated thinking for improving performance and reliability in AI&#x2010;driven disease detection. It proposes a massive reduction in demonstrative errors using the blending of GANs to synthesize diverse reality tests to alleviate predispositions and enhance show generalization. At this level, consideration instruments underline striking capabilities inside clinical snapshots or influenced individual measurements, hence upgrading interpretability and dependability. Strategies of causal induction portray clutter components associated with clarified customized cure procedures. Unified learning makes differential forms of collaborative tutoring indeed as holding records for privacy and regulatory compliance. Future studies should focus on hybrid models, ethical recommendations, flexibility, and integration with emerging technology to unlock the full potential of AI in transforming healthcare transportation.</p>
ER  - 

TY  - CHAP
TI  - The Future of AI in Disease Detection &#x2014; A Look at Emerging Trends and Future Directions in the Use of AI for Disease Detection and Diagnosis
T2  - AI in Disease Detection: Advancements and Applications
SP  - 265
EP  - 288
AU  - Binboga Siddik Yarman
AU  - Saurabh Pratap Singh Rathore
PY  - 2025
KW  - Artificial intelligence
KW  - Diseases
KW  - Medical services
KW  - Ethics
KW  - Reviews
KW  - Federated learning
KW  - Deep learning
KW  - Transfer learning
KW  - Training
KW  - Medical diagnostic imaging
DO  - 10.1002/9781394278695.ch12
PB  - IEEE
SN  - 9781394278688
UR  - http://ieeexplore.ieee.org/document/10833952
AB  - Summary <p>The combination of ensemble studying with explainable artificial intelligence (XAI) strategies represents a transformative approach to revolutionize AI&#x2010;driven disease detection in healthcare. This modern methodology targets to enhance the interpretability, robustness, and clinical relevance of AI models with the aid of leveraging the collective intelligence of numerous algorithms and providing obvious insights into the selection&#x2010;making process. Via rigorous evaluation and evaluation, this chapter looks at demonstrates the capacity of the included approach to empower clinicians with actionable insights and foster collaborative choice&#x2010;making with patients.</p> <p>The outcomes underscore the promising impact of the proposed technique, with ensemble models augmented with XAI factors showing advanced performance as compared to standalone models. Technical improvements encompass progressed predictive accuracy, resilience in opposition to adversarial assaults, and interpretability of AI&#x2010;generated predictions. Furthermore, the combination of XAI strategies allows seamless collaboration among AI structures and human professionals, fostering agree with and transparency in AI&#x2010;driven predictions.</p> <p>Looking ahead, the destiny scope of research on this domain is substantial and multifaceted, with several promising avenues for similarly exploration and innovation. Future research endeavors must prioritize the improvement of hybrid AI architectures, addressing moral, prison, and societal implications, and leveraging rising technologies inclusive of internet of medical things (IoMT), blockchain, and augmented reality (AR). With the aid of harnessing the synergies between ensemble getting to know, XAI, and rising technologies, researchers can pave the way for a future where AI&#x2010;driven diagnostic equipment empower clinicians, engage patients, and rework healthcare shipping for the betterment of society.</p>
ER  - 

TY  - CONF
TI  - Enhancing early-stage diabetes prediction with Explainable Artificial Intelligence(XAI)
T2  - 2025 International Conference on Ambient Intelligence in Health Care (ICAIHC)
SP  - 1
EP  - 6
AU  - R. Alam
AU  - M. Atif
AU  - N. Ahmad
AU  - T. V. Kalal
AU  - A. Khune
PY  - 2025
KW  - Analytical models
KW  - Explainable AI
KW  - Medical services
KW  - Predictive models
KW  - Diabetes
KW  - Complexity theory
KW  - Reliability
KW  - Forecasting
KW  - Medical diagnostic imaging
KW  - Random forests
KW  - Diabetes prediction
KW  - Machine learning
KW  - SHAP
KW  - explainable AI
DO  - 10.1109/ICAIHC64101.2025.10957089
JO  - 2025 International Conference on Ambient Intelligence in Health Care (ICAIHC)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Ambient Intelligence in Health Care (ICAIHC)
Y1  - 10-11 Jan. 2025
AB  - This research explores predicting diabetes at an early stage using Explainable Artificial Intelligence (XAI) models. Precise forecasting is essential in diabetes prediction. XAI bridges complex models and practical insights. Machine learning models are applied for early-stage diabetes prediction based on personal health features. To make models easier to understand, we used a powerful technique called SHAP values, which reveals why models make certain predictions. This unlocks the decision-making process, showing how each feature influences predictions. Simple models like decision trees are naturally understandable, while complex models like Random Forest benefit from SHAP values to make them explainable. Analyzing these values not only identifies key features but also helps assess the fairness and reliability of models. The study emphasizes the trade-off between model complexity and transparency. It highlights the importance of explainability in diabetes prediction models and shows how SHAP values effectively unravel the mysteries of complex AI. As healthcare leans more on AI, this research aids in selecting better models and promoting reliable and transparent medical AI applications. By demystifying predictive models, it advances the discussion on reliable and effective AI use in crucial healthcare situations.
ER  - 

TY  - CONF
TI  - Explainable AI for CVD Risk Prediction: An Ensemble Learning Approach with Clinical Interpretability
T2  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
SP  - 1036
EP  - 1043
AU  - J. Boobalan
AU  - L. Kiruthika
PY  - 2025
KW  - Protocols
KW  - Accuracy
KW  - Explainable AI
KW  - Pipelines
KW  - Medical services
KW  - Prediction algorithms
KW  - Feature extraction
KW  - Polynomials
KW  - Ensemble learning
KW  - Cardiovascular diseases
KW  - Cardiovascular disease prediction
KW  - Explainable AI
KW  - Ensemble learning
KW  - Clinical decision support
KW  - Healthcare analytics
DO  - 10.1109/ICSCDS65426.2025.11167113
JO  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)
Y1  - 6-8 Aug. 2025
AB  - This research created and tested an enhanced machine learning system for predicting cardiovascular risk, tackling three key data challenges: handling missing values, selecting relevant features, and managing imbalanced classes. The approach combined automatic data cleaning (using median/mode replacement), SMOTE for balancing classes, XG Boost-based feature selection, and polynomial features to model complex patterns. Four algorithms were assessed - optimized XG Boost, Random Forest, simplified Decision Tree, and a combined voting model - using 918 patient records. The ensemble method showed the best results (87.5% correct predictions, 0.92 AUC score), effectively identifying at-risk patients. Notable advancements were: (1) merging medical expertise with algorithmic feature selection, (2) boosting minority class detection by 22% using SMOTE with ensemble methods, and (3) creating standardized risk assessment aligned with medical protocols. The pipeline bridges critical gaps in CVD prediction by combining high accuracy with clinician-friendly explainability, offering a deployable tool for risk stratification.
ER  - 

TY  - CONF
TI  - Empowering Eye Health Diagnosis Through Image Analysis and Explainable AI
T2  - 2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)
SP  - 712
EP  - 717
AU  - A. P. S V
AU  - A. J
PY  - 2025
KW  - Deep learning
KW  - Glaucoma
KW  - Visualization
KW  - Diabetic retinopathy
KW  - Explainable AI
KW  - Medical services
KW  - Predictive models
KW  - Retina
KW  - Real-time systems
KW  - Medical diagnostic imaging
KW  - Eye disease detection
KW  - machine learning
KW  - explainable AI
KW  - convolutional neural networks
KW  - LIME
KW  - medical report generation
KW  - image classification
KW  - deep learning
KW  - eye health monitoring
DO  - 10.1109/ICDICI66477.2025.11134978
JO  - 2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 6th International Conference on Data Intelligence and Cognitive Informatics (ICDICI)
Y1  - 9-11 July 2025
AB  - Eye conditions such as diabetic retinopathy, cataracts, glaucoma, and myopia can cause irreversible vision loss. There is a rising opportunity to create automated, and scalable diagnostic tools as deep learning techniques and retinal imaging become more widely available. The proposed development builds an allencompassing diagnostic station for eye health through which explainable AI enhances the precise identification of different diseases while making deep learning models more understandable to users. Deep CNNs comprising DenseNet169, EfficientNetB0, InceptionV3, ResNet50, VGG16, and VGG19 weigthty systems to operate on retinal images enable multiple eye disease diagnosis such as myopia, cataract and glaucoma and diabetic retinopathy. A Local Interpretable Model-Agnostic Explanations (LIME) system uses visual explanations to show how major image componets affect model prediction results. The interface developed from Streamlit enables users to submit images instantly for predictions resulting in individual medical reports which include prevention measures. The model combines effective deep learning capabilities with explainable practices to deliver enhanced healthcare diagnosis support as well as eye health surveillance tools to users. Healthcare professionals understand and trust the model functionality because explainable AI integrations are included in its system. The technology enables widespread population coverage while enhancing accessible and efficient and reliable systems that provide eye health diagnosis services.
ER  - 

TY  - CONF
TI  - Advances in AI for Women's Healthcare: A Review of Deep Learning and NLP Approaches
T2  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
SP  - 289
EP  - 294
AU  - J. Choudhary
AU  - M. Thakur
PY  - 2025
KW  - Deep learning
KW  - Technological innovation
KW  - Reviews
KW  - Mortality
KW  - Medical services
KW  - Natural language processing
KW  - Internet of Things
KW  - Artificial intelligence
KW  - Medical diagnostic imaging
KW  - Gender issues
KW  - Women's Healthcare
KW  - Deep Learning
KW  - Natural Language Processing (NLP)
KW  - Maternal health
KW  - Artificial Intelligence (AI)
DO  - 10.1109/IDCIOT64235.2025.10915173
JO  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
Y1  - 5-7 Feb. 2025
AB  - Women's health faces critical challenges, particularly in maternal and reproductive healthcare, where complications significantly contribute to global mortality rates. Despite advancements in medical science, inequities in healthcare access and diagnosis persist, especially in underserved regions. Innovative approaches leveraging artificial intelligence (AI) technologies, such as deep learning (DL) and natural language processing (NLP), are transforming healthcare by enabling early diagnosis, personalized treatment, and scalable preventive care. This paper evaluates the transformative role of these AI-driven methods in addressing critical women's health issues, including cancer detection, maternal health, and reproductive disorders, with a focus on advancements from 2018 to 2023. These years represent a period of rapid AI evolution and its integration into healthcare systems. The present study captures important challenges like restricted diversity of datasets, issues concerning transparency in models, and obstacles in actual deployment. It collates findings to give a global perspective of AI development in women's health. It is also prepared with practical future action steps for its research to lead AI-influenced innovations shaping the future of women's healthcare.
ER  - 

TY  - CONF
TI  - Enhanced Tuberculosis Detection Using Deep Learning and GAN Data Augmentation Techniques for Chest x-Ray Analysis
T2  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
SP  - 1171
EP  - 1178
AU  - V. R. Chaykam
AU  - A. R. Koduru
AU  - K. S
AU  - C. Arun
PY  - 2025
KW  - Deep learning
KW  - Accuracy
KW  - Tuberculosis
KW  - Explainable AI
KW  - Generative adversarial networks
KW  - Data models
KW  - Convolutional neural networks
KW  - Reliability
KW  - X-ray imaging
KW  - Biomedical imaging
KW  - Tuberculosis
KW  - Machine Learning
KW  - Deep Learning
KW  - Transfer Learning
KW  - Hog Features
KW  - Explainable AI
KW  - CNN
KW  - DCGAN
DO  - 10.1109/IDCIOT64235.2025.10914765
JO  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 3rd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)
Y1  - 5-7 Feb. 2025
AB  - With around 1.6 million deaths yearly, primarily in low-resource environments, abstract-tuberculosis (TB) is a serious worldwide health issue. While human analysis can be error-prone and labor-intensive, early discovery using chest X-rays is vital. We used advanced machine learning methods including a mix of Histogram of Oriented Gradients (HOG) and Convolutional Neural Networks (CNN), alongside Deep Convolutional Generative Adversarial Networks (DCGANs) to create synthetic TB images, so helping to balance the dataset and reduce class imbalance. We applied explainable artificial intelligence (XAI) methods including LIME and Grad-CAM for greater interpretability in order to improve model transparency. The outcomes showed notable progress; our hybrid model obtained a stunning 99.5% diagnosis accuracy. With respective accuracy of 96.87% and 94.67%, models such as Xception and MobileNetV2 also fared rather well. Especially in resource-limited healthcare settings, this study provides a consistent and interpretable strategy for tuberculosis screening.
ER  - 

TY  - CONF
TI  - Decoding Tumor Gene Expression for Multiclass Cancer Classification
T2  - 2025 International Conference on Electronics and Renewable Systems (ICEARS)
SP  - 1666
EP  - 1670
AU  - V. Jyothi
AU  - M. Srujana
AU  - Y. Himasreeja
AU  - S. S. Sanjana
AU  - B. Fatima
PY  - 2025
KW  - Sequential analysis
KW  - Renewable energy sources
KW  - Reviews
KW  - Soft sensors
KW  - Genomics
KW  - Feature extraction
KW  - Reliability
KW  - Bioinformatics
KW  - Cancer
KW  - Tumors
KW  - Cancer classification
KW  - Gene-expression data
KW  - Machine learning
KW  - Personalized medicine
KW  - Early diagnosis
KW  - poorly differentiated tumors
DO  - 10.1109/ICEARS64219.2025.10941486
JO  - 2025 International Conference on Electronics and Renewable Systems (ICEARS)
IS  - 
SN  - 
VO  - 
VL  - 
JA  - 2025 International Conference on Electronics and Renewable Systems (ICEARS)
Y1  - 11-13 Feb. 2025
AB  - Cancer, a multifactorial and complex disease, is caused by genetic mutations and environmental influences leading to uncontrolled cell proliferation and the possibility of tumor spread. Recent developments in genomic analysis with the use of next-generation sequencing technologies like Whole Genome Sequencing (WGS) and Whole Exome Sequencing (WES) have greatly enhanced detection and classification of cancer. Machine learning (ML) has become a useful tool in the diagnosis of cancer, providing better accuracy in the classification of cancer types from high-level genomic and histopathological information. The following is a review of the existing machine learning methods used in cancer classification, comprising deep learning (DL) techniques, and addresses some of the major challenges like data imbalance, feature selection, and model interpretability. The paper also points towards the possibility of combining multi-modal data sources, federated learning, and explainable AI (XAI) to further improve cancer classification systems. In addition, the solution proposed in this review describes a machine learning-based framework for cancer classification, involving different ML algorithms, cross-validation methods, and sophisticated feature selection techniques for robust and reliable results.
ER  - 

